{
  "name": "augmented-reality",
  "messages": [
    {
      "type": "message",
      "user": "U03V30M0C1K",
      "text": "This content can't be displayed.",
      "ts": "1665433341.662519",
      "pinned_to": [
        "C0432FLR8G4"
      ],
      "team": "T03U5MWB2FN",
      "reactions": [
        {
          "name": "heart",
          "count": 14,
          "users": [
            "U045QMYCL79",
            "U046T0X1Z88",
            "U045WLS7EF8",
            "U045Z8Z4RTP",
            "U045Y9S46H4",
            "U04648FJDCJ",
            "U046FDK78BC",
            "U04662TK7KR",
            "U047D8MBQSU",
            "U0467SUHX0U",
            "U0462EM0ZS9",
            "U046PQWQMLM",
            "U045VNN3MPY",
            "U045X13QYNA"
          ]
        },
        {
          "name": "+1",
          "count": 9,
          "users": [
            "U046USA0WHW",
            "U046E6ZLWS0",
            "U04642CBK8A",
            "U046FDK78BC",
            "U046KTBCMRA",
            "U047CGGFCU8",
            "U047D8MBQSU",
            "U046TV7E9S7",
            "U045VNN3MPY"
          ]
        },
        {
          "name": "eyeglasses",
          "count": 3,
          "users": [
            "U047CGGFCU8",
            "U045VNN3MPY",
            "U045X13QYNA"
          ]
        },
        {
          "name": "heavy_check_mark",
          "count": 2,
          "users": [
            "U0461B02TPX",
            "U045VJUSVCN"
          ]
        },
        {
          "name": "thumbsup_all",
          "count": 2,
          "users": [
            "U046FG0DA4E",
            "U0473FN9GMP"
          ]
        },
        {
          "name": "goggles",
          "count": 1,
          "users": [
            "U045VNN3MPY"
          ]
        },
        {
          "name": "superhero",
          "count": 1,
          "users": [
            "U045VNN3MPY"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "header",
          "text": {
            "type": "plain_text",
            "text": "Welcome to Ask Apple",
            "emoji": true
          },
          "block_id": "DIG"
        },
        {
          "type": "section",
          "text": {
            "type": "mrkdwn",
            "text": "We're excited to be hosting you in the Augmented Reality channel this week! You can find the full schedule of Q\u0026amp;As for Augmented Reality by visiting the \u003chttps://apps.apple.com/us/app/apple-developer/id640199958 | Apple Developer app\u003e and \u003chttps://developer.apple.com/events/ask-apple/questions-and-answers/ | website\u003e."
          },
          "block_id": "zos"
        },
        {
          "type": "section",
          "text": {
            "type": "mrkdwn",
            "text": "If you haven’t already, please take a moment to familiarize yourself with \u003chttps://developer.apple.com/news/?id=vpbyzfg4 | how Q\u0026amp;As will work\u003e."
          },
          "block_id": "uTOG="
        },
        {
          "type": "header",
          "text": {
            "type": "plain_text",
            "text": "Attendance Policy",
            "emoji": true
          },
          "block_id": "Ikc"
        },
        {
          "type": "section",
          "text": {
            "type": "mrkdwn",
            "text": "We want to make sure these spaces are helpful and welcoming for everyone — developers and Apple employees alike. Please review and follow the \u003chttps://developer.apple.com/events/policy/online-event-attendance-policy/ | attendance policy\u003e."
          },
          "block_id": "yueO"
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03V30M0C1K\u003e added a workflow to this channel: *Ask Apple - augmented-reality*.",
      "ts": "1666018807.516839",
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "m/CP",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03V30M0C1K"
                },
                {
                  "type": "text",
                  "text": " added a workflow to this channel: "
                },
                {
                  "type": "text",
                  "text": "Ask Apple - augmented-reality",
                  "style": {
                    "bold": true
                  }
                },
                {
                  "type": "text",
                  "text": "."
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "8dfbc6f1-91f0-4599-a564-583c38d45e46",
      "type": "message",
      "user": "U0449H175SA",
      "text": "Hello and welcome again to the Augmented Reality channel. Our first activity is Q\u0026amp;A: ARKit, kicking off at 10_:00am PT Tuesday_. We hope you can join us! If you’re unable to tune-in live, you can begin sending in your questions that are related to Q\u0026amp;A: ARKit now. Select the:heavy_plus_sign:icon from the lower left, and find the _Ask A Question_ workflow. Type in your question and it will be delivered directly to our team. We’ll answer as many questions as we can during the 60 minute event on Tuesday.\n\nOur second activity, Q\u0026amp;A: RoomPlan will take place at _10:00am PT Thursday_. Please wait to submit your questions for that event until Q\u0026amp;A on ARKit has concluded. Scoping your questions to the upcoming Q\u0026amp;A activity will help us answer more questions efficiently! Thank you for understanding!",
      "ts": "1666028981.549699",
      "team": "T03U5MWB2FN",
      "reactions": [
        {
          "name": "tada",
          "count": 9,
          "users": [
            "U03V30M0C1K",
            "U04631JRW83",
            "U045VNN3MPY",
            "U046UTP0656",
            "U046USA0WHW",
            "U04645Q6KNE",
            "U044WJQ0YF8",
            "U046SQ8RLDN",
            "U04662TK7KR"
          ]
        },
        {
          "name": "swift-blue",
          "count": 6,
          "users": [
            "U045Z8Z4RTP",
            "U04631JRW83",
            "U045VNN3MPY",
            "U04645Q6KNE",
            "U04678YRK98",
            "U0464NQUV52"
          ]
        },
        {
          "name": "white_check_mark",
          "count": 1,
          "users": [
            "U04645Q6KNE"
          ]
        },
        {
          "name": "wave",
          "count": 1,
          "users": [
            "U046H38LPLZ"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "V98l8",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Hello and welcome again to the Augmented Reality channel. Our first activity is Q\u0026A: ARKit, kicking off at 10"
                },
                {
                  "type": "text",
                  "text": ":00am PT Tuesday",
                  "style": {
                    "italic": true
                  }
                },
                {
                  "type": "text",
                  "text": ". We hope you can join us! If you’re unable to tune-in live, you can begin sending in your questions that are related to Q\u0026A: ARKit now. Select the"
                },
                {
                  "type": "emoji",
                  "name": "heavy_plus_sign",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": "icon from the lower left, and find the "
                },
                {
                  "type": "text",
                  "text": "Ask A Question",
                  "style": {
                    "italic": true
                  }
                },
                {
                  "type": "text",
                  "text": " workflow. Type in your question and it will be delivered directly to our team. We’ll answer as many questions as we can during the 60 minute event on Tuesday.\n\nOur second activity, Q\u0026A: RoomPlan will take place at "
                },
                {
                  "type": "text",
                  "text": "10:00am PT Thursday",
                  "style": {
                    "italic": true
                  }
                },
                {
                  "type": "text",
                  "text": ". Please wait to submit your questions for that event until Q\u0026A on ARKit has concluded. Scoping your questions to the upcoming Q\u0026A activity will help us answer more questions efficiently! Thank you for understanding!"
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "9930916e-1963-4b27-8fb6-44e56cf43ac3",
      "type": "message",
      "user": "U0449H175SA",
      "text": "Hello again. We’re just 1 hour away from kicking off our first activity Q\u0026amp;A: ARKit at 9am PT*. We hope you can join us!\n*Our previous post mentioned 10am PT start time, sorry for that.",
      "ts": "1666105367.712579",
      "team": "T03U5MWB2FN",
      "reactions": [
        {
          "name": "flushed",
          "count": 1,
          "users": [
            "U04608QHDBP"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "sahw",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Hello again. We’re just 1 hour away from kicking off our first activity Q\u0026A: ARKit at 9am PT*. We hope you can join us!\n*Our previous post mentioned 10am PT start time, sorry for that."
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "1fccd92f-e001-4e33-a157-257f74e7b492",
      "type": "message",
      "user": "U0449H175SA",
      "text": "Welcome to Q\u0026amp;A: ARKit! We’re looking forward to answering your questions. Select the:heavy_plus_sign:icon from the lower left, and find the _Ask A Question_ workflow. Type in your question and it will be delivered directly to the team. We’ll answer as many questions as we can. While it’s unlikely we’ll be able to address every question, all your submissions are valuable; thank you for taking the time!\n\nLet’s kick it off! :rocket:",
      "ts": "1666108811.248579",
      "team": "T03U5MWB2FN",
      "reactions": [
        {
          "name": "rocket",
          "count": 2,
          "users": [
            "U03V30M0C1K",
            "U046UAH7QJJ"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "eE9F",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Welcome to Q\u0026A: ARKit! We’re looking forward to answering your questions. Select the"
                },
                {
                  "type": "emoji",
                  "name": "heavy_plus_sign",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": "icon from the lower left, and find the "
                },
                {
                  "type": "text",
                  "text": "Ask A Question",
                  "style": {
                    "italic": true
                  }
                },
                {
                  "type": "text",
                  "text": " workflow. Type in your question and it will be delivered directly to the team. We’ll answer as many questions as we can. While it’s unlikely we’ll be able to address every question, all your submissions are valuable; thank you for taking the time!\n\nLet’s kick it off! "
                },
                {
                  "type": "emoji",
                  "name": "rocket",
                  "skin_tone": 0
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046608Q205\u003e asked\n\u0026gt; Hi, I would like to find a way to help my user know an approximate length / width of a simple subject in a photo, accounting for their distance from it.\n\u0026gt; \n\u0026gt; Would that be an appropriate use of ARKit, and if so, do you have advice on where I might start with an example to learn more?  \n\u0026gt; \n\u0026gt; I have an example jpg which I can't seem to post here -- it is just a photo of a letter sized document alongside an \"L-shaped\" physical ruler.  The idea is for my app feature to replace the need for the physical ruler in the photo, such that the user would see the approximate 9x11” size regardless of distance when taking the photo.  \n\u0026gt; \n\u0026gt; Thanks!",
      "ts": "1666108891.954219",
      "thread_ts": "1666108891.954219",
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "reply_count": 3,
      "latest_reply": "1666109126.891709",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "1GdI",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046608Q205"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Hi, I would like to find a way to help my user know an approximate length \\/ width of a simple subject in a photo, accounting for their distance from it.\\n\\nWould that be an appropriate use of ARKit, and if so, do you have advice on where I might start with an example to learn more?  \\n\\nI have an example jpg which I can't seem to post here -- it is just a photo of a letter sized document alongside an \\\"L-shaped\\\" physical ruler.  The idea is for my app feature to replace the need for the physical ruler in the photo, such that the user would see the approximate 9x11\\u201d size regardless of distance when taking the photo.  \\n\\nThanks!\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "8037abdc-746c-4a3a-bdbf-126757e8d200",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "The \u003chttp://Measure.app|Measure.app\u003e shipping with iOS might already do this well enough for most users. Implementing this in your app is certainly doable but not easy. One way to do it would be to first identify the dimensions/corners of the object in 2D image space, then perform a raycast \u003chttps://developer.apple.com/documentation/arkit/arraycastquery\u003e in ARKit to go from 2D screen space to 3D locations of those corners. Distance between those 3D locations is then the approximate size of the object in meters.",
          "ts": "1666109078.631839",
          "thread_ts": "1666108891.954219",
          "edited": {
            "user": "U044WJQ0YF8",
            "ts": "1666109085.000000"
          },
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "LerB",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "The Measure.app shipping with iOS might already do this well enough for most users. Implementing this in your app is certainly doable but not easy. One way to do it would be to first identify the dimensions/corners of the object in 2D image space, then perform a raycast "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/arkit/arraycastquery",
                      "text": ""
                    },
                    {
                      "type": "text",
                      "text": " in ARKit to go from 2D screen space to 3D locations of those corners. Distance between those 3D locations is then the approximate size of the object in meters."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "347bb409-97ae-487c-bc6e-48abea898d4c",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "To detect the dimensions of the object in 2D space you might be able to leverage one of the Vision framework, e.g. `VNDetectRectanglesRequest` could be suitable to detect letters \u003chttps://developer.apple.com/documentation/vision/vndetectrectanglesrequest\u003e",
          "ts": "1666109113.398559",
          "thread_ts": "1666108891.954219",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "CYtv/",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "To detect the dimensions of the object in 2D space you might be able to leverage one of the Vision framework, e.g. "
                    },
                    {
                      "type": "text",
                      "text": "VNDetectRectanglesRequest",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " could be suitable to detect letters "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/vision/vndetectrectanglesrequest",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "0eaff4fc-9ae5-43f6-b10c-bf852b7fd35b",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "Here is a developer sample app which shows how you can combine ARKit + Vision: \u003chttps://developer.apple.com/documentation/arkit/content_anchors/tracking_and_altering_images\u003e",
          "ts": "1666109126.891709",
          "thread_ts": "1666108891.954219",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "eyes",
              "count": 1,
              "users": [
                "U046E6ZLWS0"
              ]
            },
            {
              "name": "+1",
              "count": 3,
              "users": [
                "U046608Q205",
                "U04608QHDBP",
                "U0462EM0ZS9"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "BXR",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Here is a developer sample app which shows how you can combine ARKit + Vision: "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/arkit/content_anchors/tracking_and_altering_images",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U047CGGFCU8\u003e asked\n\u0026gt; We've noticed when using `ARView` with `.occlusion` enabled objects beyond a ~10m/33ft distance disappear. Is this a hard limit or a setting?\n\u0026gt; \n\u0026gt; What's interesting, with the `showSceneUnderstanding` debug option enabled the limitation seems to be gone – objects beyond that distance are visible.",
      "ts": "1666108997.699919",
      "thread_ts": "1666108997.699919",
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "reply_count": 2,
      "latest_reply": "1666110264.005469",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "xdP",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U047CGGFCU8"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"We've noticed when using `ARView` with `.occlusion` enabled objects beyond a ~10m\\/33ft distance disappear. Is this a hard limit or a setting?\\n\\nWhat's interesting, with the `showSceneUnderstanding` debug option enabled the limitation seems to be gone \\u2013 objects beyond that distance are visible.\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "CF19C260-ABBA-4CC5-A545-0FA365FCE26B",
          "type": "message",
          "user": "U0459CTJ09H",
          "text": "Hi! This issue should be resolved in iOS 16. If it is not, please file a bug report on Feedback Assistant.",
          "ts": "1666109043.006999",
          "thread_ts": "1666108997.699919",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "tP9T",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi! This issue should be resolved in iOS 16. If it is not, please file a bug report on Feedback Assistant."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "ffbb6d6a-13b1-4717-8d7e-b02ab8c88a0e",
          "type": "message",
          "user": "U047CGGFCU8",
          "text": "Great, thanks Michael :+1:",
          "ts": "1666110264.005469",
          "thread_ts": "1666108997.699919",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Sie",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Great, thanks Michael "
                    },
                    {
                      "type": "emoji",
                      "name": "thumbsup",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046Q072H09\u003e asked\n\u0026gt; Hi. I would like to build a location based AR experience using ARKit. In general, I would like to place some in door AR objects in shopping malls and user can view the placed AR objects after all. After some investigation of ARKit API documentation, I found that Worldmap is the right way to go. However, in the real world situation, relocation using world map is quite difficult. First, it often cannot relocate the device position in a large scale indoor environment, shopping mall for instance. A long wait relocation process is usually expected. Second, the worldmap is too large, usually will take 20-40 MB in size.\n\u0026gt; \n\u0026gt; So I really want to know if there is any solution/technique for the indoor AR experience using ARKit?",
      "ts": "1666109051.383699",
      "thread_ts": "1666109051.383699",
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "reply_count": 1,
      "latest_reply": "1666109215.180229",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "rsUj",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046Q072H09"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Hi. I would like to build a location based AR experience using ARKit. In general, I would like to place some in door AR objects in shopping malls and user can view the placed AR objects after all. After some investigation of ARKit API documentation, I found that Worldmap is the right way to go. However, in the real world situation, relocation using world map is quite difficult. First, it often cannot relocate the device position in a large scale indoor environment, shopping mall for instance. A long wait relocation process is usually expected. Second, the worldmap is too large, usually will take 20-40 MB in size.\\n\\nSo I really want to know if there is any solution\\/technique for the indoor AR experience using ARKit?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "09a1ba68-69a6-4bf1-9004-f98ed4244ac3",
          "type": "message",
          "user": "U0464NUFLM7",
          "text": "Hi Qiwei! One option would be to try splitting up into multiple smaller `ARWorldMap`  files. You could use another localization mechanism to determine which one to try to load. Another alternative you could investigate is using image detection (such as posters or markers) if it suits your use case. You could then anchor the virtual content relative to the `ARImageAnchor`.",
          "ts": "1666109215.180229",
          "thread_ts": "1666109051.383699",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "UJ/o6",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi Qiwei! One option would be to try splitting up into multiple smaller "
                    },
                    {
                      "type": "text",
                      "text": "ARWorldMap",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "  files. You could use another localization mechanism to determine which one to try to load. Another alternative you could investigate is using image detection (such as posters or markers) if it suits your use case. You could then anchor the virtual content relative to the "
                    },
                    {
                      "type": "text",
                      "text": "ARImageAnchor",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U04645Q6KNE\u003e asked\n\u0026gt; RealityKit , How to play back the recorded video.",
      "ts": "1666109136.827679",
      "thread_ts": "1666109136.827679",
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "reply_count": 2,
      "latest_reply": "1666110338.413339",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "ZsK",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U04645Q6KNE"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"RealityKit , How to play back the recorded video.\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "da230263-6a49-4888-86aa-e3d2343328ba",
          "type": "message",
          "user": "U0449H175SA",
          "text": "Thank you for this question. Can you please clarify if this is related to VideoMaterial support in RealityKit, or are you looking for a different way to playback recorded video?",
          "ts": "1666110198.192859",
          "thread_ts": "1666109136.827679",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "aA/9",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thank you for this question. Can you please clarify if this is related to VideoMaterial support in RealityKit, or are you looking for a different way to playback recorded video?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "c53e2ab5-0f7f-4453-ac55-57222b7588a0",
          "type": "message",
          "user": "U0449H175SA",
          "text": "In case you’re looking for VideoMaterial Support in RealityKit, there is documentation to help you with that: \u003chttps://developer.apple.com/documentation/realitykit/videomaterial\u003e",
          "ts": "1666110338.413339",
          "thread_ts": "1666109136.827679",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "UPs/",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "In case you’re looking for VideoMaterial Support in RealityKit, there is documentation to help you with that: "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/realitykit/videomaterial",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046A4SKZ99\u003e asked\n\u0026gt; The ARKit page (\u003chttps://developer.apple.com/augmented-reality/arkit/)|https://developer.apple.com/augmented-reality/arkit/)\u003e under the heading \"People Occlusion\", says that \"Depth estimation improves on iPhone 12, iPhone 12 Pro, and iPad Pro in all apps built with ARKit, without any code changes.\" However it doesn't appear that ARKit uses the LiDAR scanner for people occlusion. For example, with my iPhone 12 Pro Max, if I build the people occlusion sample (\u003chttps://developer.apple.com/documentation/arkit/camera_lighting_and_effects/effecting_people_occlusion_in_custom_renderers)|https://developer.apple.com/documentation/arkit/camera_lighting_and_effects/effecting_people_occlusion_in_custom_renderers)\u003e and point the camera at a 2D picture of a person, the person in the picture is segmented out, even though it has no physical depth. Is there any way to benefit from the LiDAR Scanner for person segmentation?",
      "ts": "1666109166.478649",
      "thread_ts": "1666109166.478649",
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "reply_count": 4,
      "latest_reply": "1666109995.483009",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "1ja",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046A4SKZ99"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"The ARKit page (\"},{\"type\":\"link\",\"url\":\"https:\\/\\/developer.apple.com\\/augmented-reality\\/arkit\\/)\",\"text\":\"https:\\/\\/developer.apple.com\\/augmented-reality\\/arkit\\/)\"},{\"type\":\"text\",\"text\":\" under the heading \\\"People Occlusion\\\", says that \\\"Depth estimation improves on iPhone 12, iPhone 12 Pro, and iPad Pro in all apps built with ARKit, without any code changes.\\\" However it doesn't appear that ARKit uses the LiDAR scanner for people occlusion. For example, with my iPhone 12 Pro Max, if I build the people occlusion sample (\"},{\"type\":\"link\",\"url\":\"https:\\/\\/developer.apple.com\\/documentation\\/arkit\\/camera_lighting_and_effects\\/effecting_people_occlusion_in_custom_renderers)\",\"text\":\"https:\\/\\/developer.apple.com\\/documentation\\/arkit\\/camera_lighting_and_effects\\/effecting_people_occlusion_in_custom_renderers)\"},{\"type\":\"text\",\"text\":\" and point the camera at a 2D picture of a person, the person in the picture is segmented out, even though it has no physical depth. Is there any way to benefit from the LiDAR Scanner for person segmentation?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "9ab437cc-aecc-4d84-856c-5a4200e91830",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "ARKit is optimized to use the most suitable combination of sensors on all supported devices.",
          "ts": "1666109174.503539",
          "thread_ts": "1666109166.478649",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "//72c",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "ARKit is optimized to use the most suitable combination of sensors on all supported devices."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "cb1cbdb0-3f2a-4429-9670-cf0e66e5e681",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "There is no option for 3rd party developers to force person segmentation to use LIDAR.",
          "ts": "1666109194.200989",
          "thread_ts": "1666109166.478649",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "398RD",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "There is no option for 3rd party developers to force person segmentation to use LIDAR."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "17826326-23db-432a-a527-24f61ebf09d0",
          "type": "message",
          "user": "U046A4SKZ99",
          "text": "Any tips, then, to get better results from person segmentation?",
          "ts": "1666109387.411969",
          "thread_ts": "1666109166.478649",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "zaeGg",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Any tips, then, to get better results from person segmentation?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "1541846e-8ffa-4c63-bebb-6d1fbef1851b",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "Sorry, as far as I am aware there are no tricks to improve the quality of person segmentation. If you encounter issues with person segmentation, I would encourage you to file a bug with us via \u003chttps://developer.apple.com/bug-reporting/\u003e",
          "ts": "1666109995.483009",
          "thread_ts": "1666109166.478649",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U046A4SKZ99"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "J9l",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Sorry, as far as I am aware there are no tricks to improve the quality of person segmentation. If you encounter issues with person segmentation, I would encourage you to file a bug with us via "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/bug-reporting/",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U04617U8AUV\u003e asked\n\u0026gt; Is there any sample code for measuring 3d size without scanning every sides? For example, I have a square/rectangle box in front of me, any easy way I can know the dimensions?",
      "ts": "1666109223.175579",
      "thread_ts": "1666109223.175579",
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "reply_count": 1,
      "latest_reply": "1666109242.091319",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "JJC",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U04617U8AUV"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Is there any sample code for measuring 3d size without scanning every sides? For example, I have a square\\/rectangle box in front of me, any easy way I can know the dimensions?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "9102feae-5aa4-44bb-8d03-77ec0ebfc7dd",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "Unfortuntely, no. In order to determine the size of an arbitrary 3D object users will need to point the camera at all sides of the object. Only if the object is guaranteed to have some symmetry you might be able to exploit that and skip scanning sides that are mirrors of already scanned sides.",
          "ts": "1666109242.091319",
          "thread_ts": "1666109223.175579",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "gO6u",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Unfortuntely, no. In order to determine the size of an arbitrary 3D object users will need to point the camera at all sides of the object. Only if the object is guaranteed to have some symmetry you might be able to exploit that and skip scanning sides that are mirrors of already scanned sides."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046K9AM4T0\u003e asked\n\u0026gt; Is there a way we can identify clutter in space in RealityKit? So that we can hint users if the space to place the object is clear or not",
      "ts": "1666109273.574409",
      "thread_ts": "1666109273.574409",
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "reply_count": 1,
      "latest_reply": "1666109283.501219",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "l52Nx",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046K9AM4T0"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Is there a way we can identify clutter in space in RealityKit? So that we can hint users if the space to place the object is clear or not\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "44c41477-3565-4218-a710-e33efbd776d3",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "This is possible on devices that have a LIDAR scanner. On those devices you can turn on `ARSceneReconstructionMesh` \u003chttps://developer.apple.com/documentation/arkit/arscenereconstruction\u003e to get a detailed mesh of the user’s environment (surfaced via `ARMeshAnchor`). You could then e.g. compare the distance and distribution of vertices compared to a baseline, say a detected horizontal plane, to detect whether a surface is too cluttered / uneven. Here is a developer sample which shows how to work with mesh anchors in ARKit: \u003chttps://developer.apple.com/documentation/arkit/content_anchors/visualizing_and_interacting_with_a_reconstructed_scene?language=objc\u003e",
          "ts": "1666109283.501219",
          "thread_ts": "1666109273.574409",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "+1",
              "count": 2,
              "users": [
                "U045WF1CPQE",
                "U046K9AM4T0"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "YXP1",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "This is possible on devices that have a LIDAR scanner. On those devices you can turn on "
                    },
                    {
                      "type": "text",
                      "text": "ARSceneReconstructionMesh",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/arkit/arscenereconstruction",
                      "text": ""
                    },
                    {
                      "type": "text",
                      "text": " to get a detailed mesh of the user’s environment (surfaced via "
                    },
                    {
                      "type": "text",
                      "text": "ARMeshAnchor",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "). You could then e.g. compare the distance and distribution of vertices compared to a baseline, say a detected horizontal plane, to detect whether a surface is too cluttered / uneven. Here is a developer sample which shows how to work with mesh anchors in ARKit: "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/arkit/content_anchors/visualizing_and_interacting_with_a_reconstructed_scene?language=objc",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U045VNN3MPY\u003e asked\n\u0026gt; Hi, Is it possible to run multiple AR configurations in same ARView? like same app can track and augmente both face, body, hands , walls? if yes is there an example already published?",
      "ts": "1666109292.104669",
      "thread_ts": "1666109292.104669",
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "reply_count": 1,
      "latest_reply": "1666109333.246669",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "YYx7",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U045VNN3MPY"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Hi, Is it possible to run multiple AR configurations in same ARView? like same app can track and augmente both face, body, hands , walls? if yes is there an example already published?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "49cc1ea5-6af6-46b2-9c8c-691dca46d0fc",
          "type": "message",
          "user": "U0464NUFLM7",
          "text": "Hi Hassan! You can only run one configuration at a time, but some of the things you listed work together (for example, `ARBodyTrackingConfiguration` supports plane detection, i.e. you could augment walls). Face tracking only works for the front facing camera. Hand tracking (other than hand joints as part of body tracking) is not supported by ARKit.",
          "ts": "1666109333.246669",
          "thread_ts": "1666109292.104669",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U045VNN3MPY"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "xwgN",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi Hassan! You can only run one configuration at a time, but some of the things you listed work together (for example, "
                    },
                    {
                      "type": "text",
                      "text": "ARBodyTrackingConfiguration",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " supports plane detection, i.e. you could augment walls). Face tracking only works for the front facing camera. Hand tracking (other than hand joints as part of body tracking) is not supported by ARKit."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U04642C9X3L\u003e asked\n\u0026gt; How to calculate the angle between two points based on the word coordinate system in AR?",
      "ts": "1666109376.920069",
      "thread_ts": "1666109376.920069",
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "reply_count": 1,
      "latest_reply": "1666109381.553459",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "fnS7d",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U04642C9X3L"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"How to calculate the angle between two points based on the word coordinate system in AR?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "cac1ab13-880c-461c-80da-5028e4fff1f9",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "If you are referring to the angle between two vectors, you can compute that with the dot product.",
          "ts": "1666109381.553459",
          "thread_ts": "1666109376.920069",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "/62",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "If you are referring to the angle between two vectors, you can compute that with the dot product."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046G1P2R6D\u003e asked\n\u0026gt; How can we keep AR \"stable\" over time? In our app we overlay a map over the current room. We can place and scale the map to line up with the room by tying it to an ARPlaneAnchor. Unfortunately ARKit seems to make adjustments as it learns more about the environment. This can cause our initial anchor to shift. Can ARKit be stopped from improving its view of the world? Can we extend the initialization phase to a point where we can recognized that ARKit has detached enough for a point placed on the floor to remain in place as the user moves around?",
      "ts": "1666109408.016879",
      "thread_ts": "1666109408.016879",
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "reply_count": 14,
      "latest_reply": "1666112317.741189",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "tJiy",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046G1P2R6D"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"How can we keep AR \\\"stable\\\" over time? In our app we overlay a map over the current room. We can place and scale the map to line up with the room by tying it to an ARPlaneAnchor. Unfortunately ARKit seems to make adjustments as it learns more about the environment. This can cause our initial anchor to shift. Can ARKit be stopped from improving its view of the world? Can we extend the initialization phase to a point where we can recognized that ARKit has detached enough for a point placed on the floor to remain in place as the user moves around?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "fd9e597a-e31b-4762-b74e-1f0f8333054f",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "\u0026gt;\u0026gt; Can ARKit be stopped from improving its view of the world?\n You can stop listening to anchor updates, that is: Either ignore changes to the plane anchor coming in, or even better turn off plane detection on your ARConfiguration if you no longer care about updated planes. (edited)",
          "ts": "1666109420.983489",
          "thread_ts": "1666109408.016879",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "i7VPP",
              "elements": [
                {
                  "Type": "rich_text_quote",
                  "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Can ARKit be stopped from improving its view of the world?\"}],\"border\":1}"
                },
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": " You can stop listening to anchor updates, that is: Either ignore changes to the plane anchor coming in, or even better turn off plane detection on your ARConfiguration if you no longer care about updated planes. (edited)"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "7fdff788-8336-4620-87f0-4d337737c934",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "\u0026gt;\u0026gt; Can we extend the initialization phase to a point where we can recognized that ARKit has detached enough for a point placed on the floor to remain in place as the user moves around?\nIn general, we recommend you to monitor the tracking state: \u003chttps://developer.apple.com/documentation/arkit/arcamera/2909008-trackingstate\u003e . If  the tracking state is `.normal` , then you should be safe to place virtual objects in the real world. That being said, it is always possible that ARKit later on corrects the position of anchors. But these corrections should improve the accuracy of placement of your virtual objects, not make it worse.",
          "ts": "1666109467.987059",
          "thread_ts": "1666109408.016879",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "hFr2",
              "elements": [
                {
                  "Type": "rich_text_quote",
                  "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Can we extend the initialization phase to a point where we can recognized that ARKit has detached enough for a point placed on the floor to remain in place as the user moves around?\"}],\"border\":1}"
                },
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "In general, we recommend you to monitor the tracking state: "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/arkit/arcamera/2909008-trackingstate",
                      "text": ""
                    },
                    {
                      "type": "text",
                      "text": " . If  the tracking state is "
                    },
                    {
                      "type": "text",
                      "text": ".normal",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " , then you should be safe to place virtual objects in the real world. That being said, it is always possible that ARKit later on corrects the position of anchors. But these corrections should improve the accuracy of placement of your virtual objects, not make it worse."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "abfbc817-15bf-4195-b62f-b92009c1ea3f",
          "type": "message",
          "user": "U046G1P2R6D",
          "text": "Thank you Matthias. The documentation says to turn off plane detection when \"clear results\" have been obtained. What is a good metric to determine clear results? We are thinking about checking that the floor plane meets a minimum size. Or should we watch for updates to planes to slow down?",
          "ts": "1666110692.567449",
          "thread_ts": "1666109408.016879",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "GkO+",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thank you Matthias. The documentation says to turn off plane detection when \"clear results\" have been obtained. What is a good metric to determine clear results? We are thinking about checking that the floor plane meets a minimum size. Or should we watch for updates to planes to slow down?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "54601666-c6d3-45ed-a2d3-7159325dd9a8",
          "type": "message",
          "user": "U046G1P2R6D",
          "text": "I am not saying that updates make things worse. It is our use of ARKit: we have the user along a floor plan with the room. Once the user has done that, any change - good or bad - breaks the alignment. Is that atypical use?",
          "ts": "1666110798.454249",
          "thread_ts": "1666109408.016879",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "d1dK",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I am not saying that updates make things worse. It is our use of ARKit: we have the user along a floor plan with the room. Once the user has done that, any change - good or bad - breaks the alignment. Is that atypical use?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "b339fe84-83b7-407d-b91e-6e8470c024fb",
          "type": "message",
          "user": "U046G1P2R6D",
          "text": "We are watching the tracking state. Actually the coaching overlay does. Once that goes to .normal we allow the user to place the plan. Our current thinking is that we need to wait longer for ARKit to be 100% sure about the floor plane. In particular we have seen the floor plan float above the actual floor.",
          "ts": "1666110934.888079",
          "thread_ts": "1666109408.016879",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "BySK",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "We are watching the tracking state. Actually the coaching overlay does. Once that goes to .normal we allow the user to place the plan. Our current thinking is that we need to wait longer for ARKit to be 100% sure about the floor plane. In particular we have seen the floor plan float above the actual floor."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "7f63a5b2-4ef4-49d9-a06c-e9940a1ebf59",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "\u0026gt; We are thinking about checking that the floor plane meets a minimum size. \nThat sounds reasonable.",
          "ts": "1666110998.878519",
          "thread_ts": "1666109408.016879",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "azn2",
              "elements": [
                {
                  "Type": "rich_text_quote",
                  "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"We are thinking about checking that the floor plane meets a minimum size. \"}]}"
                },
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "That sounds reasonable."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "4ec9922f-7d31-4605-9326-28e2d0f17c4a",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "\u0026gt;  Once the user has done that, any change - good or bad - breaks the alignment. Is that atypical use?\nIf the floor plan is directly attached to an `ARAnchor`, then the alignment should not break. ARKit tries to minimize any change in the physical location of anchors.",
          "ts": "1666111058.005159",
          "thread_ts": "1666109408.016879",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "1m1g",
              "elements": [
                {
                  "Type": "rich_text_quote",
                  "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\" Once the user has done that, any change - good or bad - breaks the alignment. Is that atypical use?\"}]}"
                },
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "If the floor plan is directly attached to an "
                    },
                    {
                      "type": "text",
                      "text": "ARAnchor",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": ", then the alignment should not break. ARKit tries to minimize any change in the physical location of anchors."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "ae1d1621-e280-463f-b690-283183cf3591",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "So I would recommend you to always attach 3D content / your floor plane to an anchor. Are you already doing that",
          "ts": "1666111106.703209",
          "thread_ts": "1666109408.016879",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "bVNo",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "So I would recommend you to always attach 3D content / your floor plane to an anchor. Are you already doing that"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "a838ec58-93e0-4d62-b7f0-c9fd7e42ea69",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "?",
          "ts": "1666111108.143089",
          "thread_ts": "1666109408.016879",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Ck6Dl",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "2d74c6ed-151b-46bd-9d44-7f8f7fa88a01",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "\u0026gt; We are watching the tracking state. Actually the coaching overlay does. Once that goes to .normal we allow the user to place the plan.\nGreat! It should not be necessary to wait any longer after the coaching overlay has disappeared.",
          "ts": "1666111164.411439",
          "thread_ts": "1666109408.016879",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "hj9K",
              "elements": [
                {
                  "Type": "rich_text_quote",
                  "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"We are watching the tracking state. Actually the coaching overlay does. Once that goes to .normal we allow the user to place the plan.\"}]}"
                },
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Great! It should not be necessary to wait any longer after the coaching overlay has disappeared."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "eca9a18e-cfba-4e2c-8cd6-1ee277e69354",
          "type": "message",
          "user": "U046G1P2R6D",
          "text": "Yes. We actually took inspiration from Apple sample code that allows placing post-it notes and teacups. We also see random behavior with the actual sample code. Sometimes one places a virtual object on the floor, walks away and comes back to see the object is out of place. More often than not, the object then jumps back to the correct placement. Sometimes it doesn't. We are not sure if the difference is in time spent initializing before placing the virtual object, or some memory ARKit has of previous runs, or simply ARKit getting misaligned when moving around.",
          "ts": "1666111386.499919",
          "thread_ts": "1666109408.016879",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Uh++",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Yes. We actually took inspiration from Apple sample code that allows placing post-it notes and teacups. We also see random behavior with the actual sample code. Sometimes one places a virtual object on the floor, walks away and comes back to see the object is out of place. More often than not, the object then jumps back to the correct placement. Sometimes it doesn't. We are not sure if the difference is in time spent initializing before placing the virtual object, or some memory ARKit has of previous runs, or simply ARKit getting misaligned when moving around."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "f40d8bcd-a6a9-429d-908d-015a8758a63a",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "\u0026gt;  More often than not, the object then jumps back to the correct placement.\nIf you walk away and come back, it is possible that some drift has occured. When the object jumps back to the correct place this means that ARKit has performed a relocalization.",
          "ts": "1666112285.029579",
          "thread_ts": "1666109408.016879",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "bg1gv",
              "elements": [
                {
                  "Type": "rich_text_quote",
                  "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\" More often than not, the object then jumps back to the correct placement.\"}]}"
                },
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "If you walk away and come back, it is possible that some drift has occured. When the object jumps back to the correct place this means that ARKit has performed a relocalization."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "dbf7bb99-75ea-4050-932d-0fa65043893b",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "You can tell ARKit to not relocalize \u003chttps://developer.apple.com/documentation/arkit/arsessionobserver/2941046-sessionshouldattemptrelocalizati\u003e",
          "ts": "1666112306.290449",
          "thread_ts": "1666109408.016879",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "vS4",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "You can tell ARKit to not relocalize "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/arkit/arsessionobserver/2941046-sessionshouldattemptrelocalizati",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "bb8f7f8c-85b0-4a35-b92f-269fc813e59b",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "Though I would recommend to keep it on",
          "ts": "1666112317.741189",
          "thread_ts": "1666109408.016879",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "gratitude-thank-you",
              "count": 1,
              "users": [
                "U046G1P2R6D"
              ]
            },
            {
              "name": "eyes",
              "count": 1,
              "users": [
                "U0468KB4V3M"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "51JO",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Though I would recommend to keep it on"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046SQ8RLDN\u003e asked\n\u0026gt; Hi there,\n\u0026gt; I am using the captureHighResolutionFrame api to get the best pictures of the objects I want to capture.\n\u0026gt; I notice that on small objects like a tube, when looking from the top, the autofocus is good on top of the tube but the base of the tube becomes blurry. \n\u0026gt; It is as if the depth of field was not large enough to ensure both top and bottom of the tube are in-focus.\n\u0026gt; Is there any way to \"increase\" this depth of field during the ARkit session capture? A bit like what you can see in portrait mode on the photo app...\n\u0026gt; \n\u0026gt; Thanks in advance and kudos for the Ask Apple initiative!",
      "ts": "1666109421.870009",
      "thread_ts": "1666109421.870009",
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "reply_count": 2,
      "latest_reply": "1666111243.945309",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "FUC",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046SQ8RLDN"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Hi there,\\nI am using the captureHighResolutionFrame api to get the best pictures of the objects I want to capture.\\nI notice that on small objects like a tube, when looking from the top, the autofocus is good on top of the tube but the base of the tube becomes blurry. \\nIt is as if the depth of field was not large enough to ensure both top and bottom of the tube are in-focus.\\nIs there any way to \\\"increase\\\" this depth of field during the ARkit session capture? A bit like what you can see in portrait mode on the photo app...\\n\\nThanks in advance and kudos for the Ask Apple initiative!\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "0be4bf52-e325-4415-9d85-0e924e8081d1",
          "type": "message",
          "user": "U0464NUFLM7",
          "text": "Hi Pierre! It is not possible to adjust focus for high resolution frame captures. You can however use the new `configurableCaptureDeviceForPrimaryCamera` API to adjust capture settings, including focus, for regular `ARFrame`s. Maybe this can be helpful for your use case. (Note that in iOS 16 you can also select a 4K video format.)",
          "ts": "1666109541.792559",
          "thread_ts": "1666109421.870009",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "MmX",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi Pierre! It is not possible to adjust focus for high resolution frame captures. You can however use the new "
                    },
                    {
                      "type": "text",
                      "text": "configurableCaptureDeviceForPrimaryCamera",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " API to adjust capture settings, including focus, for regular "
                    },
                    {
                      "type": "text",
                      "text": "ARFrame",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "s. Maybe this can be helpful for your use case. (Note that in iOS 16 you can also select a 4K video format.)"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "b0769375-e3c8-4300-85b9-296b66b5159d",
          "type": "message",
          "user": "U046SQ8RLDN",
          "text": "I get it.\nThank you for the answer.",
          "ts": "1666111243.945309",
          "thread_ts": "1666109421.870009",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "uXtnn",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I get it.\nThank you for the answer."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U045Z8Z4RTP\u003e asked\n\u0026gt; I found an interesting crash in my app. \n\u0026gt; We use ARKit for face recognition: face detection plus face mesh and depth data map capturing. \n\u0026gt; Our app is running 24/7 in kiosk mode. \n\u0026gt; According a log, a device go out of memory. I wonder why it happens? I retain only a latest copy of capturedImage from currentFrame. Unfortunately, cannot reproduce on my side, so I can’t submit test project, but has a crash log. While running on my device, RAM amount doesn't grow up fast. :thinking_face:\n\u0026gt; \n\u0026gt; Hardware Model:      iPhone11,8\n\u0026gt; AppStoreTools:       13A227\n\u0026gt; AppVariant:          1:iPhone11,8:13\n\u0026gt; Code Type:           ARM-64 (Native)\n\u0026gt; Role:                Foreground\n\u0026gt; \n\u0026gt; OS Version:          iPhone OS 13.4 (17E255)\n\u0026gt; \n\u0026gt; Exception Type:  EXC_CRASH (SIGABRT)\n\u0026gt; Exception Codes: 0x0000000000000000, 0x0000000000000000\n\u0026gt; Exception Note:  EXC_CORPSE_NOTIFY\n\u0026gt; Triggered by Thread:  22\n\u0026gt; \n\u0026gt; Last Exception Backtrace:\n\u0026gt; 0   CoreFoundation                \t0x1be0e4164 __exceptionPreprocess + 228 (NSException.m:199)\n\u0026gt; 1   libobjc.A.dylib               \t0x1bddf8c1c objc_exception_throw + 60 (\u003chttp://objc-exception.mm:565|objc-exception.mm:565\u003e)\n\u0026gt; 2   Foundation                    \t0x1be44e7b8 allocationFailure + 60 (NSPointerArray.m:27)\n\u0026gt; 3   Foundation                    \t0x1be3c00ec -[NSConcretePointerArray arrayGrow:] + 216 (NSPointerArray.m:417)\n\u0026gt; 4   Foundation                    \t0x1be3a015c -[NSConcretePointerArray addPointer:] + 76 (NSPointerArray.m:455)\n\u0026gt; 5   ARKit                         \t0x1da7a9910 -[ARSession _sessionDidUpdateFrame:] + 148 (ARSession.m:3774)\n\u0026gt; 6   ARKit                         \t0x1da7a122c -[ARSession technique:didOutputResultData:timestamp:context:] + 10576 (ARSession.m:2411)\n\u0026gt; 7   ARKit                         \t0x1da74dae8 -[ARParentTechnique _submitResultsForTimestamp:context:] + 532 (ARParentTechnique.m:515)\n\u0026gt; 8   ARKit                         \t0x1da74d544 -[ARParentTechnique technique:didOutputResultData:timestamp:context:] + 1860 (ARParentTechnique.m:461)\n\u0026gt; 9   ARKit                         \t0x1da7d0eac -[ARFaceLightEstimationTechnique requestResultDataAtTimestamp:context:] + 1236 (\u003chttp://ARFaceLightEstimationTechnique.mm:342|ARFaceLightEstimationTechnique.mm:342\u003e)\n\u0026gt; 10  ARKit                         \t0x1da74d520 -[ARParentTechnique technique:didOutputResultData:timestamp:context:] + 1824 (ARParentTechnique.m:457)\n\u0026gt; 11  ARKit                         \t0x1da7929ec -[ARWorldAlignmentTechnique requestResultDataAtTimestamp:context:] + 1452 (ARWorldAlignmentTechnique.m:220)\n\u0026gt; 12  ARKit                         \t0x1da74d520 -[ARParentTechnique technique:didOutputResultData:timestamp:context:] + 1824 (ARParentTechnique.m:457)\n\u0026gt; 13  ARKit                         \t0x1da74dae8 -[ARParentTechnique _submitResultsForTimestamp:context:] + 532 (ARParentTechnique.m:515)\n\u0026gt; 14  libdispatch.dylib             \t0x1bdd8433c _dispatch_client_callout + 20 (object.m:495)\n\u0026gt; 15  libdispatch.dylib             \t0x1bdd86af8 _dispatch_continuation_pop + 408 (inline_internal.h:2484)\n\u0026gt; 16  libdispatch.dylib             \t0x1bdd97624 _dispatch_source_invoke + 1224 (source.c:568)\n\u0026gt; 17  libdispatch.dylib             \t0x1bdd8a72c _dispatch_lane_serial_drain + 264 (inline_internal.h:2525)\n\u0026gt; 18  libdispatch.dylib             \t0x1bdd8b2c4 _dispatch_lane_invoke + 452 (queue.c:3863)\n\u0026gt; 19  libdispatch.dylib             \t0x1bdd935c0 _dispatch_root_queue_drain + 348 (inline_internal.h:2525)\n\u0026gt; 20  libdispatch.dylib             \t0x1bdd93380 _dispatch_worker_thread + 240 (queue.c:6725)\n\u0026gt; 21  libsystem_pthread.dylib       \t0x1bdde98fc _pthread_start + 168 (pthread.c:896)\n\u0026gt; 22  libsystem_pthread.dylib       \t0x1bddf19d4 thread_start + 8",
      "ts": "1666109539.387979",
      "thread_ts": "1666109539.387979",
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "reply_count": 2,
      "latest_reply": "1666109614.313249",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "vSr",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U045Z8Z4RTP"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"I found an interesting crash in my app. \\nWe use ARKit for face recognition: face detection plus face mesh and depth data map capturing. \\nOur app is running 24\\/7 in kiosk mode. \\nAccording a log, a device go out of memory. I wonder why it happens? I retain only a latest copy of capturedImage from currentFrame. Unfortunately, cannot reproduce on my side, so I can\\u2019t submit test project, but has a crash log. While running on my device, RAM amount doesn't grow up fast. \"},{\"type\":\"emoji\",\"name\":\"thinking_face\",\"unicode\":\"1f914\"},{\"type\":\"text\",\"text\":\"\\n\\nHardware Model:      iPhone11,8\\nAppStoreTools:       13A227\\nAppVariant:          1:iPhone11,8:13\\nCode Type:           ARM-64 (Native)\\nRole:                Foreground\\n\\nOS Version:          iPhone OS 13.4 (17E255)\\n\\nException Type:  EXC_CRASH (SIGABRT)\\nException Codes: 0x0000000000000000, 0x0000000000000000\\nException Note:  EXC_CORPSE_NOTIFY\\nTriggered by Thread:  22\\n\\nLast Exception Backtrace:\\n0   CoreFoundation                \\t0x1be0e4164 __exceptionPreprocess + 228 (NSException.m:199)\\n1   libobjc.A.dylib               \\t0x1bddf8c1c objc_exception_throw + 60 (objc-exception.mm:565)\\n2   Foundation                    \\t0x1be44e7b8 allocationFailure + 60 (NSPointerArray.m:27)\\n3   Foundation                    \\t0x1be3c00ec -[NSConcretePointerArray arrayGrow:] + 216 (NSPointerArray.m:417)\\n4   Foundation                    \\t0x1be3a015c -[NSConcretePointerArray addPointer:] + 76 (NSPointerArray.m:455)\\n5   ARKit                         \\t0x1da7a9910 -[ARSession _sessionDidUpdateFrame:] + 148 (ARSession.m:3774)\\n6   ARKit                         \\t0x1da7a122c -[ARSession technique\"},{\"type\":\"emoji\",\"name\":\"didOutputResultData\"},{\"type\":\"text\",\"text\":\"timestamp\"},{\"type\":\"emoji\",\"name\":\"context\"},{\"type\":\"text\",\"text\":\"] + 10576 (ARSession.m:2411)\\n7   ARKit                         \\t0x1da74dae8 -[ARParentTechnique _submitResultsForTimestamp\"},{\"type\":\"emoji\",\"name\":\"context\"},{\"type\":\"text\",\"text\":\"] + 532 (ARParentTechnique.m:515)\\n8   ARKit                         \\t0x1da74d544 -[ARParentTechnique technique\"},{\"type\":\"emoji\",\"name\":\"didOutputResultData\"},{\"type\":\"text\",\"text\":\"timestamp\"},{\"type\":\"emoji\",\"name\":\"context\"},{\"type\":\"text\",\"text\":\"] + 1860 (ARParentTechnique.m:461)\\n9   ARKit                         \\t0x1da7d0eac -[ARFaceLightEstimationTechnique requestResultDataAtTimestamp\"},{\"type\":\"emoji\",\"name\":\"context\"},{\"type\":\"text\",\"text\":\"] + 1236 (ARFaceLightEstimationTechnique.mm:342)\\n10  ARKit                         \\t0x1da74d520 -[ARParentTechnique technique\"},{\"type\":\"emoji\",\"name\":\"didOutputResultData\"},{\"type\":\"text\",\"text\":\"timestamp\"},{\"type\":\"emoji\",\"name\":\"context\"},{\"type\":\"text\",\"text\":\"] + 1824 (ARParentTechnique.m:457)\\n11  ARKit                         \\t0x1da7929ec -[ARWorldAlignmentTechnique requestResultDataAtTimestamp\"},{\"type\":\"emoji\",\"name\":\"context\"},{\"type\":\"text\",\"text\":\"] + 1452 (ARWorldAlignmentTechnique.m:220)\\n12  ARKit                         \\t0x1da74d520 -[ARParentTechnique technique\"},{\"type\":\"emoji\",\"name\":\"didOutputResultData\"},{\"type\":\"text\",\"text\":\"timestamp\"},{\"type\":\"emoji\",\"name\":\"context\"},{\"type\":\"text\",\"text\":\"] + 1824 (ARParentTechnique.m:457)\\n13  ARKit                         \\t0x1da74dae8 -[ARParentTechnique _submitResultsForTimestamp\"},{\"type\":\"emoji\",\"name\":\"context\"},{\"type\":\"text\",\"text\":\"] + 532 (ARParentTechnique.m:515)\\n14  libdispatch.dylib             \\t0x1bdd8433c _dispatch_client_callout + 20 (object.m:495)\\n15  libdispatch.dylib             \\t0x1bdd86af8 _dispatch_continuation_pop + 408 (inline_internal.h:2484)\\n16  libdispatch.dylib             \\t0x1bdd97624 _dispatch_source_invoke + 1224 (source.c:568)\\n17  libdispatch.dylib             \\t0x1bdd8a72c _dispatch_lane_serial_drain + 264 (inline_internal.h:2525)\\n18  libdispatch.dylib             \\t0x1bdd8b2c4 _dispatch_lane_invoke + 452 (queue.c:3863)\\n19  libdispatch.dylib             \\t0x1bdd935c0 _dispatch_root_queue_drain + 348 (inline_internal.h:2525)\\n20  libdispatch.dylib             \\t0x1bdd93380 _dispatch_worker_thread + 240 (queue.c:6725)\\n21  libsystem_pthread.dylib       \\t0x1bdde98fc _pthread_start + 168 (pthread.c:896)\\n22  libsystem_pthread.dylib       \\t0x1bddf19d4 thread_start + 8\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "daaac9bd-7f0c-42cb-a002-664ee36552b5",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "This looks like a bug. It would be great if you could send this trace to us via \u003chttps://developer.apple.com/bug-reporting/\u003e",
          "ts": "1666109548.618309",
          "thread_ts": "1666109539.387979",
          "attachments": [
            {
              "fallback": "Apple Developer: Bug Reporting - Apple Developer",
              "id": 1,
              "title": "Bug Reporting - Apple Developer",
              "title_link": "https://developer.apple.com/bug-reporting/",
              "text": "Now with Feedback Assistant available on iPhone, iPad, Mac, and the web, it’s easier to submit effective bug reports and request enhancements to APIs and tools.",
              "image_url": "https://developer.apple.com/news/images/og/bug-reporting-og.jpg",
              "service_name": "Apple Developer",
              "service_icon": "https://developer.apple.com/favicon.ico",
              "from_url": "https://developer.apple.com/bug-reporting/",
              "original_url": "https://developer.apple.com/bug-reporting/",
              "blocks": null
            }
          ],
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "FUQ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "This looks like a bug. It would be great if you could send this trace to us via "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/bug-reporting/",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "7702ac1d-98b9-4066-8a33-39bbbdb0069f",
          "type": "message",
          "user": "U046E6ZLWS0",
          "text": "\u0026gt; OS Version:          iPhone OS 13.4 (17E255)\n",
          "ts": "1666109614.313249",
          "thread_ts": "1666109539.387979",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Yb5",
              "elements": [
                {
                  "Type": "rich_text_quote",
                  "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"OS Version:          iPhone OS 13.4 (17E255)\"}]}"
                },
                {
                  "type": "rich_text_section",
                  "elements": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046PQWQMLM\u003e asked\n\u0026gt; Hi I’m syouten from Japan.\n\u0026gt; I am working on an app that uses the ARKit collaborative session that uses participant’s peer device names.\n\u0026gt; My question is how to display peer’s name with multiplier connectivity?\n\u0026gt; It used to work, but in the latest iOS, peer.displayName only returns word “iPhone”.",
      "ts": "1666109603.927959",
      "thread_ts": "1666109603.927959",
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "reply_count": 2,
      "latest_reply": "1666110838.514869",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "YqR",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046PQWQMLM"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Hi I\\u2019m syouten from Japan.\\nI am working on an app that uses the ARKit collaborative session that uses participant\\u2019s peer device names.\\nMy question is how to display peer\\u2019s name with multiplier connectivity?\\nIt used to work, but in the latest iOS, peer.displayName only returns word \\u201ciPhone\\u201d.\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "50604f21-8eef-4681-87be-f73cad40b422",
          "type": "message",
          "user": "U0464NUFLM7",
          "text": "Hello! This API belongs to the `MultipeerConnectivity` framework. Please file a feedback report with the steps to reproduce the issue at \u003chttps://feedbackassistant.apple.com\u003e. Thank you!",
          "ts": "1666109681.516079",
          "thread_ts": "1666109603.927959",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "iz8kz",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hello! This API belongs to the "
                    },
                    {
                      "type": "text",
                      "text": "MultipeerConnectivity",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " framework. Please file a feedback report with the steps to reproduce the issue at "
                    },
                    {
                      "type": "link",
                      "url": "https://feedbackassistant.apple.com",
                      "text": ""
                    },
                    {
                      "type": "text",
                      "text": ". Thank you!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "c8991742-6fe4-4b7c-ade5-ab270eeda62b",
          "type": "message",
          "user": "U0461SXS43H",
          "text": "Device names from `UIDevice.current.name` in iOS 16 and macOS 13 are genericized as a privacy protecting feature",
          "ts": "1666110838.514869",
          "thread_ts": "1666109603.927959",
          "edited": {
            "user": "U0461SXS43H",
            "ts": "1666111063.000000"
          },
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "fI2",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Device names from "
                    },
                    {
                      "type": "text",
                      "text": "UIDevice.current.name",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " in iOS 16 and macOS 13 are genericized as a privacy protecting feature"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046FPKKSF3\u003e asked\n\u0026gt; Is it possible to use point cloud ?",
      "ts": "1666109628.304499",
      "thread_ts": "1666109628.304499",
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "reply_count": 1,
      "latest_reply": "1666109777.561069",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "gSQ",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046FPKKSF3"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Is it possible to use point cloud ?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "0781060c-253d-457e-9e01-b2f05866e4bc",
          "type": "message",
          "user": "U0449H175SA",
          "text": "Can you clarify how/in what context you’re looking to use point cloud(s)?",
          "ts": "1666109777.561069",
          "thread_ts": "1666109628.304499",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Xa1pA",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Can you clarify how/in what context you’re looking to use point cloud(s)?"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U045VNN3MPY\u003e asked\n\u0026gt; is there an example of recording video with AR contents (not screen recording)?",
      "ts": "1666109759.119379",
      "thread_ts": "1666109759.119379",
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "reply_count": 1,
      "latest_reply": "1666109831.155539",
      "reactions": [
        {
          "name": "+1",
          "count": 1,
          "users": [
            "U045WF1CPQE"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "rBqy",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U045VNN3MPY"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"is there an example of recording video with AR contents (not screen recording)?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "cbc2deeb-b99d-4d5d-980d-c238cee6f059",
          "type": "message",
          "user": "U0464NUFLM7",
          "text": "Hi Hassan! Are you referring to recording AR session data for later replay through Xcode? You can find more information on how to record such sequences with Reality Composer in this article: \u003chttps://developer.apple.com/documentation/arkit/arsession/recording_and_replaying_ar_session_data\u003e",
          "ts": "1666109831.155539",
          "thread_ts": "1666109759.119379",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "93Tm",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi Hassan! Are you referring to recording AR session data for later replay through Xcode? You can find more information on how to record such sequences with Reality Composer in this article: "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/arkit/arsession/recording_and_replaying_ar_session_data",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U045WF1CPQE\u003e asked\n\u0026gt; I am working on an AR app in which I want to place multiple entities in the ARSession, and programmatically connect them together. My models are custom-made in Blender and converted to USDZ.\n\u0026gt; What is the process to add child entities and have them linked to each other?",
      "ts": "1666109822.974729",
      "thread_ts": "1666109822.974729",
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "reply_count": 6,
      "latest_reply": "1666110352.038369",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "kuE",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U045WF1CPQE"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"I am working on an AR app in which I want to place multiple entities in the ARSession, and programmatically connect them together. My models are custom-made in Blender and converted to USDZ.\\nWhat is the process to add child entities and have them linked to each other?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "a61907a5-1073-4529-a75f-131bc756a4c0",
          "type": "message",
          "user": "U045N4PC189",
          "text": "Hello.\nHave you tried using the RealityKit API? \u003chttps://developer.apple.com/documentation/realitykit/\u003e\nAlso, what do you mean by \"programmatically connect them together\"?",
          "ts": "1666109913.749459",
          "thread_ts": "1666109822.974729",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "x4V",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hello.\nHave you tried using the RealityKit API? "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/realitykit/",
                      "text": ""
                    },
                    {
                      "type": "text",
                      "text": "\nAlso, what do you mean by \"programmatically connect them together\"?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "0d753734-636d-449d-a701-c716801cefaa",
          "type": "message",
          "user": "U045WF1CPQE",
          "text": "Yes, I’m using RealityKit. I want to place a first entity in the scene, and then attach several others *to the first one* based on conditions. I’m quite new to AR, so apologies for the noob question.",
          "ts": "1666110015.191589",
          "thread_ts": "1666109822.974729",
          "edited": {
            "user": "U045WF1CPQE",
            "ts": "1666110063.000000"
          },
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "I64",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Yes, I’m using RealityKit. I want to place a first entity in the scene, and then attach several others "
                    },
                    {
                      "type": "text",
                      "text": "to the first one ",
                      "style": {
                        "bold": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "based on conditions. I’m quite new to AR, so apologies for the noob question."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "31d89db3-a6bd-4e60-b1ae-62d9b19a81df",
          "type": "message",
          "user": "U046E6ZLWS0",
          "text": "If the parts can only be placed in specific ways, consider using RealityComposer and its Hide/Show actions",
          "ts": "1666110157.180979",
          "thread_ts": "1666109822.974729",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "qfR",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "If the parts can only be placed in specific ways, consider using RealityComposer and its Hide/Show actions"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "18ae54e5-5011-4f5d-b5f8-fcdb56ffee3b",
          "type": "message",
          "user": "U046E6ZLWS0",
          "text": "I place all parts, hide all except the starter at Scene start and then show them one by one later based on trigger event",
          "ts": "1666110238.713909",
          "thread_ts": "1666109822.974729",
          "edited": {
            "user": "U046E6ZLWS0",
            "ts": "1666110253.000000"
          },
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "lkYrJ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I place all parts, hide all except the starter at Scene start and then show them one by one later based on trigger event"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "c0f8ccb3-d27e-4475-8e57-3749f4637b15",
          "type": "message",
          "user": "U045N4PC189",
          "text": "You can also add Entities as children of other Entities. And remove them when needed.",
          "ts": "1666110319.399569",
          "thread_ts": "1666109822.974729",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U045WF1CPQE"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "k2l4F",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "You can also add Entities as children of other Entities. And remove them when needed."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "07b904b0-bbab-4f0e-8754-c0ac7317edf7",
          "type": "message",
          "user": "U045WF1CPQE",
          "text": "Unfortunately my use cases are too many, since I want to place the objects based on .gravityandheading and compute values for the number and orientation of the child entities. Think of a sign that points in different directions, based on the computed values.",
          "ts": "1666110352.038369",
          "thread_ts": "1666109822.974729",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "GL6Gp",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Unfortunately my use cases are too many, since I want to place the objects based on .gravityandheading and compute values for the number and orientation of the child entities. Think of a sign that points in different directions, based on the computed values."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046UAH7QJJ\u003e asked\n\u0026gt; I'm using the 'Creating a Collaborative Session' sample code as a base for my ARKit project. Which works great for basic needs, but I can't adjust it in a way to also sync the scene when objects are being deleted or being repositioned. Is that a limitation of ARSession.CollaborationData or am I doing something wrong?\n\u0026gt; \n\u0026gt; Kind regards,\n\u0026gt; Thom Pheijffer",
      "ts": "1666109841.397919",
      "thread_ts": "1666109841.397919",
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "reply_count": 3,
      "latest_reply": "1666109901.930669",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "MJK",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046UAH7QJJ"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"I'm using the 'Creating a Collaborative Session' sample code as a base for my ARKit project. Which works great for basic needs, but I can't adjust it in a way to also sync the scene when objects are being deleted or being repositioned. Is that a limitation of ARSession.CollaborationData or am I doing something wrong?\\n\\nKind regards,\\nThom Pheijffer\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "6181e307-e32b-4514-8d48-71128275aa30",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "The ARKit collaboration data is purely for ARKit on both devices to agree on a shared coordinate system. Synchronizing changes to 3D content is something that you have to do in your app - ARKit is not aware of your 3D content and would not know which content should be synchronized.",
          "ts": "1666109848.948909",
          "thread_ts": "1666109841.397919",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "rFq5",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "The ARKit collaboration data is purely for ARKit on both devices to agree on a shared coordinate system. Synchronizing changes to 3D content is something that you have to do in your app - ARKit is not aware of your 3D content and would not know which content should be synchronized."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "9917d54c-f14c-4cb5-bef4-53464363cd05",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "Note though that RealityKit has a synchronization service which can automatically synchronize content for you, as e.g. shown here \u003chttps://medium.com/flawless-app-stories/realitykit-synchronization-289ba9409a6e\u003e",
          "ts": "1666109876.310559",
          "thread_ts": "1666109841.397919",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "raised_hands",
              "count": 1,
              "users": [
                "U046E6ZLWS0"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "kauJ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Note though that RealityKit has a synchronization service which can automatically synchronize content for you, as e.g. shown here "
                    },
                    {
                      "type": "link",
                      "url": "https://medium.com/flawless-app-stories/realitykit-synchronization-289ba9409a6e",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "54c6ea15-8a99-40a0-b444-6bfe4e60616c",
          "type": "message",
          "user": "U046UAH7QJJ",
          "text": "Thank you!",
          "ts": "1666109901.930669",
          "thread_ts": "1666109841.397919",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U044WJQ0YF8"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "ELotS",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thank you!"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U04642C9X3L\u003e asked\n\u0026gt; In the demo 'Capturing Body Motion in 3D' , The foot's angle of the biped-robot is weird, how can I fix this.",
      "ts": "1666109913.475849",
      "thread_ts": "1666109913.475849",
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "reply_count": 1,
      "latest_reply": "1666109983.562869",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "Y2C",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U04642C9X3L"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"In the demo 'Capturing Body Motion in 3D' , The foot's angle of the biped-robot is weird, how can I fix this.\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "19c64677-c84e-42af-bfb7-a17ffcc6f9b4",
          "type": "message",
          "user": "U0464NUFLM7",
          "text": "Hi! We’re aware of the issue and actively investigating it. Thank you!",
          "ts": "1666109983.562869",
          "thread_ts": "1666109913.475849",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "ke23E",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi! We’re aware of the issue and actively investigating it. Thank you!"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U04625MKBGT\u003e asked\n\u0026gt; Can we request a RAW Photo during ARKitSession. Is it possible to leverage the 48MP resolution of the new iPhone 14 Pro and Pro Max during an ARKit Session?",
      "ts": "1666110086.884629",
      "thread_ts": "1666110086.884629",
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "reply_count": 2,
      "latest_reply": "1666110237.070779",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "1=eP",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U04625MKBGT"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Can we request a RAW Photo during ARKitSession. Is it possible to leverage the 48MP resolution of the new iPhone 14 Pro and Pro Max during an ARKit Session?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "3161547c-8752-48e3-95f2-1dbbb4135b02",
          "type": "message",
          "user": "U0464NUFLM7",
          "text": "Hi Markus! The high resolution capture API is optimized for performance. RAW images are not supported and the maximal resolution will be 12MP.",
          "ts": "1666110137.420709",
          "thread_ts": "1666110086.884629",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "1qm",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi Markus! The high resolution capture API is optimized for performance. RAW images are not supported and the maximal resolution will be 12MP."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "2E8F8B29-DC9C-4820-9D24-FB73BFC6F9F8",
          "type": "message",
          "user": "U04625MKBGT",
          "text": "Thank you ",
          "ts": "1666110237.070779",
          "thread_ts": "1666110086.884629",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "4Yf",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thank you "
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046FB44R9Q\u003e asked\n\u0026gt; Hi, I have built an app that shows artwork on the user's wall. It is designed to set the picture several feet in front of the user. If the wall is plain though, ARKit struggles to place the image. Is there any way I can improve this?",
      "ts": "1666110156.085299",
      "thread_ts": "1666110156.085299",
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "reply_count": 2,
      "latest_reply": "1666110605.927199",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "yiri",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046FB44R9Q"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Hi, I have built an app that shows artwork on the user's wall. It is designed to set the picture several feet in front of the user. If the wall is plain though, ARKit struggles to place the image. Is there any way I can improve this?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "dec09cb3-114b-4581-8a52-0f824a369c09",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "On devices with a LIDAR sensor (e.g. iPhone 12/13/14 Pro models) this should not be an issue, or significantly less so. On devices without a LIDAR sensor ARKit depends on detecting visual features from different angles to detect walls. A plain white wall can be challenging. Maybe you could guide your users to place artwork on walls which already have artwork on them? Those have a much higher/faster chance of being detected.",
          "ts": "1666110289.469959",
          "thread_ts": "1666110156.085299",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "mk4x",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "On devices with a LIDAR sensor (e.g. iPhone 12/13/14 Pro models) this should not be an issue, or significantly less so. On devices without a LIDAR sensor ARKit depends on detecting visual features from different angles to detect walls. A plain white wall can be challenging. Maybe you could guide your users to place artwork on walls which already have artwork on them? Those have a much higher/faster chance of being detected."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "87203ff1-864d-4645-afcf-1b6c2c883301",
          "type": "message",
          "user": "U046FB44R9Q",
          "text": "Thank you, that is helpful to know",
          "ts": "1666110605.927199",
          "thread_ts": "1666110156.085299",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U044WJQ0YF8"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "nod",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thank you, that is helpful to know"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046J3D5TPB\u003e asked\n\u0026gt; Hi, is the Lidar data available outside of the ARKit mode?\n\u0026gt; Could we access the Lidar data by taking a picture?\n\u0026gt; By taking a picture, could we access the spatial coordinates or mesh point cloud to process the measurements of the objects in the photo, in scale?\n\u0026gt; How could we achieve this?\n\u0026gt; Could you point to some documentation or sample code?\n\u0026gt; Thanks",
      "ts": "1666110351.060539",
      "thread_ts": "1666110351.060539",
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "reply_count": 2,
      "latest_reply": "1666111135.975319",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "AU5",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046J3D5TPB"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Hi, is the Lidar data available outside of the ARKit mode?\\nCould we access the Lidar data by taking a picture?\\nBy taking a picture, could we access the spatial coordinates or mesh point cloud to process the measurements of the objects in the photo, in scale?\\nHow could we achieve this?\\nCould you point to some documentation or sample code?\\nThanks\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "37bf7809-4a9e-4e9e-9b36-8da9779533b6",
          "type": "message",
          "user": "U0464NUFLM7",
          "text": "Hi Bruno, you can also access LiDAR data through AVFoundation APIs. You can find more information here: \u003chttps://developer.apple.com/documentation/avfoundation/additional_data_capture/capturing_depth_using_the_lidar_camera\u003e",
          "ts": "1666110383.457939",
          "thread_ts": "1666110351.060539",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "AWV",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi Bruno, you can also access LiDAR data through AVFoundation APIs. You can find more information here: "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/avfoundation/additional_data_capture/capturing_depth_using_the_lidar_camera",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "53b4f9e1-5682-4ba5-b08f-8cbdb60b4ecb",
          "type": "message",
          "user": "U046J3D5TPB",
          "text": "Can I get the dimensions of an object by using this?",
          "ts": "1666111135.975319",
          "thread_ts": "1666110351.060539",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "6eP=u",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Can I get the dimensions of an object by using this?"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046J3D5TPB\u003e asked\n\u0026gt; Hi, we're creating an app that aims to take a picture of an object and give us its 3D perimeter and depth. How can the Lidar sensor help us achieve this?\n\u0026gt; Thanks",
      "ts": "1666110409.736529",
      "thread_ts": "1666110409.736529",
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "reply_count": 7,
      "latest_reply": "1666110924.884099",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "5H3z",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046J3D5TPB"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Hi, we're creating an app that aims to take a picture of an object and give us its 3D perimeter and depth. How can the Lidar sensor help us achieve this?\\nThanks\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "6ec03965-5eee-4b3b-badb-0680a3f49a15",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "On devices with a LIDAR sensor, you can turn on the `ARSceneReconstructionMesh` option \u003chttps://developer.apple.com/documentation/arkit/arscenereconstruction/arscenereconstructionmesh\u003e",
          "ts": "1666110416.211989",
          "thread_ts": "1666110409.736529",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "XS=",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "On devices with a LIDAR sensor, you can turn on the "
                    },
                    {
                      "type": "text",
                      "text": "ARSceneReconstructionMesh",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " option "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/arkit/arscenereconstruction/arscenereconstructionmesh",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "a70f9fdf-1581-432f-8ef7-aba72a4179fe",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "This gives you access to `ARMeshAnchor` with a detailed mesh of the 3D object",
          "ts": "1666110432.649939",
          "thread_ts": "1666110409.736529",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "dTegx",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "This gives you access to "
                    },
                    {
                      "type": "text",
                      "text": "ARMeshAnchor",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " with a detailed mesh of the 3D object"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "478e2646-0833-4ff9-a09d-82d854c8cd8f",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "I recommend you take a look at this developer sample: \u003chttps://developer.apple.com/documentation/arkit/content_anchors/visualizing_and_interacting_with_a_reconstructed_scene?language=objc\u003e",
          "ts": "1666110444.906059",
          "thread_ts": "1666110409.736529",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "fHn",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I recommend you take a look at this developer sample: "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/arkit/content_anchors/visualizing_and_interacting_with_a_reconstructed_scene?language=objc",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "401fddee-3cb8-468c-be5c-33ba801cf798",
          "type": "message",
          "user": "U046J3D5TPB",
          "text": "Is it possible to access this data by taking a picture?",
          "ts": "1666110727.745299",
          "thread_ts": "1666110409.736529",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "chyln",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Is it possible to access this data by taking a picture?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "757162a2-01f2-4928-92aa-8d72c3fea576",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "No, you need to run an `ARSession`",
          "ts": "1666110780.594359",
          "thread_ts": "1666110409.736529",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "JXNj",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "No, you need to run an "
                    },
                    {
                      "type": "text",
                      "text": "ARSession",
                      "style": {
                        "code": true
                      }
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "dc50fb29-dba6-4a8e-b1cc-d00f7ac1293f",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "On second thought, it seems that accessing depth (not the mesh) on a photo is possible. See \u003chttps://developer.apple.com/documentation/avfoundation/additional_data_capture/capturing_photos_with_depth\u003e",
          "ts": "1666110889.791259",
          "thread_ts": "1666110409.736529",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "roiJ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "On second thought, it seems that accessing depth (not the mesh) on a photo is possible. See "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/avfoundation/additional_data_capture/capturing_photos_with_depth",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "66fa5a2f-5efc-4f85-93be-0b1f1420e99e",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "Though you would then have to compute the 3D perimeter yourself, which might not be possible from a single photo",
          "ts": "1666110924.884099",
          "thread_ts": "1666110409.736529",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Lpy",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Though you would then have to compute the 3D perimeter yourself, which might not be possible from a single photo"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046J3D5TPB\u003e asked\n\u0026gt; Hi, in Apple's Measure app, when you point the camera at a person, it shows their height.\n\u0026gt; How could we achieve something similar?\n\u0026gt; Could you point to some documentation or sample code?\n\u0026gt; Thanks",
      "ts": "1666110591.186509",
      "thread_ts": "1666110591.186509",
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "reply_count": 8,
      "latest_reply": "1666111556.715729",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "5vUH",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046J3D5TPB"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Hi, in Apple's Measure app, when you point the camera at a person, it shows their height.\\nHow could we achieve something similar?\\nCould you point to some documentation or sample code?\\nThanks\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "3becb412-2670-4794-a3be-b983b539b33e",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "You might be able to implement this yourself approximately by using ARKit’s person segmentation.",
          "ts": "1666110600.365999",
          "thread_ts": "1666110591.186509",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "WFhl",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "You might be able to implement this yourself approximately by using ARKit’s person segmentation."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "25764167-4d72-4caa-a5dc-990c634ca17d",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "And/or human body tracking",
          "ts": "1666110613.991769",
          "thread_ts": "1666110591.186509",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "7abK=",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "And/or human body tracking"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "a927903d-27e7-4019-8d79-4f5b68dac583",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "I recommend you to take a look at \u003chttps://developer.apple.com/documentation/arkit/content_anchors/capturing_body_motion_in_3d?language=objc\u003e",
          "ts": "1666110627.015649",
          "thread_ts": "1666110591.186509",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Drm",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I recommend you to take a look at "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/arkit/content_anchors/capturing_body_motion_in_3d?language=objc",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "cdbb092d-6e39-4005-8034-4eb5755e0ebd",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "And \u003chttps://developer.apple.com/documentation/arkit/camera_lighting_and_effects/occluding_virtual_content_with_people?language=objc\u003e",
          "ts": "1666110641.917199",
          "thread_ts": "1666110591.186509",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "PO2=W",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "And "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/arkit/camera_lighting_and_effects/occluding_virtual_content_with_people?language=objc",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "34073c29-5cad-45ff-ae95-85a5bcd515ca",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "Note that for body tracking, we offer an estimated scale factor: \u003chttps://developer.apple.com/documentation/arkit/arbodyanchor/3255162-estimatedscalefactor\u003e",
          "ts": "1666110667.803079",
          "thread_ts": "1666110591.186509",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Yop",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Note that for body tracking, we offer an estimated scale factor: "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/arkit/arbodyanchor/3255162-estimatedscalefactor",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "0ca27d5c-55ae-4681-86dd-fd7ccd26994d",
          "type": "message",
          "user": "U046J3D5TPB",
          "text": "Is it possible to get the persons height by taking a picture?",
          "ts": "1666111334.646649",
          "thread_ts": "1666110591.186509",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "ZJ5O",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Is it possible to get the persons height by taking a picture?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "7bbdd858-f2cf-431b-a52c-693fea4ca37b",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "This might be possible by using Vision framework: \u003chttps://developer.apple.com/videos/play/wwdc2021/10040/\u003e",
          "ts": "1666111491.285709",
          "thread_ts": "1666110591.186509",
          "attachments": [
            {
              "fallback": "Apple Developer: Detect people, faces, and poses using Vision - WWDC21 - Videos - Apple Developer",
              "id": 1,
              "title": "Detect people, faces, and poses using Vision - WWDC21 - Videos - Apple Developer",
              "title_link": "https://developer.apple.com/videos/play/wwdc2021/10040/",
              "text": "Discover the latest updates to the Vision framework to help your apps detect people, faces, and poses. Meet the Person Segmentation API,...",
              "image_url": "https://devimages-cdn.apple.com/wwdc-services/images/119/4930/4930_wide_250x141_2x.jpg",
              "service_name": "Apple Developer",
              "service_icon": "https://developer.apple.com/favicon.ico",
              "from_url": "https://developer.apple.com/videos/play/wwdc2021/10040/",
              "original_url": "https://developer.apple.com/videos/play/wwdc2021/10040/",
              "blocks": null
            }
          ],
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Q1S+Q",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "This might be possible by using Vision framework: "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/videos/play/wwdc2021/10040/",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "c3e4742c-7a04-474a-be47-c73ba24e60fb",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "Though it will be challenging to map the size of the person in pixels to a size in the real world. For that you might have to perform a raycast in ARKit to map a 2D sceen space location to a 3D location on the user’s head.",
          "ts": "1666111556.715729",
          "thread_ts": "1666110591.186509",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "9JDMg",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Though it will be challenging to map the size of the person in pixels to a size in the real world. For that you might have to perform a raycast in ARKit to map a 2D sceen space location to a 3D location on the user’s head."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U0466UZLPEY\u003e asked\n\u0026gt; Hello Apple. Thank you for this opportunity. I have 2 questions: \n\u0026gt; 1. I asked one in StackOverflow: \u003chttps://stackoverflow.com/questions/73554321/why-is-arsession-restarted-session-slowly|https://stackoverflow.com/questions/73554321/why-is-arsession-restarted-session-slowly\u003e\n\u0026gt; 2. I need to change ARKit camera to wide angle. Because I need capture during ARKit session is running. But with current ARKit camera(as I know it is builtInWideAngleCamera) captured image quality is a little low. I am going to use builtInUltraWideCamera. How can I do this?\n\u0026gt; Thank you in advance.",
      "ts": "1666110646.608909",
      "thread_ts": "1666110646.608909",
      "attachments": [
        {
          "fallback": "Stack Overflow: Why is ARSession restarted session slowly?",
          "id": 1,
          "title": "Why is ARSession restarted session slowly?",
          "title_link": "https://stackoverflow.com/questions/73554321/why-is-arsession-restarted-session-slowly",
          "text": "I am using ARKit for my AR application. I need frequently start and stop ARSession. But when I restart ARSession after stopping it is going to normal state slowly then initial start. It means resta...",
          "thumb_url": "https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon@2.png?v=73d79a89bded",
          "service_name": "Stack Overflow",
          "service_icon": "https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon.png?v=c78bd457575a",
          "from_url": "https://stackoverflow.com/questions/73554321/why-is-arsession-restarted-session-slowly",
          "original_url": "https://stackoverflow.com/questions/73554321/why-is-arsession-restarted-session-slowly",
          "blocks": null
        }
      ],
      "edited": {
        "user": "B043728TUAY",
        "ts": "1666110647.000000"
      },
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "reply_count": 2,
      "latest_reply": "1666110834.132239",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "ExE",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U0466UZLPEY"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Hello Apple. Thank you for this opportunity. I have 2 questions: \\n1. I asked one in StackOverflow: \"},{\"type\":\"link\",\"url\":\"https:\\/\\/stackoverflow.com\\/questions\\/73554321\\/why-is-arsession-restarted-session-slowly\",\"text\":\"https:\\/\\/stackoverflow.com\\/questions\\/73554321\\/why-is-arsession-restarted-session-slowly\"},{\"type\":\"text\",\"text\":\"\\n2. I need to change ARKit camera to wide angle. Because I need capture during ARKit session is running. But with current ARKit camera(as I know it is builtInWideAngleCamera) captured image quality is a little low. I am going to use builtInUltraWideCamera. How can I do this?\\nThank you in advance.\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "02c1138d-0904-4383-839c-15cd0f1ccaab",
          "type": "message",
          "user": "U0464NUFLM7",
          "text": "Hi Shohin! You may be referring to ARKit’s relocalization behavior. When you resume an existing session, ARKit by default attempts to relocalize to where it left off for five seconds. During that time, tracking state will be `.limited` with reason `.relocalizing`. You can opt out of this behavior by implementing `sessionShouldAttemptRelocalization` and returning `false`: \u003chttps://developer.apple.com/documentation/arkit/arsessionobserver/2941046-sessionshouldattemptrelocalizati\u003e",
          "ts": "1666110786.077519",
          "thread_ts": "1666110646.608909",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U045WF1CPQE"
              ]
            },
            {
              "name": "eyes",
              "count": 1,
              "users": [
                "U046E6ZLWS0"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "XzJF",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi Shohin! You may be referring to ARKit’s relocalization behavior. When you resume an existing session, ARKit by default attempts to relocalize to where it left off for five seconds. During that time, tracking state will be "
                    },
                    {
                      "type": "text",
                      "text": ".limited",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " with reason "
                    },
                    {
                      "type": "text",
                      "text": ".relocalizing",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": ". You can opt out of this behavior by implementing "
                    },
                    {
                      "type": "text",
                      "text": "sessionShouldAttemptRelocalization",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " and returning "
                    },
                    {
                      "type": "text",
                      "text": "false",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": ": "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/arkit/arsessionobserver/2941046-sessionshouldattemptrelocalizati",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "d490e3a1-a55a-4ab9-875c-8577c6beb97e",
          "type": "message",
          "user": "U0464NUFLM7",
          "text": "To your second question: Unfortunately it is not possible to use the UltraWide camera.",
          "ts": "1666110834.132239",
          "thread_ts": "1666110646.608909",
          "edited": {
            "user": "U0464NUFLM7",
            "ts": "1666110848.000000"
          },
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "O/=J",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "To your second question: Unfortunately it is not possible to use the UltraWide camera."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046E6ZLWS0\u003e asked\n\u0026gt; **iOS16 support for 2 UV maps in USDZ**\n\u0026gt; According to the page comparing the USD features of SceneKit/RealityKit/hdStorm, AR Quick Look on iOS 16 supports not just one, but two UV maps. Please provide a sample USDZ for this feature.",
      "ts": "1666110923.215689",
      "thread_ts": "1666110923.215689",
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "reply_count": 2,
      "latest_reply": "1666111058.337979",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "bo/t",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046E6ZLWS0"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"**iOS16 support for 2 UV maps in USDZ**\\nAccording to the page comparing the USD features of SceneKit\\/RealityKit\\/hdStorm, AR Quick Look on iOS 16 supports not just one, but two UV maps. Please provide a sample USDZ for this feature.\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "e2a50129-f379-4778-a8a5-db1c3aac7868",
          "type": "message",
          "user": "U0449H175SA",
          "text": "Thanks for your feedback, Thomas. We will consider adding a sample USDZ for this feature.",
          "ts": "1666110972.863439",
          "thread_ts": "1666110923.215689",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "raised_hands",
              "count": 1,
              "users": [
                "U046E6ZLWS0"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "w7B",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks for your feedback, Thomas. We will consider adding a sample USDZ for this feature."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "cdfc8fca-9b77-4b0b-9dd5-b453ae5d7692",
          "type": "message",
          "user": "U046E6ZLWS0",
          "text": "Or a USDA token snippet, because of the way it has to be declared to be compatible to ARQL",
          "ts": "1666111058.337979",
          "thread_ts": "1666110923.215689",
          "edited": {
            "user": "U046E6ZLWS0",
            "ts": "1666111143.000000"
          },
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "n/Mc",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Or a USDA token snippet, because of the way it has to be declared to be compatible to ARQL"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U0474DGRFHN\u003e asked\n\u0026gt; This is primarily related to Motion Capture but perhaps broader. Is it possible to save away the video stream + 3d metadata that is utilized when doing 3d motion capture? Ideally I would like to rerun motion capture on a saved video (maybe others would like to apply AR to a video stream).",
      "ts": "1666111367.649709",
      "thread_ts": "1666111367.649709",
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "reply_count": 4,
      "latest_reply": "1666111412.807089",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "16WQ",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U0474DGRFHN"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"This is primarily related to Motion Capture but perhaps broader. Is it possible to save away the video stream + 3d metadata that is utilized when doing 3d motion capture? Ideally I would like to rerun motion capture on a saved video (maybe others would like to apply AR to a video stream).\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "8456f3c2-ac7d-4866-9496-8644661a82ab",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "You can record an ARSession with metadata, e.g. via the Reality Composer app for iOS.",
          "ts": "1666111377.413699",
          "thread_ts": "1666111367.649709",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "uxwb",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "You can record an ARSession with metadata, e.g. via the Reality Composer app for iOS."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "23311ef5-c4b2-4b75-ba16-f3f5338e2a96",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "You can then airdrop that recording to a Mac and replay it via your apps’s scheme settings in Xcode",
          "ts": "1666111389.106529",
          "thread_ts": "1666111367.649709",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "bNrn",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "You can then airdrop that recording to a Mac and replay it via your apps’s scheme settings in Xcode"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "9b4017a3-ff13-488f-b497-d06b7202bfba",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "See this article for details: \u003chttps://developer.apple.com/documentation/arkit/arsession/recording_and_replaying_ar_session_data?language=objc\u003e",
          "ts": "1666111401.248819",
          "thread_ts": "1666111367.649709",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "NHz",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "See this article for details: "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/arkit/arsession/recording_and_replaying_ar_session_data?language=objc",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "4e1966c8-1782-44cc-84ad-315d9fb2d6d7",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "Unfortunately it is not possible to perform the recording while also doing a live motion capture.",
          "ts": "1666111412.807089",
          "thread_ts": "1666111367.649709",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "TGGx",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Unfortunately it is not possible to perform the recording while also doing a live motion capture."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046K9AM4T0\u003e asked\n\u0026gt; How to add a shadow to 3d Object in non-ar mode in reality kit so that the underlying plane edge and the plane itself is not visible?\n\u0026gt; I tried to add shadow in non-ar mode. I am using a planeMesh and casting shadow on it using directional light. But plane edges are visible and also the plane color seems to be different to the ARView even if I set both of them to be of white.",
      "ts": "1666111765.397529",
      "thread_ts": "1666111765.397529",
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "reply_count": 1,
      "latest_reply": "1666112173.803279",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "aMy4P",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046K9AM4T0"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"How to add a shadow to 3d Object in non-ar mode in reality kit so that the underlying plane edge and the plane itself is not visible?\\nI tried to add shadow in non-ar mode. I am using a planeMesh and casting shadow on it using directional light. But plane edges are visible and also the plane color seems to be different to the ARView even if I set both of them to be of white.\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "d863eb18-8c4d-4d71-952f-07fc43cd876f",
          "type": "message",
          "user": "U0459CTJ09H",
          "text": "I don't think this is possible, please file an enhancement request on feedback assistant",
          "ts": "1666112173.803279",
          "thread_ts": "1666111765.397529",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "bjAlh",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I don't think this is possible, please file an enhancement request on feedback assistant"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046K9AM4T0\u003e asked\n\u0026gt; How to cast smooth shadows like AR QuickLook in non-ar mode in RealityKit?",
      "ts": "1666111767.006029",
      "thread_ts": "1666111767.006029",
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "reply_count": 1,
      "latest_reply": "1666112162.985709",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "icqqu",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046K9AM4T0"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"How to cast smooth shadows like AR QuickLook in non-ar mode in RealityKit?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "402e2c84-9022-48f7-9bd6-b75d41e96f2c",
          "type": "message",
          "user": "U0459CTJ09H",
          "text": "I don't think this is possible, please file an enhancement request on feedback assistant",
          "ts": "1666112162.985709",
          "thread_ts": "1666111767.006029",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "U=8n",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I don't think this is possible, please file an enhancement request on feedback assistant"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U0473U8P8J0\u003e asked\n\u0026gt; I am currently playing with ARKit and RealityKit, Reality Composer.  I have a question about coordinate systems for ARImageAnchor, ARGeoAnchors and other anchors.  I created an Xcode project wherein I detect images.  In response, I put up an image entity from a Reality Composer file.  I rotated the image by 15 degrees about the y axis and it appears that the y axis is facing me, not vertical as I had suspected.  I wonder if that it due to the vertical image anchor in the Reality Composer file.  Also, I created a function that will display 3D text using 'MeshResource.generateText'.  I have to rotate the text by -pi/2 to view it.  Thus I have a question and its coordinate system.  I would be nice to have a reference that would explain the various local coordinate systems in detail.",
      "ts": "1666111771.397279",
      "thread_ts": "1666111771.397279",
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "reply_count": 1,
      "latest_reply": "1666111779.242329",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "tsO",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U0473U8P8J0"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"I am currently playing with ARKit and RealityKit, Reality Composer.  I have a question about coordinate systems for ARImageAnchor, ARGeoAnchors and other anchors.  I created an Xcode project wherein I detect images.  In response, I put up an image entity from a Reality Composer file.  I rotated the image by 15 degrees about the y axis and it appears that the y axis is facing me, not vertical as I had suspected.  I wonder if that it due to the vertical image anchor in the Reality Composer file.  Also, I created a function that will display 3D text using 'MeshResource.generateText'.  I have to rotate the text by -pi\\/2 to view it.  Thus I have a question and its coordinate system.  I would be nice to have a reference that would explain the various local coordinate systems in detail.\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "00046b3d-2a16-480f-b63d-605d667ce3f2",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "For the image tracking part: Image anchors in ARKit are defined in the XZ-plane, so the Y axis the normal of the image.",
          "ts": "1666111779.242329",
          "thread_ts": "1666111771.397279",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "9jqk/",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "For the image tracking part: Image anchors in ARKit are defined in the XZ-plane, so the Y axis the normal of the image."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U0465JR5LPN\u003e asked\n\u0026gt; 1 Can i make the arkit scanned model mesh higher quality?",
      "ts": "1666111787.033989",
      "thread_ts": "1666111787.033989",
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "reply_count": 1,
      "latest_reply": "1666112068.232089",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "c2jF",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U0465JR5LPN"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"1 Can i make the arkit scanned model mesh higher quality?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "86e4de30-df7d-4aa0-a339-0d2110237e04",
          "type": "message",
          "user": "U0459CTJ09H",
          "text": "can you provide more clarification?",
          "ts": "1666112068.232089",
          "thread_ts": "1666111787.033989",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "mEkPY",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "can you provide more clarification?"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U047CGGFCU8\u003e asked\n\u0026gt; Is there a way to automatically test an app functionality that uses an `ARSession`? \n\u0026gt; \n\u0026gt; We have automated our logic and UI tests but can't find a way to do it with AR – the record/replay doesn't seem to work in test targets. As a workaround, we have set up a robotic arm that holds an iPhone repeats certain movements when tests are run but it's not scalable. Thanks for your time :)",
      "ts": "1666111811.694769",
      "thread_ts": "1666111811.694769",
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "reply_count": 3,
      "latest_reply": "1666112150.142969",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "Twln",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U047CGGFCU8"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Is there a way to automatically test an app functionality that uses an `ARSession`? \\n\\nWe have automated our logic and UI tests but can't find a way to do it with AR \\u2013 the record\\/replay doesn't seem to work in test targets. As a workaround, we have set up a robotic arm that holds an iPhone repeats certain movements when tests are run but it's not scalable. Thanks for your time :)\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "51fcd8e6-bca8-4176-a587-007f23d6d5bf",
          "type": "message",
          "user": "U044UQFTHMX",
          "text": "ARKit has been primarily built for usage while using it with a physical hand as it takes into account the data from IMU sensors in addition to the imagery that the system captures. It would be best to test this manually for those reasons.",
          "ts": "1666111992.188049",
          "thread_ts": "1666111811.694769",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "rtTdO",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "ARKit has been primarily built for usage while using it with a physical hand as it takes into account the data from IMU sensors in addition to the imagery that the system captures. It would be best to test this manually for those reasons."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "e8fb6feb-1fd3-4304-9630-0251747663e1",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "Though recording and replaying a video from ARKit, as described here \u003chttps://developer.apple.com/documentation/arkit/arsession/recording_and_replaying_ar_session_data?language=objc\u003e should work in a test target.",
          "ts": "1666112134.916369",
          "thread_ts": "1666111811.694769",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "5vjs",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Though recording and replaying a video from ARKit, as described here "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/arkit/arsession/recording_and_replaying_ar_session_data?language=objc",
                      "text": ""
                    },
                    {
                      "type": "text",
                      "text": " should work in a test target."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "c15501d8-1522-40a7-b8ee-684d883e685b",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "And would be a good use of the record/replay feature",
          "ts": "1666112150.142969",
          "thread_ts": "1666111811.694769",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "100",
              "count": 1,
              "users": [
                "U047CGGFCU8"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "X2e",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "And would be a good use of the record/replay feature"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046K9AM4T0\u003e asked\n\u0026gt; Memory is not getting freed up even if we exit out of the AR experience in RealityKit. Is there any way to release that memory?",
      "ts": "1666111852.183179",
      "thread_ts": "1666111852.183179",
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "reply_count": 1,
      "latest_reply": "1666112006.955279",
      "reactions": [
        {
          "name": "eyes",
          "count": 1,
          "users": [
            "U0465JR5LPN"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "hMJE",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046K9AM4T0"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Memory is not getting freed up even if we exit out of the AR experience in RealityKit. Is there any way to release that memory?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "734116aa-92d3-4c41-a385-d0cb91d48953",
          "type": "message",
          "user": "U0459CTJ09H",
          "text": "it would be good to get a bug report about this on feedback assistant. We've seen issues like this before and will need more information to determine if this is a RealityKit issue or an app issue",
          "ts": "1666112006.955279",
          "thread_ts": "1666111852.183179",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "white_check_mark",
              "count": 1,
              "users": [
                "U046K9AM4T0"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "l2ox",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "it would be good to get a bug report about this on feedback assistant. We've seen issues like this before and will need more information to determine if this is a RealityKit issue or an app issue"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U04625MKBGT\u003e asked\n\u0026gt; Is there any object detection API we can combine with ARKit?",
      "ts": "1666111946.417259",
      "thread_ts": "1666111946.417259",
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "reply_count": 2,
      "latest_reply": "1666112010.162389",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "TK8D",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U04625MKBGT"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Is there any object detection API we can combine with ARKit?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "16524165-540a-4805-bac0-df928c259656",
          "type": "message",
          "user": "U044WJQ0YF8",
          "text": "ARKit has a 3D object detection feature. I recommend you to check out this developer sample: \u003chttps://developer.apple.com/documentation/arkit/content_anchors/scanning_and_detecting_3d_objects\u003e",
          "ts": "1666111950.880019",
          "thread_ts": "1666111946.417259",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "nkm",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "ARKit has a 3D object detection feature. I recommend you to check out this developer sample: "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/arkit/content_anchors/scanning_and_detecting_3d_objects",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "08d26325-ae4e-4829-a86b-92014ff4b911",
          "type": "message",
          "user": "U04625MKBGT",
          "text": "thanks!",
          "ts": "1666112010.162389",
          "thread_ts": "1666111946.417259",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U044WJQ0YF8"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "3QE",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "thanks!"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "0e75cebd-dd86-4b06-8b95-9a100fb579cf",
      "type": "message",
      "user": "U0449H175SA",
      "text": "We’re just few minutes away from concluding our Q\u0026amp;A session on ARKit. Looking at some final questions",
      "ts": "1666112303.829109",
      "team": "T03U5MWB2FN",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "a4/n/",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "We’re just few minutes away from concluding our Q\u0026A session on ARKit. Looking at some final questions"
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046A4SKZ99\u003e asked\n\u0026gt; When I use the new 4K capture in ARKit 6 on my iPhone 13 Pro Max, my device quickly heats up (within a minute or 2) and the ARKit frame rate drops to compensate. Is this expected behavior? Do you have any suggested mitigations?",
      "ts": "1666112396.107709",
      "thread_ts": "1666112396.107709",
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "reply_count": 2,
      "latest_reply": "1666112524.070049",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "NkR",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046A4SKZ99"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"When I use the new 4K capture in ARKit 6 on my iPhone 13 Pro Max, my device quickly heats up (within a minute or 2) and the ARKit frame rate drops to compensate. Is this expected behavior? Do you have any suggested mitigations?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "a8c57e31-cf6c-4b29-845c-17ad10c1116f",
          "type": "message",
          "user": "U0459CTJ09H",
          "text": "yes, this is expected behavior, since the device is transitioning to a different power state to cool off",
          "ts": "1666112496.287939",
          "thread_ts": "1666112396.107709",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "R0CR",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "yes, this is expected behavior, since the device is transitioning to a different power state to cool off"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "d73ba59a-bd2c-4de5-8933-f45ca94bef24",
          "type": "message",
          "user": "U046A4SKZ99",
          "text": "I mean, would you expect 4K ARKit capture to cause the device to heat up so quickly?",
          "ts": "1666112524.070049",
          "thread_ts": "1666112396.107709",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "H0aR",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I mean, would you expect 4K ARKit capture to cause the device to heat up so quickly?"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "35f10bec-d6af-4bfc-b225-313cb685b68c",
      "type": "message",
      "user": "U0449H175SA",
      "text": "Thank you for joining us for this Q\u0026amp;A on ARKit! We hope you enjoyed this as much as we did :sunglasses:. While we’re finished answering questions on ARKit for now the workflow will remain published. Our next event is Q\u0026amp;A: RoomPlan at _9am PT Thursday_. If you’re unable to join us live, you can send in your questions. As a reminder, please keep your questions scoped to that topic. We’ll be back with more Q\u0026amp;A soon!",
      "ts": "1666112666.533759",
      "team": "T03U5MWB2FN",
      "reactions": [
        {
          "name": "+1",
          "count": 1,
          "users": [
            "U04678YRK98"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "5cMA",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Thank you for joining us for this Q\u0026A on ARKit! We hope you enjoyed this as much as we did "
                },
                {
                  "type": "emoji",
                  "name": "sunglasses",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": ". While we’re finished answering questions on ARKit for now the workflow will remain published. Our next event is Q\u0026A: RoomPlan at "
                },
                {
                  "type": "text",
                  "text": "9am PT Thursday",
                  "style": {
                    "italic": true
                  }
                },
                {
                  "type": "text",
                  "text": ". If you’re unable to join us live, you can send in your questions. As a reminder, please keep your questions scoped to that topic. We’ll be back with more Q\u0026A soon!"
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "f1dbcd25-13ac-4ef8-b01f-6511997e1f64",
      "type": "message",
      "user": "U0449H175SA",
      "text": "Hello again. We’re just 1 hour away from kicking off our activity Q\u0026amp;A: RoomPlan at 9am PT. We hope you can join us then!\nIn the meantime please submit your questions. We’ll start answering them at 9am PT.",
      "ts": "1666278663.004629",
      "team": "T03U5MWB2FN",
      "reactions": [
        {
          "name": "swift-orange",
          "count": 1,
          "users": [
            "U04678YRK98"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "e6I",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Hello again. We’re just 1 hour away from kicking off our activity Q\u0026A: RoomPlan at 9am PT. We hope you can join us then!\nIn the meantime please submit your questions. We’ll start answering them at 9am PT."
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "05035ee1-ac2b-4da1-9be1-879f4c0655e0",
      "type": "message",
      "user": "U0449H175SA",
      "text": "Welcome to our second activity this week, Q\u0026amp;A: RoomPlan! We’re looking forward to answering your questions. Select the:heavy_plus_sign:icon from the lower left, and find the _Ask A Question_ workflow for Q\u0026amp;A: RoomPlan. Type in your question and it will be delivered directly to the team. As a reminder, please keep your questions scoped to that topic.\n\nLet’s kick it off! :mirror_ball:",
      "ts": "1666281652.935609",
      "team": "T03U5MWB2FN",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "Ukw7",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Welcome to our second activity this week, Q\u0026A: RoomPlan! We’re looking forward to answering your questions. Select the"
                },
                {
                  "type": "emoji",
                  "name": "heavy_plus_sign",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": "icon from the lower left, and find the "
                },
                {
                  "type": "text",
                  "text": "Ask A Question",
                  "style": {
                    "italic": true
                  }
                },
                {
                  "type": "text",
                  "text": " workflow for Q\u0026A: RoomPlan. Type in your question and it will be delivered directly to the team. As a reminder, please keep your questions scoped to that topic.\n\nLet’s kick it off! "
                },
                {
                  "type": "emoji",
                  "name": "mirror_ball",
                  "skin_tone": 0
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046B4CEBU7\u003e asked\n\u0026gt; Hi,\n\u0026gt; We've tested RoomPlan and it is very impressive!\n\u0026gt; One caveat is that when the room is not squarish in shape, e.g. if the wall has a curvature, RoomPlan does not seem to work well. \n\u0026gt; Is there any plan to improve scanning results on curved walls?\n\u0026gt; Thanks.",
      "ts": "1666281901.527959",
      "thread_ts": "1666281901.527959",
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "reply_count": 1,
      "latest_reply": "1666281940.468039",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "BQPG",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046B4CEBU7"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Hi,\\nWe've tested RoomPlan and it is very impressive!\\nOne caveat is that when the room is not squarish in shape, e.g. if the wall has a curvature, RoomPlan does not seem to work well. \\nIs there any plan to improve scanning results on curved walls?\\nThanks.\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "cdf3f756-0b0a-44fd-a48a-bf262e61cd93",
          "type": "message",
          "user": "U045245RL93",
          "text": "Thanks Steven for the interest and feedback. Curved wall is indeed one area we plan to further improve. If you have any visualization or samples of the particular issues you are seeing on curved walls, please send to us via Feedback Assistant. Thanks!",
          "ts": "1666281940.468039",
          "thread_ts": "1666281901.527959",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "eyes",
              "count": 1,
              "users": [
                "U046B4CEBU7"
              ]
            },
            {
              "name": "white_check_mark",
              "count": 1,
              "users": [
                "U046B4CEBU7"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Uts/7",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks Steven for the interest and feedback. Curved wall is indeed one area we plan to further improve. If you have any visualization or samples of the particular issues you are seeing on curved walls, please send to us via Feedback Assistant. Thanks!"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "1871db71-b60f-43fe-b8e2-3b78f5b23caf",
      "type": "message",
      "user": "U0449H175SA",
      "text": "While you’re still typing up your questions for us, here are some most frequent asked questions from the RoomPlan community :heart:",
      "ts": "1666282579.937679",
      "team": "T03U5MWB2FN",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "ZwvU8",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "While you’re still typing up your questions for us, here are some most frequent asked questions from the RoomPlan community "
                },
                {
                  "type": "emoji",
                  "name": "heart",
                  "skin_tone": 0
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "85c8833d-57b2-4aab-8b63-b1a039f93624",
      "type": "message",
      "user": "U044UQFTHMX",
      "text": "_FAQ: Is there a way to set LiDAR as a Required Device Capability?_",
      "ts": "1666282679.576989",
      "thread_ts": "1666282679.576989",
      "reply_count": 1,
      "latest_reply": "1666282753.904009",
      "team": "T03U5MWB2FN",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "UfS",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "FAQ: Is there a way to set LiDAR as a Required Device Capability?",
                  "style": {
                    "italic": true
                  }
                }
              ]
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "b89f9439-e762-42f9-9ec2-076dde9cdb41",
          "type": "message",
          "user": "U044UQFTHMX",
          "text": "You may check for device support using the boolean field `RoomCaptureSession.isSupported`",
          "ts": "1666282753.904009",
          "thread_ts": "1666282679.576989",
          "parent_user_id": "U044UQFTHMX",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "BLzM",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "You may check for device support using the boolean field "
                    },
                    {
                      "type": "text",
                      "text": "RoomCaptureSession.isSupported",
                      "style": {
                        "code": true
                      }
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "e7f5cdc4-2fe3-4d21-9c73-5539901e0040",
      "type": "message",
      "user": "U044UQFTHMX",
      "text": "_FAQ: What are the type of objects that RoomPlan recognizes in a room?_",
      "ts": "1666282925.862609",
      "thread_ts": "1666282925.862609",
      "reply_count": 1,
      "latest_reply": "1666282962.912499",
      "team": "T03U5MWB2FN",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "GE1b",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "FAQ: What are the type of objects that RoomPlan recognizes in a room?",
                  "style": {
                    "italic": true
                  }
                }
              ]
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "8ac21a8c-53c7-46ac-829d-2ecc0566d526",
          "type": "message",
          "user": "U044UQFTHMX",
          "text": "You can find the supported object categories at: \u003chttps://developer.apple.com/documentation/roomplan/capturedroom/object/category-swift.enum\u003e",
          "ts": "1666282962.912499",
          "thread_ts": "1666282925.862609",
          "parent_user_id": "U044UQFTHMX",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "wfeF",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "You can find the supported object categories at: "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/roomplan/capturedroom/object/category-swift.enum",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "a7001050-42e5-4e27-976e-d97affcc6238",
      "type": "message",
      "user": "U044UQFTHMX",
      "text": "_FAQ: Is is possible to use my own custom ML model with RoomPlan?_",
      "ts": "1666283075.068469",
      "thread_ts": "1666283075.068469",
      "reply_count": 1,
      "latest_reply": "1666283177.712009",
      "team": "T03U5MWB2FN",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "VtoZc",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "FAQ: Is is possible to use my own custom ML model with RoomPlan?",
                  "style": {
                    "italic": true
                  }
                }
              ]
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "52f62ca4-15dc-459b-b210-22188cb4d9da",
          "type": "message",
          "user": "U044UQFTHMX",
          "text": "Currently we do not support custom ML models out of the box in RoomPlan. However, you should still be able to use the image data from the ARSession instance and run them through your custom ML model.",
          "ts": "1666283177.712009",
          "thread_ts": "1666283075.068469",
          "parent_user_id": "U044UQFTHMX",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "d=U",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Currently we do not support custom ML models out of the box in RoomPlan. However, you should still be able to use the image data from the ARSession instance and run them through your custom ML model."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "1656d8d3-fc5e-463c-855d-747ed38e3fe9",
      "type": "message",
      "user": "U044UQFTHMX",
      "text": "_FAQ: How can I generate a 2D floor plan along with dimensions using RoomPlan?_",
      "ts": "1666283310.157489",
      "thread_ts": "1666283310.157489",
      "reply_count": 1,
      "latest_reply": "1666283351.340449",
      "team": "T03U5MWB2FN",
      "reactions": [
        {
          "name": "clap",
          "count": 1,
          "users": [
            "U044WGBSFEH"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "iBAHt",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "FAQ: How can I generate a 2D floor plan along with dimensions using RoomPlan?",
                  "style": {
                    "italic": true
                  }
                }
              ]
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "c382f18f-8fb0-4ef4-986d-0f37dee6538e",
          "type": "message",
          "user": "U044UQFTHMX",
          "text": "RoomPlan outputs a 3D floor plan. You may set the z-coordinate to 0, which will flatten it and thus give you a 2D top-down floor plan.",
          "ts": "1666283351.340449",
          "thread_ts": "1666283310.157489",
          "parent_user_id": "U044UQFTHMX",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "P9Md",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "RoomPlan outputs a 3D floor plan. You may set the z-coordinate to 0, which will flatten it and thus give you a 2D top-down floor plan."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U04625MKBGT\u003e asked\n\u0026gt; What's the biggest size of a room we can scan.",
      "ts": "1666283500.641439",
      "thread_ts": "1666283500.641439",
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "reply_count": 1,
      "latest_reply": "1666283545.779789",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "CtZx",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U04625MKBGT"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"What's the biggest size of a room we can scan.\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "e133b59e-e205-4fce-9e9c-4455b04150b0",
          "type": "message",
          "user": "U045245RL93",
          "text": "We recommend room sizes within 30ft by 30ft (9m by 9m) to have the best user experiences.",
          "ts": "1666283545.779789",
          "thread_ts": "1666283500.641439",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "0CU",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "We recommend room sizes within 30ft by 30ft (9m by 9m) to have the best user experiences."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U04625MKBGT\u003e asked\n\u0026gt; Are there any plans to add some textures to the captures using a combined Photogrammetry Session for example ?",
      "ts": "1666283769.868509",
      "thread_ts": "1666283769.868509",
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "reply_count": 1,
      "latest_reply": "1666283880.468099",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "BQWoi",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U04625MKBGT"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Are there any plans to add some textures to the captures using a combined Photogrammetry Session for example ?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "eafdf508-4cc3-44ae-b700-8bd2157c3672",
          "type": "message",
          "user": "U044UQFTHMX",
          "text": "Thank you for your suggestion. We always welcome feedback on how to improve RoomPlan experience. It would be great if you could outline your use case and reach out to us through \u003chttps://feedbackassistant.apple.com\u003e",
          "ts": "1666283880.468099",
          "thread_ts": "1666283769.868509",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "white_check_mark",
              "count": 1,
              "users": [
                "U04625MKBGT"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "6oNg",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thank you for your suggestion. We always welcome feedback on how to improve RoomPlan experience. It would be great if you could outline your use case and reach out to us through "
                    },
                    {
                      "type": "link",
                      "url": "https://feedbackassistant.apple.com",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "78b18d88-e206-48b9-96d9-0dc20af6d5b5",
      "type": "message",
      "user": "U0449H175SA",
      "text": "Switching gears here :gear:. We’d love to hear from you what improvements and new features you would like to see for RoomPlan?",
      "ts": "1666284084.737869",
      "team": "T03U5MWB2FN",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "0=N",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Switching gears here "
                },
                {
                  "type": "emoji",
                  "name": "gear",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": ". We’d love to hear from you what improvements and new features you would like to see for RoomPlan?"
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U04625MKBGT\u003e asked\n\u0026gt; Would love to be able to capture multiple rooms in an apartment for example or gallery space and combine them",
      "ts": "1666284694.164339",
      "thread_ts": "1666284694.164339",
      "subtype": "bot_message",
      "bot_id": "B043728TUAY",
      "username": "Ask Apple - augmented-reality",
      "reply_count": 3,
      "latest_reply": "1666284879.138419",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "Gt2RS",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U04625MKBGT"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Would love to be able to capture multiple rooms in an apartment for example or gallery space and combine them\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "4c84873e-533a-4f15-8aab-c21c99190fda",
          "type": "message",
          "user": "U045UPLHSN4",
          "text": "Thank you for this suggestion. It’s already possible today to scan individual rooms and then stitch them together manually, but we will definitely consider your feedback for future API improvements.",
          "ts": "1666284716.133899",
          "thread_ts": "1666284694.164339",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "LkJ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thank you for this suggestion. It’s already possible today to scan individual rooms and then stitch them together manually, but we will definitely consider your feedback for future API improvements."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "91d9c426-4f11-4d5b-b0cd-77b063961bab",
          "type": "message",
          "user": "U04625MKBGT",
          "text": "yes but trying to do as much on device as possible.",
          "ts": "1666284860.468589",
          "thread_ts": "1666284694.164339",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "+1",
              "count": 2,
              "users": [
                "U0449H175SA",
                "U045245RL93"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "AzKD",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "yes but trying to do as much on device as possible."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "d437355b-aaa7-46cd-8c39-655dd2cdaeed",
          "type": "message",
          "user": "U04625MKBGT",
          "text": "thanks for taking note",
          "ts": "1666284879.138419",
          "thread_ts": "1666284694.164339",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "z7kh",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "thanks for taking note"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "d33e8e28-8dc4-4698-b93f-78a252e5a660",
      "type": "message",
      "user": "U044UQFTHMX",
      "text": "_FAQ: What output file formats does RoomPlan export to?_",
      "ts": "1666284820.194019",
      "thread_ts": "1666284820.194019",
      "reply_count": 4,
      "latest_reply": "1666285298.403979",
      "team": "T03U5MWB2FN",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "dZk",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "FAQ: What output file formats does RoomPlan export to?",
                  "style": {
                    "italic": true
                  }
                }
              ]
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "567bcfa6-ab4e-430e-be66-c7338dafc3e3",
          "type": "message",
          "user": "U044UQFTHMX",
          "text": "You may use this API, `CaptuedRoom.export` to export USD format like USD/USDA/USDZ). You can also parse the `CapturedRoom` structures to do a custom conversion.\n\u003chttps://developer.apple.com/documentation/roomplan/capturedroom/usdexportoptions\u003e",
          "ts": "1666284963.810219",
          "thread_ts": "1666284820.194019",
          "parent_user_id": "U044UQFTHMX",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "sTsVR",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "You may use this API, "
                    },
                    {
                      "type": "text",
                      "text": "CaptuedRoom.export",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " to export USD format like USD/USDA/USDZ). You can also parse the "
                    },
                    {
                      "type": "text",
                      "text": "CapturedRoom",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " structures to do a custom conversion.\n"
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/roomplan/capturedroom/usdexportoptions",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "e9c00162-79fe-4f71-98c5-0f9ad019f08e",
          "type": "message",
          "user": "U04625MKBGT",
          "text": "would that enable us to do semantic exclusions for let's say room but without tables ?",
          "ts": "1666285120.651409",
          "thread_ts": "1666284820.194019",
          "parent_user_id": "U044UQFTHMX",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "sj3V/",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "would that enable us to do semantic exclusions for let's say room but without tables ?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "1584db91-86ac-4436-891e-c577049afa6c",
          "type": "message",
          "user": "U044UQFTHMX",
          "text": "Yes, you should be able to exclude any objects that you desire to filter out before saving it to a usdz file",
          "ts": "1666285274.185509",
          "thread_ts": "1666284820.194019",
          "parent_user_id": "U044UQFTHMX",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "raised_hands",
              "count": 1,
              "users": [
                "U04625MKBGT"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "RdL",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Yes, you should be able to exclude any objects that you desire to filter out before saving it to a usdz file"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "d43459d9-5751-4ad9-bf41-8367b6c6a045",
          "type": "message",
          "user": "U04625MKBGT",
          "text": "that's a great feature",
          "ts": "1666285298.403979",
          "thread_ts": "1666284820.194019",
          "parent_user_id": "U044UQFTHMX",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "heart",
              "count": 1,
              "users": [
                "U044UQFTHMX"
              ]
            },
            {
              "name": "gratitude-thank-you",
              "count": 1,
              "users": [
                "U044UQFTHMX"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "+DA",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "that's a great feature"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "5272665b-9a6f-4f4f-a56a-2b42d3a30846",
      "type": "message",
      "user": "U044UQFTHMX",
      "text": "_FAQ: Does RoomPlan process the output all on device?_",
      "ts": "1666285162.284329",
      "thread_ts": "1666285162.284329",
      "reply_count": 1,
      "latest_reply": "1666285193.010109",
      "team": "T03U5MWB2FN",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "C2Wjq",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "FAQ: Does RoomPlan process the output all on device?",
                  "style": {
                    "italic": true
                  }
                }
              ]
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "0bf251eb-8876-45cb-8ea9-d98f2563e784",
          "type": "message",
          "user": "U044UQFTHMX",
          "text": "Yes. RoomPlan processes the output all on device. The data never leaves the devices and thus protects user privacy!",
          "ts": "1666285193.010109",
          "thread_ts": "1666285162.284329",
          "parent_user_id": "U044UQFTHMX",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "X6Q1",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Yes. RoomPlan processes the output all on device. The data never leaves the devices and thus protects user privacy!"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "0b7a4cbd-3c07-4dc7-87f6-906608aa7963",
      "type": "message",
      "user": "U0449H175SA",
      "text": "Thank you for joining us for this Q\u0026amp;A! With that our Q\u0026amp;A activities have concluded. For any remaining questions or feedback that you’d like to share with us, here are some next steps:\n• File feedback! Let us know what’s not clear or what behavior seems a bit off by using the Feedback Assistant app or going to: \u003chttp://feedbackassistant.apple.com|feedbackassistant.apple.com\u003e\n• Ask a question on the Apple Developer Forums: \u003chttps://developer.apple.com/forums/\u003e\n• Submit a TSI. Developer Technical Support engineers are available to give you code-level support. You can submit a TSI here: \u003chttps://developer.apple.com/support/technical/\u003e\nWe’ll be closing the workflow now. Thank you so much for making this such an engaging week!",
      "ts": "1666285299.350749",
      "attachments": [
        {
          "fallback": "Apple Developer Forums",
          "id": 1,
          "title": "Apple Developer Forums",
          "title_link": "https://developer.apple.com/forums/",
          "text": "Connect with fellow developers and Apple experts as you give and receive help on a wide variety of development topics, from implementing new technologies to established best practices",
          "service_name": "developer.apple.com",
          "service_icon": "https://forums.developer.apple.com/forums/build-09152022-1/public/assets/favicon.ico",
          "from_url": "https://developer.apple.com/forums/",
          "original_url": "https://developer.apple.com/forums/",
          "blocks": null
        },
        {
          "fallback": "Requesting Technical Support - Support - Apple Developer",
          "id": 2,
          "title": "Requesting Technical Support - Support - Apple Developer",
          "title_link": "https://developer.apple.com/support/technical/",
          "text": "Learn how to receive code-level help from an Apple engineer by submitting a Technical Support Incident.",
          "service_name": "developer.apple.com",
          "service_icon": "https://developer.apple.com/favicon.ico",
          "from_url": "https://developer.apple.com/support/technical/",
          "original_url": "https://developer.apple.com/support/technical/",
          "blocks": null
        }
      ],
      "team": "T03U5MWB2FN",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "MhB",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Thank you for joining us for this Q\u0026A! With that our Q\u0026A activities have concluded. For any remaining questions or feedback that you’d like to share with us, here are some next steps:\n"
                }
              ]
            },
            {
              "Type": "rich_text_list",
              "Raw": "{\"type\":\"rich_text_list\",\"elements\":[{\"type\":\"rich_text_section\",\"elements\":[{\"type\":\"text\",\"text\":\"File feedback! Let us know what\\u2019s not clear or what behavior seems a bit off by using the Feedback Assistant app or going to: \"},{\"type\":\"link\",\"url\":\"http:\\/\\/feedbackassistant.apple.com\",\"text\":\"feedbackassistant.apple.com\"}]},{\"type\":\"rich_text_section\",\"elements\":[{\"type\":\"text\",\"text\":\"Ask a question on the Apple Developer Forums: \"},{\"type\":\"link\",\"url\":\"https:\\/\\/developer.apple.com\\/forums\\/\"}]},{\"type\":\"rich_text_section\",\"elements\":[{\"type\":\"text\",\"text\":\"Submit a TSI. Developer Technical Support engineers are available to give you code-level support. You can submit a TSI here: \"},{\"type\":\"link\",\"url\":\"https:\\/\\/developer.apple.com\\/support\\/technical\\/\"}]}],\"style\":\"bullet\",\"indent\":0,\"border\":0}"
            },
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "\nWe’ll be closing the workflow now. Thank you so much for making this such an engaging week!"
                }
              ]
            }
          ]
        }
      ]
    }
  ],
  "channel_id": "C0432FLR8G4"
}
