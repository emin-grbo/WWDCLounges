{
  "name": "accessibility",
  "messages": [
    {
      "type": "message",
      "user": "U03V30M0C1K",
      "text": "This content can't be displayed.",
      "ts": "1665432740.963829",
      "thread_ts": "1665432740.963829",
      "pinned_to": [
        "C0432BW1HN0"
      ],
      "reply_count": 1,
      "latest_reply": "1666301034.493009",
      "team": "T03U5MWB2FN",
      "reactions": [
        {
          "name": "raised_hands",
          "count": 10,
          "users": [
            "U046368HTM1",
            "U046G37DF33",
            "U0465FCQK43",
            "U04632FDSNS",
            "U045X3WH4CE",
            "U04680XMJN9",
            "U045X6PBB8F",
            "U0479KYC6CQ",
            "U0468SB0YNB",
            "U046PANNT43"
          ]
        },
        {
          "name": "flag-ua",
          "count": 1,
          "users": [
            "U046MM68XB4"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "header",
          "text": {
            "type": "plain_text",
            "text": "Welcome to Ask Apple",
            "emoji": true
          },
          "block_id": "VVYfG"
        },
        {
          "type": "section",
          "text": {
            "type": "mrkdwn",
            "text": "We're excited to be hosting you in the Accessibility channel this week! You can find the full schedule of Q\u0026amp;As for Accessibility by visiting the \u003chttps://apps.apple.com/us/app/apple-developer/id640199958 | Apple Developer app\u003e and \u003chttps://developer.apple.com/events/ask-apple/questions-and-answers/ | website\u003e."
          },
          "block_id": "7rs0"
        },
        {
          "type": "section",
          "text": {
            "type": "mrkdwn",
            "text": "If you haven’t already, please take a moment to familiarize yourself with \u003chttps://developer.apple.com/news/?id=vpbyzfg4 | how Q\u0026amp;As will work\u003e."
          },
          "block_id": "rIr0e"
        },
        {
          "type": "header",
          "text": {
            "type": "plain_text",
            "text": "Attendance Policy",
            "emoji": true
          },
          "block_id": "Lvh"
        },
        {
          "type": "section",
          "text": {
            "type": "mrkdwn",
            "text": "We want to make sure these spaces are helpful and welcoming for everyone — developers and Apple employees alike. Please review and follow the \u003chttps://developer.apple.com/events/policy/online-event-attendance-policy/ | attendance policy\u003e."
          },
          "block_id": "3gWjn"
        }
      ],
      "slackdump_thread_replies": [
        {
          "type": "message",
          "user": "U04678YRK98",
          "text": "Hello Team ,\nI would like to learn about Augmented Reality \u0026amp; Virtual Reality for 100 Individual Workspaces for students in Schools and University’s.Apple’s Workspace with MacBook Air,  iMac , iPad Pro ,iPhone,AirPods Max, HomePod mini,Phone Lightning Dock and All Hardware Mounts.Apple to the next Level for students.Upgrading the Universe.\tApple’s Upgrade Entry to Global Education and Asset Management.Integration with 30 % Institutions Worldwide with Apple’s Supply Chain.",
          "ts": "1666301034.493009",
          "thread_ts": "1665432740.963829",
          "subtype": "moderated",
          "parent_user_id": "U03V30M0C1K",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "JPu+",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hello Team ,\nI would like to learn about Augmented Reality \u0026 Virtual Reality for 100 Individual Workspaces for students in Schools and University’s.Apple’s Workspace with MacBook Air,  iMac , iPad Pro ,iPhone,AirPods Max, HomePod mini,Phone Lightning Dock and All Hardware Mounts.Apple to the next Level for students.Upgrading the Universe.\tApple’s Upgrade Entry to Global Education and Asset Management.Integration with 30 % Institutions Worldwide with Apple’s Supply Chain."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03V30M0C1K\u003e added a workflow to this channel: *Ask Apple - accessibility*.",
      "ts": "1666018836.580109",
      "subtype": "bot_message",
      "bot_id": "B0434N8CV28",
      "username": "Ask Apple - accessibility",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "mFO",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03V30M0C1K"
                },
                {
                  "type": "text",
                  "text": " added a workflow to this channel: "
                },
                {
                  "type": "text",
                  "text": "Ask Apple - accessibility",
                  "style": {
                    "bold": true
                  }
                },
                {
                  "type": "text",
                  "text": "."
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "f96a7cc7-3cc7-4231-a908-52e3dbc3cd2a",
      "type": "message",
      "user": "U0449LGV1FV",
      "text": ":mechanical_arm: Welcome to the Apple Accessibility channel! We'll be here to answer all your programming, design and experiential questions about assistive technology and accessibility. Our first activity is Tuesday, 1PM PDT -- \"An Apple Watch For Everyone\" -- which will be a fun introduction to how technology can help everyone.\n\nYou can begin sending in your questions that are related to Accessibility now. Select the:heavy_plus_sign:icon from the lower left, and find the _Ask A Question_ workflow. Type in your question and it will be delivered directly to the team. We'll start answering them during our event time tomorrow :+1:",
      "ts": "1666020168.339539",
      "team": "T03U5MWB2FN",
      "reactions": [
        {
          "name": "tada",
          "count": 8,
          "users": [
            "U03V30M0C1K",
            "U046ES912UR",
            "U0465R7QB3N",
            "U045Q0J840P",
            "U046DJLPUUS",
            "U0449J0BZGW",
            "U04631JRW83",
            "U046G37DF33"
          ]
        },
        {
          "name": "watch",
          "count": 2,
          "users": [
            "U0449J0BZGW",
            "U04631JRW83"
          ]
        },
        {
          "name": "+1",
          "count": 1,
          "users": [
            "U0467TW5ESE"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "pJs",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "emoji",
                  "name": "mechanical_arm",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": " Welcome to the Apple Accessibility channel! We'll be here to answer all your programming, design and experiential questions about assistive technology and accessibility. Our first activity is Tuesday, 1PM PDT -- \"An Apple Watch For Everyone\" -- which will be a fun introduction to how technology can help everyone.\n\nYou can begin sending in your questions that are related to Accessibility now. Select the"
                },
                {
                  "type": "emoji",
                  "name": "heavy_plus_sign",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": "icon from the lower left, and find the "
                },
                {
                  "type": "text",
                  "text": "Ask A Question",
                  "style": {
                    "italic": true
                  }
                },
                {
                  "type": "text",
                  "text": " workflow. Type in your question and it will be delivered directly to the team. We'll start answering them during our event time tomorrow "
                },
                {
                  "type": "emoji",
                  "name": "+1",
                  "skin_tone": 0
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "7405dcd0-45de-4e76-8314-d30759eacb89",
      "type": "message",
      "user": "U044D824R8V",
      "text": "Hi everyone! We are excited to start our first Q\u0026amp;A in just under an hour: \"An Apple Watch for Everyone\" at 1 PM PDT! If you can't join us live, hit the :heavy_plus_sign: icon from the lower left and use the \"Ask a Question\" workflow to submit your questions in advance, and our accessibility experts will be on hand to answer as many as we can. We look forward to chatting with you soon!",
      "ts": "1666120228.284359",
      "team": "T03U5MWB2FN",
      "reactions": [
        {
          "name": "rocket",
          "count": 6,
          "users": [
            "U03V30M0C1K",
            "U0465R7QB3N",
            "U046J102475",
            "U046DA9R188",
            "U046G37DF33",
            "U0449J0BZGW"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "1SDA",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Hi everyone! We are excited to start our first Q\u0026A in just under an hour: \"An Apple Watch for Everyone\" at 1 PM PDT! If you can't join us live, hit the "
                },
                {
                  "type": "emoji",
                  "name": "heavy_plus_sign",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": " icon from the lower left and use the \"Ask a Question\" workflow to submit your questions in advance, and our accessibility experts will be on hand to answer as many as we can. We look forward to chatting with you soon!"
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "47def35d-941b-42b8-9df3-51177aa2de07",
      "type": "message",
      "user": "U044D824R8V",
      "text": "Welcome to An Apple Watch for Everyone! We’re excited to answer your questions. Select the:heavy_plus_sign:icon from the lower left, and find the _Ask A Question_ workflow. Type in your question and it will be delivered directly to our accessibility experts. We’ll answer as many questions as we can. While we may not be able to answer every question, we appreciate all of your submissions; thank you for taking the time to join us! :rocket:",
      "ts": "1666123216.266599",
      "team": "T03U5MWB2FN",
      "reactions": [
        {
          "name": "watch",
          "count": 3,
          "users": [
            "U03V30M0C1K",
            "U044D822929",
            "U0449J0BZGW"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "/y9YG",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Welcome to An Apple Watch for Everyone! We’re excited to answer your questions. Select the"
                },
                {
                  "type": "emoji",
                  "name": "heavy_plus_sign",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": "icon from the lower left, and find the "
                },
                {
                  "type": "text",
                  "text": "Ask A Question",
                  "style": {
                    "italic": true
                  }
                },
                {
                  "type": "text",
                  "text": " workflow. Type in your question and it will be delivered directly to our accessibility experts. We’ll answer as many questions as we can. While we may not be able to answer every question, we appreciate all of your submissions; thank you for taking the time to join us! "
                },
                {
                  "type": "emoji",
                  "name": "rocket",
                  "skin_tone": 0
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "5df32ace-7ded-46ba-8dcb-72e7e96b6e26",
      "type": "message",
      "user": "U044D824R8V",
      "text": "While we are hanging out, what's everyone's favorite accessibility feature on the watch? My personal favorite is AssistiveTouch! It's so cool to be able to use my apple watch with one hand. :smile:",
      "ts": "1666123800.971049",
      "thread_ts": "1666123800.971049",
      "reply_count": 2,
      "latest_reply": "1666124584.908039",
      "team": "T03U5MWB2FN",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "N4Ta",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "While we are hanging out, what's everyone's favorite accessibility feature on the watch? My personal favorite is AssistiveTouch! It's so cool to be able to use my apple watch with one hand. "
                },
                {
                  "type": "emoji",
                  "name": "smile",
                  "skin_tone": 0
                }
              ]
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "a61fde0a-3e46-44f4-a59d-662ac7afa24f",
          "type": "message",
          "user": "U046JND8CKB",
          "text": "I love the look of AssistiveTouch, I keep meaning to try it out",
          "ts": "1666123861.473289",
          "thread_ts": "1666123800.971049",
          "parent_user_id": "U044D824R8V",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "heart",
              "count": 1,
              "users": [
                "U044D824R8V"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "2TTJ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I love the look of AssistiveTouch, I keep meaning to try it out"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "098a8d31-ab84-435d-9c3e-bc1ba39d28c4",
          "type": "message",
          "user": "U03V30M0C1K",
          "text": "As your Framework Evangelist for Accessibility, perhaps I might be biased. But my favorite thing about the accessible nature of the Apple Watch is what a fantastic job the engineering teams have done in ensuring you as developers have the tools to create a wonderful, inclusive experience!! :heart:",
          "ts": "1666124584.908039",
          "thread_ts": "1666123800.971049",
          "parent_user_id": "U044D824R8V",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "rocket",
              "count": 1,
              "users": [
                "U044D824R8V"
              ]
            },
            {
              "name": "hammer_and_wrench",
              "count": 1,
              "users": [
                "U044D824R8V"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "TaO",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "As your Framework Evangelist for Accessibility, perhaps I might be biased. But my favorite thing about the accessible nature of the Apple Watch is what a fantastic job the engineering teams have done in ensuring you as developers have the tools to create a wonderful, inclusive experience!! "
                    },
                    {
                      "type": "emoji",
                      "name": "heart",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046JMFLKV3\u003e asked\n\u0026gt; Hi! Not sure what kind of questions to ask for the \"An Apple Watch for everyone\" Q\u0026amp;A ; but I want to send to you a big up for all the accessibility work at Apple. I love all the investment and all the accessibility tech in Apple product, as well that I love how the API are neat and nice to use. It's never been easier to create accessible apps ; so yeah ... big up for that, for your work and your team.\n\u0026gt; Keep going!",
      "ts": "1666124430.813529",
      "thread_ts": "1666124430.813529",
      "subtype": "bot_message",
      "bot_id": "B0434N8CV28",
      "username": "Ask Apple - accessibility",
      "reply_count": 5,
      "latest_reply": "1666126690.707739",
      "reactions": [
        {
          "name": "heart",
          "count": 6,
          "users": [
            "U046S70K9A4",
            "U044G9DLCUB",
            "U046JND8CKB",
            "U03V30M0C1K",
            "U04631JRW83",
            "U0449J0BZGW"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "=v0+",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046JMFLKV3"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Hi! Not sure what kind of questions to ask for the \\\"An Apple Watch for everyone\\\" Q\u0026A ; but I want to send to you a big up for all the accessibility work at Apple. I love all the investment and all the accessibility tech in Apple product, as well that I love how the API are neat and nice to use. It's never been easier to create accessible apps ; so yeah ... big up for that, for your work and your team.\\nKeep going!\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "ade821a8-aaad-41f4-a939-384a90aa366b",
          "type": "message",
          "user": "U044D824R8V",
          "text": "Thanks for the call out Thomas! We certainly love making our products as accessible as possible, but we couldn't do it without the hard work of developers like yourself adopting our APIs and making your apps as accessible as possible! Likewise, keep going! :smile:",
          "ts": "1666124484.799209",
          "thread_ts": "1666124430.813529",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "construction_worker",
              "count": 1,
              "users": [
                "U046JMFLKV3"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "dMBZZ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks for the call out Thomas! We certainly love making our products as accessible as possible, but we couldn't do it without the hard work of developers like yourself adopting our APIs and making your apps as accessible as possible! Likewise, keep going! "
                    },
                    {
                      "type": "emoji",
                      "name": "smile",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "6c3f3f69-6ba0-44f6-9b17-846ed2adc0cc",
          "type": "message",
          "user": "U046G37DF33",
          "text": "Certainly, the APIs across the platform (iOS, macOS, tvOS, watchOS) are great, and have made it far easier for me to add support for special needs students to several of my apps.  I crave more consistency in the frameworks across the OSes though, as trying to build an app that works on everything ends up being far more complex than I’d expected.",
          "ts": "1666125443.451609",
          "thread_ts": "1666124430.813529",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "eS3qk",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Certainly, the APIs across the platform (iOS, macOS, tvOS, watchOS) are great, and have made it far easier for me to add support for special needs students to several of my apps.  I crave more consistency in the frameworks across the OSes though, as trying to build an app that works on everything ends up being far more complex than I’d expected."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "9363a5ce-b924-4870-93df-a907ef54aa3b",
          "type": "message",
          "user": "U044D824R8V",
          "text": "Thanks for the feedback Peter! If there's ever specific places you are finding inconsistencies across the platforms, please feel free to let us know by filing a feedback report at \u003chttp://feedbackassistant.apple.com|feedbackassistant.apple.com\u003e. We love hearing from developers and are always looking for ways to improve the experience you all have with our APIs.",
          "ts": "1666125576.217969",
          "thread_ts": "1666124430.813529",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Y4i3",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks for the feedback Peter! If there's ever specific places you are finding inconsistencies across the platforms, please feel free to let us know by filing a feedback report at "
                    },
                    {
                      "type": "link",
                      "url": "http://feedbackassistant.apple.com",
                      "text": "feedbackassistant.apple.com"
                    },
                    {
                      "type": "text",
                      "text": ". We love hearing from developers and are always looking for ways to improve the experience you all have with our APIs."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "ab741642-3140-415a-8e55-6651fc48edfe",
          "type": "message",
          "user": "U046G37DF33",
          "text": "Thanks.  Yes I think that will be needed.  Games are one genre of app that seems to suffer when it comes to accessibility support, so frameworks like SpriteKit and SceneKit need solid work to encourage us devs to add that support.  Games for everyone!",
          "ts": "1666126556.792079",
          "thread_ts": "1666124430.813529",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "wf/h7",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks.  Yes I think that will be needed.  Games are one genre of app that seems to suffer when it comes to accessibility support, so frameworks like SpriteKit and SceneKit need solid work to encourage us devs to add that support.  Games for everyone!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "99d40581-6ef1-4ccb-a946-bcce4b581053",
          "type": "message",
          "user": "U044D824R8V",
          "text": "There's definitely lots of cool stuff happening in the accessible gaming space! We love seeing improvements in that area.",
          "ts": "1666126690.707739",
          "thread_ts": "1666124430.813529",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "xn0",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "There's definitely lots of cool stuff happening in the accessible gaming space! We love seeing improvements in that area."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "0e3d01a9-c697-4be6-a64e-db05005b26af",
      "type": "message",
      "user": "U044D824R8V",
      "text": "Speaking of AssistiveTouch, a new feature we're super excited about in watchOS 9 this year is Quick Actions! Quick Actions is a feature that enables people to perform a prominent action in your app, well... quickly! Simply double pinch to perform a presented quick action. It can be enabled in Accessibility \u0026gt; Quick Actions on your Apple Watch. For example, we've adopted quick actions in our apps to answer an incoming call, snooze an alarm, or dismiss a notification, just to name a few! You can add quick actions to your own apps with the `accessibilityQuickAction(style:content:)` modifier in SwiftUI, check out the API to learn more: \u003chttps://developer.apple.com/documentation/swiftui/view/accessibilityquickaction(style:content:)\u003e\n\nHave any of you tried quick actions in your watchOS apps? We'd love to hear about what you're doing with this API!",
      "ts": "1666125042.552959",
      "edited": {
        "user": "U044D824R8V",
        "ts": "1666125215.000000"
      },
      "team": "T03U5MWB2FN",
      "reactions": [
        {
          "name": "raised_hands",
          "count": 1,
          "users": [
            "U044G9DLCUB"
          ]
        },
        {
          "name": "star-struck",
          "count": 1,
          "users": [
            "U046DA9R188"
          ]
        },
        {
          "name": "rocket",
          "count": 1,
          "users": [
            "U0449J0BZGW"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "SDbQ",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Speaking of AssistiveTouch, a new feature we're super excited about in watchOS 9 this year is Quick Actions! Quick Actions is a feature that enables people to perform a prominent action in your app, well... quickly! Simply double pinch to perform a presented quick action. It can be enabled in Accessibility \u003e Quick Actions on your Apple Watch. For example, we've adopted quick actions in our apps to answer an incoming call, snooze an alarm, or dismiss a notification, just to name a few! You can add quick actions to your own apps with the "
                },
                {
                  "type": "text",
                  "text": "accessibilityQuickAction(style:content:)",
                  "style": {
                    "code": true
                  }
                },
                {
                  "type": "text",
                  "text": " modifier in SwiftUI, check out the API to learn more: "
                },
                {
                  "type": "link",
                  "url": "https://developer.apple.com/documentation/swiftui/view/accessibilityquickaction(style:content:)",
                  "text": ""
                },
                {
                  "type": "text",
                  "text": "\n\nHave any of you tried quick actions in your watchOS apps? We'd love to hear about what you're doing with this API!"
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046S70K9A4\u003e asked\n\u0026gt; :wave: I remember reading something about new SSML support (speech synthesis markup language) at WWDC.  Can that be used with VoiceOver descriptions?",
      "ts": "1666126349.342549",
      "thread_ts": "1666126349.342549",
      "subtype": "bot_message",
      "bot_id": "B0434N8CV28",
      "username": "Ask Apple - accessibility",
      "reply_count": 2,
      "latest_reply": "1666126772.195429",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "gvu",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046S70K9A4"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"emoji\",\"name\":\"wave\",\"unicode\":\"1f44b\"},{\"type\":\"text\",\"text\":\" I remember reading something about new SSML support (speech synthesis markup language) at WWDC.  Can that be used with VoiceOver descriptions?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "76027b76-fcab-4822-ba16-14732ce4e01d",
          "type": "message",
          "user": "U044D824R8V",
          "text": "It's not currently possible to use SSML in accessibilityLabels or values. If this would be useful for a particular use case, definitely let us know by filing a report at \u003chttp://feedbackassistant.apple.com|feedbackassistant.apple.com\u003e!\n\nIn the meantime, if you're finding the need to use SSML in some sort of announcement for VoiceOver users, you can do so using `AVSpeechSynthesizer`, just be sure to set `prefersAssistiveTechnologySettings` on your utterances so that the correct voice properties are used when you announcement is playing. For things like accessibility labels that you want VO to read when an item is focused, we don't have a way to do this right now but we do have some attributed string keys that can help specify things like language or pronunciation which may help!",
          "ts": "1666126499.433309",
          "thread_ts": "1666126349.342549",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "wFWT",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "It's not currently possible to use SSML in accessibilityLabels or values. If this would be useful for a particular use case, definitely let us know by filing a report at "
                    },
                    {
                      "type": "link",
                      "url": "http://feedbackassistant.apple.com",
                      "text": "feedbackassistant.apple.com"
                    },
                    {
                      "type": "text",
                      "text": "!\n\nIn the meantime, if you're finding the need to use SSML in some sort of announcement for VoiceOver users, you can do so using "
                    },
                    {
                      "type": "text",
                      "text": "AVSpeechSynthesizer",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": ", just be sure to set "
                    },
                    {
                      "type": "text",
                      "text": "prefersAssistiveTechnologySettings",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " on your utterances so that the correct voice properties are used when you announcement is playing. For things like accessibility labels that you want VO to read when an item is focused, we don't have a way to do this right now but we do have some attributed string keys that can help specify things like language or pronunciation which may help!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "1e58e039-394b-42c8-920d-59d1af12c70f",
          "type": "message",
          "user": "U046S70K9A4",
          "text": "Thanks for the guidance Dan :v:",
          "ts": "1666126772.195429",
          "thread_ts": "1666126349.342549",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "sunglasses",
              "count": 1,
              "users": [
                "U044D824R8V"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "/rN",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks for the guidance Dan "
                    },
                    {
                      "type": "emoji",
                      "name": "v",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046W3ACDC2\u003e asked\n\u0026gt; Is Assistive Touch doing anything specific with Digital Crown focus? We've been having some issues with Assistive Touch turned on, appearing Lists would not grab focus of the digital crown (the digital crown wouldn't work on a List) until one would touch something on the screen. We've been unable to achieve focus programatically. Also, is there a way to figure out that an item has been focused on with assistive touch? Thanks!",
      "ts": "1666126759.157879",
      "thread_ts": "1666126759.157879",
      "subtype": "bot_message",
      "bot_id": "B0434N8CV28",
      "username": "Ask Apple - accessibility",
      "reply_count": 2,
      "latest_reply": "1666127129.501429",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "D06",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046W3ACDC2"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Is Assistive Touch doing anything specific with Digital Crown focus? We've been having some issues with Assistive Touch turned on, appearing Lists would not grab focus of the digital crown (the digital crown wouldn't work on a List) until one would touch something on the screen. We've been unable to achieve focus programatically. Also, is there a way to figure out that an item has been focused on with assistive touch? Thanks!\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "11228d83-825a-4267-97ba-1e51e7e91095",
          "type": "message",
          "user": "U044D822929",
          "text": "Thank you for reaching out Luka! We would expect the digital crown to work normally while AssistiveTouch is on. If this isn’t what you’re experiencing, you can help us by filing a report at \u003chttp://feedbackassistant.apple.com|feedbackassistant.apple.com\u003e with a sample project that reproduces this behavior to help us investigate the issue. Have you tried using the scroll actions via the AssistiveTouch action menu? This method may help you scroll through Lists when AssistiveTouch is enabled. To answer your second question, there is no way to determine which item has focus with AssistiveTouch turned on.",
          "ts": "1666126810.434789",
          "thread_ts": "1666126759.157879",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "raised_hands",
              "count": 1,
              "users": [
                "U046W3ACDC2"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "69oQ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thank you for reaching out Luka! We would expect the digital crown to work normally while AssistiveTouch is on. If this isn’t what you’re experiencing, you can help us by filing a report at "
                    },
                    {
                      "type": "link",
                      "url": "http://feedbackassistant.apple.com",
                      "text": "feedbackassistant.apple.com"
                    },
                    {
                      "type": "text",
                      "text": " with a sample project that reproduces this behavior to help us investigate the issue. Have you tried using the scroll actions via the AssistiveTouch action menu? This method may help you scroll through Lists when AssistiveTouch is enabled. To answer your second question, there is no way to determine which item has focus with AssistiveTouch turned on."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "196b55fb-6ce9-4aac-a806-7c860409493c",
          "type": "message",
          "user": "U046W3ACDC2",
          "text": "Thanks for answering! Scroll actions work fine, the issue is in Assistive Touch seemingly interfering with \"normal\" watch use, which is unfortunate if one has it turned on just as an affordance and not using it exclusively. I'll try putting together a simple sample project.",
          "ts": "1666127129.501429",
          "thread_ts": "1666126759.157879",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "pray::skin-tone-2",
              "count": 1,
              "users": [
                "U044D824R8V"
              ]
            },
            {
              "name": "pray",
              "count": 1,
              "users": [
                "U044D822929"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "4qGJQ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks for answering! Scroll actions work fine, the issue is in Assistive Touch seemingly interfering with \"normal\" watch use, which is unfortunate if one has it turned on just as an affordance and not using it exclusively. I'll try putting together a simple sample project."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "f304630a-ff9c-4aa3-9bda-202c5e90838f",
      "type": "message",
      "user": "U044D824R8V",
      "text": "Thank you for joining us for this Q\u0026amp;A! I hope you had as much fun as we did :sunglasses:. While we’re finished answering questions for now (we're hard at work making the watch, and all other apple products, as accessible as possible!) the workflow will remain published. Keep the questions coming! Our next event is at 2 PM PDT on Thursday, and is a general Accessibility Q\u0026amp;A. If you’re unable to join us live, you can send in your questions and we'll do our best to answer them when the event starts. As a reminder, please keep your questions scoped to that topic. We’ll be back with more Q\u0026amp;A soon! :wave::skin-tone-2:",
      "ts": "1666126999.013399",
      "team": "T03U5MWB2FN",
      "reactions": [
        {
          "name": "partying_face",
          "count": 7,
          "users": [
            "U03V30M0C1K",
            "U044D822929",
            "U04563C4N1W",
            "U0449J0BZGW",
            "U044JR1DRD2",
            "U04631JRW83",
            "U0471EA0XN2"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "wTvpq",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Thank you for joining us for this Q\u0026A! I hope you had as much fun as we did "
                },
                {
                  "type": "emoji",
                  "name": "sunglasses",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": ". While we’re finished answering questions for now (we're hard at work making the watch, and all other apple products, as accessible as possible!) the workflow will remain published. Keep the questions coming! Our next event is at 2 PM PDT on Thursday, and is a general Accessibility Q\u0026A. If you’re unable to join us live, you can send in your questions and we'll do our best to answer them when the event starts. As a reminder, please keep your questions scoped to that topic. We’ll be back with more Q\u0026A soon! "
                },
                {
                  "type": "emoji",
                  "name": "wave",
                  "skin_tone": 2
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "1664cb28-ac8d-49d0-8f71-c99cde002b43",
      "type": "message",
      "user": "U0449LGV1FV",
      "text": ":mechanical_arm: Hello and Welcome back :zap:\n\nOur live Accessibility Q\u0026amp;A will start in 30 minutes at 2PM PDT. We’ll answer the questions that everyone has been submitting up to now and anything else you’d like to discuss related to Accessible technology and making apps work with VoiceOver, Switch Control, Voice Control and more!",
      "ts": "1666297971.331479",
      "team": "T03U5MWB2FN",
      "reactions": [
        {
          "name": "partying_face",
          "count": 4,
          "users": [
            "U03V30M0C1K",
            "U044D824R8V",
            "U044Z1BL294",
            "U046Y0G27B7"
          ]
        },
        {
          "name": "raised_hands::skin-tone-2",
          "count": 1,
          "users": [
            "U044D824R8V"
          ]
        },
        {
          "name": "raised_hands",
          "count": 2,
          "users": [
            "U044Z1BL294",
            "U046Y0G27B7"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "Zn2",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "emoji",
                  "name": "mechanical_arm",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": " Hello and Welcome back "
                },
                {
                  "type": "emoji",
                  "name": "zap",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": "\n\nOur live Accessibility Q\u0026A will start in 30 minutes at 2PM PDT. We’ll answer the questions that everyone has been submitting up to now and anything else you’d like to discuss related to Accessible technology and making apps work with VoiceOver, Switch Control, Voice Control and more!"
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "d2b7dc95-2c60-4d16-933b-97c111a1a289",
      "type": "message",
      "user": "U0449LGV1FV",
      "text": "We’re ready to get started! Select the:heavy_plus_sign:icon from the lower left, and find the _Ask A Question_ workflow. Type in your questions and we’ll start working through the list as fast as we can!\n\nWe’ll also start posting up questions that have already been asked.",
      "ts": "1666299677.790199",
      "team": "T03U5MWB2FN",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "e=rxq",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "We’re ready to get started! Select the"
                },
                {
                  "type": "emoji",
                  "name": "heavy_plus_sign",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": "icon from the lower left, and find the "
                },
                {
                  "type": "text",
                  "text": "Ask A Question",
                  "style": {
                    "italic": true
                  }
                },
                {
                  "type": "text",
                  "text": " workflow. Type in your questions and we’ll start working through the list as fast as we can!\n\nWe’ll also start posting up questions that have already been asked."
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U04664GDJD8\u003e asked\n\u0026gt; VoiceOver for numbers such \"100.25\" reads \"100 dot 25\". What is the best approach to fix VoiceOver saying \"100 point 25\"?",
      "ts": "1666299695.944839",
      "thread_ts": "1666299695.944839",
      "subtype": "bot_message",
      "bot_id": "B0434N8CV28",
      "username": "Ask Apple - accessibility",
      "reply_count": 1,
      "latest_reply": "1666299754.759359",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "yNj",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U04664GDJD8"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"VoiceOver for numbers such \\\"100.25\\\" reads \\\"100 dot 25\\\". What is the best approach to fix VoiceOver saying \\\"100 point 25\\\"?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "14d19e05-5da6-406c-8f9c-30209ee53791",
          "type": "message",
          "user": "U044D824R8V",
          "text": "The best way to do this is to replace the \".\" with the word \"point\" in your accessibility label. Please make sure you limit this to the localizations that would be appropriate for this replacement.\n\nYou can also use the IPA Notation attributed string key to specify how you want a particular piece of text spoken:\n\u003chttps://developer.apple.com/documentation/uikit/uiaccessibilityspeechattributeipanotation?language=objc\u003e\n\nNote that VoiceOver users can set their own punctuation settings and specify how they want individual pieces of punctuation spoken, so it may be best to leave the default behavior as is.",
          "ts": "1666299754.759359",
          "thread_ts": "1666299695.944839",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "c2pe",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "The best way to do this is to replace the \".\" with the word \"point\" in your accessibility label. Please make sure you limit this to the localizations that would be appropriate for this replacement.\n\nYou can also use the IPA Notation attributed string key to specify how you want a particular piece of text spoken:\n"
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/uikit/uiaccessibilityspeechattributeipanotation?language=objc",
                      "text": ""
                    },
                    {
                      "type": "text",
                      "text": "\n\nNote that VoiceOver users can set their own punctuation settings and specify how they want individual pieces of punctuation spoken, so it may be best to leave the default behavior as is."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046UL04VAP\u003e asked\n\u0026gt; When trying to unit test accessibility properties on UIKit, they’re usually nil. The workaround is run the tests on a host app and display the view on screen. This behavior also gets enabled if we open the accessibility inspector once.\n\u0026gt; \n\u0026gt; Is there a better way to get the a11y properties in tests without these workarounds?",
      "ts": "1666299718.543759",
      "thread_ts": "1666299718.543759",
      "subtype": "bot_message",
      "bot_id": "B0434N8CV28",
      "username": "Ask Apple - accessibility",
      "reply_count": 1,
      "latest_reply": "1666299827.612829",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "5ee+3",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046UL04VAP"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"When trying to unit test accessibility properties on UIKit, they\\u2019re usually nil. The workaround is run the tests on a host app and display the view on screen. This behavior also gets enabled if we open the accessibility inspector once.\\n\\nIs there a better way to get the a11y properties in tests without these workarounds?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "4a7b598a-cc76-47ed-b0be-cb31ab1f0eb7",
          "type": "message",
          "user": "U0449LGV1FV",
          "text": "First the background - Accessibility doesn’t get loaded into app process space until an accessibility client (like VoiceOver) needs it.\nSo your solution is probably the best available for your flow.\n\nAnother idea is to leave a feature like Speak Screen enabled, which is also an accessibility client, then accessibility properties will become available.",
          "ts": "1666299827.612829",
          "thread_ts": "1666299718.543759",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "gVaSD",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "First the background - Accessibility doesn’t get loaded into app process space until an accessibility client (like VoiceOver) needs it.\nSo your solution is probably the best available for your flow.\n\nAnother idea is to leave a feature like Speak Screen enabled, which is also an accessibility client, then accessibility properties will become available."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U04710PEQKE\u003e asked\n\u0026gt; Hello, \n\u0026gt; I'd like to know what would be the appropriate approach for the following scenario:\n\u0026gt; \n\u0026gt; Consider that we have a label \"213.3 km\" and VO declares \"213 dot 3 kilometers\". Many claim that the proper form is the one where the symbol \".\" - dot is replaced with the word \"point,\" making it \"213 point 3,\" but what exactly should we be looking for? \n\u0026gt; \n\u0026gt; Given that the \"point\" version wouldn't be an accurate translation in other languages, would the version in the system be correct? \n\u0026gt; What should we consider about?\n\u0026gt; \n\u0026gt; Thank you!",
      "ts": "1666299830.607729",
      "thread_ts": "1666299830.607729",
      "subtype": "bot_message",
      "bot_id": "B0434N8CV28",
      "username": "Ask Apple - accessibility",
      "reply_count": 1,
      "latest_reply": "1666299854.032009",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "L4YbX",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U04710PEQKE"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Hello, \\nI'd like to know what would be the appropriate approach for the following scenario:\\n\\nConsider that we have a label \\\"213.3 km\\\" and VO declares \\\"213 dot 3 kilometers\\\". Many claim that the proper form is the one where the symbol \\\".\\\" - dot is replaced with the word \\\"point,\\\" making it \\\"213 point 3,\\\" but what exactly should we be looking for? \\n\\nGiven that the \\\"point\\\" version wouldn't be an accurate translation in other languages, would the version in the system be correct? \\nWhat should we consider about?\\n\\nThank you!\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "dfd6bf65-5d3b-460c-9a35-6b58d1d25d77",
          "type": "message",
          "user": "U044D824R8V",
          "text": "You can customize this by expanding the string to include the word \"point\" instead of the \".\" in the text. Make sure though that this string is localized, or that you limit this replacement to only the locales that make sense. Note that VoiceOver users however can modify their punctuation settings, to control which punctuation is spoken, and what string to speak for a given piece of punctuation, so it's probably best practice to let the system speak this based on the user's preferences in this case rather than make a custom replacement yourself, unless you have a really specific use case. (Also see my answer to the similar question above!)",
          "ts": "1666299854.032009",
          "thread_ts": "1666299830.607729",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Cko=",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "You can customize this by expanding the string to include the word \"point\" instead of the \".\" in the text. Make sure though that this string is localized, or that you limit this replacement to only the locales that make sense. Note that VoiceOver users however can modify their punctuation settings, to control which punctuation is spoken, and what string to speak for a given piece of punctuation, so it's probably best practice to let the system speak this based on the user's preferences in this case rather than make a custom replacement yourself, unless you have a really specific use case. (Also see my answer to the similar question above!)"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U045P37JXSB\u003e asked\n\u0026gt; I have developed several accessibility apps for iPhone and iPad using unity3D. One problem that unity can't seem to fix is enabling on enter, hover and on exit events for a pointer device on objects. It would be extremely helpful if Apple would add this capability to the Apple unity plugin. Perhaps it could be part of a button trait functionality. I would also be interested in any suggestions on how to do this now for unity apps for iPad pointer devices. Thanks.",
      "ts": "1666299875.728589",
      "thread_ts": "1666299875.728589",
      "subtype": "bot_message",
      "bot_id": "B0434N8CV28",
      "username": "Ask Apple - accessibility",
      "reply_count": 1,
      "latest_reply": "1666299904.523709",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "G+0Gy",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U045P37JXSB"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"I have developed several accessibility apps for iPhone and iPad using unity3D. One problem that unity can't seem to fix is enabling on enter, hover and on exit events for a pointer device on objects. It would be extremely helpful if Apple would add this capability to the Apple unity plugin. Perhaps it could be part of a button trait functionality. I would also be interested in any suggestions on how to do this now for unity apps for iPad pointer devices. Thanks.\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "808be249-1b85-4d27-bd6f-c132c0576358",
          "type": "message",
          "user": "U0449LGV1FV",
          "text": "Thanks for the suggestion. We’ll note it internally, but we would also recommend filing a feedback.",
          "ts": "1666299904.523709",
          "thread_ts": "1666299875.728589",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Jwmj",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks for the suggestion. We’ll note it internally, but we would also recommend filing a feedback."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U04631JRW83\u003e asked\n\u0026gt; What are best practices for disabled states? Is changing opacity or going greyscale the preferred behavior, and should disabled states still be visually accessible (text on a button)?",
      "ts": "1666299889.095249",
      "thread_ts": "1666299889.095249",
      "subtype": "bot_message",
      "bot_id": "B0434N8CV28",
      "username": "Ask Apple - accessibility",
      "reply_count": 1,
      "latest_reply": "1666299902.738849",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "h6RvZ",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U04631JRW83"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"What are best practices for disabled states? Is changing opacity or going greyscale the preferred behavior, and should disabled states still be visually accessible (text on a button)?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "67c3b3fb-f407-4eae-afe2-9e23525688c2",
          "type": "message",
          "user": "U044D824R8V",
          "text": "Visually, our guidance for disabled states usually follows our general guidance for accessible UIs. Ensure that everything is high contrast, responds to dynamic type, and don't use color alone to differentiate meaning. It's also important to convey not enabled states to assistive technologies, like VoiceOver. Make sure any control that is not enabled has the trait `UIAccessibilityTraitNotEnabled` so that users of assistive technologies are informed properly about these controls.",
          "ts": "1666299902.738849",
          "thread_ts": "1666299889.095249",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "vhPSp",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Visually, our guidance for disabled states usually follows our general guidance for accessible UIs. Ensure that everything is high contrast, responds to dynamic type, and don't use color alone to differentiate meaning. It's also important to convey not enabled states to assistive technologies, like VoiceOver. Make sure any control that is not enabled has the trait "
                    },
                    {
                      "type": "text",
                      "text": "UIAccessibilityTraitNotEnabled",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " so that users of assistive technologies are informed properly about these controls."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U045VJUAUDC\u003e asked\n\u0026gt; Is it acceptable to use failing contrast scores for certain elements such as placeholder text in a textfield?",
      "ts": "1666299956.293739",
      "thread_ts": "1666299956.293739",
      "subtype": "bot_message",
      "bot_id": "B0434N8CV28",
      "username": "Ask Apple - accessibility",
      "reply_count": 4,
      "latest_reply": "1666300154.999489",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "z/E",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U045VJUAUDC"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Is it acceptable to use failing contrast scores for certain elements such as placeholder text in a textfield?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "69dc31d9-364e-4b71-9de6-512f4a2c7048",
          "type": "message",
          "user": "U044D824R8V",
          "text": "We recommend a 4:1 contrast ratio from text to background color. If the contrast score fails, it's not usually good practice to use those colors, even for placeholder text",
          "ts": "1666299979.742799",
          "thread_ts": "1666299956.293739",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "rKx",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "We recommend a 4:1 contrast ratio from text to background color. If the contrast score fails, it's not usually good practice to use those colors, even for placeholder text"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "09166482-9372-44ed-8834-efe26ba32642",
          "type": "message",
          "user": "U045VJUAUDC",
          "text": "Right, so you wouldn’t recommend something like this?",
          "ts": "1666300021.219319",
          "thread_ts": "1666299956.293739",
          "edited": {
            "user": "U045VJUAUDC",
            "ts": "1666300031.000000"
          },
          "files": [
            {
              "id": "F047JGC0G20",
              "created": 1666300015,
              "timestamp": 1666300015,
              "name": "image.png",
              "title": "image.png",
              "mimetype": "image/png",
              "image_exif_rotation": 0,
              "filetype": "png",
              "pretty_type": "PNG",
              "user": "U045VJUAUDC",
              "mode": "hosted",
              "editable": false,
              "is_external": false,
              "external_type": "",
              "size": 765364,
              "url": "",
              "url_download": "",
              "url_private": "C0432BW1HN0/F047JGC0G20-image.png",
              "url_private_download": "C0432BW1HN0/F047JGC0G20-image.png",
              "original_h": 1964,
              "original_w": 1978,
              "thumb_64": "https://files.slack.com/files-tmb/T01PTBJ95PS-F047JGC0G20-64c22b4b3a/image_64.png",
              "thumb_80": "https://files.slack.com/files-tmb/T01PTBJ95PS-F047JGC0G20-64c22b4b3a/image_80.png",
              "thumb_160": "https://files.slack.com/files-tmb/T01PTBJ95PS-F047JGC0G20-64c22b4b3a/image_160.png",
              "thumb_360": "https://files.slack.com/files-tmb/T01PTBJ95PS-F047JGC0G20-64c22b4b3a/image_360.png",
              "thumb_360_gif": "",
              "thumb_360_w": 360,
              "thumb_360_h": 357,
              "thumb_480": "https://files.slack.com/files-tmb/T01PTBJ95PS-F047JGC0G20-64c22b4b3a/image_480.png",
              "thumb_480_w": 480,
              "thumb_480_h": 477,
              "thumb_720": "https://files.slack.com/files-tmb/T01PTBJ95PS-F047JGC0G20-64c22b4b3a/image_720.png",
              "thumb_720_w": 720,
              "thumb_720_h": 715,
              "thumb_960": "https://files.slack.com/files-tmb/T01PTBJ95PS-F047JGC0G20-64c22b4b3a/image_960.png",
              "thumb_960_w": 960,
              "thumb_960_h": 953,
              "thumb_1024": "https://files.slack.com/files-tmb/T01PTBJ95PS-F047JGC0G20-64c22b4b3a/image_1024.png",
              "thumb_1024_w": 1024,
              "thumb_1024_h": 1017,
              "permalink": "https://appleevents.enterprise.slack.com/files/U045VJUAUDC/F047JGC0G20/image.png",
              "permalink_public": "https://slack-files.com/T01PTBJ95PS-F047JGC0G20-28ba27d1d6",
              "edit_link": "",
              "preview": "",
              "preview_highlight": "",
              "lines": 0,
              "lines_more": 0,
              "is_public": false,
              "public_url_shared": false,
              "channels": null,
              "groups": null,
              "ims": null,
              "initial_comment": {},
              "comments_count": 0,
              "num_stars": 0,
              "is_starred": false,
              "shares": {
                "public": null,
                "private": null
              }
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "W=3",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Right, so you wouldn’t recommend something like this?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "af7dea66-39ee-4840-abf4-4ab7c7608c0e",
          "type": "message",
          "user": "U044D824R8V",
          "text": "Correct, I'd expect it to be 4:1 even in the placeholder case, there should be some good color choices there that will still be able to convey the placeholder state :slightly_smiling_face:",
          "ts": "1666300136.276939",
          "thread_ts": "1666299956.293739",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "gYYc",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Correct, I'd expect it to be 4:1 even in the placeholder case, there should be some good color choices there that will still be able to convey the placeholder state "
                    },
                    {
                      "type": "emoji",
                      "name": "slightly_smiling_face",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "18806d78-52c7-4325-97b6-382e26247104",
          "type": "message",
          "user": "U045VJUAUDC",
          "text": "Cool - thankyou!",
          "ts": "1666300154.999489",
          "thread_ts": "1666299956.293739",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "+1::skin-tone-2",
              "count": 1,
              "users": [
                "U044D824R8V"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "wxF",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Cool - thankyou!"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046G37DF33\u003e asked\n\u0026gt; Hi. I have a game, World of Hex, which is in the store on iOS, macOS and tvOS.  For the past 4 months I’ve been working on adding accessibility to the game for each platform.\n\u0026gt; \n\u0026gt; For the most part, on iOS and macOS I have it working, and enabling VoiceOver places the app into a state where the user is able to interact via what I believe are standard accessibility interactions.\n\u0026gt; \n\u0026gt; On tvOS however I have encountered a number of issues that relate to the interaction between the accessibility framework and the UIFocusSystem framework.\n\u0026gt; \n\u0026gt; No matter what I try, I seem to hit problems where interacting (via the Siri remote) with the Apple TV when VoiceOver is enabled seems to sort-of work in that I can navigate around the various UI elements however the UIFocusSystem seems to steal some of the interactions such as selecting an item (e.g. pressing a button).  Where I can get the Accessibility framework to respond to an interaction that is fine, but some are always eaten by UIFocusSystem (resulting in a “bonk” sound, that incidentally, I can not disable), so the experience is always incomplete.\n\u0026gt; \n\u0026gt; I’ve had to shelve to project recently, however this forum is, I’m hoping going to provide me with an opportunity to make some progress again.\n\u0026gt; \n\u0026gt; As an aside, testing this via the Simulator is impossible thanks to the lack of VoiceOver support from within the simulator.",
      "ts": "1666299973.606799",
      "thread_ts": "1666299973.606799",
      "subtype": "bot_message",
      "bot_id": "B0434N8CV28",
      "username": "Ask Apple - accessibility",
      "reply_count": 21,
      "latest_reply": "1666303340.286509",
      "reactions": [
        {
          "name": "gratitude-thank-you",
          "count": 1,
          "users": [
            "U046G37DF33"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "78HqA",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046G37DF33"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Hi. I have a game, World of Hex, which is in the store on iOS, macOS and tvOS.  For the past 4 months I\\u2019ve been working on adding accessibility to the game for each platform.\\n\\nFor the most part, on iOS and macOS I have it working, and enabling VoiceOver places the app into a state where the user is able to interact via what I believe are standard accessibility interactions.\\n\\nOn tvOS however I have encountered a number of issues that relate to the interaction between the accessibility framework and the UIFocusSystem framework.\\n\\nNo matter what I try, I seem to hit problems where interacting (via the Siri remote) with the Apple TV when VoiceOver is enabled seems to sort-of work in that I can navigate around the various UI elements however the UIFocusSystem seems to steal some of the interactions such as selecting an item (e.g. pressing a button).  Where I can get the Accessibility framework to respond to an interaction that is fine, but some are always eaten by UIFocusSystem (resulting in a \\u201cbonk\\u201d sound, that incidentally, I can not disable), so the experience is always incomplete.\\n\\nI\\u2019ve had to shelve to project recently, however this forum is, I\\u2019m hoping going to provide me with an opportunity to make some progress again.\\n\\nAs an aside, testing this via the Simulator is impossible thanks to the lack of VoiceOver support from within the simulator.\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "377f0579-3a16-4302-8c39-d09ccc4499ee",
          "type": "message",
          "user": "U0449LGV1FV",
          "text": "Trying to summarize - there are elements that you have in your app that VoiceOver cannot navigate to? Is that the basic problem?",
          "ts": "1666300097.036239",
          "thread_ts": "1666299973.606799",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "biWcH",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Trying to summarize - there are elements that you have in your app that VoiceOver cannot navigate to? Is that the basic problem?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "bb72fe03-e965-4632-819a-e0e140731390",
          "type": "message",
          "user": "U04563C4N1W",
          "text": "Can you also confirm which mode you have VoiceOver running in? You can do this by tapping the Siri remote 3 times with two fingers. I think having VoiceOver in Navigation mode will be the best experience for a game.",
          "ts": "1666300651.569679",
          "thread_ts": "1666299973.606799",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "PPkfW",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Can you also confirm which mode you have VoiceOver running in? You can do this by tapping the Siri remote 3 times with two fingers. I think having VoiceOver in Navigation mode will be the best experience for a game."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "83A982BE-DD13-4053-AD1E-969C47F79746",
          "type": "message",
          "user": "U046G37DF33",
          "text": "I activate voiceover using the triple-menu button click. That puts it in (I believe) navigation mode where swiping left/right moves the accessibility “cursor” between buttons. That only works reliably if I make a point of _*not*_ using UIFocus* but even then a press on the Siri remote central button is still eaten by UIFocus* in that pressing the button elicits a “donk” sound like there is nothing to focus on. ",
          "ts": "1666301361.845829",
          "thread_ts": "1666299973.606799",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "C5J",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I activate voiceover using the triple-menu button click"
                    },
                    {
                      "type": "text",
                      "text": "."
                    },
                    {
                      "type": "text",
                      "text": " That puts it in (I believe"
                    },
                    {
                      "type": "text",
                      "text": ")"
                    },
                    {
                      "type": "text",
                      "text": " navigation mode where swiping left/right moves the accessibility “cursor” between buttons"
                    },
                    {
                      "type": "text",
                      "text": "."
                    },
                    {
                      "type": "text",
                      "text": " That only works reliably if I make a point of "
                    },
                    {
                      "type": "text",
                      "text": "not",
                      "style": {
                        "bold": true,
                        "italic": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "u"
                    },
                    {
                      "type": "text",
                      "text": "sing UIFocus* but even then a press on the Siri remote central button is still eaten by UIFocus* in that pressing the button elicits a “donk” sound like there is nothing to focus on"
                    },
                    {
                      "type": "text",
                      "text": "."
                    },
                    {
                      "type": "text",
                      "text": " "
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "0ed80019-74f7-4d2e-ad84-62f88ce4a8f2",
          "type": "message",
          "user": "U044D824R8V",
          "text": "are you saying that when you swipe/left and right on the remote that native focus (UIFocus) doesn't change? If so, you are in exploration mode",
          "ts": "1666301444.332499",
          "thread_ts": "1666299973.606799",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "DutO1",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "are you saying that when you swipe/left and right on the remote that native focus (UIFocus) doesn't change? If so, you are in exploration mode"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "2BB0E02F-1041-4497-B295-F8C33F66CA0F",
          "type": "message",
          "user": "U046G37DF33",
          "text": "On macOS and iOS I can also take advantage of the double-tap-and-hold accessibility gesture when I want to let the user manipulate (say) a 3d camera movement. I can’t work out how to achieve that on tvOS. ",
          "ts": "1666301587.656759",
          "thread_ts": "1666299973.606799",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "0aCT",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "On macOS and iOS I can also take advantage of the double-tap-and-hold accessibility gesture "
                    },
                    {
                      "type": "text",
                      "text": "w"
                    },
                    {
                      "type": "text",
                      "text": "hen I "
                    },
                    {
                      "type": "text",
                      "text": "w"
                    },
                    {
                      "type": "text",
                      "text": "ant to let the user manipulate (say) a 3d camera movement"
                    },
                    {
                      "type": "text",
                      "text": "."
                    },
                    {
                      "type": "text",
                      "text": " I "
                    },
                    {
                      "type": "text",
                      "text": "can’t"
                    },
                    {
                      "type": "text",
                      "text": " work out how to achieve that on tvOS"
                    },
                    {
                      "type": "text",
                      "text": "."
                    },
                    {
                      "type": "text",
                      "text": " "
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "1ac56aa6-089b-4bb4-825c-ade765aaa9e6",
          "type": "message",
          "user": "U044D824R8V",
          "text": "In navigation mode on tvOS, gestures should pass through to the system as if VoiceOver was off, VoiceOver won't be stealing any swipes/taps etc. Our intention is that most VoiceOver users will live primarily in navigation mode, with exploration mode available when there's static content that's not natively focusable",
          "ts": "1666301648.044859",
          "thread_ts": "1666299973.606799",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "GdMU",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "In navigation mode on tvOS, gestures should pass through to the system as if VoiceOver was off, VoiceOver won't be stealing any swipes/taps etc. Our intention is that most VoiceOver users will live primarily in navigation mode, with exploration mode available when there's static content that's not natively focusable"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "D4D4B83A-F9A2-4904-86D2-21FBF30190BB",
          "type": "message",
          "user": "U046G37DF33",
          "text": "Back to your reply. I tried retooling to use UIFocus* but found it clunky to use and even when I g he ad it working reasonably well, it’s interruption of the voiceover APIs made it unusable. So I reverted to my own focus system and “focused” (no pun intended) on getting the accessibility support working whilst disabling UIFocus*",
          "ts": "1666301833.202319",
          "thread_ts": "1666299973.606799",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "w/h",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Back to your reply"
                    },
                    {
                      "type": "text",
                      "text": "."
                    },
                    {
                      "type": "text",
                      "text": " I tried retooling to use UIFocus* but found it clunky to use and even when I g he ad it working reasonably well"
                    },
                    {
                      "type": "text",
                      "text": ","
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "it’s"
                    },
                    {
                      "type": "text",
                      "text": " interruption of the voiceover APIs made it unusable"
                    },
                    {
                      "type": "text",
                      "text": "."
                    },
                    {
                      "type": "text",
                      "text": " So I reverted to my own focus system and "
                    },
                    {
                      "type": "text",
                      "text": "“"
                    },
                    {
                      "type": "text",
                      "text": "focuse"
                    },
                    {
                      "type": "text",
                      "text": "d"
                    },
                    {
                      "type": "text",
                      "text": "” (no pun intended"
                    },
                    {
                      "type": "text",
                      "text": ")"
                    },
                    {
                      "type": "text",
                      "text": " on getting the accessibility support working whilst disabling UIFocus*"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "7d9ce541-0635-4d76-b3aa-c9c45bd3ca25",
          "type": "message",
          "user": "U044D824R8V",
          "text": "in navigation mode, if you are managing focus yourself, VoiceOver won't know what accessibility elements have focus, so you'll need to instead use announcement notifications to tell VoiceOver what to speak. \u003chttps://developer.apple.com/documentation/uikit/uiaccessibilityannouncementnotification?language=objc\u003e",
          "ts": "1666301956.695529",
          "thread_ts": "1666299973.606799",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "wvHl",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "in navigation mode, if you are managing focus yourself, VoiceOver won't know what accessibility elements have focus, so you'll need to instead use announcement notifications to tell VoiceOver what to speak. "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/uikit/uiaccessibilityannouncementnotification?language=objc",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "CF8E53C5-38C7-4DAA-BC82-BEB06588DB42",
          "type": "message",
          "user": "U046G37DF33",
          "text": "Oh my focus system manages the ui accessibility element tree and keeps the accessibility APIs fed. That part works quite well. My main issue is when UIFocus gets in the way even when there are no focusable nodes from its point of view",
          "ts": "1666302073.856059",
          "thread_ts": "1666299973.606799",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "wcV4M",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Oh my focus system manages the ui accessibility element tree and keeps the accessibility APIs fed"
                    },
                    {
                      "type": "text",
                      "text": "."
                    },
                    {
                      "type": "text",
                      "text": " That part works quite well"
                    },
                    {
                      "type": "text",
                      "text": "."
                    },
                    {
                      "type": "text",
                      "text": " My main issue is when UIFocus gets in the way even when there are no focusable nodes from its point of view"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "397cf164-b636-4466-9410-8628054260ee",
          "type": "message",
          "user": "U044D824R8V",
          "text": "are you saying this a problem when VoiceOver is on only?",
          "ts": "1666302106.494509",
          "thread_ts": "1666299973.606799",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "ej1",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "are you saying this a problem when VoiceOver is on only?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "ad513698-ceae-4d97-9686-af1920488bb4",
          "type": "message",
          "user": "U044D824R8V",
          "text": "the behavior you have with UIFocus should be the same regardless of whether or not VoiceOver is on, if you are in navigation mode",
          "ts": "1666302129.949899",
          "thread_ts": "1666299973.606799",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "F+94p",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "the behavior you have with UIFocus should be the same regardless of whether or not VoiceOver is on, if you are in navigation mode"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "E8968E2F-B4BF-4D5D-9396-9ECF7BEA187A",
          "type": "message",
          "user": "U046G37DF33",
          "text": "Yes only when voiceover is on. ",
          "ts": "1666302147.051809",
          "thread_ts": "1666299973.606799",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "vBV",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Yes only when voiceover is on"
                    },
                    {
                      "type": "text",
                      "text": "."
                    },
                    {
                      "type": "text",
                      "text": " "
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "a3c2a02e-0163-42d9-90e9-8d0d6e340020",
          "type": "message",
          "user": "U044D824R8V",
          "text": "could you share more about how you are telling VoiceOver what to focus on?",
          "ts": "1666302173.230899",
          "thread_ts": "1666299973.606799",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "xSmR",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "could you share more about how you are telling VoiceOver what to focus on?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "210f99a6-ae4d-4259-924d-6502c0bdff4d",
          "type": "message",
          "user": "U044D824R8V",
          "text": "which APIs are you using?",
          "ts": "1666302181.305229",
          "thread_ts": "1666299973.606799",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "iHcit",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "which APIs are you using?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "c0795877-0b69-4bd6-8c79-ff2034073452",
          "type": "message",
          "user": "U04563C4N1W",
          "text": "If you are in Navigation mode and then hit a directional key on the Siri remote, VoiceOver actually will play the “bonk” sound if it encounters a focus border. Perhaps that is the issue here",
          "ts": "1666302233.978959",
          "thread_ts": "1666299973.606799",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "pAuiL",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "If you are in Navigation mode and then hit a directional key on the Siri remote, VoiceOver actually will play the “bonk” sound if it encounters a focus border. Perhaps that is the issue here"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "df71478e-96b3-4858-99d5-f8eb576c054c",
          "type": "message",
          "user": "U046G37DF33",
          "text": "OK \u003c@U04563C4N1W\u003e that is interesting.  So I’m using SpriteKit, all in ObjC because the app was started back in 2016 or so,  The various SKNodes that act as buttons all implement the UIAccessibilityElement protocol via a proxy.  The SKScene makes those proxys visible to voiceover so that when VoiceOver is activated, the user can navigate (or explore, it seems) around the app using left/right swipes.  A press on the Siri remote activates the SKNode that VoiceOver currently has focused.  If I also try to support UIFocus by implementing canBocumeFocused and returning YES then UIFocus gets involved and unless I also put a lot of extra work in, it all becomes a muddle.  So I’ve stuck with returning NO from canBecomeFocused everywhere and I use my own focus system that is entirely SpriteKit based (that way it works with and without VoiceOver).  When VoiceOveris enabled by the user it (correctly) gets the UIAccessibilityContainer from the SKScene (which in this instance is the overlaySKScene of a SCNView).  that container makes available to the OS, the list of UIAccessibilityElement proxys.  Navigating around those works, but some gestures like the button press can get eaten.  On tvOS, because I can’t work out how to use double-tap-and-hold, I chose to add gesture recognizers for the 4 directional buttons on the siri remote to allow the user to move the camera that way.  Works fine without voice over enabled, but with it disabled I run into “bonk” sounds.  I thought it was UIFocus getting in the way but now you say that UIAccessibility can also “bonk” so maybe thats a lead.",
          "ts": "1666303020.846849",
          "thread_ts": "1666299973.606799",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "yG9Q",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "OK "
                    },
                    {
                      "type": "user",
                      "user_id": "U04563C4N1W"
                    },
                    {
                      "type": "text",
                      "text": " that is interesting.  So I’m using SpriteKit, all in ObjC because the app was started back in 2016 or so,  The various SKNodes that act as buttons all implement the UIAccessibilityElement protocol via a proxy.  The SKScene makes those proxys visible to voiceover so that when VoiceOver is activated, the user can navigate (or explore, it seems) around the app using left/right swipes.  A press on the Siri remote activates the SKNode that VoiceOver currently has focused.  If I also try to support UIFocus by implementing canBocumeFocused and returning YES then UIFocus gets involved and unless I also put a lot of extra work in, it all becomes a muddle.  So I’ve stuck with returning NO from canBecomeFocused everywhere and I use my own focus system that is entirely SpriteKit based (that way it works with and without VoiceOver).  When VoiceOveris enabled by the user it (correctly) gets the UIAccessibilityContainer from the SKScene (which in this instance is the overlaySKScene of a SCNView).  that container makes available to the OS, the list of UIAccessibilityElement proxys.  Navigating around those works, but some gestures like the button press can get eaten.  On tvOS, because I can’t work out how to use double-tap-and-hold, I chose to add gesture recognizers for the 4 directional buttons on the siri remote to allow the user to move the camera that way.  Works fine without voice over enabled, but with it disabled I run into “bonk” sounds.  I thought it was UIFocus getting in the way but now you say that UIAccessibility can also “bonk” so maybe thats a lead."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "4ba9b0d0-655c-42d5-a265-6a9f0bda46f6",
          "type": "message",
          "user": "U046G37DF33",
          "text": "sorry for the wall",
          "ts": "1666303025.142509",
          "thread_ts": "1666299973.606799",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "PJ3m2",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "sorry for the wall"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "727510b4-e1fa-4cae-bf5a-a548fe5a990f",
          "type": "message",
          "user": "U044D824R8V",
          "text": "interesting, if you can file a feedback report with some sample code we might want to take a look at this. In navigation mode, we shouldn't be focusing on these SKNodes if canBecomeFocused is NO I'm pretty sure, everything should default to your custom focus system I'd think.",
          "ts": "1666303180.235499",
          "thread_ts": "1666299973.606799",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "dvY",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "interesting, if you can file a feedback report with some sample code we might want to take a look at this. In navigation mode, we shouldn't be focusing on these SKNodes if canBecomeFocused is NO I'm pretty sure, everything should default to your custom focus system I'd think."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "c998aeda-5bc9-435a-9fe5-491dc10f4b04",
          "type": "message",
          "user": "U04563C4N1W",
          "text": "ahh i see, so i think what might be happening is when VO moves by item (siri direction button press) we monitor the result of canBecomeFocused and the focus movement. If we get the same element back, we play the bonk sound which is supposed to let users know they reached a border. It seems like we might need some API to suppress this behavior. I wonder if you can return some sort of sentinel element that is different so that VoiceOver doesnt think it is landing on the same element each time.",
          "ts": "1666303217.752949",
          "thread_ts": "1666299973.606799",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "YdvjA",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "ahh i see, so i think what might be happening is when VO moves by item (siri direction button press) we monitor the result of canBecomeFocused and the focus movement. If we get the same element back, we play the bonk sound which is supposed to let users know they reached a border. It seems like we might need some API to suppress this behavior. I wonder if you can return some sort of sentinel element that is different so that VoiceOver doesnt think it is landing on the same element each time."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "e125d7ff-6a00-44dc-bae4-4793f39bd40c",
          "type": "message",
          "user": "U046G37DF33",
          "text": "\u003c@U044D824R8V\u003e OK.  I’ve started the process of cutting the app down to a minimum to demonstrate the problems I’m having with a DTS call or feedback in mind.  I’ll continue that path.",
          "ts": "1666303289.868929",
          "thread_ts": "1666299973.606799",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "+1::skin-tone-2",
              "count": 1,
              "users": [
                "U044D824R8V"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "d8M",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "user",
                      "user_id": "U044D824R8V"
                    },
                    {
                      "type": "text",
                      "text": " OK.  I’ve started the process of cutting the app down to a minimum to demonstrate the problems I’m having with a DTS call or feedback in mind.  I’ll continue that path."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "e18e1d74-dae3-447c-9f21-14707f62babb",
          "type": "message",
          "user": "U046G37DF33",
          "text": "\u003c@U04563C4N1W\u003e ooohhh.  interesting idea.  I’ll give that a try.  it would be nice to have a work around whilst I also follow the DTS/feedback path.  Thank you",
          "ts": "1666303340.286509",
          "thread_ts": "1666299973.606799",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Ri1Gc",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "user",
                      "user_id": "U04563C4N1W"
                    },
                    {
                      "type": "text",
                      "text": " ooohhh.  interesting idea.  I’ll give that a try.  it would be nice to have a work around whilst I also follow the DTS/feedback path.  Thank you"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046G4C02JV\u003e asked\n\u0026gt; Considering that Apple UI frameworks have built-in accessibility, it works well if we use the framework views and controls. However, if we stray from that such as by creating custom views, not subclassing the base class, or layer several views to create a more complicated component, there is the possibility of losing some context for the component. Now for making the component accessible or enhancing it, there are APIs for that.\n\u0026gt; \n\u0026gt; For example, let’s say we have a custom segmented control, simply a stack view made up of labels and another view that is added on top when selected. To let the user know whether the single tab is selected, we can add to our component to add or remove the `.isSelected` trait to the view that represents the single segment. But the base UISegmentedControl does mention the number of tabs to choose from (i.e. “1 of n”). I try to look for examples across Apple’s apps and ecosystem to better understand how you all have handled making views and controls understandable, intractable, and navigable. And so I’ve come across some questions:\n\u0026gt; \n\u0026gt; \t1. For custom views and controls that are similar to Apple’s views and controls, in the overall appearance and behavior, what do you all suggest in ensuring that these custom components are, not necessarily the same, but close to how the views and controls in the UIKit and SwiftUI frameworks handle the accessibility UX. \n\u0026gt; \t2. And an extension to the question above, regarding more complicated scenarios such as combining views to form a component. What is the best way to handle such scenarios? Just to continue the example from above, I came across a scenario where my app required a pager with a custom segmented control at the top. Very similar behavior to a tab bar navigation and to the iOS Home Screen.\n\u0026gt; \n\u0026gt; Hopefully that makes sense! I understand how to make views accessible. Luckily, there are APIs for that :) I want to better understand what are some best practices and/or suggestions for going about making custom views and controls and more complicated scenarios that combine views and controls into a component accessible.",
      "ts": "1666299999.474889",
      "thread_ts": "1666299999.474889",
      "subtype": "bot_message",
      "bot_id": "B0434N8CV28",
      "username": "Ask Apple - accessibility",
      "reply_count": 4,
      "latest_reply": "1666301014.903669",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "U4KTw",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046G4C02JV"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Considering that Apple UI frameworks have built-in accessibility, it works well if we use the framework views and controls. However, if we stray from that such as by creating custom views, not subclassing the base class, or layer several views to create a more complicated component, there is the possibility of losing some context for the component. Now for making the component accessible or enhancing it, there are APIs for that.\\n\\nFor example, let\\u2019s say we have a custom segmented control, simply a stack view made up of labels and another view that is added on top when selected. To let the user know whether the single tab is selected, we can add to our component to add or remove the `.isSelected` trait to the view that represents the single segment. But the base UISegmentedControl does mention the number of tabs to choose from (i.e. \\u201c1 of n\\u201d). I try to look for examples across Apple\\u2019s apps and ecosystem to better understand how you all have handled making views and controls understandable, intractable, and navigable. And so I\\u2019ve come across some questions:\\n\\n\\t1. For custom views and controls that are similar to Apple\\u2019s views and controls, in the overall appearance and behavior, what do you all suggest in ensuring that these custom components are, not necessarily the same, but close to how the views and controls in the UIKit and SwiftUI frameworks handle the accessibility UX. \\n\\t2. And an extension to the question above, regarding more complicated scenarios such as combining views to form a component. What is the best way to handle such scenarios? Just to continue the example from above, I came across a scenario where my app required a pager with a custom segmented control at the top. Very similar behavior to a tab bar navigation and to the iOS Home Screen.\\n\\nHopefully that makes sense! I understand how to make views accessible. Luckily, there are APIs for that :) I want to better understand what are some best practices and\\/or suggestions for going about making custom views and controls and more complicated scenarios that combine views and controls into a component accessible.\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "6786f92a-3f5c-4468-bc58-4ed576d8a1b5",
          "type": "message",
          "user": "U044D824R8V",
          "text": "Hi Cassandra, sounds like you're already practicing some good habits when it comes to making custom controls accessible! Looking for examples throughout our UI is a great start. For example, in your case of your custom segmented control, adding the selected trait and an accessibilityValue that tells you the number of items in the control is a good practice. You can always create a sample app, add the default UIKit/SwiftUI control to the app and play around with VoiceOver to see how we've gone about making these controls accessible, and then try to follow those design principles.\n\nAs far as for reusing these components in larger controls, I'd say it's important to look at your control as a whole and do what's right for that control. Just because some design works well for a smaller control doesn't necessarily mean it will make sense for when that control is reused as part of a larger control in a different way, so think critically about each control and customize the accessibility of each subcomponent for the role it's playing in your app at a given time.",
          "ts": "1666300010.234929",
          "thread_ts": "1666299999.474889",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Nl0",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi Cassandra, sounds like you're already practicing some good habits when it comes to making custom controls accessible! Looking for examples throughout our UI is a great start. For example, in your case of your custom segmented control, adding the selected trait and an accessibilityValue that tells you the number of items in the control is a good practice. You can always create a sample app, add the default UIKit/SwiftUI control to the app and play around with VoiceOver to see how we've gone about making these controls accessible, and then try to follow those design principles.\n\nAs far as for reusing these components in larger controls, I'd say it's important to look at your control as a whole and do what's right for that control. Just because some design works well for a smaller control doesn't necessarily mean it will make sense for when that control is reused as part of a larger control in a different way, so think critically about each control and customize the accessibility of each subcomponent for the role it's playing in your app at a given time."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "df290765-8b9b-4daa-adf2-d8abf38c68e2",
          "type": "message",
          "user": "U0449P12PP0",
          "text": "I'd also add that if you're using SwiftUI, the \u003chttps://developer.apple.com/documentation/swiftui/grid/accessibilityrepresentation(representation:)|accessibilityRepresentation(representation:)\u003e modifier can be a great way to still take advantage of the out-of-the-box accessibility that comes with the base SwiftUI views! Adding this modifier to a custom view can allow you to still use your custom version of a component, but have assistive technologies treat it as a system component and automatically expose things like increment and decrement actions for a slider, for example.",
          "ts": "1666300489.425259",
          "thread_ts": "1666299999.474889",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "partying_face",
              "count": 1,
              "users": [
                "U044D824R8V"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "t12",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I'd also add that if you're using SwiftUI, the "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/swiftui/grid/accessibilityrepresentation(representation:)",
                      "text": "accessibilityRepresentation(representation:)"
                    },
                    {
                      "type": "text",
                      "text": " modifier can be a great way to still take advantage of the out-of-the-box accessibility that comes with the base SwiftUI views! Adding this modifier to a custom view can allow you to still use your custom version of a component, but have assistive technologies treat it as a system component and automatically expose things like increment and decrement actions for a slider, for example."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "88e09388-8541-48e6-b9ec-55bf35d58fa9",
          "type": "message",
          "user": "U046G4C02JV",
          "text": "Thank you Dan and Ryan for the awesome guidance and suggestions! Definitely helps as I continue to learn about the several APIs that are available and how to customize the accessibility for the components I work on. I appreciate you taking the time to answer my question :slightly_smiling_face:",
          "ts": "1666300956.353419",
          "thread_ts": "1666299999.474889",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "dVnq",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thank you Dan and Ryan for the awesome guidance and suggestions! Definitely helps as I continue to learn about the several APIs that are available and how to customize the accessibility for the components I work on. I appreciate you taking the time to answer my question "
                    },
                    {
                      "type": "emoji",
                      "name": "slightly_smiling_face",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "cc0e7344-38fc-4c50-af05-8a6545a63059",
          "type": "message",
          "user": "U044D824R8V",
          "text": "Anytime! Thanks for submitting it!",
          "ts": "1666301014.903669",
          "thread_ts": "1666299999.474889",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "d7iAj",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Anytime! Thanks for submitting it!"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U04607CDQ05\u003e asked\n\u0026gt; does @AccessibilityFocusState handle keyboard focus as well? Based on my experience, it doesn't seem to be working?",
      "ts": "1666300027.340099",
      "thread_ts": "1666300027.340099",
      "subtype": "bot_message",
      "bot_id": "B0434N8CV28",
      "username": "Ask Apple - accessibility",
      "reply_count": 3,
      "latest_reply": "1666302292.913069",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "x94y9",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U04607CDQ05"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"does @AccessibilityFocusState handle keyboard focus as well? Based on my experience, it doesn't seem to be working?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "d148e336-6df6-499e-9cf2-7b33b7c48f33",
          "type": "message",
          "user": "U044G9DLCUB",
          "text": "Hi John, keyboard focus is handled by UIFocusEnvironment and UIFocusItem.",
          "ts": "1666300033.452209",
          "thread_ts": "1666300027.340099",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "5x86x",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi John, keyboard focus is handled by UIFocusEnvironment and UIFocusItem."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "6497b305-38db-4aba-8c65-7e4bee8ca272",
          "type": "message",
          "user": "U045VJUAUDC",
          "text": "You can use `@FocusState` alongside `@AccessibilityFocusState`",
          "ts": "1666300234.103339",
          "thread_ts": "1666300027.340099",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U044G9DLCUB"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "EyAc",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "You can use "
                    },
                    {
                      "type": "text",
                      "text": "@FocusState",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " alongside "
                    },
                    {
                      "type": "text",
                      "text": "@AccessibilityFocusState",
                      "style": {
                        "code": true
                      }
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "4492992a-a10e-4ccc-b4ee-c2eb6da5d053",
          "type": "message",
          "user": "U046LKK3L81",
          "text": "Isn’t there something about this only works inside a NavigationView (assuming SwiftUI)",
          "ts": "1666302292.913069",
          "thread_ts": "1666300027.340099",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "ASu",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Isn’t there something about this only works inside a NavigationView (assuming SwiftUI)"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U0463JX7JTU\u003e asked\n\u0026gt; What is the best way to handle accessibility in a social feed?",
      "ts": "1666300061.099159",
      "thread_ts": "1666300061.099159",
      "subtype": "bot_message",
      "bot_id": "B0434N8CV28",
      "username": "Ask Apple - accessibility",
      "reply_count": 1,
      "latest_reply": "1666300075.892459",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "j9b",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U0463JX7JTU"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"What is the best way to handle accessibility in a social feed?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "9bfad7d5-9516-48da-8095-a4f3fbfe1365",
          "type": "message",
          "user": "U044D824R8V",
          "text": "Our general best practices should apply to social feeds as well. Make sure everything is properly labeled and accessible to assistive technologies, use high contrast fonts and colors, and support dynamic type! Some of these feeds will continually pull in new content. Depending on how frequently the content is refreshing, it might be a good idea to announce to VoiceOver users when new content has appeared, or move VoiceOver focus to the newest content when it appears by posting a layout changed notification. This could potentially be disruptive though if your app is updating super frequently, so this kind of needs to be evaluated on a case by case basis. If you have more specific questions for a particular use case, feel free to elaborate in the thread!",
          "ts": "1666300075.892459",
          "thread_ts": "1666300061.099159",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "RuX",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Our general best practices should apply to social feeds as well. Make sure everything is properly labeled and accessible to assistive technologies, use high contrast fonts and colors, and support dynamic type! Some of these feeds will continually pull in new content. Depending on how frequently the content is refreshing, it might be a good idea to announce to VoiceOver users when new content has appeared, or move VoiceOver focus to the newest content when it appears by posting a layout changed notification. This could potentially be disruptive though if your app is updating super frequently, so this kind of needs to be evaluated on a case by case basis. If you have more specific questions for a particular use case, feel free to elaborate in the thread!"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046G37DF33\u003e asked\n\u0026gt; I note that SpriteKit / SceneKit have limited support for accessibility baked in on macOS.  Can we get feature parity for this on iOS/tvOS?  Right now I need to litter my code with conditional compilation if I want an applications accessibility support to be consistent across all three platforms.",
      "ts": "1666300115.556099",
      "thread_ts": "1666300115.556099",
      "subtype": "bot_message",
      "bot_id": "B0434N8CV28",
      "username": "Ask Apple - accessibility",
      "reply_count": 1,
      "latest_reply": "1666300142.089589",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "sg0P",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046G37DF33"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"I note that SpriteKit \\/ SceneKit have limited support for accessibility baked in on macOS.  Can we get feature parity for this on iOS\\/tvOS?  Right now I need to litter my code with conditional compilation if I want an applications accessibility support to be consistent across all three platforms.\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "f3c9b9c1-f827-4cc0-8e7d-a3444738cb5f",
          "type": "message",
          "user": "U0449LGV1FV",
          "text": "Thank you for the suggestion! We’ll note this, but if you can also file a feedback that would be helpful to push this along too.",
          "ts": "1666300142.089589",
          "thread_ts": "1666300115.556099",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "q7DDJ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thank you for the suggestion! We’ll note this, but if you can also file a feedback that would be helpful to push this along too."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U045WGB2MAS\u003e asked\n\u0026gt; Is there an audit we can run on our apps to check for accessibly issues?",
      "ts": "1666300205.510339",
      "thread_ts": "1666300205.510339",
      "subtype": "bot_message",
      "bot_id": "B0434N8CV28",
      "username": "Ask Apple - accessibility",
      "reply_count": 1,
      "latest_reply": "1666300210.737879",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "olvX",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U045WGB2MAS"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Is there an audit we can run on our apps to check for accessibly issues?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "2f478c29-0c0d-4e2e-ac50-a4bde2072761",
          "type": "message",
          "user": "U044G9DLCUB",
          "text": "Hi Tyson, yes! The Accessibility Inspector provides audit functionality; you can open it by control-clicking on Xcode, then selecting Open Developer Tool \u0026gt; Accessibility Inspector.\n\nThe second tab on the top right corner allows you to run Accessibility audits against the targeted device and app.\n\nThe Accessibility Inspector will report potential areas to investigate like fixed text sizes (that do not respond to Dynamic Type preference changes), image contrast, among others.",
          "ts": "1666300210.737879",
          "thread_ts": "1666300205.510339",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "partying_face",
              "count": 2,
              "users": [
                "U045WGB2MAS",
                "U046LKK3L81"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "e+BnN",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi Tyson, yes! The Accessibility Inspector provides audit functionality; you can open it by control-clicking on Xcode, then selecting Open Developer Tool \u003e Accessibility Inspector.\n\nThe second tab on the top right corner allows you to run Accessibility audits against the targeted device and app.\n\nThe Accessibility Inspector will report potential areas to investigate like fixed text sizes (that do not respond to Dynamic Type preference changes), image contrast, among others."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046PCPQEV7\u003e asked\n\u0026gt; My question is related to a VoiceOver issue in iOS 16.\n\u0026gt; I have an app that utilises MapKit, and in pre-iOS 16 devices, VoiceOver recognised the map annotations and user location annotation. However, they are not recognised by VoiceOver in iOS 16 devices.\n\u0026gt; If I cycle through the screen elements from top to bottom and vice versa a few times, it recognises them, but the behaviour is very inconsistent.\n\u0026gt; I am using a custom annotation class, and the user location annotation is the system's default.",
      "ts": "1666300212.203149",
      "thread_ts": "1666300212.203149",
      "subtype": "bot_message",
      "bot_id": "B0434N8CV28",
      "username": "Ask Apple - accessibility",
      "reply_count": 1,
      "latest_reply": "1666300233.626109",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "WzppO",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046PCPQEV7"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"My question is related to a VoiceOver issue in iOS 16.\\nI have an app that utilises MapKit, and in pre-iOS 16 devices, VoiceOver recognised the map annotations and user location annotation. However, they are not recognised by VoiceOver in iOS 16 devices.\\nIf I cycle through the screen elements from top to bottom and vice versa a few times, it recognises them, but the behaviour is very inconsistent.\\nI am using a custom annotation class, and the user location annotation is the system's default.\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "7657b45d-fc48-4e56-be62-27b0063dbe25",
          "type": "message",
          "user": "U0449LGV1FV",
          "text": "Thanks for your reporting this. We’ll note it, but if you can file a feedback that would be very helpful.",
          "ts": "1666300233.626109",
          "thread_ts": "1666300212.203149",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U046PCPQEV7"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "/pfS",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks for your reporting this. We’ll note it, but if you can file a feedback that would be very helpful."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046Y0G27B7\u003e asked\n\u0026gt; I am trying to use `@AccessibilityFocusState` to place VoiceOver focus on a specific view when entering a new screen. The system’s default choice of forcing focus on the top left element keeps interrupting my view from receiving focus. I was able to get it working after adding a long delay on the property when entering the screen, but I don’t think this is the best solution. `@AccessibilityFocusState` seems to work without a delay when changing the focus location on the current screen, but not when I’m navigating to another screen. What is the recommended approach to target your VoiceOver focus location when first entering a screen?",
      "ts": "1666300264.345369",
      "thread_ts": "1666300264.345369",
      "subtype": "bot_message",
      "bot_id": "B0434N8CV28",
      "username": "Ask Apple - accessibility",
      "reply_count": 2,
      "latest_reply": "1666300295.365139",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "XLBb",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046Y0G27B7"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"I am trying to use `@AccessibilityFocusState` to place VoiceOver focus on a specific view when entering a new screen. The system\\u2019s default choice of forcing focus on the top left element keeps interrupting my view from receiving focus. I was able to get it working after adding a long delay on the property when entering the screen, but I don\\u2019t think this is the best solution. `@AccessibilityFocusState` seems to work without a delay when changing the focus location on the current screen, but not when I\\u2019m navigating to another screen. What is the recommended approach to target your VoiceOver focus location when first entering a screen?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "73b6f5bc-1055-43ee-8226-ca4f07b0691a",
          "type": "message",
          "user": "U044G9DLCUB",
          "text": "Hi Paul, we’re making a note of this; if you’re able to file this using Feedback Assistant, that’d be awesome as well. Thanks!",
          "ts": "1666300268.473939",
          "thread_ts": "1666300264.345369",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "dnLx",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi Paul, we’re making a note of this; if you’re able to file this using Feedback Assistant, that’d be awesome as well. Thanks!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "557f1539-2a8b-42bf-a41f-77a0bacb2f24",
          "type": "message",
          "user": "U046Y0G27B7",
          "text": "Will do. Thank you! :+1:",
          "ts": "1666300295.365139",
          "thread_ts": "1666300264.345369",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "1jO",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Will do. Thank you! "
                    },
                    {
                      "type": "emoji",
                      "name": "+1",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046Z7NUEH4\u003e asked\n\u0026gt; I create a UICollectionView with cells of type UICollectionViewListCell. The cells have `detail` system accessory. Since the user can trigger an action when he taps that detail accessory, I want to add accessibility information to that button. How is this possible?",
      "ts": "1666300412.465679",
      "thread_ts": "1666300412.465679",
      "subtype": "bot_message",
      "bot_id": "B0434N8CV28",
      "username": "Ask Apple - accessibility",
      "reply_count": 1,
      "latest_reply": "1666300492.132299",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "wbKwP",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046Z7NUEH4"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"I create a UICollectionView with cells of type UICollectionViewListCell. The cells have `detail` system accessory. Since the user can trigger an action when he taps that detail accessory, I want to add accessibility information to that button. How is this possible?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "cf42171b-ea37-4fa6-85d0-2e82b02cf979",
          "type": "message",
          "user": "U044D824R8V",
          "text": "The detail button if you are using a system accessory should be accessible by default in your cell. However, our typical recommendation here is to expose this as a custom action, so that when the user swipes up or down on the cell they can activate a \"show details\" action to tap on the details button. Check out the API here:\n\u003chttps://developer.apple.com/documentation/uikit/uiaccessibilitycustomaction?language=objc\u003e\n\nThis will allow you to customize the label and behavior that will happen when a user requests more details. Make sure to set `isAccessibilityElement` to `true` on your collection view cell as well, so that the button is no longer individually navigable, this will speed up navigation for VoiceOver users as well",
          "ts": "1666300492.132299",
          "thread_ts": "1666300412.465679",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "qQ=km",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "The detail button if you are using a system accessory should be accessible by default in your cell. However, our typical recommendation here is to expose this as a custom action, so that when the user swipes up or down on the cell they can activate a \"show details\" action to tap on the details button. Check out the API here:\n"
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/uikit/uiaccessibilitycustomaction?language=objc",
                      "text": ""
                    },
                    {
                      "type": "text",
                      "text": "\n\nThis will allow you to customize the label and behavior that will happen when a user requests more details. Make sure to set "
                    },
                    {
                      "type": "text",
                      "text": "isAccessibilityElement",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " to "
                    },
                    {
                      "type": "text",
                      "text": "true",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " on your collection view cell as well, so that the button is no longer individually navigable, this will speed up navigation for VoiceOver users as well"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046K40HFAN\u003e asked\n\u0026gt; Hi, Apple! Thanks always for the amazing accessible products!\n\u0026gt; \n\u0026gt; I have a question about `isAccessibleElement` API.  It seems that default value of `isAccessibleElement` for most of UIControls are `false`. And it's little bit counter-intuitive for me, becuase they are actually accessible to assistive technologies like VoiceOver by default.\n\u0026gt; \n\u0026gt; Is there a reason why the default value of `isAccessibilityElement` false? And why are they still `accessible`? \n\u0026gt; \n\u0026gt; Also, is there any way to find out a UIControl is actually accessible to assistive technology? \n\u0026gt; (So that I can safely delete this kind of code :sweat_smile: \u003chttps://github.com/banksalad/AXSnapshot/blob/1c00f9b7f5a8eabbf56f201abecd097e83d83439/Sources/AXSnapshot/UIResponder%2BExtension.swift#L45)|https://github.com/banksalad/AXSnapshot/blob/1c00f9b7f5a8eabbf56f201abecd097e83d83439/Sources/AXSnapshot/UIResponder%2BExtension.swift#L45)\u003e",
      "ts": "1666300441.628139",
      "thread_ts": "1666300441.628139",
      "attachments": [
        {
          "fallback": "GitHub: AXSnapshot/UIResponder+Extension.swift at 1c00f9b7f5a8eabbf56f201abecd097e83d83439 · banksalad/AXSnapshot",
          "id": 1,
          "title": "AXSnapshot/UIResponder+Extension.swift at 1c00f9b7f5a8eabbf56f201abecd097e83d83439 · banksalad/AXSnapshot",
          "title_link": "https://github.com/banksalad/AXSnapshot/blob/1c00f9b7f5a8eabbf56f201abecd097e83d83439/Sources/AXSnapshot/UIResponder%2BExtension.swift#L45)",
          "text": "Text Formatted Snapshot for Accessibility Experience Testing - AXSnapshot/UIResponder+Extension.swift at 1c00f9b7f5a8eabbf56f201abecd097e83d83439 · banksalad/AXSnapshot",
          "image_url": "https://opengraph.githubassets.com/35a8ad9299bab7ad1129c2762b22bf553a868529b8bfd42fd08f3073f2ace919/banksalad/AXSnapshot",
          "service_name": "GitHub",
          "service_icon": "https://a.slack-edge.com/80588/img/unfurl_icons/github.png",
          "from_url": "https://github.com/banksalad/AXSnapshot/blob/1c00f9b7f5a8eabbf56f201abecd097e83d83439/Sources/AXSnapshot/UIResponder%2BExtension.swift#L45)",
          "original_url": "https://github.com/banksalad/AXSnapshot/blob/1c00f9b7f5a8eabbf56f201abecd097e83d83439/Sources/AXSnapshot/UIResponder%2BExtension.swift#L45)",
          "blocks": null
        }
      ],
      "edited": {
        "user": "B0434N8CV28",
        "ts": "1666300443.000000"
      },
      "subtype": "bot_message",
      "bot_id": "B0434N8CV28",
      "username": "Ask Apple - accessibility",
      "reply_count": 1,
      "latest_reply": "1666300576.624739",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "bFhH",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046K40HFAN"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Hi, Apple! Thanks always for the amazing accessible products!\\n\\nI have a question about `isAccessibleElement` API.  It seems that default value of `isAccessibleElement` for most of UIControls are `false`. And it's little bit counter-intuitive for me, becuase they are actually accessible to assistive technologies like VoiceOver by default.\\n\\nIs there a reason why the default value of `isAccessibilityElement` false? And why are they still `accessible`? \\n\\nAlso, is there any way to find out a UIControl is actually accessible to assistive technology? \\n(So that I can safely delete this kind of code \"},{\"type\":\"emoji\",\"name\":\"sweat_smile\",\"unicode\":\"1f605\"},{\"type\":\"text\",\"text\":\" \"},{\"type\":\"link\",\"url\":\"https:\\/\\/github.com\\/banksalad\\/AXSnapshot\\/blob\\/1c00f9b7f5a8eabbf56f201abecd097e83d83439\\/Sources\\/AXSnapshot\\/UIResponder%2BExtension.swift#L45)\",\"text\":\"https:\\/\\/github.com\\/banksalad\\/AXSnapshot\\/blob\\/1c00f9b7f5a8eabbf56f201abecd097e83d83439\\/Sources\\/AXSnapshot\\/UIResponder%2BExtension.swift#L45)\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "943978a2-62d9-407c-877b-b389f7b74609",
          "type": "message",
          "user": "U0449LGV1FV",
          "text": "There are a few things to consider here.\n\n1. If an Assistive Technology (like VoiceOver) is not running, then many properties will return nil/false, because accessibility is only loaded when needed. If you’re seeing UIButton.isAccessibilityElement == false — that’s probably what’s happening\n2. UIControl itself is *NOT* isAccessibilityElement = true, because it’s a generic element and it’s semantic meaning is unclear on its own… (is it a slider or a button or something else?). In those case the developer would have to set that the appropriate accessibility properties to help define what it is (label, traits, and isAccessibilityElement)",
          "ts": "1666300576.624739",
          "thread_ts": "1666300441.628139",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "P2sI",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "There are a few things to consider here.\n\n"
                    }
                  ]
                },
                {
                  "Type": "rich_text_list",
                  "Raw": "{\"type\":\"rich_text_list\",\"elements\":[{\"type\":\"rich_text_section\",\"elements\":[{\"type\":\"text\",\"text\":\"If an Assistive Technology (like VoiceOver) is not running, then many properties will return nil\\/false, because accessibility is only loaded when needed. If you\\u2019re seeing UIButton.isAccessibilityElement == false \\u2014 that\\u2019s probably what\\u2019s happening\"}]},{\"type\":\"rich_text_section\",\"elements\":[{\"type\":\"text\",\"text\":\"UIControl itself is \"},{\"type\":\"text\",\"text\":\"NOT\",\"style\":{\"bold\":true}},{\"type\":\"text\",\"text\":\" isAccessibilityElement = true, because it\\u2019s a generic element and it\\u2019s semantic meaning is unclear on its own\\u2026 (is it a slider or a button or something else?). In those case the developer would have to set that the appropriate accessibility properties to help define what it is (label, traits, and isAccessibilityElement)\"}]}],\"style\":\"ordered\",\"indent\":0,\"border\":0}"
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046Y0G27B7\u003e asked\n\u0026gt; Using the Text view’s new Markdown formatting support in SwiftUI, I am attempting to create a line of text containing two inline links. On iOS 15, when VoiceOver focus is placed on this view, the rotor tool displays a \"Links\" option allowing access to each available link. On iOS 16, the same scenario results in the \"Links\" rotor option not being displayed. This seems to prevent VoiceOver from accessing any inline link. Is this change intentional? What is the recommended approach to handle inline links with VoiceOver in SwiftUI for iOS 16?\n\u0026gt;  \n\u0026gt; An example of this behavior can be found in the Weather App. At the very bottom of the screen is a line of text containing two inline links: \"Learn more about weather data and map data\". Placing VoiceOver focus on this element results in the link rotor displaying on iOS 15 and not 16.",
      "ts": "1666300624.487169",
      "thread_ts": "1666300624.487169",
      "subtype": "bot_message",
      "bot_id": "B0434N8CV28",
      "username": "Ask Apple - accessibility",
      "reply_count": 1,
      "latest_reply": "1666300652.879299",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "2xH3",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046Y0G27B7"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Using the Text view\\u2019s new Markdown formatting support in SwiftUI, I am attempting to create a line of text containing two inline links. On iOS 15, when VoiceOver focus is placed on this view, the rotor tool displays a \\\"Links\\\" option allowing access to each available link. On iOS 16, the same scenario results in the \\\"Links\\\" rotor option not being displayed. This seems to prevent VoiceOver from accessing any inline link. Is this change intentional? What is the recommended approach to handle inline links with VoiceOver in SwiftUI for iOS 16?\\n \\nAn example of this behavior can be found in the Weather App. At the very bottom of the screen is a line of text containing two inline links: \\\"Learn more about weather data and map data\\\". Placing VoiceOver focus on this element results in the link rotor displaying on iOS 15 and not 16.\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "260c96a6-d418-465f-8b22-dbb764208c48",
          "type": "message",
          "user": "U0449LGV1FV",
          "text": "Hi - Thanks for reporting this. We’ll make a note internally and if you can file a feedback it would be very much appreciated.",
          "ts": "1666300652.879299",
          "thread_ts": "1666300624.487169",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "0id",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi - Thanks for reporting this. We’ll make a note internally and if you can file a feedback it would be very much appreciated."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046LKK3L81\u003e asked\n\u0026gt; SwiftUI and SFSymbols are great for supporting Dynamic Text. I test with the control center slide that goes up the 135% should I be testing my interface to bigger text? How do I do that?",
      "ts": "1666300708.167069",
      "thread_ts": "1666300708.167069",
      "subtype": "bot_message",
      "bot_id": "B0434N8CV28",
      "username": "Ask Apple - accessibility",
      "reply_count": 16,
      "latest_reply": "1666301829.510209",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "xh3",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046LKK3L81"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"SwiftUI and SFSymbols are great for supporting Dynamic Text. I test with the control center slide that goes up the 135% should I be testing my interface to bigger text? How do I do that?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "e965a085-c217-4b13-b14b-8b3be1eb2633",
          "type": "message",
          "user": "U044D824R8V",
          "text": "Definitely! Larger text sizes are available in Settings \u0026gt; Accessibility \u0026gt; Display and Text Size \u0026gt; Larger Text. Toggle this switch to On, and you'll get 5 additional sizes, and your control center slider will add the additional sizes as well. It's definitely a great idea to test all of the AX sizes as well. Typically, you might want to make some modifications at those 5 larger sizes as well, such as converting horizontal layouts to vertical layouts to allow text more room to grow.",
          "ts": "1666300784.800019",
          "thread_ts": "1666300708.167069",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "7FJ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Definitely! Larger text sizes are available in Settings \u003e Accessibility \u003e Display and Text Size \u003e Larger Text. Toggle this switch to On, and you'll get 5 additional sizes, and your control center slider will add the additional sizes as well. It's definitely a great idea to test all of the AX sizes as well. Typically, you might want to make some modifications at those 5 larger sizes as well, such as converting horizontal layouts to vertical layouts to allow text more room to grow."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "523c50ef-6327-465b-a358-687d15164fac",
          "type": "message",
          "user": "U046LKK3L81",
          "text": "Wow! fitting my interface in with text that big will be a challenge. I suppose that’s where ViewThatFits comes in. But I want to keep supporting iOS15.",
          "ts": "1666301030.490329",
          "thread_ts": "1666300708.167069",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "yDSv",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Wow! fitting my interface in with text that big will be a challenge. I suppose that’s where ViewThatFits comes in. But I want to keep supporting iOS15."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "af6be7c8-8aff-4c15-9d6e-2d56cc8494bb",
          "type": "message",
          "user": "U044D824R8V",
          "text": "These sizes have been available since at least iOS 11, so no worries about backwards compatibility there",
          "ts": "1666301076.433709",
          "thread_ts": "1666300708.167069",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "lNr=",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "These sizes have been available since at least iOS 11, so no worries about backwards compatibility there"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "d3fb16e9-8d00-41ea-a735-3a9c00c3a531",
          "type": "message",
          "user": "U046LKK3L81",
          "text": "Oh the sizes I can get to now - even on the simulator. It’s how to make my SwiftUI app interface be usable!",
          "ts": "1666301122.375029",
          "thread_ts": "1666300708.167069",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "+1::skin-tone-2",
              "count": 1,
              "users": [
                "U044D824R8V"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "xn4Yg",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Oh the sizes I can get to now - even on the simulator. It’s how to make my SwiftUI app interface be usable!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "bf114b10-eab3-4bab-8e07-a5e2f4946478",
          "type": "message",
          "user": "U044D824R8V",
          "text": "If you're looking for inspiration, I'd look at some of our built in apps to see how we've tried to accommodate large text. For example, in the Weather app we remove the temperature slider and put the high/low temp on the next line when you have an AX text size on to give the text more room",
          "ts": "1666301223.004569",
          "thread_ts": "1666300708.167069",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "iH3",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "If you're looking for inspiration, I'd look at some of our built in apps to see how we've tried to accommodate large text. For example, in the Weather app we remove the temperature slider and put the high/low temp on the next line when you have an AX text size on to give the text more room"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "0db4c01b-a383-4ab4-9a21-f008dd55288b",
          "type": "message",
          "user": "U044D824R8V",
          "text": "While we try to avoid removing UI, in that particular case, the visual is redundant to the high/low text values so we felt it more important to make that text large, while still trying to keep the UI somewhat compact.",
          "ts": "1666301262.425909",
          "thread_ts": "1666300708.167069",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Naot",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "While we try to avoid removing UI, in that particular case, the visual is redundant to the high/low text values so we felt it more important to make that text large, while still trying to keep the UI somewhat compact."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "1bfecd30-5a52-49d9-9309-35ad473a4863",
          "type": "message",
          "user": "U046LKK3L81",
          "text": "I see my Text gets huge - but the text in my pickers doesn’t scale nearly as big (at least not in the simulator) is there a way to scale those up to huge too?",
          "ts": "1666301291.823999",
          "thread_ts": "1666300708.167069",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "xCx",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I see my Text gets huge - but the text in my pickers doesn’t scale nearly as big (at least not in the simulator) is there a way to scale those up to huge too?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "28bb0967-f85e-408a-9ec4-bbe81071a6db",
          "type": "message",
          "user": "U044D824R8V",
          "text": "which pickers are you referring to? Is this something custom you've built, or a default control?",
          "ts": "1666301322.933399",
          "thread_ts": "1666300708.167069",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "+MElR",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "which pickers are you referring to? Is this something custom you've built, or a default control?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "f1e2de43-d7c8-45d8-bccb-daf5f07eb9cb",
          "type": "message",
          "user": "U046LKK3L81",
          "text": "it’s a DatePicker in SwiftUI",
          "ts": "1666301393.798419",
          "thread_ts": "1666300708.167069",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "zOzQo",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "it’s a DatePicker in SwiftUI"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "828ea3f2-d8b1-45fc-8a95-2c0dbc1cf824",
          "type": "message",
          "user": "U046LKK3L81",
          "text": "default.",
          "ts": "1666301400.775659",
          "thread_ts": "1666300708.167069",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "68fhj",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "default."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "2cba4a6c-bffe-4455-9dc3-7ece7853e536",
          "type": "message",
          "user": "U044D824R8V",
          "text": "gotcha, default controls should scale to large text by default, if you're not seeing that please file a feedback report for us to look into. Some controls don't have room to grow and we support those in other ways, using things like the large content viewer.",
          "ts": "1666301498.512789",
          "thread_ts": "1666300708.167069",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "qW3",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "gotcha, default controls should scale to large text by default, if you're not seeing that please file a feedback report for us to look into. Some controls don't have room to grow and we support those in other ways, using things like the large content viewer."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "5d77c0ff-c547-493d-add8-14c905e77e86",
          "type": "message",
          "user": "U046LKK3L81",
          "text": "OK - it seems like the DatePicker limited to time could get bigger. The date picker is about as bit as it can be… but my interface is unusable. What’s the large content viewer?",
          "ts": "1666301639.463689",
          "thread_ts": "1666300708.167069",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "bA23",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "OK - it seems like the DatePicker limited to time could get bigger. The date picker is about as bit as it can be… but my interface is unusable. What’s the large content viewer?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "c573b70b-9b16-4af0-b2cb-f4997432dbda",
          "type": "message",
          "user": "U044D824R8V",
          "text": "\u003chttps://developer.apple.com/documentation/uikit/uilargecontentvieweritem?language=objc\u003e",
          "ts": "1666301694.777739",
          "thread_ts": "1666300708.167069",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U046LKK3L81"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "FUl=",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/uikit/uilargecontentvieweritem?language=objc",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "3beac493-0b3a-4d45-a638-767658e3a147",
          "type": "message",
          "user": "U044D824R8V",
          "text": "also check out this talk \u003chttps://developer.apple.com/wwdc19/261\u003e",
          "ts": "1666301721.713829",
          "thread_ts": "1666300708.167069",
          "attachments": [
            {
              "fallback": "Apple Developer: Large Content Viewer - Ensuring Readability for Everyone - WWDC19 - Videos - Apple Developer",
              "id": 1,
              "title": "Large Content Viewer - Ensuring Readability for Everyone - WWDC19 - Videos - Apple Developer",
              "title_link": "https://developer.apple.com/wwdc19/261",
              "text": "Tab Bars can't grow with dynamic text, but the Large Content Viewer helps them to be seen by people with low vision. iOS 13 brings this...",
              "image_url": "https://devimages-cdn.apple.com/wwdc-services/images/48/2819/2819_wide_250x141_2x.jpg",
              "service_name": "Apple Developer",
              "service_icon": "https://developer.apple.com/favicon.ico",
              "from_url": "https://developer.apple.com/wwdc19/261",
              "original_url": "https://developer.apple.com/wwdc19/261",
              "blocks": null
            }
          ],
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "olTy",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "also check out this talk "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/wwdc19/261",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "7ef5d06b-fe8d-4e72-9541-58ec22024467",
          "type": "message",
          "user": "U046LKK3L81",
          "text": "Thanks - I’ll check it out!:raised_hands:",
          "ts": "1666301783.132469",
          "thread_ts": "1666300708.167069",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "+1::skin-tone-2",
              "count": 1,
              "users": [
                "U044D824R8V"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "TSX",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks - I’ll check it out!"
                    },
                    {
                      "type": "emoji",
                      "name": "raised_hands",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "79d276c0-91f2-4dab-9f12-0bd28798f3cf",
          "type": "message",
          "user": "U044D824R8V",
          "text": "and lastly in SwiftUI: \u003chttps://developer.apple.com/documentation/swiftui/image/accessibilityshowslargecontentviewer(_:)\u003e",
          "ts": "1666301829.510209",
          "thread_ts": "1666300708.167069",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U046LKK3L81"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Yf3a",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "and lastly in SwiftUI: "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/swiftui/image/accessibilityshowslargecontentviewer(_:)",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046S70K9A4\u003e asked\n\u0026gt; Are there any way through Accessibility or VisionKit to interpret ASL?  (like speech-to-text but sign-to-text)?",
      "ts": "1666300770.137099",
      "thread_ts": "1666300770.137099",
      "subtype": "bot_message",
      "bot_id": "B0434N8CV28",
      "username": "Ask Apple - accessibility",
      "reply_count": 2,
      "latest_reply": "1666301014.968889",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "rjG",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046S70K9A4"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Are there any way through Accessibility or VisionKit to interpret ASL?  (like speech-to-text but sign-to-text)?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "3abf1a21-b09e-4b3d-938e-a3e07c6fdd0e",
          "type": "message",
          "user": "U0449LGV1FV",
          "text": "Not at this time.",
          "ts": "1666300782.237759",
          "thread_ts": "1666300770.137099",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "yBZ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Not at this time."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "42b2dc1a-7dbb-4e97-9d39-c308ccc6accf",
          "type": "message",
          "user": "U0449LGV1FV",
          "text": "But please file your feedbacks with your use cases. They help prioritize and drive development!",
          "ts": "1666301014.968889",
          "thread_ts": "1666300770.137099",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "3rt",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "But please file your feedbacks with your use cases. They help prioritize and drive development!"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046E348GSG\u003e asked\n\u0026gt; With a popup menu, I add On/Mixed/Off State Images to the NSMenuItems. The images are created with code (NSImage imageWithSize:…). But Voice Over reads out the entries as \"Space Menu Name\" (literally, it says the word “Space” followed by the menu name). With the default images, it says \"Tick Menu Name\" or \"Hyphen Menu Name\"). How can I get it to say something else (even the defaults would be fine) so that visually impaired users can differentiate the state? Setting the name or accessibilityDescription of the image does not work. I need this for macOS 10.13+. Thanks.",
      "ts": "1666300934.484599",
      "thread_ts": "1666300934.484599",
      "subtype": "bot_message",
      "bot_id": "B0434N8CV28",
      "username": "Ask Apple - accessibility",
      "reply_count": 1,
      "latest_reply": "1666301094.269079",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "/z5EV",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046E348GSG"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"With a popup menu, I add On\\/Mixed\\/Off State Images to the NSMenuItems. The images are created with code (NSImage imageWithSize:\\u2026). But Voice Over reads out the entries as \\\"Space Menu Name\\\" (literally, it says the word \\u201cSpace\\u201d followed by the menu name). With the default images, it says \\\"Tick Menu Name\\\" or \\\"Hyphen Menu Name\\\"). How can I get it to say something else (even the defaults would be fine) so that visually impaired users can differentiate the state? Setting the name or accessibilityDescription of the image does not work. I need this for macOS 10.13+. Thanks.\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "3ba47b27-4506-40e9-af80-518468d8010a",
          "type": "message",
          "user": "U044Z1BL294",
          "text": "We'll definitely take note of this and filing a feedback report about the image's accessibilityDescription not working would be really helpful here! In the mean time, NSMenuItem implements the NSAccessibilityProtocol so you should be able to provide any accessibilityLabel on the menu item object to override what VoiceOver users hear when navigating to that item such as including state information.",
          "ts": "1666301094.269079",
          "thread_ts": "1666300934.484599",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "email",
              "count": 1,
              "users": [
                "U046E348GSG"
              ]
            },
            {
              "name": "mailbox_closed",
              "count": 1,
              "users": [
                "U046E348GSG"
              ]
            },
            {
              "name": "-1",
              "count": 1,
              "users": [
                "U046E348GSG"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "rZCc",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "We'll definitely take note of this and filing a feedback report about the image's accessibilityDescription not working would be really helpful here! In the mean time, NSMenuItem implements the NSAccessibilityProtocol so you should be able to provide any accessibilityLabel on the menu item object to override what VoiceOver users hear when navigating to that item such as including state information."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U0465DVJZ4P\u003e asked\n\u0026gt; Are there any suggestions/advice/recommended best practices for VoiceOver focus management particularly when moving between View Controllers? For example, a VoiceOver user taps a share button, perhaps 100 cells down on a tableview, opening a share screen. But when the share screen closes, VoiceOver focus gets reset back to the top of the ViewController.  Is this a behaviour that we should override?",
      "ts": "1666301215.324979",
      "thread_ts": "1666301215.324979",
      "subtype": "bot_message",
      "bot_id": "B0434N8CV28",
      "username": "Ask Apple - accessibility",
      "reply_count": 4,
      "latest_reply": "1666302065.086139",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "+Yb6E",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U0465DVJZ4P"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Are there any suggestions\\/advice\\/recommended best practices for VoiceOver focus management particularly when moving between View Controllers? For example, a VoiceOver user taps a share button, perhaps 100 cells down on a tableview, opening a share screen. But when the share screen closes, VoiceOver focus gets reset back to the top of the ViewController.  Is this a behaviour that we should override?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "0732eea9-0fca-4884-9537-10b745d475c7",
          "type": "message",
          "user": "U0449LGV1FV",
          "text": "What you’re describing is preferred behavior when possible.\n\nWhen VoiceOver is going down a stack of UI, ideally it would return to the previous place in the stack as it goes back up.\n(However as it goes down, VoiceOver should start at the top of the UI).",
          "ts": "1666301296.416749",
          "thread_ts": "1666301215.324979",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Bxq4L",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "What you’re describing is preferred behavior when possible.\n\nWhen VoiceOver is going down a stack of UI, ideally it would return to the previous place in the stack as it goes back up.\n(However as it goes down, VoiceOver should start at the top of the UI)."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "50000a7f-86ec-40a3-b589-c38255b826a3",
          "type": "message",
          "user": "U0465DVJZ4P",
          "text": "\u0026gt; What you’re describing is preferred behavior when possible.\nSorry, do you mean we should override the default way that the OS manages focus in this case (e.g, storing a reference to the share button and programmatically returning focus to that view when we go back up the stack)? or the default iOS focus management (putting focus back to the top of the page) is the preferred behaviour?",
          "ts": "1666301867.503259",
          "thread_ts": "1666301215.324979",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "pqeF",
              "elements": [
                {
                  "Type": "rich_text_quote",
                  "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"What you\\u2019re describing is preferred behavior when possible.\"}]}"
                },
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Sorry, do you mean we should override the default way that the OS manages focus in this case (e.g, storing a reference to the share button and programmatically returning focus to that view when we go back up the stack)? or the default iOS focus management (putting focus back to the top of the page) is the preferred behaviour?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "55d67f9b-b5f4-4eba-87c2-b7f79089e730",
          "type": "message",
          "user": "U0449LGV1FV",
          "text": "If you’re able to restore focus to the previous item that would be a better experience. VoiceOver would ideally be able to do this, but I don’t think VoiceOver always can know whether the UI is a stack of UI or completely new screen.",
          "ts": "1666301982.499689",
          "thread_ts": "1666301215.324979",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "feG",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "If you’re able to restore focus to the previous item that would be a better experience. VoiceOver would ideally be able to do this, but I don’t think VoiceOver always can know whether the UI is a stack of UI or completely new screen."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "8f38dbe8-b571-482f-a951-a4249ac1de10",
          "type": "message",
          "user": "U0465DVJZ4P",
          "text": "Ok - thanks for the clarification!",
          "ts": "1666302065.086139",
          "thread_ts": "1666301215.324979",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "WETc",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Ok - thanks for the clarification!"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U045ZGP2QCV\u003e asked\n\u0026gt; How can I customize VoiceOver pronunciation of proper nouns (apart from the app's name)? For example \"SeedFi\" vs \"seed fee\".",
      "ts": "1666301730.695099",
      "thread_ts": "1666301730.695099",
      "subtype": "bot_message",
      "bot_id": "B0434N8CV28",
      "username": "Ask Apple - accessibility",
      "reply_count": 8,
      "latest_reply": "1666302526.907259",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "aZQdv",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U045ZGP2QCV"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"How can I customize VoiceOver pronunciation of proper nouns (apart from the app's name)? For example \\\"SeedFi\\\" vs \\\"seed fee\\\".\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "4ed30c9e-f008-463c-8306-499f0390ecfe",
          "type": "message",
          "user": "U0449LGV1FV",
          "text": "In UIKit, you could use attributedAccessibilityLabel paired with\n\n```// Use an NSString, containing International Phonetic Alphabet (IPA) symbols.\n// Controls the pronunciation of a word or phrase, e.g. a proper name.\nUIKIT_EXTERN NSAttributedStringKey const UIAccessibilitySpeechAttributeIPANotation API_AVAILABLE(ios(11.0));```",
          "ts": "1666301759.910869",
          "thread_ts": "1666301730.695099",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "E5pD",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "In UIKit, you could use attributedAccessibilityLabel paired with\n\n"
                    }
                  ]
                },
                {
                  "Type": "rich_text_preformatted",
                  "Raw": "{\"type\":\"rich_text_preformatted\",\"elements\":[{\"type\":\"text\",\"text\":\"\\/\\/ Use an NSString, containing International Phonetic Alphabet (IPA) symbols.\\n\\/\\/ Controls the pronunciation of a word or phrase, e.g. a proper name.\\nUIKIT_EXTERN NSAttributedStringKey const UIAccessibilitySpeechAttributeIPANotation API_AVAILABLE(ios(11.0));\"}],\"border\":0}"
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "6307be6a-4a6d-4ccb-881d-5aa4b8d19138",
          "type": "message",
          "user": "U044D824R8V",
          "text": "\u003chttps://developer.apple.com/documentation/uikit/uiaccessibilityspeechattributeipanotation?language=objc\u003e",
          "ts": "1666301790.053719",
          "thread_ts": "1666301730.695099",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "1IW",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/uikit/uiaccessibilityspeechattributeipanotation?language=objc",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "1e389e7d-ffb4-403d-81bd-378431cc3422",
          "type": "message",
          "user": "U0449LGV1FV",
          "text": "In SwiftUI, you can do the following\n\u003chttps://developer.apple.com/documentation/swiftui/text/speechphoneticrepresentation(_:)\u003e\n\n```Text(\"Anne wants to \") +\nText(\"live\")\n    . speechPhoneticRepresentation(\"lɪv\") +\nText(\" on Main Street.\")```",
          "ts": "1666301838.995629",
          "thread_ts": "1666301730.695099",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "clap",
              "count": 2,
              "users": [
                "U045WGB2MAS",
                "U046S70K9A4"
              ]
            },
            {
              "name": "heart",
              "count": 1,
              "users": [
                "U045ZGP2QCV"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "NYE+",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "In SwiftUI, you can do the following\n"
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/swiftui/text/speechphoneticrepresentation(_:)",
                      "text": ""
                    },
                    {
                      "type": "text",
                      "text": "\n\n"
                    }
                  ]
                },
                {
                  "Type": "rich_text_preformatted",
                  "Raw": "{\"type\":\"rich_text_preformatted\",\"elements\":[{\"type\":\"text\",\"text\":\"Text(\\\"Anne wants to \\\") +\\nText(\\\"live\\\")\\n    . speechPhoneticRepresentation(\\\"l\\u026av\\\") +\\nText(\\\" on Main Street.\\\")\"}],\"border\":0}"
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "d07fbbdd-670c-49a3-90a4-e12a662c8926",
          "type": "message",
          "user": "U0449LGV1FV",
          "text": "If you want this applied everywhere in your app, that’s probably not possible right now in a straightforward manner. You could potentially feed every UI string through something that would apply attributes, but that’s a bit unwieldy.",
          "ts": "1666301908.709439",
          "thread_ts": "1666301730.695099",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Pxmc",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "If you want this applied everywhere in your app, that’s probably not possible right now in a straightforward manner. You could potentially feed every UI string through something that would apply attributes, but that’s a bit unwieldy."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "a3c309b7-b725-4b85-b72c-b8e4b59e763d",
          "type": "message",
          "user": "U045ZGP2QCV",
          "text": "Yeah, that's tough w/ AttributedString etc. Thanks for the tip.",
          "ts": "1666302322.501779",
          "thread_ts": "1666301730.695099",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "2aq",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Yeah, that's tough w/ AttributedString etc. Thanks for the tip."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "a15f1b88-d1ff-4982-8b8a-bf3d9fb2080e",
          "type": "message",
          "user": "U045ZGP2QCV",
          "text": "Ideally it would be handled on a localized string level",
          "ts": "1666302340.724789",
          "thread_ts": "1666301730.695099",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "En+",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Ideally it would be handled on a localized string level"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "725448de-8b9f-498b-862d-0deef2d8ccbd",
          "type": "message",
          "user": "U0449LGV1FV",
          "text": "But if that’s what your after, please file your feedbacks. It is conceivable we could have an app level pronunciation replacement strategy.",
          "ts": "1666302467.565869",
          "thread_ts": "1666301730.695099",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "387",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "But if that’s what your after, please file your feedbacks. It is conceivable we could have an app level pronunciation replacement strategy."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "58138376-2250-426a-bbd3-c1cc64b20ccf",
          "type": "message",
          "user": "U045ZGP2QCV",
          "text": "Thanks. It also appears the SwiftUI API didn't pop out of beta and doesn't autocomplete. :disappointed: I'll open some feedbacks.",
          "ts": "1666302526.907259",
          "thread_ts": "1666301730.695099",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "4A/q",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks. It also appears the SwiftUI API didn't pop out of beta and doesn't autocomplete. "
                    },
                    {
                      "type": "emoji",
                      "name": "disappointed",
                      "skin_tone": 0
                    },
                    {
                      "type": "text",
                      "text": " I'll open some feedbacks."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U045ZGP2QCV\u003e asked\n\u0026gt; We'd like to adopt mindfully anonymized accessibility telemetry to our finance app to add another layer of protection against undiscovered issues and regressions (e.g., abnormally low VoiceOver or large accessibility text size usage or flow completions or error recoveries).\n\u0026gt; \n\u0026gt; In order to preclude the chance of linking or storing medical insights to a specific user, or even to a cohort of potential sessions, our iOS team is taking a number of encryption and anonymization measures in partnership with our infosec team and an outside vendor.\n\u0026gt; \n\u0026gt; Does your team have any relevant tips, guidance, or know of any patient advocacy organizations who might be already working on this?\n\u0026gt; \n\u0026gt; We'd all prefer if Apple offered these analytics as part of App Store Connect's Metrics. These analytics could be numerical or, if there is fear showing a low percentage of users might be demotivating or potentially identifying, a simple binary to flag \"unexpectedly low\". Collecting actionable analytics to flag problems would help users, enrich Apple's ecosystem, and help developers adhere to regulations and expand market access.  (FB11705152)",
      "ts": "1666302689.930629",
      "thread_ts": "1666302689.930629",
      "subtype": "bot_message",
      "bot_id": "B0434N8CV28",
      "username": "Ask Apple - accessibility",
      "reply_count": 4,
      "latest_reply": "1666303365.629239",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "GniB3",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U045ZGP2QCV"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"We'd like to adopt mindfully anonymized accessibility telemetry to our finance app to add another layer of protection against undiscovered issues and regressions (e.g., abnormally low VoiceOver or large accessibility text size usage or flow completions or error recoveries).\\n\\nIn order to preclude the chance of linking or storing medical insights to a specific user, or even to a cohort of potential sessions, our iOS team is taking a number of encryption and anonymization measures in partnership with our infosec team and an outside vendor.\\n\\nDoes your team have any relevant tips, guidance, or know of any patient advocacy organizations who might be already working on this?\\n\\nWe'd all prefer if Apple offered these analytics as part of App Store Connect's Metrics. These analytics could be numerical or, if there is fear showing a low percentage of users might be demotivating or potentially identifying, a simple binary to flag \\\"unexpectedly low\\\". Collecting actionable analytics to flag problems would help users, enrich Apple's ecosystem, and help developers adhere to regulations and expand market access.  (FB11705152)\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "f517504f-85a2-45fc-8daa-1c2399b4aa25",
          "type": "message",
          "user": "U0449LGV1FV",
          "text": "Thank you for your commitment to maintaining user privacy! Obviously, users place a lot of trust in us, both at Apple and as App Developers, to responsibly manage information.\n\nUsing various de-identifying techniques are a good step. You don’t want to be storing info that is directly connected to users that’s not relevant or information that could be used to connect identities.\n\nI think collecting aggregate data is generally OK. When we’re talking about accessibility, sometimes those numbers can be low, and unfortunately I’ve seen many cases where businesses have used that data to NOT add support.\n\nSo I think it also matters what you want to do with that data. Your stated cases seem like good uses of the data. If VoiceOver users are getting stuck at a Check Cashing stage in a Bank app and abandoning it, you may want to know that so you can re-evaluate that user flow.",
          "ts": "1666302944.919629",
          "thread_ts": "1666302689.930629",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "aPv",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thank you for your commitment to maintaining user privacy! Obviously, users place a lot of trust in us, both at Apple and as App Developers, to responsibly manage information.\n\nUsing various de-identifying techniques are a good step. You don’t want to be storing info that is directly connected to users that’s not relevant or information that could be used to connect identities.\n\nI think collecting aggregate data is generally OK. When we’re talking about accessibility, sometimes those numbers can be low, and unfortunately I’ve seen many cases where businesses have used that data to NOT add support.\n\nSo I think it also matters what you want to do with that data. Your stated cases seem like good uses of the data. If VoiceOver users are getting stuck at a Check Cashing stage in a Bank app and abandoning it, you may want to know that so you can re-evaluate that user flow."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "25445070-6f5a-455c-92de-266279e3d5ff",
          "type": "message",
          "user": "U045ZGP2QCV",
          "text": "\u003c@U0449LGV1FV\u003e Would Apple consider releasing some generalized benchmarks about feature activation? (e.g., 30% use DynamicType, 35% dark mode, 15% reduce brightness etc., possibly grouping things like VO/SC in a mindful way)",
          "ts": "1666303157.708009",
          "thread_ts": "1666302689.930629",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "cCc",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "user",
                      "user_id": "U0449LGV1FV"
                    },
                    {
                      "type": "text",
                      "text": " Would Apple consider releasing some generalized benchmarks about feature activation? (e.g., 30% use DynamicType, 35% dark mode, 15% reduce brightness etc., possibly grouping things like VO/SC in a mindful way)"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "f8e64850-acfc-4187-b1fa-955f56008c97",
          "type": "message",
          "user": "U045ZGP2QCV",
          "text": "Re: low numbers, yes, that's a bit of a \"prioritization\" fear of mine. Luckily our general counsel understands just one user is a lawsuit we don't want... and I'm in a regulated industry. Others aren't. :disappointed:",
          "ts": "1666303232.579549",
          "thread_ts": "1666302689.930629",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "c1q",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Re: low numbers, yes, that's a bit of a \"prioritization\" fear of mine. Luckily our general counsel understands just one user is a lawsuit we don't want... and I'm in a regulated industry. Others aren't. "
                    },
                    {
                      "type": "emoji",
                      "name": "disappointed",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "becdeaae-04e7-4b87-8f9a-b1cb1360129e",
          "type": "message",
          "user": "U0449LGV1FV",
          "text": "We can bring it up, but I can’t say for sure one way or another right now.",
          "ts": "1666303365.629239",
          "thread_ts": "1666302689.930629",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "QfS",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "We can bring it up, but I can’t say for sure one way or another right now."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U0474582YCS\u003e asked\n\u0026gt; I'm trying to read Zoom meeting app's window, but for window element, it just shows as \"\u0026lt;AXApplication \"us.zoom.xos\" (pid=23913)\u0026gt; [Attribute.role: AXApplication, Attribute.title: \u003chttp://zoom.us|zoom.us\u003e]\"; I use Accessibility Inspector to target an element, when I target any app's window, it only display as AXApplication; when I restart my app, it works!",
      "ts": "1666302917.395579",
      "thread_ts": "1666302917.395579",
      "subtype": "bot_message",
      "bot_id": "B0434N8CV28",
      "username": "Ask Apple - accessibility",
      "reply_count": 1,
      "latest_reply": "1666302954.649289",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "QiFT",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U0474582YCS"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"I'm trying to read Zoom meeting app's window, but for window element, it just shows as \\\"\u003cAXApplication \\\"us.zoom.xos\\\" (pid=23913)\u003e [Attribute.role: AXApplication, Attribute.title: zoom.us]\\\"; I use Accessibility Inspector to target an element, when I target any app's window, it only display as AXApplication; when I restart my app, it works!\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "2d2ef8fe-39a9-48ac-a9e3-4a976093ca05",
          "type": "message",
          "user": "U044Z1BL294",
          "text": "Thanks for the question! Please file a feedback report for us and if you can provide any sample code that would be really helpful here!",
          "ts": "1666302954.649289",
          "thread_ts": "1666302917.395579",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "8+k",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks for the question! Please file a feedback report for us and if you can provide any sample code that would be really helpful here!"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "2b805d31-1959-4fca-906a-f19c40e58f69",
      "type": "message",
      "user": "U0449LGV1FV",
      "text": ":heart: Thank you everyone for all your questions and participation! :joy:\nThis was super exciting for us and great to get feedback on issues that are impacting apps and users.\n\nRemember keep filing those feedbacks!",
      "ts": "1666303371.901929",
      "team": "T03U5MWB2FN",
      "reactions": [
        {
          "name": "v",
          "count": 2,
          "users": [
            "U046S70K9A4",
            "U0465DVJZ4P"
          ]
        },
        {
          "name": "partying_face",
          "count": 5,
          "users": [
            "U044D824R8V",
            "U046LKK3L81",
            "U044G9DLCUB",
            "U045WGB2MAS",
            "U046G4C02JV"
          ]
        },
        {
          "name": "sunglasses",
          "count": 2,
          "users": [
            "U044D824R8V",
            "U045WGB2MAS"
          ]
        },
        {
          "name": "rocket",
          "count": 3,
          "users": [
            "U03V30M0C1K",
            "U044G9DLCUB",
            "U046G37DF33"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "m8m",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "emoji",
                  "name": "heart",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": " Thank you everyone for all your questions and participation! "
                },
                {
                  "type": "emoji",
                  "name": "joy",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": "\nThis was super exciting for us and great to get feedback on issues that are impacting apps and users.\n\nRemember keep filing those feedbacks!"
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "af2d23e8-a65f-4383-bad0-22145dc228b0",
      "type": "message",
      "user": "U044G9DLCUB",
      "text": "Hi everyone! Thank you again for sending in all your questions and chatting with us this week! We really appreciate everybody taking the time not only to come to us with their feedback and ideas, but also for always striving to make truly accessible experiences for everyone.\n\nI’ll be opening up threads for a little bit today in case anybody wanted to provide feedback on how everything went for them; if you also have Feedback Assistant IDs that you have since created, now would be an awesome time to let us know about those too! :pray:\n\nThanks again and hope you have a great rest of your week!",
      "ts": "1666377331.855879",
      "thread_ts": "1666377331.855879",
      "reply_count": 2,
      "latest_reply": "1666383081.281779",
      "team": "T03U5MWB2FN",
      "reactions": [
        {
          "name": "gratitude-thank-you",
          "count": 2,
          "users": [
            "U046G37DF33",
            "U0465A9B2NQ"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "tItL",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Hi everyone! Thank you again for sending in all your questions and chatting with us this week! We really appreciate everybody taking the time not only to come to us with their feedback and ideas, but also for always striving to make truly accessible experiences for everyone.\n\nI’ll be opening up threads for a little bit today in case anybody wanted to provide feedback on how everything went for them; if you also have Feedback Assistant IDs that you have since created, now would be an awesome time to let us know about those too! "
                },
                {
                  "type": "emoji",
                  "name": "pray",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": "\n\nThanks again and hope you have a great rest of your week!"
                }
              ]
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "2D2340D9-FBF4-4BE8-9068-773E4E88C782",
          "type": "message",
          "user": "U046G37DF33",
          "text": "In my case I may not have time to get my test rig app prepped for feedback assistant this quickly. Is there a tag or keyword we can apply in FA that might connect the teams to these discussions if the threads are closed again?",
          "ts": "1666382869.424629",
          "thread_ts": "1666377331.855879",
          "parent_user_id": "U044G9DLCUB",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "40RJ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "In my case I may not have time to get my test rig app prepped for feedback assistant this quickly"
                    },
                    {
                      "type": "text",
                      "text": "."
                    },
                    {
                      "type": "text",
                      "text": " Is there a tag or keyword we can apply in FA that might connect the teams to these discussions if the threads are closed again?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "c8409874-3905-4626-976c-82f52e8d4f19",
          "type": "message",
          "user": "U044G9DLCUB",
          "text": "We tend to follow our feedback requests pretty closely so a brief update mentioning that this was something that was brought up during Ask Apple will be sufficient. :slightly_smiling_face: Thank you Peter!",
          "ts": "1666383081.281779",
          "thread_ts": "1666377331.855879",
          "parent_user_id": "U044G9DLCUB",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "raised_hands",
              "count": 1,
              "users": [
                "U046G37DF33"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "bu3",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "We tend to follow our feedback requests pretty closely so a brief update mentioning that this was something that was brought up during Ask Apple will be sufficient. "
                    },
                    {
                      "type": "emoji",
                      "name": "slightly_smiling_face",
                      "skin_tone": 0
                    },
                    {
                      "type": "text",
                      "text": " Thank you Peter!"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    }
  ],
  "channel_id": "C0432BW1HN0"
}
