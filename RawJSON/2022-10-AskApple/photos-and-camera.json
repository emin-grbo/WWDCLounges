{
  "name": "photos-and-camera",
  "messages": [
    {
      "type": "message",
      "user": "U03V30M0C1K",
      "text": "This content can't be displayed.",
      "ts": "1665433677.637999",
      "thread_ts": "1665433677.637999",
      "pinned_to": [
        "C043CP508PK"
      ],
      "reply_count": 1,
      "latest_reply": "1666301199.352339",
      "team": "T03U5MWB2FN",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "header",
          "text": {
            "type": "plain_text",
            "text": "Welcome to Ask Apple",
            "emoji": true
          },
          "block_id": "vks"
        },
        {
          "type": "section",
          "text": {
            "type": "mrkdwn",
            "text": "We're excited to be hosting you in the Photos and Camera channel this week! You can find the full schedule of Q\u0026amp;As for Photos and Camera by visiting the \u003chttps://apps.apple.com/us/app/apple-developer/id640199958 | Apple Developer app\u003e and \u003chttps://developer.apple.com/events/ask-apple/questions-and-answers/ | website\u003e."
          },
          "block_id": "nlc"
        },
        {
          "type": "section",
          "text": {
            "type": "mrkdwn",
            "text": "If you haven’t already, please take a moment to familiarize yourself with \u003chttps://developer.apple.com/news/?id=vpbyzfg4 | how Q\u0026amp;As will work\u003e."
          },
          "block_id": "VQ9t"
        },
        {
          "type": "header",
          "text": {
            "type": "plain_text",
            "text": "Attendance Policy",
            "emoji": true
          },
          "block_id": "rOz"
        },
        {
          "type": "section",
          "text": {
            "type": "mrkdwn",
            "text": "We want to make sure these spaces are helpful and welcoming for everyone — developers and Apple employees alike. Please review and follow the \u003chttps://developer.apple.com/events/policy/online-event-attendance-policy/ | attendance policy\u003e."
          },
          "block_id": "KH85"
        }
      ],
      "slackdump_thread_replies": [
        {
          "type": "message",
          "user": "U04678YRK98",
          "text": "Hello Team ,\nI would like to learn about Augmented Reality \u0026amp; Virtual Reality for 100 Individual Workspaces for students in Schools and University’s.Apple’s Workspace with MacBook Air,  iMac , iPad Pro ,iPhone,AirPods Max,HomePod mini,Phone Lightning Dock and All Hardware Mounts.Apple to the next Level for students.Upgrading the Universe.\tApple’s Upgrade Entry to Global Education and Asset Management.Integration with 30 % Institutions Worldwide with Apple’s Supply Chain.",
          "ts": "1666301199.352339",
          "thread_ts": "1665433677.637999",
          "subtype": "moderated",
          "parent_user_id": "U03V30M0C1K",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "DXG",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hello Team ,\nI would like to learn about Augmented Reality \u0026 Virtual Reality for 100 Individual Workspaces for students in Schools and University’s.Apple’s Workspace with MacBook Air,  iMac , iPad Pro ,iPhone,AirPods Max,HomePod mini,Phone Lightning Dock and All Hardware Mounts.Apple to the next Level for students.Upgrading the Universe.\tApple’s Upgrade Entry to Global Education and Asset Management.Integration with 30 % Institutions Worldwide with Apple’s Supply Chain."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03V30M0C1K\u003e added a workflow to this channel: *Ask Apple - photos-and-camera*.",
      "ts": "1666018989.834189",
      "subtype": "bot_message",
      "bot_id": "B0431LJ7G4D",
      "username": "Ask Apple - photos-and-camera",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "1/yoM",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03V30M0C1K"
                },
                {
                  "type": "text",
                  "text": " added a workflow to this channel: "
                },
                {
                  "type": "text",
                  "text": "Ask Apple - photos-and-camera",
                  "style": {
                    "bold": true
                  }
                },
                {
                  "type": "text",
                  "text": "."
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "d97dd918-024b-4cc7-821d-0195ca53966e",
      "type": "message",
      "user": "U0455QUCD9N",
      "text": "*Let's talk about PhotoKit.*\nFor the next hour we've got a team of Engineers from the Photos team here to answer all your questions around PhotoKit, Photos Picker, and everything related to integrating with Photos in your app. Use the :heavy_plus_sign: button to kick off the workflow. And don't hesitate to follow-up in discussion using the threads that are created. We're looking forward to a lively conversation. :tada:",
      "ts": "1666202430.090189",
      "team": "T03U5MWB2FN",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "Fz4",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Let's talk about PhotoKit.",
                  "style": {
                    "bold": true
                  }
                },
                {
                  "type": "text",
                  "text": "\nFor the next hour we've got a team of Engineers from the Photos team here to answer all your questions around PhotoKit, Photos Picker, and everything related to integrating with Photos in your app. Use the "
                },
                {
                  "type": "emoji",
                  "name": "heavy_plus_sign",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": " button to kick off the workflow. And don't hesitate to follow-up in discussion using the threads that are created. We're looking forward to a lively conversation. "
                },
                {
                  "type": "emoji",
                  "name": "tada",
                  "skin_tone": 0
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U04707WB62C\u003e asked\n\u0026gt; In UIImagePickerCOntrollerDelegate, there are 2 functions\n\u0026gt; \n\u0026gt; extension ViewController: UIImagePickerControllerDelegate {\n\u0026gt;     func imagePickerController(_ picker: UIImagePickerController, didFinishPickingMediaWithInfo info: [UIImagePickerController.InfoKey : Any]) {\n\u0026gt; \n\u0026gt; \t// script to process image when select an image from album and dismiss after the processing\n\u0026gt;     }\n\u0026gt; \n\u0026gt;     func imagePickerControllerDidCancel(_ picker: UIImagePickerController) {\n\u0026gt; \t// the dismiss at this section will make the ‘cancel’ button on the top left of the album controller view being able to dismiss\n\u0026gt;         dismiss(animated: true, completion: nil)\n\u0026gt;     }\n\u0026gt; }\n\u0026gt; \n\u0026gt; \n\u0026gt; For the new PHPickerViewControllerDelegate\n\u0026gt; \n\u0026gt; extension AlbumViewController: PHPickerViewControllerDelegate {\n\u0026gt;     func picker(_ picker: PHPickerViewController, didFinishPicking results: [PHPickerResult]) {\n\u0026gt; \t// only has one function which serve the similar function as the ‘func imagePickerController’ in UIImagePickerControllerDelegate\n\u0026gt;     }\n\u0026gt; }\n\u0026gt; \n\u0026gt; ==\u0026gt; how to dismiss the ‘cancel’ button on the top left of the album controller view since there’s no more ’ func imagePickerControllerDidCancel’ with the new ‘PHPickerViewControllerDelegate’..? Simply tapping the `cancel` button won’t dismiss the album view controller with the new PHPickerViewControllerDelegate. If put dismiss(animated: true, completion:nil) under func picker(), it also won’t dismiss the album view controller even the ‘cancel’ button is tapped.\n\u0026gt; \n\u0026gt; Kindly advise how to link the cancel button dismiss with the new PHPickerViewControllerDelegate that comes only 1 single function picker(). Thanks.",
      "ts": "1666202734.019839",
      "thread_ts": "1666202734.019839",
      "subtype": "bot_message",
      "bot_id": "B0431LJ7G4D",
      "username": "Ask Apple - photos-and-camera",
      "reply_count": 2,
      "latest_reply": "1666202792.171569",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "PtHg",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U04707WB62C"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"In UIImagePickerCOntrollerDelegate, there are 2 functions\\n\\nextension ViewController: UIImagePickerControllerDelegate {\\n    func imagePickerController(_ picker: UIImagePickerController, didFinishPickingMediaWithInfo info: [UIImagePickerController.InfoKey : Any]) {\\n\\n\\t\\/\\/ script to process image when select an image from album and dismiss after the processing\\n    }\\n\\n    func imagePickerControllerDidCancel(_ picker: UIImagePickerController) {\\n\\t\\/\\/ the dismiss at this section will make the \\u2018cancel\\u2019 button on the top left of the album controller view being able to dismiss\\n        dismiss(animated: true, completion: nil)\\n    }\\n}\\n\\n\\nFor the new PHPickerViewControllerDelegate\\n\\nextension AlbumViewController: PHPickerViewControllerDelegate {\\n    func picker(_ picker: PHPickerViewController, didFinishPicking results: [PHPickerResult]) {\\n\\t\\/\\/ only has one function which serve the similar function as the \\u2018func imagePickerController\\u2019 in UIImagePickerControllerDelegate\\n    }\\n}\\n\\n==\u003e how to dismiss the \\u2018cancel\\u2019 button on the top left of the album controller view since there\\u2019s no more \\u2019 func imagePickerControllerDidCancel\\u2019 with the new \\u2018PHPickerViewControllerDelegate\\u2019..? Simply tapping the `cancel` button won\\u2019t dismiss the album view controller with the new PHPickerViewControllerDelegate. If put dismiss(animated: true, completion:nil) under func picker(), it also won\\u2019t dismiss the album view controller even the \\u2018cancel\\u2019 button is tapped.\\n\\nKindly advise how to link the cancel button dismiss with the new PHPickerViewControllerDelegate that comes only 1 single function picker(). Thanks.\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "5fbe1e63-1941-4c99-85f1-bb94e3071819",
          "type": "message",
          "user": "U04561LA9ME",
          "text": "`picker:didFinishPicking:` will be called with empty results if the “Cancel” button is tapped. If `configuration.preselectedAssetIdentifiers` is set, the delegate will be called with preselected assets only. You should also implement `presentationControllerDidDismiss:` if you have swipe to dismiss enabled.",
          "ts": "1666202776.348729",
          "thread_ts": "1666202734.019839",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "trJR",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "picker:didFinishPicking:",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " will be called with empty results if the “Cancel” button is tapped. If "
                    },
                    {
                      "type": "text",
                      "text": "configuration.preselectedAssetIdentifiers",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " is set, the delegate will be called with preselected assets only. You should also implement "
                    },
                    {
                      "type": "text",
                      "text": "presentationControllerDidDismiss:",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " if you have swipe to dismiss enabled."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "20ce6ebc-d0dc-4abc-a4d8-35cc2362583d",
          "type": "message",
          "user": "U04561LA9ME",
          "text": "\u003chttps://developer.apple.com/documentation/uikit/uiadaptivepresentationcontrollerdelegate/3229889-presentationcontrollerdiddismiss?language=objc\u003e",
          "ts": "1666202792.171569",
          "thread_ts": "1666202734.019839",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "pjRc",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/uikit/uiadaptivepresentationcontrollerdelegate/3229889-presentationcontrollerdiddismiss?language=objc",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046JND8CKB\u003e asked\n\u0026gt; Is it possible to save directly to the hidden albums folder? I've been playing around with the Capturing Photos code and changed -\n\u0026gt; let photoCollection = PhotoCollection(smartAlbum: .smartAlbumUserLibrary) - \n\u0026gt; to -\n\u0026gt; let photoCollection = PhotoCollection(smartAlbum: .smartAlbumAllHidden)\n\u0026gt; but it didn't work for me.",
      "ts": "1666203302.391739",
      "thread_ts": "1666203302.391739",
      "subtype": "bot_message",
      "bot_id": "B0431LJ7G4D",
      "username": "Ask Apple - photos-and-camera",
      "reply_count": 2,
      "latest_reply": "1666203763.419519",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "c9mm",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046JND8CKB"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Is it possible to save directly to the hidden albums folder? I've been playing around with the Capturing Photos code and changed -\\nlet photoCollection = PhotoCollection(smartAlbum: .smartAlbumUserLibrary) - \\nto -\\nlet photoCollection = PhotoCollection(smartAlbum: .smartAlbumAllHidden)\\nbut it didn't work for me.\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "bf8d07ba-b931-4a4b-9036-4a92bc3c0792",
          "type": "message",
          "user": "U0449MFKRGE",
          "text": "You can put an asset into the hidden album by setting the hidden property on that asset in a change request, see: \u003chttps://developer.apple.com/documentation/photokit/phasset/1624773-hidden\u003e\n\nTake special note of the changes in iOS 16 and macOS Ventura about whether or not your app can fetch hidden assets though.",
          "ts": "1666203319.768769",
          "thread_ts": "1666203302.391739",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "/MT=",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "You can put an asset into the hidden album by setting the hidden property on that asset in a change request, see: "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/photokit/phasset/1624773-hidden",
                      "text": ""
                    },
                    {
                      "type": "text",
                      "text": "\n\nTake special note of the changes in iOS 16 and macOS Ventura about whether or not your app can fetch hidden assets though."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "feefab31-94fd-4142-a9f3-cfbd92ef7af4",
          "type": "message",
          "user": "U046JND8CKB",
          "text": "Thanks Matt, I'll look into that",
          "ts": "1666203763.419519",
          "thread_ts": "1666203302.391739",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "l/w/a",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks Matt, I'll look into that"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046368HTM1\u003e asked\n\u0026gt; In iOS16, shortcuts app there is a shortcut action called \"Remove Background\". Is this available as an API to do the \"Copy Subject\" feature from within third party apps?",
      "ts": "1666203403.688309",
      "thread_ts": "1666203403.688309",
      "subtype": "bot_message",
      "bot_id": "B0431LJ7G4D",
      "username": "Ask Apple - photos-and-camera",
      "reply_count": 2,
      "latest_reply": "1666203786.909339",
      "reactions": [
        {
          "name": "+1",
          "count": 2,
          "users": [
            "U045Y19K154",
            "U045MLXJX71"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "ohKK",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046368HTM1"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"In iOS16, shortcuts app there is a shortcut action called \\\"Remove Background\\\". Is this available as an API to do the \\\"Copy Subject\\\" feature from within third party apps?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "a27f4775-540c-4762-8b67-82269aff25af",
          "type": "message",
          "user": "U0449MFKRGE",
          "text": "There is unfortunately not API available to accomplish this. Please file a Feedback request detailing the kind of API you’d like to see for your app’s usecase.",
          "ts": "1666203446.801389",
          "thread_ts": "1666203403.688309",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "PKru",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "There is unfortunately not API available to accomplish this. Please file a Feedback request detailing the kind of API you’d like to see for your app’s usecase."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "df20ab07-57cf-4768-80eb-d2d6530a2e35",
          "type": "message",
          "user": "U045Y19K154",
          "text": "See also this discussion - I really really want this in an API - \u003chttps://appledeveloper.slack.com/archives/C042X5L3V7X/p1666198956467119\u003e",
          "ts": "1666203786.909339",
          "thread_ts": "1666203403.688309",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "yPbN",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "See also this discussion - I really really want this in an API - "
                    },
                    {
                      "type": "link",
                      "url": "https://appledeveloper.slack.com/archives/C042X5L3V7X/p1666198956467119",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046PB6DX3P\u003e asked\n\u0026gt; Hello, I'm developing an app using LiDAR sensor.\n\u0026gt; I trying to get the LiDAR data and transform in to meters or inches.\n\u0026gt; I saw all sample code of 'Depth Data Capture' and 'Point Cloud'.\n\u0026gt; But I could find a way to get LiDAR's raw data.\n\u0026gt; All of those code is wrapped into Metal so I couldn't get the LiDAR's raw data.\n\u0026gt; I only need LiDAR depth.\n\u0026gt; Is there any way to get LiDAR's raw or meter data?",
      "ts": "1666203490.051329",
      "thread_ts": "1666203490.051329",
      "subtype": "bot_message",
      "bot_id": "B0431LJ7G4D",
      "username": "Ask Apple - photos-and-camera",
      "reply_count": 1,
      "latest_reply": "1666203665.752399",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "5tZG",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046PB6DX3P"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Hello, I'm developing an app using LiDAR sensor.\\nI trying to get the LiDAR data and transform in to meters or inches.\\nI saw all sample code of 'Depth Data Capture' and 'Point Cloud'.\\nBut I could find a way to get LiDAR's raw data.\\nAll of those code is wrapped into Metal so I couldn't get the LiDAR's raw data.\\nI only need LiDAR depth.\\nIs there any way to get LiDAR's raw or meter data?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "8b33d8c9-fabc-4216-8a4a-8edb325bcf0b",
          "type": "message",
          "user": "U044JPW4FBN",
          "text": "We do not support retrieving Raw LiDAR data via AVCapture APIs, just the sample code and APIs above.\n\nFor measurement, we recommend the use of ARKit APIs instead.",
          "ts": "1666203665.752399",
          "thread_ts": "1666203490.051329",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "62NF",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "We do not support retrieving Raw LiDAR data via AVCapture APIs, just the sample code and APIs above.\n\nFor measurement, we recommend the use of ARKit APIs instead."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046A955XF1\u003e asked\n\u0026gt; Since there is (very unfortunately) no official API to access photos in iCloud directly, is there a way to get notified about added/removed photos? What's the supported way of adding/removing/listing photos from  iCloud?\n\u0026gt; This questions is targeted at iOS and macOS.",
      "ts": "1666203664.426069",
      "thread_ts": "1666203664.426069",
      "subtype": "bot_message",
      "bot_id": "B0431LJ7G4D",
      "username": "Ask Apple - photos-and-camera",
      "reply_count": 1,
      "latest_reply": "1666203757.228019",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "=8T/g",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046A955XF1"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Since there is (very unfortunately) no official API to access photos in iCloud directly, is there a way to get notified about added\\/removed photos? What's the supported way of adding\\/removing\\/listing photos from  iCloud?\\nThis questions is targeted at iOS and macOS.\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "d0b38a34-45b9-4802-933f-523c38a4cbb1",
          "type": "message",
          "user": "U044G7N0E5R",
          "text": "Hello! Have you looked at the new `PhotoKit` change history?  It allows you to get notified as changes to the library occur, even when your app is not running. Here's the WWDC 2022 video about this topic:\n\n\u003chttps://developer.apple.com/videos/play/wwdc2022/10132/\u003e",
          "ts": "1666203757.228019",
          "thread_ts": "1666203664.426069",
          "attachments": [
            {
              "fallback": "Apple Developer: Discover PhotoKit change history - WWDC22 - Videos - Apple Developer",
              "id": 1,
              "title": "Discover PhotoKit change history - WWDC22 - Videos - Apple Developer",
              "title_link": "https://developer.apple.com/videos/play/wwdc2022/10132/",
              "text": "PhotoKit can help you build rich, photo-centric features. Learn how you can easily track changes to image assets with the latest APIs in...",
              "image_url": "https://devimages-cdn.apple.com/wwdc-services/images/124/6629/6629_wide_250x141_2x.jpg",
              "service_name": "Apple Developer",
              "service_icon": "https://developer.apple.com/favicon.ico",
              "from_url": "https://developer.apple.com/videos/play/wwdc2022/10132/",
              "original_url": "https://developer.apple.com/videos/play/wwdc2022/10132/",
              "blocks": null
            }
          ],
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "bUg",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hello! Have you looked at the new "
                    },
                    {
                      "type": "text",
                      "text": "PhotoKit",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " change history?  It allows you to get notified as changes to the library occur, even when your app is not running. Here's the WWDC 2022 video about this topic:\n\n"
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/videos/play/wwdc2022/10132/",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U04656V5MGU\u003e asked\n\u0026gt; Hello! I'm working on adding Live Text support to my photo browsing app. Unfortunately adding an ImageAnalysisInteraction to a PHLivePhotoView makes it so you can't tap and hold to play the Live Photo. Is this a known issue or could I doing something wrong? I have tried setting the interaction’s delegate and implemented interaction(_:shouldBeginAt:for:) (to maybe return false if there's a conflict) but it does not get called when I tap and hold on the Live Photo (not overtop text) to try to play it. Thanks!",
      "ts": "1666203736.199009",
      "thread_ts": "1666203736.199009",
      "subtype": "bot_message",
      "bot_id": "B0431LJ7G4D",
      "username": "Ask Apple - photos-and-camera",
      "reply_count": 7,
      "latest_reply": "1666221290.368369",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "zLrU3",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U04656V5MGU"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Hello! I'm working on adding Live Text support to my photo browsing app. Unfortunately adding an ImageAnalysisInteraction to a PHLivePhotoView makes it so you can't tap and hold to play the Live Photo. Is this a known issue or could I doing something wrong? I have tried setting the interaction\\u2019s delegate and implemented interaction(_\"},{\"type\":\"emoji\",\"name\":\"shouldBeginAt\"},{\"type\":\"text\",\"text\":\"for:) (to maybe return false if there's a conflict) but it does not get called when I tap and hold on the Live Photo (not overtop text) to try to play it. Thanks!\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "ade3c387-6575-4102-8492-28fee6d4dc5b",
          "type": "message",
          "user": "U04561LA9ME",
          "text": "You should be able to move its `playbackGestureRecognizer` to a different view.\n```/// Gesture used to trigger playback. By default, added to the receiver. Can be moved to a different view.\n@property (readonly, nonatomic, strong) UIGestureRecognizer *playbackGestureRecognizer;```\n",
          "ts": "1666203752.393639",
          "thread_ts": "1666203736.199009",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "MAt",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "You should be able to move its "
                    },
                    {
                      "type": "text",
                      "text": "playbackGestureRecognizer",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " to a different view.\n"
                    }
                  ]
                },
                {
                  "Type": "rich_text_preformatted",
                  "Raw": "{\"type\":\"rich_text_preformatted\",\"elements\":[{\"type\":\"text\",\"text\":\"\\/\\/\\/ Gesture used to trigger playback. By default, added to the receiver. Can be moved to a different view.\\n@property (readonly, nonatomic, strong) UIGestureRecognizer *playbackGestureRecognizer;\"}],\"border\":0}"
                },
                {
                  "type": "rich_text_section",
                  "elements": []
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "824f14cd-46ca-4087-8e86-bd31613f941a",
          "type": "message",
          "user": "U04656V5MGU",
          "text": "Huh! So the PHLivePhotoView is the topmost view, I don't see where I could try moving it to :thinking_face:",
          "ts": "1666203847.403389",
          "thread_ts": "1666203736.199009",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "TtHb4",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Huh! So the PHLivePhotoView is the topmost view, I don't see where I could try moving it to "
                    },
                    {
                      "type": "emoji",
                      "name": "thinking_face",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "e7ed92d5-5315-467b-bc34-396b46adfdb6",
          "type": "message",
          "user": "U04656V5MGU",
          "text": "Are you noting it's expected to not play in this scenario and I should use a different view like a dedicated play view to trigger play? Ideally it would work like the Photos app where you can tap and hold to play, or if you tap and hold text it selects the text instead.",
          "ts": "1666204041.695089",
          "thread_ts": "1666203736.199009",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "KZK",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Are you noting it's expected to not play in this scenario and I should use a different view like a dedicated play view to trigger play? Ideally it would work like the Photos app where you can tap and hold to play, or if you tap and hold text it selects the text instead."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "0f796a45-2c00-4ddd-8c89-d88de6ddc442",
          "type": "message",
          "user": "U04561LA9ME",
          "text": "It might be possible to create a transparent view on top and move the gesture recognizer there to resolve the gesture conflict. However, if it doesn’t work then creating a dedicated play view will be the best option. Please file a Feedback request though!",
          "ts": "1666204177.841559",
          "thread_ts": "1666203736.199009",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "1gk9",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "It might be possible to create a transparent view on top and move the gesture recognizer there to resolve the gesture conflict. However, if it doesn’t work then creating a dedicated play view will be the best option. Please file a Feedback request though!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "c8a3cb50-a031-43a7-a7b8-b7a86b2c3a39",
          "type": "message",
          "user": "U04656V5MGU",
          "text": "Ok thanks! I've submitted FB11585815. Maybe should create a sample project to go along with it if that would be helpful?",
          "ts": "1666204310.225479",
          "thread_ts": "1666203736.199009",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "XcLJ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Ok thanks! I've submitted FB11585815. Maybe should create a sample project to go along with it if that would be helpful?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "5f862a63-f3d2-490e-a892-2eaea5343dff",
          "type": "message",
          "user": "U04561LA9ME",
          "text": "Thank you! A sample project would be very helpful!",
          "ts": "1666204912.984989",
          "thread_ts": "1666203736.199009",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "OfNH",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thank you! A sample project would be very helpful!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "620ae9e1-eb50-4f3f-9b24-8b62098fdcda",
          "type": "message",
          "user": "U04656V5MGU",
          "text": "I've added a sample project to FB11585815, thanks \u003c@U04561LA9ME\u003e!",
          "ts": "1666221290.368369",
          "thread_ts": "1666203736.199009",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "UDU",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I've added a sample project to FB11585815, thanks "
                    },
                    {
                      "type": "user",
                      "user_id": "U04561LA9ME"
                    },
                    {
                      "type": "text",
                      "text": "!"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046LQHLZCJ\u003e asked\n\u0026gt; Dear Apple Team\n\u0026gt; I'm looking for a way to fetch all photos from the photolibrary for a specific region. Is there an API to accomplish that?",
      "ts": "1666203881.541189",
      "thread_ts": "1666203881.541189",
      "subtype": "bot_message",
      "bot_id": "B0431LJ7G4D",
      "username": "Ask Apple - photos-and-camera",
      "reply_count": 1,
      "latest_reply": "1666204060.905979",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "Ybu37",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046LQHLZCJ"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Dear Apple Team\\nI'm looking for a way to fetch all photos from the photolibrary for a specific region. Is there an API to accomplish that?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "ae865b0a-9cf6-4692-9aa3-3814cd8f4da1",
          "type": "message",
          "user": "U0449MFKRGE",
          "text": "There is no API that allows for a location bounded fetch or similar. If you wanted to do this with api today you’d need to do a lot of the processing on the location property on individual PHAssets. Please file a Feedback request detailing what usecase your app needs.",
          "ts": "1666204060.905979",
          "thread_ts": "1666203881.541189",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "raised_hands",
              "count": 1,
              "users": [
                "U046LQHLZCJ"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "2dz7",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "There is no API that allows for a location bounded fetch or similar. If you wanted to do this with api today you’d need to do a lot of the processing on the location property on individual PHAssets. Please file a Feedback request detailing what usecase your app needs."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046FNKEFC1\u003e asked\n\u0026gt; I am using the new AVCaptureMultiCamSession, to create a picture-in-picture video. My video inputs are recorded separately with one that includes the audio. Given the concurrent nature of the data streams, I am experiencing empty frames at the beginning of each recording. How should I address this?",
      "ts": "1666204051.993409",
      "thread_ts": "1666204051.993409",
      "subtype": "bot_message",
      "bot_id": "B0431LJ7G4D",
      "username": "Ask Apple - photos-and-camera",
      "reply_count": 2,
      "latest_reply": "1666208237.395599",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "mJw6P",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046FNKEFC1"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"I am using the new AVCaptureMultiCamSession, to create a picture-in-picture video. My video inputs are recorded separately with one that includes the audio. Given the concurrent nature of the data streams, I am experiencing empty frames at the beginning of each recording. How should I address this?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "58a87c08-d3fb-42e1-8b14-b3dd4a124a7e",
          "type": "message",
          "user": "U044JPW4FBN",
          "text": "We have in fact sample code that does this, AVMultiCamPiP: \u003chttps://developer.apple.com/documentation/avfoundation/capture_setup/avmulticampip_capturing_from_multiple_cameras\u003e",
          "ts": "1666204106.559799",
          "thread_ts": "1666204051.993409",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "tz2zw",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "We have in fact sample code that does this, AVMultiCamPiP: "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/avfoundation/capture_setup/avmulticampip_capturing_from_multiple_cameras",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "61f1ea44-89df-4cf2-9c0d-8ef46bd95dd0",
          "type": "message",
          "user": "U046FNKEFC1",
          "text": "Yep I actually used that to inform my implementation. Big difference with mine is that I save them data streams separately. This allows me to have separate front/back videos that I can use/move uniquely.",
          "ts": "1666208237.395599",
          "thread_ts": "1666204051.993409",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "EWW",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Yep I actually used that to inform my implementation. Big difference with mine is that I save them data streams separately. This allows me to have separate front/back videos that I can use/move uniquely."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046670RUE8\u003e asked\n\u0026gt; Is it possible to access the depth image from each frame of Cinematic Video? This would ideally be available when creating a video composition like this:\n\u0026gt; \n\u0026gt; AVMutableVideoComposition(asset: asset, applyingCIFiltersWithHandler: { request in ...\n\u0026gt; \n\u0026gt; I want to apply my custom anamorphic lens blur algorithm to Cinematic Video, which would look amazing!\n\u0026gt; \n\u0026gt; Thanks!\n\u0026gt; James",
      "ts": "1666204354.478109",
      "thread_ts": "1666204354.478109",
      "subtype": "bot_message",
      "bot_id": "B0431LJ7G4D",
      "username": "Ask Apple - photos-and-camera",
      "reply_count": 4,
      "latest_reply": "1666209349.964269",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "7pnql",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046670RUE8"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Is it possible to access the depth image from each frame of Cinematic Video? This would ideally be available when creating a video composition like this:\\n\\nAVMutableVideoComposition(asset: asset, applyingCIFiltersWithHandler: { request in ...\\n\\nI want to apply my custom anamorphic lens blur algorithm to Cinematic Video, which would look amazing!\\n\\nThanks!\\nJames\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "4012bfa2-8ed6-4670-a472-01d44e50f839",
          "type": "message",
          "user": "U044JPW4FBN",
          "text": "Sorry, this is not currently supported. If this is an important feature for you please file an ER as a FB incident.",
          "ts": "1666204451.763279",
          "thread_ts": "1666204354.478109",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Cr7",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Sorry, this is not currently supported. If this is an important feature for you please file an ER as a FB incident."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "10eb516f-bc31-4cb5-825e-f93dadf66e8b",
          "type": "message",
          "user": "U046670RUE8",
          "text": "Will do. Thanks!",
          "ts": "1666204606.535809",
          "thread_ts": "1666204354.478109",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "UZ/",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Will do. Thanks!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "def74083-785c-4f0d-b7a8-593305b2ccca",
          "type": "message",
          "user": "U046670RUE8",
          "text": "By ER and FB, do you mean file a bug report with Feedback Assistance?  \u003chttps://developer.apple.com/bug-reporting/\u003e ?",
          "ts": "1666205945.682089",
          "thread_ts": "1666204354.478109",
          "attachments": [
            {
              "fallback": "Apple Developer: Bug Reporting - Apple Developer",
              "id": 1,
              "title": "Bug Reporting - Apple Developer",
              "title_link": "https://developer.apple.com/bug-reporting/",
              "text": "Now with Feedback Assistant available on iPhone, iPad, Mac, and the web, it’s easier to submit effective bug reports and request enhancements to APIs and tools.",
              "image_url": "https://developer.apple.com/news/images/og/bug-reporting-og.jpg",
              "service_name": "Apple Developer",
              "service_icon": "https://developer.apple.com/favicon.ico",
              "from_url": "https://developer.apple.com/bug-reporting/",
              "original_url": "https://developer.apple.com/bug-reporting/",
              "blocks": null
            }
          ],
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "DKMF",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "By ER and FB, do you mean file a bug report with Feedback Assistance?  "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/bug-reporting/",
                      "text": ""
                    },
                    {
                      "type": "text",
                      "text": " ?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "83cbc6e8-c552-480b-82cf-1e0a6331139b",
          "type": "message",
          "user": "U044JPW4FBN",
          "text": "ER = Enhancement Request. FB = Feedback Incident via Feedback Assistant, yes.",
          "ts": "1666209349.964269",
          "thread_ts": "1666204354.478109",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U046670RUE8"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "NSxW",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "ER = Enhancement Request. FB = Feedback Incident via Feedback Assistant, yes."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U045ZS8EQ5T\u003e asked\n\u0026gt; Photos taken with an iPhone or iPad are usually displayed with brighter colors and highlights in Photos than those imported from somewhere else.\n\u0026gt; After a lot of digging, we found that some EXIF tags in the `{MakerApple}` section contain HDR tone mapping information. Images captures on iPhone 12 and newer also contain an auxiliary HDR gain map that influences local tone mapping.\n\u0026gt; \n\u0026gt; Since iOS 16 there are now APIs for rendering EDR content within an app. However, all WWDC sessions about EDR only mention video content, even though images can be HDR as well. For instance, OpenEXR images or images with an HDR color space can be rendered in EDR just fine.\n\u0026gt; \n\u0026gt; However, it is not possible to load HDR images taken with an iPhone in a way that the HDR information is retained. All APIs in PhotoKit, Image I/O, and Core Image only load the SDR part of the image, not taking into account the image’s metadata and gain map. There _are_ APIs in Image I/O for extracting the gain map, but I couldn’t find any documentation on how it is applied to the image to achieve HDR.\n\u0026gt; \n\u0026gt; Could you please shed some light on how the gain map is applied in Photos so that we can also display it properly in our EDR-enabled applications? Thanks!",
      "ts": "1666204397.625879",
      "thread_ts": "1666204397.625879",
      "subtype": "bot_message",
      "bot_id": "B0431LJ7G4D",
      "username": "Ask Apple - photos-and-camera",
      "reply_count": 2,
      "latest_reply": "1666247954.977579",
      "reactions": [
        {
          "name": "+1",
          "count": 1,
          "users": [
            "U045MLXJX71"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "niwGG",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U045ZS8EQ5T"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Photos taken with an iPhone or iPad are usually displayed with brighter colors and highlights in Photos than those imported from somewhere else.\\nAfter a lot of digging, we found that some EXIF tags in the `{MakerApple}` section contain HDR tone mapping information. Images captures on iPhone 12 and newer also contain an auxiliary HDR gain map that influences local tone mapping.\\n\\nSince iOS 16 there are now APIs for rendering EDR content within an app. However, all WWDC sessions about EDR only mention video content, even though images can be HDR as well. For instance, OpenEXR images or images with an HDR color space can be rendered in EDR just fine.\\n\\nHowever, it is not possible to load HDR images taken with an iPhone in a way that the HDR information is retained. All APIs in PhotoKit, Image I\\/O, and Core Image only load the SDR part of the image, not taking into account the image\\u2019s metadata and gain map. There _are_ APIs in Image I\\/O for extracting the gain map, but I couldn\\u2019t find any documentation on how it is applied to the image to achieve HDR.\\n\\nCould you please shed some light on how the gain map is applied in Photos so that we can also display it properly in our EDR-enabled applications? Thanks!\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "00cb36a9-a948-477b-bbe0-a83645e4df11",
          "type": "message",
          "user": "U0449MFKRGE",
          "text": "We do not provide API that details how these images are rendered inside the Photos App. Please file a Feedback about the exact behavior you’d desire in this space (or paste the FB number here in case you already have some filed).",
          "ts": "1666204538.063449",
          "thread_ts": "1666204397.625879",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "M/R",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "We do not provide API that details how these images are rendered inside the Photos App. Please file a Feedback about the exact behavior you’d desire in this space (or paste the FB number here in case you already have some filed)."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "24d74b56-7cac-46a1-beb6-fc906fbb243a",
          "type": "message",
          "user": "U045ZS8EQ5T",
          "text": "\u003c@U0449MFKRGE\u003e Thanks! Here: `FB11512515` and `FB11512528`",
          "ts": "1666247954.977579",
          "thread_ts": "1666204397.625879",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "gratitude-thank-you",
              "count": 1,
              "users": [
                "U0449MFKRGE"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "5Ipi",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "user",
                      "user_id": "U0449MFKRGE"
                    },
                    {
                      "type": "text",
                      "text": " Thanks! Here: "
                    },
                    {
                      "type": "text",
                      "text": "FB11512515",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " and "
                    },
                    {
                      "type": "text",
                      "text": "FB11512528",
                      "style": {
                        "code": true
                      }
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U0464URMX6F\u003e asked\n\u0026gt; Hi. I am working for \u003chttp://Infrakit.com|Infrakit.com\u003e We provide mobile and web based collaboration solution for construction site. We have both Android and iOS apps. We have external GPS receivers for accuracy for attaching it to photos or using other features -- as it is needed on the construction site. Android works fine with external receivers, receiving data via NMEA data and parsing it. However when it comes to iOS it seems very hard to connect/test external GPS devices. Can you please guide us more how to use external gps devices with iOS apps and get the location instead of using phone's internal GPS. I am not sure where to ask this question but as we are using photos and tag with gps coordinates I will ask here and then request you guys to leave me to the correct channel or person. Thanks in advance",
      "ts": "1666204617.352409",
      "thread_ts": "1666204617.352409",
      "subtype": "bot_message",
      "bot_id": "B0431LJ7G4D",
      "username": "Ask Apple - photos-and-camera",
      "reply_count": 4,
      "latest_reply": "1666205742.525759",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "Ujr",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U0464URMX6F"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Hi. I am working for Infrakit.com We provide mobile and web based collaboration solution for construction site. We have both Android and iOS apps. We have external GPS receivers for accuracy for attaching it to photos or using other features -- as it is needed on the construction site. Android works fine with external receivers, receiving data via NMEA data and parsing it. However when it comes to iOS it seems very hard to connect\\/test external GPS devices. Can you please guide us more how to use external gps devices with iOS apps and get the location instead of using phone's internal GPS. I am not sure where to ask this question but as we are using photos and tag with gps coordinates I will ask here and then request you guys to leave me to the correct channel or person. Thanks in advance\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "7e55e0c4-0f2b-48b6-860e-94111fcb1d01",
          "type": "message",
          "user": "U0449MFKRGE",
          "text": "This question is probably better sent over to Bluetooth or other connectivity teams, unfortunately the current teams here for PhotoKit \u0026amp; Camera don’t have the expertise in this area of working with external GPS products.",
          "ts": "1666204667.308209",
          "thread_ts": "1666204617.352409",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Xzw",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "This question is probably better sent over to Bluetooth or other connectivity teams, unfortunately the current teams here for PhotoKit \u0026 Camera don’t have the expertise in this area of working with external GPS products."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "9ef18f1b-55aa-4218-b668-211c04b318ae",
          "type": "message",
          "user": "U0464URMX6F",
          "text": "I could not find that channel. Can you please guide me",
          "ts": "1666205255.505839",
          "thread_ts": "1666204617.352409",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Bfqj",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I could not find that channel. Can you please guide me"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "1afc1361-8aa7-45ee-9ec0-4bac41cea6a5",
          "type": "message",
          "user": "U0449MFKRGE",
          "text": "There are not any ongoing activities with those teams. I’d recommend submitting a \u003chttps://developer.apple.com/support/technical/|TSI\u003e or the developer forums for these teams.",
          "ts": "1666205575.137429",
          "thread_ts": "1666204617.352409",
          "attachments": [
            {
              "fallback": "Requesting Technical Support - Support - Apple Developer",
              "id": 1,
              "title": "Requesting Technical Support - Support - Apple Developer",
              "title_link": "https://developer.apple.com/support/technical/",
              "text": "Learn how to receive code-level help from an Apple engineer by submitting a Technical Support Incident.",
              "service_name": "developer.apple.com",
              "service_icon": "https://developer.apple.com/favicon.ico",
              "from_url": "https://developer.apple.com/support/technical/",
              "original_url": "https://developer.apple.com/support/technical/",
              "blocks": null
            }
          ],
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "vQGnz",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "There are not any ongoing activities with those teams. I’d recommend submitting a "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/support/technical/",
                      "text": "TSI"
                    },
                    {
                      "type": "text",
                      "text": " or the developer forums for these teams."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "53d3f443-df95-4803-bdc9-ae2ab36cbcc7",
          "type": "message",
          "user": "U0464URMX6F",
          "text": "Thank you!!",
          "ts": "1666205742.525759",
          "thread_ts": "1666204617.352409",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "RdX",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thank you!!"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U045Y19K154\u003e asked\n\u0026gt; is there an easy way to copy all comments made in a shared library in Photos to the photos' keyword fields?",
      "ts": "1666204863.513349",
      "thread_ts": "1666204863.513349",
      "subtype": "bot_message",
      "bot_id": "B0431LJ7G4D",
      "username": "Ask Apple - photos-and-camera",
      "reply_count": 9,
      "latest_reply": "1666206011.448079",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "E=ki",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U045Y19K154"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"is there an easy way to copy all comments made in a shared library in Photos to the photos' keyword fields?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "f19e423f-49ad-4b8b-8363-f7728873a558",
          "type": "message",
          "user": "U044JPHC99S",
          "text": "There isn't any API to access the comments from cloud shared assets, nor is there an API to add keywords. Please file a feedback to request API to support these actions and describe the app workflow/behavior you are trying to support, thanks.",
          "ts": "1666205055.327049",
          "thread_ts": "1666204863.513349",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "v=Hod",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "There isn't any API to access the comments from cloud shared assets, nor is there an API to add keywords. Please file a feedback to request API to support these actions and describe the app workflow/behavior you are trying to support, thanks."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "20aeef3d-a5ab-44f3-826b-11606e32387f",
          "type": "message",
          "user": "U045Y19K154",
          "text": "Just checked and the comments aren’t detectable in exiftool",
          "ts": "1666205090.891389",
          "thread_ts": "1666204863.513349",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "v9S3r",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Just checked and the comments aren’t detectable in exiftool"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "2e22f76e-4423-4a4d-bd5f-cf29add31cb9",
          "type": "message",
          "user": "U045Y19K154",
          "text": "OK thanks",
          "ts": "1666205205.999949",
          "thread_ts": "1666204863.513349",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "j/Bz",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "OK thanks"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "980b40be-9e1d-4648-b0fe-7929c278bbaf",
          "type": "message",
          "user": "U044JPHC99S",
          "text": "I thought you were referring to the comments made on Cloud Shared (`PHAssetSourceTypeCloudShared`) assets, were you referring to the comments that appear in library photos as a \"Caption\" in the UI?",
          "ts": "1666205372.556239",
          "thread_ts": "1666204863.513349",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Dr1",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I thought you were referring to the comments made on Cloud Shared ("
                    },
                    {
                      "type": "text",
                      "text": "PHAssetSourceTypeCloudShared",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": ") assets, were you referring to the comments that appear in library photos as a \"Caption\" in the UI?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "7bd7bb14-933c-491b-8963-de30d8842d1c",
          "type": "message",
          "user": "U045Y19K154",
          "text": "No, the ones that appear in the Comments field at the bottom in iPhone and behind the comments icon on Photos for Mac:",
          "ts": "1666205593.337229",
          "thread_ts": "1666204863.513349",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "M3Th",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "No, the ones that appear in the Comments field at the bottom in iPhone and behind the comments icon on Photos for Mac:"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "b7c3e676-47bb-4d02-87c5-f874ce1af764",
          "type": "message",
          "user": "U045Y19K154",
          "ts": "1666205644.765709",
          "thread_ts": "1666204863.513349",
          "files": [
            {
              "id": "F047B9KTPFE",
              "created": 1666205633,
              "timestamp": 1666205633,
              "name": "Screenshot 2022-10-19 at 11.52.49 AM.png",
              "title": "Screenshot 2022-10-19 at 11.52.49 AM.png",
              "mimetype": "image/png",
              "image_exif_rotation": 0,
              "filetype": "png",
              "pretty_type": "PNG",
              "user": "U045Y19K154",
              "mode": "hosted",
              "editable": false,
              "is_external": false,
              "external_type": "",
              "size": 70752,
              "url": "",
              "url_download": "",
              "url_private": "C043CP508PK/F047B9KTPFE-Screenshot 2022-10-19 at 11.52.49 AM.png",
              "url_private_download": "C043CP508PK/F047B9KTPFE-Screenshot 2022-10-19 at 11.52.49 AM.png",
              "original_h": 138,
              "original_w": 372,
              "thumb_64": "https://files.slack.com/files-tmb/T01PTBJ95PS-F047B9KTPFE-7b0dece9c0/screenshot_2022-10-19_at_11.52.49_am_64.png",
              "thumb_80": "https://files.slack.com/files-tmb/T01PTBJ95PS-F047B9KTPFE-7b0dece9c0/screenshot_2022-10-19_at_11.52.49_am_80.png",
              "thumb_160": "https://files.slack.com/files-tmb/T01PTBJ95PS-F047B9KTPFE-7b0dece9c0/screenshot_2022-10-19_at_11.52.49_am_160.png",
              "thumb_360": "https://files.slack.com/files-tmb/T01PTBJ95PS-F047B9KTPFE-7b0dece9c0/screenshot_2022-10-19_at_11.52.49_am_360.png",
              "thumb_360_gif": "",
              "thumb_360_w": 360,
              "thumb_360_h": 134,
              "thumb_480": "",
              "thumb_480_w": 0,
              "thumb_480_h": 0,
              "thumb_720": "",
              "thumb_720_w": 0,
              "thumb_720_h": 0,
              "thumb_960": "",
              "thumb_960_w": 0,
              "thumb_960_h": 0,
              "thumb_1024": "",
              "thumb_1024_w": 0,
              "thumb_1024_h": 0,
              "permalink": "https://appleevents.enterprise.slack.com/files/U045Y19K154/F047B9KTPFE/screenshot_2022-10-19_at_11.52.49_am.png",
              "permalink_public": "https://slack-files.com/T01PTBJ95PS-F047B9KTPFE-4004e2df56",
              "edit_link": "",
              "preview": "",
              "preview_highlight": "",
              "lines": 0,
              "lines_more": 0,
              "is_public": false,
              "public_url_shared": false,
              "channels": null,
              "groups": null,
              "ims": null,
              "initial_comment": {},
              "comments_count": 0,
              "num_stars": 0,
              "is_starred": false,
              "shares": {
                "public": null,
                "private": null
              }
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": null
        },
        {
          "client_msg_id": "690dcddf-5fe8-4262-93da-c94159e03e62",
          "type": "message",
          "user": "U044JPHC99S",
          "text": "Got it, thanks for confirming. Yes, those are comments on cloud shared assets (not captions on user library assets)",
          "ts": "1666205804.766409",
          "thread_ts": "1666204863.513349",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "QS4L",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Got it, thanks for confirming. Yes, those are comments on cloud shared assets (not captions on user library assets)"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "45a440fa-4ff1-4f2a-8ac2-36e415b71f0f",
          "type": "message",
          "user": "U045Y19K154",
          "text": "And so is there no way to read them?  Even to produce a csv with Comments and Filename would be helpful",
          "ts": "1666205932.706519",
          "thread_ts": "1666204863.513349",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "cdM3x",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "And so is there no way to read them?  Even to produce a csv with Comments and Filename would be helpful"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "e7060fb9-61a7-4c06-832e-20cecb78a639",
          "type": "message",
          "user": "U045Y19K154",
          "text": "Also how will this work with the new shared library in iOS 16.1 (if you can say…)",
          "ts": "1666206011.448079",
          "thread_ts": "1666204863.513349",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "U5aMw",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Also how will this work with the new shared library in iOS 16.1 (if you can say…)"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U045ZS8EQ5T\u003e asked\n\u0026gt; A few of our users reported that images saved with our apps disappear from their library in Photos after a few seconds. All of them own a Mac with an old version of macOS, and all of them have iCloud syncing enabled for Photos.\n\u0026gt; Our apps use Core Image to process images. Core Image will transfer most of the input's metadata to the output. While we thought this was generally a good idea, this seems to be causing the issue:\n\u0026gt; The old version of Photos (or even iPhoto?) that is running on the Mac seems to think that the output image of our app is a duplicate of the original image that was loaded into our app. As soon as the iCloud sync happens, the Mac removes the image from the library, even when it's in sleep mode. When the Mac is turned off or disconnected from the internet, the images stay in the library—until the Mac comes back online.\n\u0026gt; This seems to be caused by the output's metadata, but we couldn't figure out what fields are causing the old Photos to detect the new image as duplicate.\n\u0026gt; Do you know what metadata field we need to change to not be considered a duplicate?",
      "ts": "1666204880.638529",
      "thread_ts": "1666204880.638529",
      "subtype": "bot_message",
      "bot_id": "B0431LJ7G4D",
      "username": "Ask Apple - photos-and-camera",
      "reply_count": 1,
      "latest_reply": "1666204888.697329",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "cXE",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U045ZS8EQ5T"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"A few of our users reported that images saved with our apps disappear from their library in Photos after a few seconds. All of them own a Mac with an old version of macOS, and all of them have iCloud syncing enabled for Photos.\\nOur apps use Core Image to process images. Core Image will transfer most of the input's metadata to the output. While we thought this was generally a good idea, this seems to be causing the issue:\\nThe old version of Photos (or even iPhoto?) that is running on the Mac seems to think that the output image of our app is a duplicate of the original image that was loaded into our app. As soon as the iCloud sync happens, the Mac removes the image from the library, even when it's in sleep mode. When the Mac is turned off or disconnected from the internet, the images stay in the library\\u2014until the Mac comes back online.\\nThis seems to be caused by the output's metadata, but we couldn't figure out what fields are causing the old Photos to detect the new image as duplicate.\\nDo you know what metadata field we need to change to not be considered a duplicate?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "4c7d93c5-0e2e-4560-b7be-74923989e126",
          "type": "message",
          "user": "U044G7N0E5R",
          "text": "Hello! Thanks for the question. Saving images with PhotoKit and iCloud syncing should not be doing any deduplication. If this is reproducible, please reproduce with the Photos diagnostics with this profile and open a feedback request so we can investigate further:\n\n\u003chttps://developer.apple.com/bug-reporting/profiles-and-logs/?name=Photos\u003e",
          "ts": "1666204888.697329",
          "thread_ts": "1666204880.638529",
          "attachments": [
            {
              "fallback": "Profiles and Logs - Bug Reporting - Apple Developer",
              "id": 1,
              "title": "Profiles and Logs - Bug Reporting - Apple Developer",
              "title_link": "https://developer.apple.com/bug-reporting/profiles-and-logs/?name=Photos",
              "text": "Get details on providing logs, reproducible test cases, and other information that will help us investigate and diagnose your reported issues.",
              "service_name": "developer.apple.com",
              "service_icon": "https://developer.apple.com/favicon.ico",
              "from_url": "https://developer.apple.com/bug-reporting/profiles-and-logs/?name=Photos",
              "original_url": "https://developer.apple.com/bug-reporting/profiles-and-logs/?name=Photos",
              "blocks": null
            }
          ],
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "=Nj",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hello! Thanks for the question. Saving images with PhotoKit and iCloud syncing should not be doing any deduplication. If this is reproducible, please reproduce with the Photos diagnostics with this profile and open a feedback request so we can investigate further:\n\n"
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/bug-reporting/profiles-and-logs/?name=Photos",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U04656V5MGU\u003e asked\n\u0026gt; It seems PHLivePhotoView doesn't provide a way for the user to play it in a Mac Catalyst app, unlike on iOS where you long press to play (and and hold doesn't do anything). The Photos app has a LIVE badge when hovered plays it. Do we need to implement this type of control ourselves or is there a way the system provides to play a Live Photo?",
      "ts": "1666205344.111889",
      "thread_ts": "1666205344.111889",
      "subtype": "bot_message",
      "bot_id": "B0431LJ7G4D",
      "username": "Ask Apple - photos-and-camera",
      "reply_count": 8,
      "latest_reply": "1666208313.346489",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "yTg",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U04656V5MGU"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"It seems PHLivePhotoView doesn't provide a way for the user to play it in a Mac Catalyst app, unlike on iOS where you long press to play (and and hold doesn't do anything). The Photos app has a LIVE badge when hovered plays it. Do we need to implement this type of control ourselves or is there a way the system provides to play a Live Photo?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "16326546-1aec-44c6-a2a7-806c0ff546e6",
          "type": "message",
          "user": "U04561LA9ME",
          "text": "It sounds like an bug if `playbackGestureRecognizer` doesn’t work as expected in a Mac Catalyst app. Please open a feedback request so we can investigate further.",
          "ts": "1666205352.182979",
          "thread_ts": "1666205344.111889",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "DQNz",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "It sounds like an bug if "
                    },
                    {
                      "type": "text",
                      "text": "playbackGestureRecognizer",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " doesn’t work as expected in a Mac Catalyst app. Please open a feedback request so we can investigate further."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "672b97e5-3819-4f52-ba6b-943325ce38a0",
          "type": "message",
          "user": "U04656V5MGU",
          "text": "Thanks \u003c@U04561LA9ME\u003e, can you clarify what the expected behavior is on Catalyst for the `playbackGestureRecognizer`? Is it supposed to play upon click and hold just like iOS or is it supposed to be working differently?",
          "ts": "1666205419.860139",
          "thread_ts": "1666205344.111889",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "4dPc",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks "
                    },
                    {
                      "type": "user",
                      "user_id": "U04561LA9ME"
                    },
                    {
                      "type": "text",
                      "text": ", can you clarify what the expected behavior is on Catalyst for the "
                    },
                    {
                      "type": "text",
                      "text": "playbackGestureRecognizer",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "? Is it supposed to play upon click and hold just like iOS or is it supposed to be working differently?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "d85cc75e-381d-4797-9b43-178da2b0d99e",
          "type": "message",
          "user": "U04656V5MGU",
          "text": "I have submitted FB11653991, could follow-up with a sample project too",
          "ts": "1666205469.959329",
          "thread_ts": "1666205344.111889",
          "edited": {
            "user": "U04656V5MGU",
            "ts": "1666205497.000000"
          },
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Uc8",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I have submitted FB11653991, could follow-up with a sample project too"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "019b5016-ed11-491d-94ac-26c5d76793e9",
          "type": "message",
          "user": "U04561LA9ME",
          "text": "It is supposed to be working like iOS.",
          "ts": "1666205514.528999",
          "thread_ts": "1666205344.111889",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U04656V5MGU"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "rEe+",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "It is supposed to be working like iOS."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "47b05a2d-2ce9-4e81-bba9-1564b232c154",
          "type": "message",
          "user": "U04561LA9ME",
          "text": "To workaround the issue, you can implement your own control / gesture via:\n\n```- (void)startPlaybackWithStyle:(PHLivePhotoViewPlaybackStyle)playbackStyle;\n- (void)stopPlayback;```\n",
          "ts": "1666205840.456379",
          "thread_ts": "1666205344.111889",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "MEcy",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "To workaround the issue, you can implement your own control / gesture via:\n\n"
                    }
                  ]
                },
                {
                  "Type": "rich_text_preformatted",
                  "Raw": "{\"type\":\"rich_text_preformatted\",\"elements\":[{\"type\":\"text\",\"text\":\"- (void)startPlaybackWithStyle:(PHLivePhotoViewPlaybackStyle)playbackStyle;\\n- (void)stopPlayback;\"}],\"border\":0}"
                },
                {
                  "type": "rich_text_section",
                  "elements": []
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "c150b4a2-c485-40dd-8b5f-f65d7b4b956a",
          "type": "message",
          "user": "U04656V5MGU",
          "text": "Ok cool thanks! FB11653991 is more of a feature request to make PHLivePhotoView work like it does in the Photos app. I can file a new bug report and include a sample project showing click and hold to play not working in Catalyst.",
          "ts": "1666205943.406029",
          "thread_ts": "1666205344.111889",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Hecsy",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Ok cool thanks! FB11653991 is more of a feature request to make PHLivePhotoView work like it does in the Photos app. I can file a new bug report and include a sample project showing click and hold to play not working in Catalyst."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "8b9414d5-ccb2-4716-95d2-ef9f67ac7d38",
          "type": "message",
          "user": "U04561LA9ME",
          "text": "Thanks!",
          "ts": "1666205959.904469",
          "thread_ts": "1666205344.111889",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "9dNe",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "44a6c688-be18-4b63-8718-3111e1f88d55",
          "type": "message",
          "user": "U04656V5MGU",
          "text": "FB11705385 thank youuu",
          "ts": "1666208313.346489",
          "thread_ts": "1666205344.111889",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "dpTJr",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "FB11705385 thank youuu"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U0475PNNXCZ\u003e asked\n\u0026gt; We have an application where a sports participants place iPhones on tripods and record 1 hour long sports matches. We run into a number of challenges and wonder what best practices there are to provide the best user experience:\n\u0026gt; - If a user receives a call during their match, the recording stops. The video is streamed during recording so we can't ask the user to disable the internet connection. We recommend that the user puts the phone into \"Do not disturb\". Is there anyway we can check the status of this so that we can better signpost to a user to enable? Ideally, we'd be able to ask a user to enable t before allowing them to record.\n\u0026gt; - Battery life is also challenged for these recordings. Can we read a users battery percentage before they start recording so that we can let them know how long they can expect to be able to record before they get close to running out of battery?\n\u0026gt; - In rare cases (such as sun shining on the phones), we've run into overheating issues. Is it possible to be notified that we're approaching the limit? If this is the case, we could disable the streaming but keep the recording storing to disk so that none fo their action is lost.",
      "ts": "1666205692.580769",
      "thread_ts": "1666205692.580769",
      "subtype": "bot_message",
      "bot_id": "B0431LJ7G4D",
      "username": "Ask Apple - photos-and-camera",
      "reply_count": 1,
      "latest_reply": "1666205844.503079",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "MSk",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U0475PNNXCZ"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"We have an application where a sports participants place iPhones on tripods and record 1 hour long sports matches. We run into a number of challenges and wonder what best practices there are to provide the best user experience:\\n- If a user receives a call during their match, the recording stops. The video is streamed during recording so we can't ask the user to disable the internet connection. We recommend that the user puts the phone into \\\"Do not disturb\\\". Is there anyway we can check the status of this so that we can better signpost to a user to enable? Ideally, we'd be able to ask a user to enable t before allowing them to record.\\n- Battery life is also challenged for these recordings. Can we read a users battery percentage before they start recording so that we can let them know how long they can expect to be able to record before they get close to running out of battery?\\n- In rare cases (such as sun shining on the phones), we've run into overheating issues. Is it possible to be notified that we're approaching the limit? If this is the case, we could disable the streaming but keep the recording storing to disk so that none fo their action is lost.\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "f9592b60-6837-4f03-aab6-3275934b8d5b",
          "type": "message",
          "user": "U044JPW4FBN",
          "text": "This is a multipart question:\n• There is no API to read the DND state, if this is important to you please file an ER.\n• There's existing API to do this, `UIDevice.batteryLevel`.\n• There's existing API for this too, you can register for thermal notifications from `AVCaptureDevice.SystemPressureState`. We did a WWDC talk on this a couple years back.\n",
          "ts": "1666205844.503079",
          "thread_ts": "1666205692.580769",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "gratitude-thank-you",
              "count": 1,
              "users": [
                "U0475PNNXCZ"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "mAS",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "This is a multipart question:\n"
                    }
                  ]
                },
                {
                  "Type": "rich_text_list",
                  "Raw": "{\"type\":\"rich_text_list\",\"elements\":[{\"type\":\"rich_text_section\",\"elements\":[{\"type\":\"text\",\"text\":\"There is no API to read the DND state, if this is important to you please file an ER.\"}]},{\"type\":\"rich_text_section\",\"elements\":[{\"type\":\"text\",\"text\":\"There's existing API to do this, \"},{\"type\":\"text\",\"text\":\"UIDevice.batteryLevel\",\"style\":{\"code\":true}},{\"type\":\"text\",\"text\":\".\"}]},{\"type\":\"rich_text_section\",\"elements\":[{\"type\":\"text\",\"text\":\"There's existing API for this too, you can register for thermal notifications from \"},{\"type\":\"text\",\"text\":\"AVCaptureDevice.SystemPressureState\",\"style\":{\"code\":true}},{\"type\":\"text\",\"text\":\". We did a WWDC talk on this a couple years back.\"}]}],\"style\":\"bullet\",\"indent\":0,\"border\":0}"
                },
                {
                  "type": "rich_text_section",
                  "elements": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046Y2ULL2U\u003e asked\n\u0026gt; On Mac Catalyst object detection is triggered by system automatically against each frame captured from Camara which causes high cpu usage, We don't expect object detection when camera capturing the video. \n\u0026gt; It is reproducible with sample project \u003chttps://developer.apple.com/documentation/avfoundation/capture_setup/avcam_building_a_camera_app).|https://developer.apple.com/documentation/avfoundation/capture_setup/avcam_building_a_camera_app).\u003e\n\u0026gt; Is the system issue? and when will you address this issue?",
      "ts": "1666207552.958109",
      "thread_ts": "1666207552.958109",
      "subtype": "bot_message",
      "bot_id": "B0431LJ7G4D",
      "username": "Ask Apple - photos-and-camera",
      "reply_count": 1,
      "latest_reply": "1666207636.866599",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "wD=8q",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046Y2ULL2U"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"On Mac Catalyst object detection is triggered by system automatically against each frame captured from Camara which causes high cpu usage, We don't expect object detection when camera capturing the video. \\nIt is reproducible with sample project \"},{\"type\":\"link\",\"url\":\"https:\\/\\/developer.apple.com\\/documentation\\/avfoundation\\/capture_setup\\/avcam_building_a_camera_app).\",\"text\":\"https:\\/\\/developer.apple.com\\/documentation\\/avfoundation\\/capture_setup\\/avcam_building_a_camera_app).\"},{\"type\":\"text\",\"text\":\"\\nIs the system issue? and when will you address this issue?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "586696df-a772-4416-adfa-29dcb3b11aba",
          "type": "message",
          "user": "U0449MVNVJS",
          "text": "We're aware of the issue (thank you for filing the bug with FeedbackAssistant), have reproduced it in house, and hope to address it in a future release.",
          "ts": "1666207636.866599",
          "thread_ts": "1666207552.958109",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "iwnCB",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "We're aware of the issue (thank you for filing the bug with FeedbackAssistant), have reproduced it in house, and hope to address it in a future release."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046FAXBSTT\u003e asked\n\u0026gt; How to detect iPhone 14 Pro camera?\n\u0026gt; It is .builtInTripleCamera and virtualDeviceSwitchOverVideoZoomFactors returns [2, 6], same as iPhone 13 Pro. ( not [2, 4, 6] )",
      "ts": "1666207758.960119",
      "thread_ts": "1666207758.960119",
      "subtype": "bot_message",
      "bot_id": "B0431LJ7G4D",
      "username": "Ask Apple - photos-and-camera",
      "reply_count": 2,
      "latest_reply": "1666208172.571219",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "+fva",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046FAXBSTT"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"How to detect iPhone 14 Pro camera?\\nIt is .builtInTripleCamera and virtualDeviceSwitchOverVideoZoomFactors returns [2, 6], same as iPhone 13 Pro. ( not [2, 4, 6] )\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "35b79626-ba22-4113-9cf5-462d77b37f50",
          "type": "message",
          "user": "U0449MVNVJS",
          "text": "Take a look at the new `-AVCaptureDeviceFormat.secondaryNativeResolutionZoomFactors` API.",
          "ts": "1666207804.302539",
          "thread_ts": "1666207758.960119",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "sdy+B",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Take a look at the new "
                    },
                    {
                      "type": "text",
                      "text": "-AVCaptureDeviceFormat.secondaryNativeResolutionZoomFactors",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " API."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "cf8e5d76-648f-43e1-89d8-40fea7f6ac10",
          "type": "message",
          "user": "U046FAXBSTT",
          "text": "Thank you!",
          "ts": "1666208172.571219",
          "thread_ts": "1666207758.960119",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "/hVC",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thank you!"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U0461SXS43H\u003e asked\n\u0026gt; In Apple's sample capture code, some camera configurations are not supported it seems for depth data... how should we solve this? Much thanks.\n\u0026gt; \n\u0026gt;         if let depthData = photo.depthData?.converting(toDepthDataType:\n\u0026gt;                                                         kCVPixelFormatType_DisparityFloat32),\n\u0026gt;            let colorSpace = CGColorSpace(name: CGColorSpace.linearGray) {\n\u0026gt;             \n\u0026gt;             let depthImage = CIImage( cvImageBuffer: depthData.depthDataMap,        //FIXME: [api] -[CIImage initWithCVImageBuffer:options:] failed because the buffer is nil.\n\u0026gt;                                       options: [ .auxiliaryDisparity: true ] )\n\u0026gt;             \n\u0026gt;             \n\u0026gt;             depthMapData = context.tiffRepresentation(of: depthImage,\n\u0026gt;                                                       format: .Lf,\n\u0026gt;                                                       colorSpace: colorSpace,\n\u0026gt;                                                       options: [.disparityImage: depthImage])\n\u0026gt;         }",
      "ts": "1666207969.535819",
      "thread_ts": "1666207969.535819",
      "subtype": "bot_message",
      "bot_id": "B0431LJ7G4D",
      "username": "Ask Apple - photos-and-camera",
      "reply_count": 4,
      "latest_reply": "1666210417.037509",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "d2/",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U0461SXS43H"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"In Apple's sample capture code, some camera configurations are not supported it seems for depth data... how should we solve this? Much thanks.\\n\\n        if let depthData = photo.depthData?.converting(toDepthDataType:\\n                                                        kCVPixelFormatType_DisparityFloat32),\\n           let colorSpace = CGColorSpace(name: CGColorSpace.linearGray) {\\n            \\n            let depthImage = CIImage( cvImageBuffer: depthData.depthDataMap,        \\/\\/FIXME: [api] -[CIImage initWithCVImageBuffer\"},{\"type\":\"emoji\",\"name\":\"options\"},{\"type\":\"text\",\"text\":\"] failed because the buffer is nil.\\n                                      options: [ .auxiliaryDisparity: true ] )\\n            \\n            \\n            depthMapData = context.tiffRepresentation(of: depthImage,\\n                                                      format: .Lf,\\n                                                      colorSpace: colorSpace,\\n                                                      options: [.disparityImage: depthImage])\\n        }\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "519508a8-0b9f-4f8e-b99d-f39d88dd84e1",
          "type": "message",
          "user": "U0449MVNVJS",
          "text": "Not all AVCaptureDevices and formats support depth data delivery. The dual lens cameras do (Dual, DualWide), as well as LiDAR depth and TrueDepth. To make sure you select a format that supports depth, you can iterate through an AVCaptureDevice's `-formats` and inspect each one's `supportedDepthDataFormats` array. If the array is non nil, you should be able to connect it to a AVCapturePhotoOutput, request depth, and get it in your resulting photo.",
          "ts": "1666208176.928819",
          "thread_ts": "1666207969.535819",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "mZe",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Not all AVCaptureDevices and formats support depth data delivery. The dual lens cameras do (Dual, DualWide), as well as LiDAR depth and TrueDepth. To make sure you select a format that supports depth, you can iterate through an AVCaptureDevice's "
                    },
                    {
                      "type": "text",
                      "text": "-formats",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " and inspect each one's "
                    },
                    {
                      "type": "text",
                      "text": "supportedDepthDataFormats",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " array. If the array is non nil, you should be able to connect it to a AVCapturePhotoOutput, request depth, and get it in your resulting photo."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "53b017f9-3812-458d-923e-2e3d42f9107a",
          "type": "message",
          "user": "U0461SXS43H",
          "text": "much thanks :slightly_smiling_face:",
          "ts": "1666209210.404519",
          "thread_ts": "1666207969.535819",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Nxat",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "much thanks "
                    },
                    {
                      "type": "emoji",
                      "name": "slightly_smiling_face",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "e61f5364-4a1e-4364-ac9c-cdf5d93d7b67",
          "type": "message",
          "user": "U045620H2NL",
          "text": "To request depth on AVCapturePhotoOutput, You would need to enable depth data delivery on AVCapturePhotoOutput:\nTo do that, app would need to check if the PhotoOutput supports depthDataDelivery using `AVCapturePhotoOutput.depthDataDeliverySupported`  and then app can enable depthDataDelivery using `AVCapturePhotoOutput.depthDataDeliveryEnabled = YES`\n\nAnd then when requesting a photo, ensure that `AVCapturePhotoSettings.depthDataDeliveryEnabled = YES` is also set.",
          "ts": "1666210196.652659",
          "thread_ts": "1666207969.535819",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "GBtf",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "To request depth on AVCapturePhotoOutput, You would need to enable depth data delivery on AVCapturePhotoOutput:\nTo do that, app would need to check if the PhotoOutput supports depthDataDelivery using "
                    },
                    {
                      "type": "text",
                      "text": "AVCapturePhotoOutput.depthDataDeliverySupported",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "  and then app can enable depthDataDelivery using "
                    },
                    {
                      "type": "text",
                      "text": "AVCapturePhotoOutput.depthDataDeliveryEnabled = YES",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n\nAnd then when requesting a photo, ensure that "
                    },
                    {
                      "type": "text",
                      "text": "AVCapturePhotoSettings.depthDataDeliveryEnabled = YES",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " is also set."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "ebe2cdc1-4801-4b93-a8d5-f564d6cee78c",
          "type": "message",
          "user": "U0461SXS43H",
          "text": "thank you for the additional details",
          "ts": "1666210417.037509",
          "thread_ts": "1666207969.535819",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "GuG",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "thank you for the additional details"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046LCHGB53\u003e asked\n\u0026gt; Can I disable pre-flash (the quick flash that happens during a photo with flash, meant to reduce redeye) from the AVFoundation API?",
      "ts": "1666208215.370169",
      "thread_ts": "1666208215.370169",
      "subtype": "bot_message",
      "bot_id": "B0431LJ7G4D",
      "username": "Ask Apple - photos-and-camera",
      "reply_count": 1,
      "latest_reply": "1666208390.071179",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "6EWQ",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046LCHGB53"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Can I disable pre-flash (the quick flash that happens during a photo with flash, meant to reduce redeye) from the AVFoundation API?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "5bcb6840-3433-40cd-ab96-ae47afc9f70f",
          "type": "message",
          "user": "U044JPW4FBN",
          "text": "Unfortunately, no. Also, pre-flash is about more than redeye; it's also about AE/AF.",
          "ts": "1666208390.071179",
          "thread_ts": "1666208215.370169",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "xnZEF",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Unfortunately, no. Also, pre-flash is about more than redeye; it's also about AE/AF."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046UFX1QSH\u003e asked\n\u0026gt; Is AVCaptureDevice.showSystemUserInterface() supported on macOS? Nothing happens after calling it.",
      "ts": "1666208459.810119",
      "thread_ts": "1666208459.810119",
      "subtype": "bot_message",
      "bot_id": "B0431LJ7G4D",
      "username": "Ask Apple - photos-and-camera",
      "reply_count": 1,
      "latest_reply": "1666208604.962989",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "/SwX8",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046UFX1QSH"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Is AVCaptureDevice.showSystemUserInterface() supported on macOS? Nothing happens after calling it.\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "76ed70c4-8d90-4279-9477-86a952cfb09f",
          "type": "message",
          "user": "U0449MVNVJS",
          "text": "We're aware of this problem and are working toward a fix. Currently there is a problem calling this API on mac from a Sandboxed app. You have three choices:\n1. call it from an unsandboxed app (but sandboxes are good, so don't do that).\n2. Work around the current sandbox violation by adding “com.apple.controlcenter.show.toggles” to your array of “com.apple.security.temporary-exception.mach-lookup.global-name”\n3. Wait for a proper fix.",
          "ts": "1666208604.962989",
          "thread_ts": "1666208459.810119",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "hpZBT",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "We're aware of this problem and are working toward a fix. Currently there is a problem calling this API on mac from a Sandboxed app. You have three choices:\n"
                    }
                  ]
                },
                {
                  "Type": "rich_text_list",
                  "Raw": "{\"type\":\"rich_text_list\",\"elements\":[{\"type\":\"rich_text_section\",\"elements\":[{\"type\":\"text\",\"text\":\"call it from an unsandboxed app (but sandboxes are good, so don't do that).\"}]},{\"type\":\"rich_text_section\",\"elements\":[{\"type\":\"text\",\"text\":\"Work around the current sandbox violation by adding \\u201ccom.apple.controlcenter.show.toggles\\u201d to your array of \\u201ccom.apple.security.temporary-exception.mach-lookup.global-name\\u201d\"}]},{\"type\":\"rich_text_section\",\"elements\":[{\"type\":\"text\",\"text\":\"Wait for a proper fix.\"}]}],\"style\":\"ordered\",\"indent\":0,\"border\":0}"
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U0463182SAZ\u003e asked\n\u0026gt; I have a question regarding the AVCaptureMultiCamSession: We want to set up the camera session with two input ports from the same virtual AVCaptureDevice for (synchronized) video, but we need the still image only from only one port of the AVCaptureDevice. How can we configure this? Right now, when we pick the format the camera session always allocates buffers for two still images which results in hardwareCosts of 1.03. We would also like the capture session to apply auto-exposure to only one input port. Is that possible?",
      "ts": "1666208689.372479",
      "thread_ts": "1666208689.372479",
      "subtype": "bot_message",
      "bot_id": "B0431LJ7G4D",
      "username": "Ask Apple - photos-and-camera",
      "reply_count": 5,
      "latest_reply": "1666212932.804519",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "39c",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U0463182SAZ"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"I have a question regarding the AVCaptureMultiCamSession: We want to set up the camera session with two input ports from the same virtual AVCaptureDevice for (synchronized) video, but we need the still image only from only one port of the AVCaptureDevice. How can we configure this? Right now, when we pick the format the camera session always allocates buffers for two still images which results in hardwareCosts of 1.03. We would also like the capture session to apply auto-exposure to only one input port. Is that possible?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "c7dfea35-d112-434f-bf1a-d607119e181d",
          "type": "message",
          "user": "U0449MVNVJS",
          "text": "Sounds like you want to run the two cameras unsynchronized. Instead of using a virtual camera, you can simply run two separate physical cameras. You can control their exposure independently in this configuration, and only hook up one of them to an AVCapturePhotoOutput, which should reduce hardwareCost.",
          "ts": "1666208754.086499",
          "thread_ts": "1666208689.372479",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "8rhc5",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Sounds like you want to run the two cameras unsynchronized. Instead of using a virtual camera, you can simply run two separate physical cameras. You can control their exposure independently in this configuration, and only hook up one of them to an AVCapturePhotoOutput, which should reduce hardwareCost."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "557a67b5-dcfe-4871-ac69-877eee65c367",
          "type": "message",
          "user": "U0463182SAZ",
          "text": "Two different AVCaptureDevice work, but ideally we want to have a synchronized output of e.g. tele and wide-angle. And when we use a format with still image resolution 4032x3024 for the virtual camera, the hardware costs exceed 1.0 after adding the second AVCaptureConnection from the tele lens port.",
          "ts": "1666208941.748879",
          "thread_ts": "1666208689.372479",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "v0+T",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Two different AVCaptureDevice work, but ideally we want to have a synchronized output of e.g. tele and wide-angle. And when we use a format with still image resolution 4032x3024 for the virtual camera, the hardware costs exceed 1.0 after adding the second AVCaptureConnection from the tele lens port."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "c6b71ee2-c66f-4f31-b0e2-bf998de57c8c",
          "type": "message",
          "user": "U0449MVNVJS",
          "text": "The Dual camera does not support different exposures on its constituent physical cameras. It treats them as one.",
          "ts": "1666210099.743269",
          "thread_ts": "1666208689.372479",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "qVxVu",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "The Dual camera does not support different exposures on its constituent physical cameras. It treats them as one."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "95054e99-dbb8-4a63-bc69-89f90c8c0fa1",
          "type": "message",
          "user": "U0463182SAZ",
          "text": "Ok, we have the problem that when the flash fires, the still image is sometimes overexposed when using two ports from the same AVCaptureDevice. When using to AVCaptureDevices the flash-exposure is ok.",
          "ts": "1666212793.953609",
          "thread_ts": "1666208689.372479",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "30/xo",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Ok, we have the problem that when the flash fires, the still image is sometimes overexposed when using two ports from the same AVCaptureDevice. When using to AVCaptureDevices the flash-exposure is ok."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "981f73a9-3957-4c23-8d5e-d7eb1e973b5a",
          "type": "message",
          "user": "U0463182SAZ",
          "text": "Regarding the still image, when we set up Ultra Wide and Wide Angle lenses as ports, the still image by default always is coming from the ultrawide lens. We have to use virtualDeviceConstituentPhotoDeliveryEnabled to get the wide angle camera still image. Is there a way to change this? We only need the wide-angle still image.",
          "ts": "1666212932.804519",
          "thread_ts": "1666208689.372479",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "zrc",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Regarding the still image, when we set up Ultra Wide and Wide Angle lenses as ports, the still image by default always is coming from the ultrawide lens. We have to use virtualDeviceConstituentPhotoDeliveryEnabled to get the wide angle camera still image. Is there a way to change this? We only need the wide-angle still image."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U04625MKBGT\u003e asked\n\u0026gt; Hi Apple Team. We are trying to integrate the new 2x camera option into our app that is available on the newly release iPhone 14 Pro / Pro Max.\n\u0026gt; \n\u0026gt; Basically we use lockForConfiguration\n\u0026gt; \u003chttps://developer.apple.com/documentation/avfoundation/avcapturedevice/1387810-lockforconfiguration|https://developer.apple.com/documentation/avfoundation/avcapturedevice/1387810-lockforconfiguration\u003e\n\u0026gt; \n\u0026gt; And then set the videoZoomFactor\n\u0026gt; \u003chttps://developer.apple.com/documentation/avfoundation/avcapturedevice/1624611-videozoomfactor|https://developer.apple.com/documentation/avfoundation/avcapturedevice/1624611-videozoomfactor\u003e\n\u0026gt; \n\u0026gt; And it seems to have no effect for the secondary zoom factor.\n\u0026gt; \n\u0026gt; Do you have any advice on how we can get 2x to work.",
      "ts": "1666208942.484359",
      "thread_ts": "1666208942.484359",
      "subtype": "bot_message",
      "bot_id": "B0431LJ7G4D",
      "username": "Ask Apple - photos-and-camera",
      "reply_count": 57,
      "latest_reply": "1666212483.269739",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "Qs/di",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U04625MKBGT"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Hi Apple Team. We are trying to integrate the new 2x camera option into our app that is available on the newly release iPhone 14 Pro \\/ Pro Max.\\n\\nBasically we use lockForConfiguration\\n\"},{\"type\":\"link\",\"url\":\"https:\\/\\/developer.apple.com\\/documentation\\/avfoundation\\/avcapturedevice\\/1387810-lockforconfiguration\",\"text\":\"https:\\/\\/developer.apple.com\\/documentation\\/avfoundation\\/avcapturedevice\\/1387810-lockforconfiguration\"},{\"type\":\"text\",\"text\":\"\\n\\nAnd then set the videoZoomFactor\\n\"},{\"type\":\"link\",\"url\":\"https:\\/\\/developer.apple.com\\/documentation\\/avfoundation\\/avcapturedevice\\/1624611-videozoomfactor\",\"text\":\"https:\\/\\/developer.apple.com\\/documentation\\/avfoundation\\/avcapturedevice\\/1624611-videozoomfactor\"},{\"type\":\"text\",\"text\":\"\\n\\nAnd it seems to have no effect for the secondary zoom factor.\\n\\nDo you have any advice on how we can get 2x to work.\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "d97dfb16-fd14-42f8-8792-a9212d61fb86",
          "type": "message",
          "user": "U0449MVNVJS",
          "text": "Hi there, Markus. What is the AVCaptureDeviceType of the camera you're working with? What exact value are you setting the `videoZoomFactor` to? And after setting it, are you calling `unlockForConfiguration`? This should result in a zoom change being immediately visible in video preview.",
          "ts": "1666209036.245689",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "EBLO",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi there, Markus. What is the AVCaptureDeviceType of the camera you're working with? What exact value are you setting the "
                    },
                    {
                      "type": "text",
                      "text": "videoZoomFactor",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " to? And after setting it, are you calling "
                    },
                    {
                      "type": "text",
                      "text": "unlockForConfiguration",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "? This should result in a zoom change being immediately visible in video preview."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "f9282966-eaa1-4234-a92a-647695be6eaf",
          "type": "message",
          "user": "U044GAP6X6W",
          "text": "\u0026gt;\u0026gt; And it seems to have no effect for the secondary zoom factor\nI'm curious what you observed that led to this determination",
          "ts": "1666209145.074739",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "wge",
              "elements": [
                {
                  "Type": "rich_text_quote",
                  "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"And it seems to have no effect for the secondary zoom factor\"}],\"border\":1}"
                },
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I'm curious what you observed that led to this determination"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "7A54BE2E-04FB-40AD-A84B-DE5B642BBB59",
          "type": "message",
          "user": "U04625MKBGT",
          "text": "We set 2.0 on the zoom factor ",
          "ts": "1666209220.415309",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "s4s",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "We set 2.0 on the zoom factor "
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "0CE44AE9-2963-4C50-B86B-68FD8C0BBC65",
          "type": "message",
          "user": "U04625MKBGT",
          "text": "But there is no visible change on the camera ",
          "ts": "1666209233.050969",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "twl",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "But there is no visible change on the camera "
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "4d6f4ca8-a359-4ef2-bfe3-d67fb8d16ff6",
          "type": "message",
          "user": "U044GAP6X6W",
          "text": "I don't know enough about your configuration, but have you tried other zoomFactors? did they perform as expected or is 2x behaving differently?",
          "ts": "1666209344.657959",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "otW",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I don't know enough about your configuration, but have you tried other zoomFactors? did they perform as expected or is 2x behaving differently?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "7a7e86a5-9979-4454-8258-8e0792bbd57d",
          "type": "message",
          "user": "U044GAP6X6W",
          "text": "One thing to note is that zoomFactors are all relative to the base zoom factor of the widest lens if this is a virtual device, and that will always be 1x",
          "ts": "1666209806.433389",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "3p8",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "One thing to note is that zoomFactors are all relative to the base zoom factor of the widest lens if this is a virtual device, and that will always be 1x"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "ec636e80-1301-4964-8d3b-f2c237565379",
          "type": "message",
          "user": "U04625MKBGT",
          "text": "*`private`* `*func* getVideoDevices() *throws* -\u0026gt; [(AVCaptureDevice.DeviceType, CGFloat, Float)] {`\n    `*let* deviceTypes: [AVCaptureDevice.DeviceType] = [.builtInWideAngleCamera, .builtInTelephotoCamera, .builtInUltraWideCamera, .builtInDualCamera, .builtInDualWideCamera, .builtInTripleCamera]`\n    `*var* result : [(AVCaptureDevice.DeviceType, CGFloat, Float)] = []`\n     \n    `print(\"=== CAMERA CONFIG START ===\")`\n    *`if`* `*let* defaultDevice = AVCaptureDevice.default(for: .video) {`\n      `*let* defaultFieldOfView = defaultDevice.activeFormat.videoFieldOfView`\n      `print(\"defaultFieldOfView\", defaultFieldOfView)`\n      `*for* dt *in* deviceTypes {`\n        *`if`* `*let* device = AVCaptureDevice.default(dt, for: .video, position: .back) {`\n          `*let* zoomFactor: Float = defaultFieldOfView / device.activeFormat.videoFieldOfView`\n          `*if* !result.contains(where: { r *in* abs(zoomFactor-r.2) \u0026lt; 0.1 }) {`\n            `result.append((dt, 1, zoomFactor))`\n            `print(\"main config\", dt.rawValue, zoomFactor, device.activeFormat.videoMaxZoomFactor)`\n          `}`\n          `*for* factor *in* device.activeFormat.secondaryNativeResolutionZoomFactors {`\n            `*let* f = Float(factor) * zoomFactor`\n            `*if* !result.contains(where: { r *in* abs(f-r.2) \u0026lt; 0.1 }) {`\n              `result.append((dt, factor, f))`\n              `print(\"sub config\", dt.rawValue, factor, f)`\n            `}`\n          `}`\n        `}`\n      `}`\n    `}`\n    `print(\"=== CAMERA CONFIG END ===\")`\n    `*return* result.sorted { a, b *in* a.2 \u0026lt; b.2 }`\n  `}`\n   \n  *`private`* `*func* getVideoDevice(type: AVCaptureDevice.DeviceType, factor: CGFloat) *throws* -\u0026gt; AVCaptureDevice {`\n    `*let* device = AVCaptureDevice.default(type, for: .video, position: .back)!`\n    `*if* factor != 1 {`\n      `*try* device.lockForConfiguration()`\n      `device.videoZoomFactor = factor`\n      `device.unlockForConfiguration()`\n    `}`\n     \n    `*return* device`\n  `}`",
          "ts": "1666209809.853889",
          "thread_ts": "1666208942.484359",
          "edited": {
            "user": "U04625MKBGT",
            "ts": "1666209985.000000"
          },
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "L1BiS",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "private",
                      "style": {
                        "bold": true,
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " ",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "func",
                      "style": {
                        "bold": true,
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " getVideoDevices() ",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "throws",
                      "style": {
                        "bold": true,
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " -\u003e [(AVCaptureDevice.DeviceType, CGFloat, Float)] {",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "    ",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "let",
                      "style": {
                        "bold": true,
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " deviceTypes: [AVCaptureDevice.DeviceType] = [.builtInWideAngleCamera, .builtInTelephotoCamera, .builtInUltraWideCamera, .builtInDualCamera, .builtInDualWideCamera, .builtInTripleCamera]",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "    ",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "var",
                      "style": {
                        "bold": true,
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " result : [(AVCaptureDevice.DeviceType, CGFloat, Float)] = []",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "     ",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "    print(\"=== CAMERA CONFIG START ===\")",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "    ",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "if",
                      "style": {
                        "bold": true,
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " ",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "let",
                      "style": {
                        "bold": true,
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " defaultDevice = AVCaptureDevice.default(for: .video) {",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "      ",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "let",
                      "style": {
                        "bold": true,
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " defaultFieldOfView = defaultDevice.activeFormat.videoFieldOfView",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "      print(\"defaultFieldOfView\", defaultFieldOfView)",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "      ",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "for",
                      "style": {
                        "bold": true,
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " dt ",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "in",
                      "style": {
                        "bold": true,
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " deviceTypes {",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "        ",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "if",
                      "style": {
                        "bold": true,
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " ",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "let",
                      "style": {
                        "bold": true,
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " device = AVCaptureDevice.default(dt, for: .video, position: .back) {",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "          ",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "let",
                      "style": {
                        "bold": true,
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " zoomFactor: Float = defaultFieldOfView / device.activeFormat.videoFieldOfView",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "          ",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "if",
                      "style": {
                        "bold": true,
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " !result.contains(where: { r ",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "in",
                      "style": {
                        "bold": true,
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " abs(zoomFactor-r.2) \u003c 0.1 }) {",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "            result.append((dt, 1, zoomFactor))",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "            print(\"main config\", dt.rawValue, zoomFactor, device.activeFormat.videoMaxZoomFactor)",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "          }",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "          ",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "for",
                      "style": {
                        "bold": true,
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " factor ",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "in",
                      "style": {
                        "bold": true,
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " device.activeFormat.secondaryNativeResolutionZoomFactors {",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "            ",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "let",
                      "style": {
                        "bold": true,
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " f = Float(factor) * zoomFactor",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "            ",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "if",
                      "style": {
                        "bold": true,
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " !result.contains(where: { r ",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "in",
                      "style": {
                        "bold": true,
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " abs(f-r.2) \u003c 0.1 }) {",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "              result.append((dt, factor, f))",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "              print(\"sub config\", dt.rawValue, factor, f)",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "            }",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "          }",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "        }",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "      }",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "    }",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "    print(\"=== CAMERA CONFIG END ===\")",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "    ",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "return",
                      "style": {
                        "bold": true,
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " result.sorted { a, b ",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "in",
                      "style": {
                        "bold": true,
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " a.2 \u003c b.2 }",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "  }",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "   ",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "  ",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "private",
                      "style": {
                        "bold": true,
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " ",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "func",
                      "style": {
                        "bold": true,
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " getVideoDevice(type: AVCaptureDevice.DeviceType, factor: CGFloat) ",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "throws",
                      "style": {
                        "bold": true,
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " -\u003e AVCaptureDevice {",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "    ",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "let",
                      "style": {
                        "bold": true,
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " device = AVCaptureDevice.default(type, for: .video, position: .back)!",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "    ",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "if",
                      "style": {
                        "bold": true,
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " factor != 1 {",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "      ",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "try",
                      "style": {
                        "bold": true,
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " device.lockForConfiguration()",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "      device.videoZoomFactor = factor",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "      device.unlockForConfiguration()",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "    }",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "     ",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "    ",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "return",
                      "style": {
                        "bold": true,
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " device",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "  }",
                      "style": {
                        "code": true
                      }
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "2946d8a4-cadc-4464-93f9-01eb1239571f",
          "type": "message",
          "user": "U044GAP6X6W",
          "text": "so if you're configuring a virtual device that includes the SuperWide, 1x will be the SuperWide fully zoomed, out, 2x will be the wide camera, zoomed out, and 4x will be the wide camera, zoomed in 2x",
          "ts": "1666209884.862099",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "urw",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "so if you're configuring a virtual device that includes the SuperWide, 1x will be the SuperWide fully zoomed, out, 2x will be the wide camera, zoomed out, and 4x will be the wide camera, zoomed in 2x"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "21de74e1-c1c3-4fe2-a8e8-62d610608b9b",
          "type": "message",
          "user": "U044GAP6X6W",
          "text": "ok so you seem to be calling lock and unlock correctly",
          "ts": "1666210087.800739",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "dvt+h",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "ok so you seem to be calling lock and unlock correctly"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "a5b679e2-21dd-48fa-beac-e75dc8c3c3e3",
          "type": "message",
          "user": "U044GAP6X6W",
          "text": "but I still don't know enough about your environment",
          "ts": "1666210144.773079",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "9Wh",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "but I still don't know enough about your environment"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "b947e7ae-d6e6-4baa-9553-9c45269152e3",
          "type": "message",
          "user": "U04625MKBGT",
          "text": "one thing that seems to happen is that the camera is still in 48MP resolution",
          "ts": "1666210197.815439",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "H6lF",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "one thing that seems to happen is that the camera is still in 48MP resolution"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "75afe52c-4457-41be-8e80-a6d5fff515bf",
          "type": "message",
          "user": "U04625MKBGT",
          "text": "when we switch the camera",
          "ts": "1666210204.253259",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "wbvX",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "when we switch the camera"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "236f8621-c1f2-469e-b376-ad18ffcf9f2f",
          "type": "message",
          "user": "U04625MKBGT",
          "text": "since we configured it to achieve the full 48MP image on 1x",
          "ts": "1666210224.695519",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "z4ovE",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "since we configured it to achieve the full 48MP image on 1x"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "11b15236-2597-478a-bec3-51cd658106cb",
          "type": "message",
          "user": "U04625MKBGT",
          "text": "`// Check Pro Raw photo support`\n    *`if`* `*let* device = AVCaptureDevice.default(.builtInWideAngleCamera,`\n                        `for: .video,`\n                        `position: .back), !isProRawCaptureSupported {`\n      `*if* device.formats.contains(where: { $0.supportedMaxPhotoDimensions.contains(where: { $0.width*$0.height == 6048*8064 }) }) {`\n        `isProRawCaptureSupported = *true*`\n      `}`\n    `}`",
          "ts": "1666210230.029999",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "8OW",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "// Check Pro Raw photo support",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "    ",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "if",
                      "style": {
                        "bold": true,
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " ",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "let",
                      "style": {
                        "bold": true,
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " device = AVCaptureDevice.default(.builtInWideAngleCamera,",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "                        for: .video,",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "                        position: .back), !isProRawCaptureSupported {",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "      ",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "if",
                      "style": {
                        "bold": true,
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " device.formats.contains(where: { $0.supportedMaxPhotoDimensions.contains(where: { $0.width*$0.height == 6048*8064 }) }) {",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "        isProRawCaptureSupported = ",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "true",
                      "style": {
                        "bold": true,
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "      }",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "    }",
                      "style": {
                        "code": true
                      }
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "5e65c504-1ccd-4b61-be58-45a03f03bc34",
          "type": "message",
          "user": "U044GAP6X6W",
          "text": "which one of these device types are you using?: `[.builtInWideAngleCamera, .builtInTelephotoCamera, .builtInUltraWideCamera, .builtInDualCamera, .builtInDualWideCamera, .builtInTripleCamera]`",
          "ts": "1666210241.103369",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "/04",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "which one of these device types are you using?: "
                    },
                    {
                      "type": "text",
                      "text": "[.builtInWideAngleCamera, .builtInTelephotoCamera, .builtInUltraWideCamera, .builtInDualCamera, .builtInDualWideCamera, .builtInTripleCamera]",
                      "style": {
                        "code": true
                      }
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "dd638e15-0268-4917-ac5b-64c097d4ce62",
          "type": "message",
          "user": "U04625MKBGT",
          "text": "builtInWideAngleCamera",
          "ts": "1666210307.036119",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "KPH",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "builtInWideAngleCamera"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "642e7d9a-f39e-4f7f-aabe-34c72d6ae9e1",
          "type": "message",
          "user": "U044GAP6X6W",
          "text": "cool",
          "ts": "1666210315.883859",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "w+7",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "cool"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "0f2a7911-40f3-4ab2-b37f-a018b5ad5308",
          "type": "message",
          "user": "U044GAP6X6W",
          "text": "ok so do you have a session running and streaming preview frames to the screen?",
          "ts": "1666210349.421589",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "etz5q",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "ok so do you have a session running and streaming preview frames to the screen?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "b49746ef-8706-41a0-a0ae-5ac0a496dab5",
          "type": "message",
          "user": "U04625MKBGT",
          "text": "*=== CAMERA CONFIG START ===*\n*defaultFieldOfView 70.47243*\n*main config AVCaptureDeviceTypeBuiltInWideAngleCamera 1.0 189.0*\n*sub config AVCaptureDeviceTypeBuiltInWideAngleCamera 2.0 2.0*\n*main config AVCaptureDeviceTypeBuiltInTelephotoCamera 2.6681063 123.75*\n*main config AVCaptureDeviceTypeBuiltInUltraWideCamera 0.6635778 123.75*\n*=== CAMERA CONFIG END ===*\n[11:50 AM] *2022-10-07 11:50:10.699712+0200 Plinth Capture[1463:251491] [CameraViewModel] \u0026gt;\u0026gt;\u0026gt; Set Max Photo Dimensions in Photo Output Settings - 8064 x 6048*\n*2022-10-07 11:50:13.284292+0200 Plinth Capture[1463:252000] [CameraViewModel] \u0026gt;\u0026gt;\u0026gt; Set Max Photo Dimensions in Photo Output Settings - 8064 x 6048*",
          "ts": "1666210449.161759",
          "thread_ts": "1666208942.484359",
          "edited": {
            "user": "U04625MKBGT",
            "ts": "1666210458.000000"
          },
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "4aEAe",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "=== CAMERA CONFIG START ===",
                      "style": {
                        "bold": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "defaultFieldOfView 70.47243",
                      "style": {
                        "bold": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "main config AVCaptureDeviceTypeBuiltInWideAngleCamera 1.0 189.0",
                      "style": {
                        "bold": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "sub config AVCaptureDeviceTypeBuiltInWideAngleCamera 2.0 2.0",
                      "style": {
                        "bold": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "main config AVCaptureDeviceTypeBuiltInTelephotoCamera 2.6681063 123.75",
                      "style": {
                        "bold": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "main config AVCaptureDeviceTypeBuiltInUltraWideCamera 0.6635778 123.75",
                      "style": {
                        "bold": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "=== CAMERA CONFIG END ===",
                      "style": {
                        "bold": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n[11:50 AM] "
                    },
                    {
                      "type": "text",
                      "text": "2022-10-07 11:50:10.699712+0200 Plinth Capture[1463:251491] [CameraViewModel] \u003e\u003e\u003e Set Max Photo Dimensions in Photo Output Settings - 8064 x 6048",
                      "style": {
                        "bold": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "2022-10-07 11:50:13.284292+0200 Plinth Capture[1463:252000] [CameraViewModel] \u003e\u003e\u003e Set Max Photo Dimensions in Photo Output Settings - 8064 x 6048",
                      "style": {
                        "bold": true
                      }
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "ab00c4f1-4382-4b8e-9e6e-0d41db7e42fb",
          "type": "message",
          "user": "U04625MKBGT",
          "text": "the last 2 lines are switching from 1x to 2x via Zoom Factors and its still at 48MP resolution",
          "ts": "1666210490.321959",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "0eO2",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "the last 2 lines are switching from 1x to 2x via Zoom Factors and its still at 48MP resolution"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "e8a430c4-87b7-4b6f-83db-7d16ae2b1fff",
          "type": "message",
          "user": "U044GAP6X6W",
          "text": "what is still at 48MP resolution?",
          "ts": "1666210580.745739",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "42Q",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "what is still at 48MP resolution?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "0bd9c230-a6ad-4b6f-a2f3-a72e40ef30fc",
          "type": "message",
          "user": "U04625MKBGT",
          "text": "builtInWideAngleCamera",
          "ts": "1666210617.309379",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "koEr",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "builtInWideAngleCamera"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "4fa0917c-ff7a-4955-8553-4bf0938b61e4",
          "type": "message",
          "user": "U044GAP6X6W",
          "text": "what is your expectation? that the MaxPhotoDimensions property will reflect the zoomFactor?",
          "ts": "1666210677.407959",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Vbx",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "what is your expectation? that the MaxPhotoDimensions property will reflect the zoomFactor?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "521079eb-c3d1-4985-b30e-41a835325925",
          "type": "message",
          "user": "U04625MKBGT",
          "text": "but technically shouldn’t it switch to *4032 x 3024 in that mode*",
          "ts": "1666210694.541069",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "l7b",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "but technically shouldn’t it switch to "
                    },
                    {
                      "type": "text",
                      "text": "4032 x 3024 in that mode",
                      "style": {
                        "bold": true
                      }
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "0416a0e5-99c3-405e-a426-a54c8c14b0ee",
          "type": "message",
          "user": "U04625MKBGT",
          "text": "since it centers in on the sensor",
          "ts": "1666210705.591989",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "rz+",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "since it centers in on the sensor"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "c46108dc-2b69-42d0-9fa9-12abf15ae3df",
          "type": "message",
          "user": "U044GAP6X6W",
          "text": "that's not part of the API",
          "ts": "1666210717.384179",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "WAU",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "that's not part of the API"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "b93a6a6d-ed42-4734-877f-0ae5af35506d",
          "type": "message",
          "user": "U044GAP6X6W",
          "text": "maxPhotoDimensions is user settable, and as long as its a valid value it will stay the same",
          "ts": "1666210752.744419",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "SUNR",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "maxPhotoDimensions is user settable, and as long as its a valid value it will stay the same"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "74462332-7af8-4649-b99b-e2526082a8af",
          "type": "message",
          "user": "U044GAP6X6W",
          "text": "and it describes the max size photo you will accept",
          "ts": "1666210781.067979",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "ilKD",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "and it describes the max size photo you will accept"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "de838ee6-4986-44c0-888a-3f4339dde361",
          "type": "message",
          "user": "U044GAP6X6W",
          "text": "if you zoom, from 1-2x, what you get will get smaller, but it will never exceed 48MP",
          "ts": "1666210802.979379",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "a+S",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "if you zoom, from 1-2x, what you get will get smaller, but it will never exceed 48MP"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "df32681b-bc37-46ec-a27f-4c2b88e9bc1c",
          "type": "message",
          "user": "U04625MKBGT",
          "text": "got it",
          "ts": "1666210814.567079",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "52R4",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "got it"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "0db585f6-6799-47bd-bec4-a483c56cfac2",
          "type": "message",
          "user": "U04625MKBGT",
          "text": "so that’s not the issue then",
          "ts": "1666210822.853339",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "l7lT",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "so that’s not the issue then"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "69871c34-cf63-4b9e-8203-f19fd060925e",
          "type": "message",
          "user": "U044GAP6X6W",
          "text": "so I'm still not clear on the issue you're experiencing",
          "ts": "1666210840.754679",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "=r6",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "so I'm still not clear on the issue you're experiencing"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "3493cb34-1845-43bd-bd1e-5f9b8bb26ce1",
          "type": "message",
          "user": "U04625MKBGT",
          "text": "we do not see any zoom on the image at all",
          "ts": "1666210870.778619",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "ct61",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "we do not see any zoom on the image at all"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "3cfbb8f8-60b6-487a-addf-4545c0e3e6bc",
          "type": "message",
          "user": "U044GAP6X6W",
          "text": "I'd like to know if you have a session running and streaming preview frames to the screen",
          "ts": "1666210883.484669",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "IC6Pv",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I'd like to know if you have a session running and streaming preview frames to the screen"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "7e3d3949-a501-421a-acda-e9d633468a35",
          "type": "message",
          "user": "U04625MKBGT",
          "text": "unless we switch to another camera",
          "ts": "1666210884.037089",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "wI+J",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "unless we switch to another camera"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "9ac21015-be77-423a-a5db-c29231f510d7",
          "type": "message",
          "user": "U04625MKBGT",
          "text": "not currently",
          "ts": "1666210900.956889",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "W6s4",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "not currently"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "df7c2014-9d89-45d9-931a-8275341f0b52",
          "type": "message",
          "user": "U044GAP6X6W",
          "text": "ok, so you're not streaming frames, and the zoom factor isn't changing, its just not producing the expected effect",
          "ts": "1666210940.487699",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "+9E",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "ok, so you're not streaming frames, and the zoom factor isn't changing, its just not producing the expected effect"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "3772904f-9edb-46ca-979c-159375532fe5",
          "type": "message",
          "user": "U044GAP6X6W",
          "text": "are you capturing a photo with a zoomFactor of 2x?",
          "ts": "1666210980.910379",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "n+u5L",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "are you capturing a photo with a zoomFactor of 2x?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "8a3462fc-3209-4aa1-81dc-3a8e04c75ad0",
          "type": "message",
          "user": "U04625MKBGT",
          "text": "*2022-10-19 22:27:17.487457+0200 Plinth Capture[3196:553533] [CameraViewModel] inProgressCaptures=1*\n*2022-10-19 22:27:17.515291+0200 Plinth Capture[3196:553308] [PhotoCaptureDelegate] Captured gravity vector: Optional(__C.CMAcceleration(x: -0.004714278504252434, y: -0.7081868052482605, z: -0.7060093283653259))*\n*2022-10-19 22:27:19.385817+0200 Plinth Capture[3196:553308] [PhotoCaptureDelegate] DidFinishProcessingPhoto: photo=\u0026lt;AVCapturePhoto: 0x2819625d0 pts:36717.302168 1/2 (raw) settings:uid:8 photo:{8064x6048 expected photos:2} raw:{8064x6048} prev:{512x384} thumb:{512x384} time:0.106-0.121\u0026gt;*\n*2022-10-19 22:27:19.386029+0200 Plinth Capture[3196:553308] [PhotoCaptureDelegate] colorSpace .linearGray not available... can’t save depth data!*\n*2022-10-19 22:27:19.388477+0200 Plinth Capture[3196:553308] [PhotoCaptureDelegate] DidFinishProcessingPhoto: photo=\u0026lt;AVCapturePhoto: 0x2819620d0 pts:36717.302168 2/2 settings:uid:8 photo:{8064x6048 expected photos:2} raw:{8064x6048} prev:{512x384} thumb:{512x384} time:0.106-0.121\u0026gt;*\n*2022-10-19 22:27:19.388575+0200 Plinth Capture[3196:553308] [PhotoCaptureDelegate] colorSpace .linearGray not available... can’t save depth data!*\n*DidFinishCapture!*",
          "ts": "1666211307.027769",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "XOlsf",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "2022-10-19 22:27:17.487457+0200 Plinth Capture[3196:553533] [CameraViewModel] inProgressCaptures=1",
                      "style": {
                        "bold": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "2022-10-19 22:27:17.515291+0200 Plinth Capture[3196:553308] [PhotoCaptureDelegate] Captured gravity vector: Optional(__C.CMAcceleration(x: -0.004714278504252434, y: -0.7081868052482605, z: -0.7060093283653259))",
                      "style": {
                        "bold": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "2022-10-19 22:27:19.385817+0200 Plinth Capture[3196:553308] [PhotoCaptureDelegate] DidFinishProcessingPhoto: photo=\u003cAVCapturePhoto: 0x2819625d0 pts:36717.302168 1/2 (raw) settings:uid:8 photo:{8064x6048 expected photos:2} raw:{8064x6048} prev:{512x384} thumb:{512x384} time:0.106-0.121\u003e",
                      "style": {
                        "bold": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "2022-10-19 22:27:19.386029+0200 Plinth Capture[3196:553308] [PhotoCaptureDelegate] colorSpace .linearGray not available... can’t save depth data!",
                      "style": {
                        "bold": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "2022-10-19 22:27:19.388477+0200 Plinth Capture[3196:553308] [PhotoCaptureDelegate] DidFinishProcessingPhoto: photo=\u003cAVCapturePhoto: 0x2819620d0 pts:36717.302168 2/2 settings:uid:8 photo:{8064x6048 expected photos:2} raw:{8064x6048} prev:{512x384} thumb:{512x384} time:0.106-0.121\u003e",
                      "style": {
                        "bold": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "2022-10-19 22:27:19.388575+0200 Plinth Capture[3196:553308] [PhotoCaptureDelegate] colorSpace .linearGray not available... can’t save depth data!",
                      "style": {
                        "bold": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "DidFinishCapture!",
                      "style": {
                        "bold": true
                      }
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "95e61913-3621-4d2f-a9d9-275860297533",
          "type": "message",
          "user": "U044GAP6X6W",
          "text": "It seems you've captured a photo, and maybe it appears to be all the way zoomed out?",
          "ts": "1666211436.894699",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "ilS",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "It seems you've captured a photo, and maybe it appears to be all the way zoomed out?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "200b5af5-b1ef-4cc9-975e-02acd4b536df",
          "type": "message",
          "user": "U04625MKBGT",
          "text": "yes exactly",
          "ts": "1666211476.887989",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "DjG",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "yes exactly"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "f51dddfa-0b66-4204-a804-fdfe259fa913",
          "type": "message",
          "user": "U044GAP6X6W",
          "text": "have you tried other zoom factors besides 2x?",
          "ts": "1666211489.304729",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "tt965",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "have you tried other zoom factors besides 2x?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "57ac0288-6838-409e-bcd0-e881a34d9a92",
          "type": "message",
          "user": "U044GAP6X6W",
          "text": "Nothing has changed in the API for setting zoom",
          "ts": "1666211673.947539",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Ffbh5",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Nothing has changed in the API for setting zoom"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "3ea7020e-a429-4f2c-a75d-10f74c194942",
          "type": "message",
          "user": "U044GAP6X6W",
          "text": "you should always be able to set any valid value and see the setting reflected in the FOV of the photo you capture",
          "ts": "1666211702.601479",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "vj9sO",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "you should always be able to set any valid value and see the setting reflected in the FOV of the photo you capture"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "500de94f-c1e9-46a8-a57e-ba227cedf6cd",
          "type": "message",
          "user": "U044GAP6X6W",
          "text": "Without a more thorough understanding of your code I'm a bit limited in how much I can debug here...",
          "ts": "1666211804.300699",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "DEmi",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Without a more thorough understanding of your code I'm a bit limited in how much I can debug here..."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "a0a315c0-4f7c-4def-8798-4b910e5800e5",
          "type": "message",
          "user": "U04625MKBGT",
          "text": "it reports the sub config as 2.0 max so we cannot set it higher\n*sub config AVCaptureDeviceTypeBuiltInWideAngleCamera 2.0 2.0*",
          "ts": "1666211831.620839",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "EnN",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "it reports the sub config as 2.0 max so we cannot set it higher\n"
                    },
                    {
                      "type": "text",
                      "text": "sub config AVCaptureDeviceTypeBuiltInWideAngleCamera 2.0 2.0",
                      "style": {
                        "bold": true
                      }
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "7b881274-d8e5-4f08-ad64-e436f9866c98",
          "type": "message",
          "user": "U04625MKBGT",
          "text": "yeah I undertand",
          "ts": "1666211916.645109",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "TQik",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "yeah I undertand"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "71daa646-1923-4eea-99b7-69425ab4c570",
          "type": "message",
          "user": "U044GAP6X6W",
          "text": "You can absolutely set the zoom higher than 2x",
          "ts": "1666211955.727079",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Fgb",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "You can absolutely set the zoom higher than 2x"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "592ae71f-732e-4388-8a43-85f48b867e1a",
          "type": "message",
          "user": "U044GAP6X6W",
          "text": "I believe your code is printing the secondaryNativeResolutionZoomFactors, which is in no way a maximum",
          "ts": "1666212011.497469",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "pumeL",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I believe your code is printing the secondaryNativeResolutionZoomFactors, which is in no way a maximum"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "1895f129-589b-4cb7-aa90-0910bea32188",
          "type": "message",
          "user": "U044GAP6X6W",
          "text": "see the documentation here: \u003chttps://developer.apple.com/documentation/avfoundation/avcapturedeviceformat/3950865-secondarynativeresolutionzoomfac\u003e",
          "ts": "1666212048.862339",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "yAB",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "see the documentation here: "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/avfoundation/avcapturedeviceformat/3950865-secondarynativeresolutionzoomfac",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "9eb27a58-b10c-457e-8d06-a8c5348c42ef",
          "type": "message",
          "user": "U04625MKBGT",
          "text": "yeah it is. ok we will try to set it higher and see if it changes in any way",
          "ts": "1666212049.909879",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "lZU1",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "yeah it is. ok we will try to set it higher and see if it changes in any way"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "24610143-1c58-4f9f-8d09-8bbbe5d3f651",
          "type": "message",
          "user": "U044GAP6X6W",
          "text": "In the see also section, there's a link to \u003chttps://developer.apple.com/documentation/avfoundation/avcapturedeviceformat/1624635-videomaxzoomfactor\u003e which I believe are generally very high limits",
          "ts": "1666212104.169689",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Qxs",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "In the see also section, there's a link to "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/avfoundation/avcapturedeviceformat/1624635-videomaxzoomfactor",
                      "text": ""
                    },
                    {
                      "type": "text",
                      "text": " which I believe are generally very high limits"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "f2b25512-5a8d-4c04-a1f5-020e37bc3a4e",
          "type": "message",
          "user": "U04625MKBGT",
          "text": "ok we will try that next",
          "ts": "1666212313.377559",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "UE6Z",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "ok we will try that next"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "fbe37b95-2e70-4fa3-abbc-604f14457d7a",
          "type": "message",
          "user": "U04625MKBGT",
          "text": "thank you",
          "ts": "1666212318.330609",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "qXL",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "thank you"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "421986d0-adb3-4a2c-87a4-01bd61aa6f30",
          "type": "message",
          "user": "U044GAP6X6W",
          "text": "If this issue persists, a bug report via FeedbackAssistant, with a sample project illustrating the problem, could be warranted",
          "ts": "1666212385.850949",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "white_check_mark",
              "count": 1,
              "users": [
                "U04625MKBGT"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "YAuF",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "If this issue persists, a bug report via FeedbackAssistant, with a sample project illustrating the problem, could be warranted"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "41754817-f4ae-4c38-842e-21e56cf392a4",
          "type": "message",
          "user": "U04625MKBGT",
          "text": "will submit a report if we cannot find a solution",
          "ts": "1666212433.748859",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "cmj",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "will submit a report if we cannot find a solution"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "5e6aab93-b7fc-49be-a58a-f578c5396934",
          "type": "message",
          "user": "U04625MKBGT",
          "text": "thank you for your help",
          "ts": "1666212483.269739",
          "thread_ts": "1666208942.484359",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "nrp",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "thank you for your help"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U04641XFD0S\u003e asked\n\u0026gt; Do I have to explicitly stop the AVCaptureSession when the app enters the background?",
      "ts": "1666209264.887799",
      "thread_ts": "1666209264.887799",
      "subtype": "bot_message",
      "bot_id": "B0431LJ7G4D",
      "username": "Ask Apple - photos-and-camera",
      "reply_count": 1,
      "latest_reply": "1666209306.670529",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "Y8sY",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U04641XFD0S"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Do I have to explicitly stop the AVCaptureSession when the app enters the background?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "19b9af6a-334c-4123-aa9d-bceb83b5bdc5",
          "type": "message",
          "user": "U0449MVNVJS",
          "text": "Absolutely not! The session automatically gets interrupted when your app goes to the background and automatically resumes when you're foregrounded. :+1:",
          "ts": "1666209306.670529",
          "thread_ts": "1666209264.887799",
          "team": "T03U5MWB2FN",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U04641XFD0S"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "0xQX",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Absolutely not! The session automatically gets interrupted when your app goes to the background and automatically resumes when you're foregrounded. "
                    },
                    {
                      "type": "emoji",
                      "name": "thumbsup",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046Y632KFY\u003e asked\n\u0026gt; We have an application that uses wired camera, captures it’s output and displays it on the screen. This camera has snapshot button which stopped working from macOS 12.3. We’ve researched this issue, found that camera has two interfaces, first is used for receiving interrupt signal from our camera (it is passed when the snapshot button is clicked) and second is used for video streaming. Before macOS version 12.3 snapshot functionality worked as expected, but not starting from this version. We found that inability to receive interrupt information from our camera is because we can’t open a connection to the first camera interface. When the camera is configured, it’s interfaces become connected with UVCAssistant objects which setup the interfaces and handle their work. UVCAssistant objects keep exclusive access to camera interfaces, so they don’t give us the ability to receive an interrupt signal. \n\u0026gt;  \n\u0026gt; We have created custom dext to match with IOUSBHostDevice object that represents camera and configured camera on our own to be able to open interfaces and keep exclusive access to them. But if we do configuring camera with valid configuration that specified in descriptor, system default UVCAssistant object matches interfaces and keeps exclusive access to them. We've created dext that matches interfaces instead of camera object, but we couldn't setup interfaces properly and camera was not recognised. \u2028We have been looking for the different solution, tried the one described in \u003chttps://github.com/libusb/libusb/pull/911|https://github.com/libusb/libusb/pull/911\u003e . We managed to make UVCAssistant objects become detached from camera interfaces and open interfaces via our application to listen to the interrupt events but the streaming has been broken. The application couldn't stream the video if UVCAssistant objects are not matched with camera interfaces.\n\u0026gt;  \n\u0026gt; Also we performed sniffing the traffic, tried to recreate commands passed by UVCAssistant objects to camera interfaces but our attempts failed, camera remained unrecognised.\n\u0026gt;  \n\u0026gt; Our questions are:\n\u0026gt; \t:black_small_square:\tis it possible to prevent UVCAssistant object from connecting with first camera interface and allow another UVCAssistant object to be connected with second camera interface, will it work for us, will the camera be recognised in such case? (As we researched it is impossible, USBDeviceReEnumerate with kUSBReEnumerateCaptureDeviceMask gives us the ability to detach all system objects from our camera and interfaces but not one of them)\n\u0026gt; \t:black_small_square:\tif the first solution is impossible, please provide us the information how to setup camera interfaces so the camera will be recognised and be able to receive interrupt signals and do streaming (the preferable way is to setup camera interfaces using IOKit, from our application, if it’s impossible we can accept the dext solution)\n\u0026gt; \t:black_small_square:\tif previous questions don’t lead to a solution, probably our way is creation CoreMediaIOExtension but in such way we should find the way to setup camera interfaces as well.\n\u0026gt; \t:black_small_square:\tis it possible to get information about hardware button click in some other way?",
      "ts": "1666209679.405049",
      "thread_ts": "1666209679.405049",
      "attachments": [
        {
          "fallback": "GitHub: macOS: implement kernel driver detach by osy · Pull Request #911 · libusb/libusb",
          "id": 1,
          "title": "macOS: implement kernel driver detach by osy · Pull Request #911 · libusb/libusb",
          "title_link": "https://github.com/libusb/libusb/pull/911",
          "text": "It's a well known issue on macOS that you cannot use libusb to attach to an interface already claimed by an KEXT for exclusive access. The common workaround is to do sudo kextunload or inject a cod...",
          "image_url": "https://opengraph.githubassets.com/81d084a3edddf42f8536fcd6dd94eaf5719637f375aec52eb392e1ae4ac4e8a6/libusb/libusb/pull/911",
          "service_name": "GitHub",
          "service_icon": "https://a.slack-edge.com/80588/img/unfurl_icons/github.png",
          "from_url": "https://github.com/libusb/libusb/pull/911",
          "original_url": "https://github.com/libusb/libusb/pull/911",
          "blocks": null
        }
      ],
      "edited": {
        "user": "B0431LJ7G4D",
        "ts": "1666209680.000000"
      },
      "subtype": "bot_message",
      "bot_id": "B0431LJ7G4D",
      "username": "Ask Apple - photos-and-camera",
      "reply_count": 10,
      "latest_reply": "1666211508.475079",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "yRA",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046Y632KFY"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"We have an application that uses wired camera, captures it\\u2019s output and displays it on the screen. This camera has snapshot button which stopped working from macOS 12.3. We\\u2019ve researched this issue, found that camera has two interfaces, first is used for receiving interrupt signal from our camera (it is passed when the snapshot button is clicked) and second is used for video streaming. Before macOS version 12.3 snapshot functionality worked as expected, but not starting from this version. We found that inability to receive interrupt information from our camera is because we can\\u2019t open a connection to the first camera interface. When the camera is configured, it\\u2019s interfaces become connected with UVCAssistant objects which setup the interfaces and handle their work. UVCAssistant objects keep exclusive access to camera interfaces, so they don\\u2019t give us the ability to receive an interrupt signal.\\u00a0\\n\\u00a0\\nWe have created custom dext to match with IOUSBHostDevice object that represents camera and configured camera on our own to be able to open interfaces and keep exclusive access to them. But if we do configuring camera with valid configuration that specified in descriptor, system default UVCAssistant object matches interfaces and keeps exclusive access to them. We've created dext that matches interfaces instead of camera object, but we couldn't setup interfaces properly and camera was not recognised.\\u00a0\\u2028We have been looking for the different solution, tried the one described in \"},{\"type\":\"link\",\"url\":\"https:\\/\\/github.com\\/libusb\\/libusb\\/pull\\/911\",\"text\":\"https:\\/\\/github.com\\/libusb\\/libusb\\/pull\\/911\"},{\"type\":\"text\",\"text\":\"\\u00a0. We managed to make UVCAssistant objects become detached from camera interfaces and open interfaces via our application to listen to the interrupt events but the streaming has been broken. The application couldn't stream the video if UVCAssistant objects are not matched with camera interfaces.\\n\\u00a0\\nAlso we performed sniffing the traffic, tried to recreate commands passed by UVCAssistant objects to camera interfaces but our attempts failed, camera remained unrecognised.\\n\\u00a0\\nOur questions are:\\n\\t\"},{\"type\":\"emoji\",\"name\":\"black_small_square\",\"unicode\":\"25aa-fe0f\"},{\"type\":\"text\",\"text\":\"\\tis it possible to prevent UVCAssistant object from connecting with first camera interface and allow another UVCAssistant object to be connected with second camera interface, will it work for us, will the camera be recognised in such case? (As we researched it is impossible, USBDeviceReEnumerate with kUSBReEnumerateCaptureDeviceMask gives us the ability to detach all system objects from our camera and interfaces but not one of them)\\n\\t\"},{\"type\":\"emoji\",\"name\":\"black_small_square\",\"unicode\":\"25aa-fe0f\"},{\"type\":\"text\",\"text\":\"\\tif the first solution is impossible, please provide us the information how to setup camera interfaces so the camera will be recognised and be able to receive interrupt signals and do streaming (the preferable way is to setup camera interfaces using IOKit, from our application, if it\\u2019s impossible we can accept the dext solution)\\n\\t\"},{\"type\":\"emoji\",\"name\":\"black_small_square\",\"unicode\":\"25aa-fe0f\"},{\"type\":\"text\",\"text\":\"\\tif previous questions don\\u2019t lead to a solution, probably our way is creation CoreMediaIOExtension but in such way we should find the way to setup camera interfaces as well.\\n\\t\"},{\"type\":\"emoji\",\"name\":\"black_small_square\",\"unicode\":\"25aa-fe0f\"},{\"type\":\"text\",\"text\":\"\\tis it possible to get information about hardware button click in some other way?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "3b6718b1-be67-47c4-9948-7da87e989535",
          "type": "message",
          "user": "U0449MVNVJS",
          "text": "Hi \u003c@U046Y632KFY\u003e. Have you tried following the guidance at \u003chttps://developer.apple.com/documentation/coremediaio/overriding_the_default_usb_video_class_extension?changes=_7_2\u003e ?",
          "ts": "1666209724.122129",
          "thread_ts": "1666209679.405049",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "ARnJe",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi "
                    },
                    {
                      "type": "user",
                      "user_id": "U046Y632KFY"
                    },
                    {
                      "type": "text",
                      "text": ". Have you tried following the guidance at "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/coremediaio/overriding_the_default_usb_video_class_extension?changes=_7_2",
                      "text": ""
                    },
                    {
                      "type": "text",
                      "text": " ?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "f2177fb5-6a76-4187-9436-5cf3ce23a2d5",
          "type": "message",
          "user": "U046Y632KFY",
          "text": "Thank you for quick reply! Yes, we took a look at this topic. As we understood the CoreMediaIO solution is available for hardware based cameras only from macOS Ventura, am I right? If it is our way to solve the issue, could you please provide a bit more information, probably some samples.",
          "ts": "1666209964.950539",
          "thread_ts": "1666209679.405049",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "GHy",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thank you for quick reply! Yes, we took a look at this topic. As we understood the CoreMediaIO solution is available for hardware based cameras only from macOS Ventura, am I right? If it is our way to solve the issue, could you please provide a bit more information, probably some samples."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "783062c4-d11e-4420-9f3a-cdf603916a71",
          "type": "message",
          "user": "U0449MVNVJS",
          "text": "CoreMediaIO Extensions are available starting in macOS 12.3.",
          "ts": "1666210315.540529",
          "thread_ts": "1666209679.405049",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "G8nEl",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "CoreMediaIO Extensions are available starting in macOS 12.3."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "cf156fc0-730c-4ad1-b6b0-ccb29410a4b8",
          "type": "message",
          "user": "U046Y632KFY",
          "text": "So we can create CoreMediaIO extension for hardware based camera starting from macOS 12.3 that gives us the ability to replace standard UVCAssistant objects connected with camera interfaces. Ok, we'll follow this way. Thank you!",
          "ts": "1666210571.966759",
          "thread_ts": "1666209679.405049",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "oPhXC",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "So we can create CoreMediaIO extension for hardware based camera starting from macOS 12.3 that gives us the ability to replace standard UVCAssistant objects connected with camera interfaces. Ok, we'll follow this way. Thank you!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "8d5be8b7-ac8d-402b-b2a6-074d32f756ed",
          "type": "message",
          "user": "U046Y632KFY",
          "text": "One more question, do you have some guidance how we can set up the interfaces when we override default USB video class extension?",
          "ts": "1666210814.012069",
          "thread_ts": "1666209679.405049",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "CS1=",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "One more question, do you have some guidance how we can set up the interfaces when we override default USB video class extension?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "b48b8e76-9078-4a4f-b5ce-5cf372f2b5d8",
          "type": "message",
          "user": "U0449MVNVJS",
          "text": "Yep — please only override the devices with the special features you need to control. :+1:",
          "ts": "1666210846.613919",
          "thread_ts": "1666209679.405049",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "bqi",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Yep — please only override the devices with the special features you need to control. "
                    },
                    {
                      "type": "emoji",
                      "name": "thumbsup",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "3b62c0d3-8102-462f-9ee6-51b08025406a",
          "type": "message",
          "user": "U046Y632KFY",
          "text": "So we should only override the first interface of our camera which is the source of the interrupt event and don't touch the second interface that will be handled by default UVCAssistant object. Thank you!",
          "ts": "1666211042.716089",
          "thread_ts": "1666209679.405049",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "=rv",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "So we should only override the first interface of our camera which is the source of the interrupt event and don't touch the second interface that will be handled by default UVCAssistant object. Thank you!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "8759f47e-9539-4b71-b8a2-2f6c3280ca01",
          "type": "message",
          "user": "U0449MVNVJS",
          "text": "Re. \"the first interface\", are you referring to the control interface ?\nI'm not sure what first interface means here, maybe you could send us the USB descriptor and `ioreg -lwx0` dump ?",
          "ts": "1666211311.578419",
          "thread_ts": "1666209679.405049",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "88/X+",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Re. \"the first interface\", are you referring to the control interface ?\nI'm not sure what first interface means here, maybe you could send us the USB descriptor and "
                    },
                    {
                      "type": "text",
                      "text": "ioreg -lwx0",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " dump ?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "f9c0190f-86f1-4020-a479-6f9dccbd93b7",
          "type": "message",
          "user": "U046Y632KFY",
          "text": "Yes I mean control interface)",
          "ts": "1666211350.764549",
          "thread_ts": "1666209679.405049",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Vrwep",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Yes I mean control interface)"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "7bd934fe-f055-4cfd-98ea-0c0694eae9b1",
          "type": "message",
          "user": "U046Y632KFY",
          "ts": "1666211508.475079",
          "thread_ts": "1666209679.405049",
          "files": [
            {
              "id": "F046URC7SF9",
              "created": 1666211503,
              "timestamp": 1666211503,
              "name": "Screenshot 2022-08-30 at 13.01.44.png",
              "title": "Screenshot 2022-08-30 at 13.01.44.png",
              "mimetype": "image/png",
              "image_exif_rotation": 1,
              "filetype": "png",
              "pretty_type": "PNG",
              "user": "U046Y632KFY",
              "mode": "hosted",
              "editable": false,
              "is_external": false,
              "external_type": "",
              "size": 302186,
              "url": "",
              "url_download": "",
              "url_private": "C043CP508PK/F046URC7SF9-Screenshot 2022-08-30 at 13.01.44.png",
              "url_private_download": "C043CP508PK/F046URC7SF9-Screenshot 2022-08-30 at 13.01.44.png",
              "original_h": 763,
              "original_w": 1007,
              "thumb_64": "https://files.slack.com/files-tmb/T01PTBJ95PS-F046URC7SF9-fe5f64d281/screenshot_2022-08-30_at_13.01.44_64.png",
              "thumb_80": "https://files.slack.com/files-tmb/T01PTBJ95PS-F046URC7SF9-fe5f64d281/screenshot_2022-08-30_at_13.01.44_80.png",
              "thumb_160": "https://files.slack.com/files-tmb/T01PTBJ95PS-F046URC7SF9-fe5f64d281/screenshot_2022-08-30_at_13.01.44_160.png",
              "thumb_360": "https://files.slack.com/files-tmb/T01PTBJ95PS-F046URC7SF9-fe5f64d281/screenshot_2022-08-30_at_13.01.44_360.png",
              "thumb_360_gif": "",
              "thumb_360_w": 360,
              "thumb_360_h": 273,
              "thumb_480": "https://files.slack.com/files-tmb/T01PTBJ95PS-F046URC7SF9-fe5f64d281/screenshot_2022-08-30_at_13.01.44_480.png",
              "thumb_480_w": 480,
              "thumb_480_h": 364,
              "thumb_720": "https://files.slack.com/files-tmb/T01PTBJ95PS-F046URC7SF9-fe5f64d281/screenshot_2022-08-30_at_13.01.44_720.png",
              "thumb_720_w": 720,
              "thumb_720_h": 546,
              "thumb_960": "https://files.slack.com/files-tmb/T01PTBJ95PS-F046URC7SF9-fe5f64d281/screenshot_2022-08-30_at_13.01.44_960.png",
              "thumb_960_w": 960,
              "thumb_960_h": 727,
              "thumb_1024": "",
              "thumb_1024_w": 0,
              "thumb_1024_h": 0,
              "permalink": "https://appleevents.enterprise.slack.com/files/U046Y632KFY/F046URC7SF9/screenshot_2022-08-30_at_13.01.44.png",
              "permalink_public": "https://slack-files.com/T01PTBJ95PS-F046URC7SF9-04bb5f22bd",
              "edit_link": "",
              "preview": "",
              "preview_highlight": "",
              "lines": 0,
              "lines_more": 0,
              "is_public": false,
              "public_url_shared": false,
              "channels": null,
              "groups": null,
              "ims": null,
              "initial_comment": {},
              "comments_count": 0,
              "num_stars": 0,
              "is_starred": false,
              "shares": {
                "public": null,
                "private": null
              }
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": null
        }
      ]
    },
    {
      "client_msg_id": "dddbb1b1-5558-441c-b21c-52a0f5e4b261",
      "type": "message",
      "user": "U0455QUCD9N",
      "text": "\u003c!here\u003e\n*Keep the questions coming!*\nThere's been a whole lot of questions coming. So many in fact that we got an early jump on answering them. We've got a full team of Engineers live in the channel for the next 40 minutes (until 2 PM Cupertino Time). Get your questions in using the :heavy_plus_sign: below and we'll do our best to get to them all. Please understand that even if we don't get to your question or have an opportunity to respond to feature suggestions, we greatly appreciate all of your feedback.",
      "ts": "1666210965.924399",
      "team": "T03U5MWB2FN",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "pLm",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "broadcast",
                  "range": "here"
                },
                {
                  "type": "text",
                  "text": "\n"
                },
                {
                  "type": "text",
                  "text": "Keep the questions coming!",
                  "style": {
                    "bold": true
                  }
                },
                {
                  "type": "text",
                  "text": "\nThere's been a whole lot of questions coming. So many in fact that we got an early jump on answering them. We've got a full team of Engineers live in the channel for the next 40 minutes (until 2 PM Cupertino Time). Get your questions in using the "
                },
                {
                  "type": "emoji",
                  "name": "heavy_plus_sign",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": " below and we'll do our best to get to them all. Please understand that even if we don't get to your question or have an opportunity to respond to feature suggestions, we greatly appreciate all of your feedback."
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U045WN67YKY\u003e asked\n\u0026gt; I capture video to an AVFragmentedAsset on a shared directory on the local disk (on macOS). When I open this asset from an iOS app, I don't get any AVAssetDurationDidChangeNotification. This used to work on previous versions of macOS and iOS. Has anything changed in relation to this functionality?",
      "ts": "1666211524.254509",
      "thread_ts": "1666211524.254509",
      "subtype": "bot_message",
      "bot_id": "B0431LJ7G4D",
      "username": "Ask Apple - photos-and-camera",
      "reply_count": 2,
      "latest_reply": "1666215519.611469",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "Ojr",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U045WN67YKY"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"I capture video to an AVFragmentedAsset on a shared directory on the local disk (on macOS). When I open this asset from an iOS app, I don't get any AVAssetDurationDidChangeNotification. This used to work on previous versions of macOS and iOS. Has anything changed in relation to this functionality?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "8e4d1c4c-5277-4e99-9d8b-09186a31872c",
          "type": "message",
          "user": "U0449MVNVJS",
          "text": "A bug report via FeedbackAssistant is probably warranted.\nThe most common cause of problems like that is that the value of the AVAsset's duration property hasn't been explicitly loaded. There are no change notifications until after that happens.",
          "ts": "1666211587.657959",
          "thread_ts": "1666211524.254509",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "pjozi",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "A bug report via FeedbackAssistant is probably warranted.\nThe most common cause of problems like that is that the value of the AVAsset's duration property hasn't been explicitly loaded. There are no change notifications until after that happens."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "a7594ce1-8f06-4897-b84f-43fa3a0d62c1",
          "type": "message",
          "user": "U045WN67YKY",
          "text": "Thanks for answering, I knew that. I create the AVFragmentedAssetMinder after the duration and containsFragments keys are loaded for the asset and after that I add the notification observer. I do the same on the capturing app on macOS and it works, but for the remote reader on iOS it does not. That is what confuses me.",
          "ts": "1666215519.611469",
          "thread_ts": "1666211524.254509",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "+rP",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks for answering, I knew that. I create the AVFragmentedAssetMinder after the duration and containsFragments keys are loaded for the asset and after that I add the notification observer. I do the same on the capturing app on macOS and it works, but for the remote reader on iOS it does not. That is what confuses me."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U047YV93L3S\u003e asked\n\u0026gt; We develop video analysis software products including our flagship GammaPix technology to detect ionizing radioactivity using smartphone and other cameras. Our customers include public safety, environmental protection, citizen science and education users who leverage this capability for various purposes. 99% of our 120,000 users are on Android because we're able to make repeated, unattended measurements in the background to keep people safe.\n\u0026gt; \n\u0026gt; Many of the agencies we're in contact with are using iOS devices. This  includes our New York City Police Department customer, who recently switched from Android to iOS, and no longer have the monitoring capability. Our users would benefit by our app having the ability to access the camera in the background from time to time to acquire short pieces of video. The video is only useful to use when the lens is covered, and aborts immediately otherwise. All data is disposed of immediately after our proprietary image processing and analysis is complete.\n\u0026gt; \n\u0026gt; We understand and respect the constraints that Apple places on camera access to protect user's privacy. Our use cases lie with various public safety organizations that have enterprise distribution channels. Are there any mechanisms that we could use within an enterprise distribution environment that would enable background camera access for our customers?",
      "ts": "1666212186.695629",
      "thread_ts": "1666212186.695629",
      "subtype": "bot_message",
      "bot_id": "B0431LJ7G4D",
      "username": "Ask Apple - photos-and-camera",
      "reply_count": 5,
      "latest_reply": "1666212726.260059",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "1CfZX",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U047YV93L3S"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"We develop video analysis software products including our flagship GammaPix technology to detect ionizing radioactivity using smartphone and other cameras. Our customers include public safety, environmental protection, citizen science and education users who leverage this capability for various purposes. 99% of our 120,000 users are on Android because we're able to make repeated, unattended measurements in the background to keep people safe.\\n\\nMany of the agencies we're in contact with are using iOS devices. This  includes our New York City Police Department customer, who recently switched from Android to iOS, and no longer have the monitoring capability. Our users would benefit by our app having the ability to access the camera in the background from time to time to acquire short pieces of video. The video is only useful to use when the lens is covered, and aborts immediately otherwise. All data is disposed of immediately after our proprietary image processing and analysis is complete.\\n\\nWe understand and respect the constraints that Apple places on camera access to protect user's privacy. Our use cases lie with various public safety organizations that have enterprise distribution channels. Are there any mechanisms that we could use within an enterprise distribution environment that would enable background camera access for our customers?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "fea035b0-bb34-456c-bc42-645b209d5f68",
          "type": "message",
          "user": "U0449MVNVJS",
          "text": "Hi \u003c@U047YV93L3S\u003e, can you clarify your statement about \"the video is only useful to use when the lens is covered\"? How do you capture video if the lens is covered?",
          "ts": "1666212230.865779",
          "thread_ts": "1666212186.695629",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Sn1",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi "
                    },
                    {
                      "type": "user",
                      "user_id": "U047YV93L3S"
                    },
                    {
                      "type": "text",
                      "text": ", can you clarify your statement about \"the video is only useful to use when the lens is covered\"? How do you capture video if the lens is covered?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "a68dc0ab-3402-42b3-9f76-6986fa759535",
          "type": "message",
          "user": "U047YV93L3S",
          "text": "Hi Brad. The way our application works is that when radiation hits the camera sensor, then it sometimes leaves behind a bright spot. This is more detectable if the image is otherwise dark. So what we're interested in is black video, like when the camera is covered, so we can look for the spots.",
          "ts": "1666212343.768279",
          "thread_ts": "1666212186.695629",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "gfC=7",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi Brad. The way our application works is that when radiation hits the camera sensor, then it sometimes leaves behind a bright spot. This is more detectable if the image is otherwise dark. So what we're interested in is black video, like when the camera is covered, so we can look for the spots."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "07b59b9e-f5e4-46b6-ab02-369966b96468",
          "type": "message",
          "user": "U047YV93L3S",
          "text": "For us, anything else is in the image is bothersome noise, not signal.",
          "ts": "1666212417.151319",
          "thread_ts": "1666212186.695629",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "IlEb",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "For us, anything else is in the image is bothersome noise, not signal."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "5dc0ec83-4746-4c12-bdfc-240dccb54076",
          "type": "message",
          "user": "U0449MVNVJS",
          "text": "Gotcha. And this measurement can't be taken from an app? So the user is aware of what's going on?",
          "ts": "1666212553.358439",
          "thread_ts": "1666212186.695629",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "V0Bnw",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Gotcha. And this measurement can't be taken from an app? So the user is aware of what's going on?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "ce347286-05bf-4163-ac50-155ec4b5389c",
          "type": "message",
          "user": "U047YV93L3S",
          "text": "It can, and is, being taken from the app in the current version, but that requires the user's intervention to take the reading. What our Android users appreciate is that when the device is otherwise not in use, a reading can be taken automatically, and the user alerted if radiation is detected.",
          "ts": "1666212726.260059",
          "thread_ts": "1666212186.695629",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "wu6v",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "It can, and is, being taken from the app in the current version, but that requires the user's intervention to take the reading. What our Android users appreciate is that when the device is otherwise not in use, a reading can be taken automatically, and the user alerted if radiation is detected."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U046H3RMJK0\u003e asked\n\u0026gt; This question relates to the Photo Library on OSX. The app deals with HEIC files, that the user creates and saves, and then later the user can open, modify, and save the HEIC file again.  The process is fairly conventional if the HEIC file resides on the OSX file system.  My question is whether a parallel process can be used where the HEIC file effectively resides in the OSX Photo Library.\n\u0026gt; \n\u0026gt; Right now the app uses the following code to both create and re-write the HEIC file (aka Photo Library asset) in the Photo Library.\n\u0026gt; \n\u0026gt;   do\n\u0026gt;     {\n\u0026gt;       try PHPhotoLibrary.shared().performChangesAndWait({\n\u0026gt;         let request = PHAssetCreationRequest.forAsset()\n\u0026gt;         let options = PHAssetResourceCreationOptions()\n\u0026gt;         options.shouldMoveFile = true\n\u0026gt;         request.addResource(with: .photo, fileURL: fileUrl, options: options)\n\u0026gt;         localIdentifier = request.placeholderForCreatedAsset?.localIdentifier\n\u0026gt;         })\n\u0026gt;       }\n\u0026gt;       catch  { localIdentifier = nil }\n\u0026gt; \n\u0026gt; And to read the HEIC file the app uses the local identifier / cloud identifier.\n\u0026gt; \n\u0026gt; More specifically, my question is whether what the app is trying to do is sensible (and reliable), plus if so, if the above code is the recommended method.  Assuming the above code is on the right track, the one item that is fuzzy to me is writing the file uses the HEIC file name, while the reading uses the local identifier.  So when re-writing, does specifying the same HEIC file URL as the creation truly cause the original HEIC file to be replaced in the Photo library.  Or should the HEIC file first be deleted using the local identifier, and then created completely new.  Note that I am interested in creating and recovering XMP metadata, which is why the HEIC file is nice for the app.",
      "ts": "1666289677.326919",
      "thread_ts": "1666289677.326919",
      "subtype": "bot_message",
      "bot_id": "B0431LJ7G4D",
      "username": "Ask Apple - photos-and-camera",
      "reply_count": 3,
      "latest_reply": "1666298666.986789",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "LY+hS",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U046H3RMJK0"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"This question relates to the Photo Library on OSX. The app deals with HEIC files, that the user creates and saves, and then later the user can open, modify, and save the HEIC file again.  The process is fairly conventional if the HEIC file resides on the OSX file system.  My question is whether a parallel process can be used where the HEIC file effectively resides in the OSX Photo Library.\\n\\nRight now the app uses the following code to both create and re-write the HEIC file (aka Photo Library asset) in the Photo Library.\\n\\n  do\\n    {\\n      try PHPhotoLibrary.shared().performChangesAndWait({\\n        let request = PHAssetCreationRequest.forAsset()\\n        let options = PHAssetResourceCreationOptions()\\n        options.shouldMoveFile = true\\n        request.addResource(with: .photo, fileURL: fileUrl, options: options)\\n        localIdentifier = request.placeholderForCreatedAsset?.localIdentifier\\n        })\\n      }\\n      catch  { localIdentifier = nil }\\n\\nAnd to read the HEIC file the app uses the local identifier \\/ cloud identifier.\\n\\nMore specifically, my question is whether what the app is trying to do is sensible (and reliable), plus if so, if the above code is the recommended method.  Assuming the above code is on the right track, the one item that is fuzzy to me is writing the file uses the HEIC file name, while the reading uses the local identifier.  So when re-writing, does specifying the same HEIC file URL as the creation truly cause the original HEIC file to be replaced in the Photo library.  Or should the HEIC file first be deleted using the local identifier, and then created completely new.  Note that I am interested in creating and recovering XMP metadata, which is why the HEIC file is nice for the app.\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "2c6741b0-a084-46af-9255-49de5e3f1070",
          "type": "message",
          "user": "U0449MFKRGE",
          "text": "If I understand correctly, you’re asking about replacing an existing assets resources with one that’s been turned into a HEIC? That is not supported. You cannot replace the original resources of an asset that exist in the library. If you want to do something like this you’ll need to create a new asset and add resources to that asset.",
          "ts": "1666289743.114499",
          "thread_ts": "1666289677.326919",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "H4dX",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "If I understand correctly, you’re asking about replacing an existing assets resources with one that’s been turned into a HEIC? That is not supported. You cannot replace the original resources of an asset that exist in the library. If you want to do something like this you’ll need to create a new asset and add resources to that asset."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "7593e1bd-e825-47be-bc20-97fb8bcef9e1",
          "type": "message",
          "user": "U046H3RMJK0",
          "text": "Thanks.  Maybe to make sure.  For the case of the file system, I read the image (with custom metadata) file, modify it, and then write the file, with the read and write using the same file name.  However, in the case of the photo library, I read the asset (image with metadata), modify it, delete the original asset, and then create a new asset.  Basically the photo library does not quite have ease of modification that a file system file has.",
          "ts": "1666291377.529489",
          "thread_ts": "1666289677.326919",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "dBe",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks.  Maybe to make sure.  For the case of the file system, I read the image (with custom metadata) file, modify it, and then write the file, with the read and write using the same file name.  However, in the case of the photo library, I read the asset (image with metadata), modify it, delete the original asset, and then create a new asset.  Basically the photo library does not quite have ease of modification that a file system file has."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "d6b5c097-7e12-42fd-bbfa-e46a81190b7b",
          "type": "message",
          "user": "U0449MFKRGE",
          "text": "correct, the modification is a different model to ensure user data integrity",
          "ts": "1666298666.986789",
          "thread_ts": "1666289677.326919",
          "team": "T03U5MWB2FN",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "R18",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "correct, the modification is a different model to ensure user data integrity"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    }
  ],
  "channel_id": "C043CP508PK"
}
