{
  "name": "photos-camera-lounge",
  "messages": [
    {
      "type": "message",
      "user": "U03EBH4MA8Y",
      "text": "This content can't be displayed.",
      "ts": "1654551212.866369",
      "team": "T031SG5MZ7U",
      "reactions": [
        {
          "name": "heart",
          "count": 11,
          "users": [
            "U03JB85MK35",
            "U03J22ZNK34",
            "U03JKNC8XK6",
            "U03JBLJLAM8",
            "U03JYF8GT7A",
            "U03JELDBMT3",
            "U03JELVMV7T",
            "U03J24JKNCW",
            "U03JE7D37QU",
            "U03K8L1DCSU",
            "U03J8B88VE1"
          ]
        },
        {
          "name": "wave",
          "count": 8,
          "users": [
            "U03J5ML5CQL",
            "U03JKNC8XK6",
            "U03JYF8GT7A",
            "U03J24JKNCW",
            "U03J8B88VE1",
            "U03KBCLJVR6",
            "U03HMD2QTRD",
            "U03JG9JF529"
          ]
        },
        {
          "name": "thumbsup_all",
          "count": 4,
          "users": [
            "U03JKNC8XK6",
            "U03J21D4DC2",
            "U03J24JKNCW",
            "U03J8B88VE1"
          ]
        },
        {
          "name": "swift-orange",
          "count": 5,
          "users": [
            "U03JKNC8XK6",
            "U03J24JKNCW",
            "U03J1UB5G8K",
            "U03J8B88VE1",
            "U03JYGNH21W"
          ]
        },
        {
          "name": "camera",
          "count": 4,
          "users": [
            "U03JELVMV7T",
            "U03J24JKNCW",
            "U03J8B88VE1",
            "U03HQNTQK33"
          ]
        },
        {
          "name": "flag-pt",
          "count": 2,
          "users": [
            "U03J8B88VE1",
            "U03HVDF8N6A"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "header",
          "text": {
            "type": "plain_text",
            "text": "Welcome to the Photos \u0026amp; Camera Digital Lounge!",
            "emoji": true
          },
          "block_id": "mEYL"
        },
        {
          "type": "image",
          "image_url": "https://devimages-cdn.apple.com/wwdc-services/images/wwdc22/slack/Photos%20%26%20Camera%20-%20regular%20hero%403x.png",
          "alt_text": "A multi-colored outline of a camera on a black background ",
          "block_id": "XVl1c"
        },
        {
          "type": "section",
          "text": {
            "type": "mrkdwn",
            "text": "Welcome to the WWDC22 Photos \u0026amp; Camera Digital Lounge! We’ve got an exciting week planned for you. You can find the full schedule of events in the \u003chttps://developer.apple.com/news/?id=6iaddtl6| Apple Developer app and on developer.apple.com\u003e, and activities for all lounges kick off on June 7."
          },
          "block_id": "wlK6i"
        },
        {
          "type": "section",
          "text": {
            "type": "mrkdwn",
            "text": "If you haven't already, please take a moment to familiarize yourself with \u003chttps://developer.apple.com/news/?id=735utu4s|how the Digital Lounges will work\u003e."
          },
          "block_id": "U1svi"
        },
        {
          "type": "header",
          "text": {
            "type": "plain_text",
            "text": "WWDC22 Interactive Events Policy",
            "emoji": true
          },
          "block_id": "Ylwo"
        },
        {
          "type": "section",
          "text": {
            "type": "mrkdwn",
            "text": "We want to make sure these spaces are helpful and welcoming for everyone — developers and Apple employees alike. Please review and follow the \u003chttps://developer.apple.com/wwdc22/policies/interactive-events/1/Apple-Developer-WWDC22-Interactive-Events-Attendance-Policy.pdf| WWDC22 Interactive Events Policy\u003e."
          },
          "block_id": "EnrmG"
        },
        {
          "type": "section",
          "text": {
            "type": "mrkdwn",
            "text": "Have a great WWDC!"
          },
          "block_id": "QYXqp"
        }
      ]
    },
    {
      "client_msg_id": "c0691ca8-8bd0-4577-b132-fd7f05d5a7c4",
      "type": "message",
      "user": "U03DJTBMHFF",
      "text": "\u003c!here\u003e *Join us in 30 minutes* for _Q\u0026amp;A: Camera capture_\nHi, all! We have assembled a great team of engineers from the Camera Capture team to answer your questions and engage in lively discussion regarding all things related to camera usage in your apps. Don't hesitate to submit your questions via the workflow whether they are related to existing APIs or the new camera features announced yesterday. See you soon!",
      "ts": "1654619534.868169",
      "team": "T031SG5MZ7U",
      "reactions": [
        {
          "name": "partying_face",
          "count": 8,
          "users": [
            "U03JRP87THN",
            "U03JBLJLAM8",
            "U03JYHSL6AD",
            "U03HVCK66P8",
            "U03HZS2A4P7",
            "U03HTHW18UX",
            "U03JBMMB10A",
            "U03JE7H2DM4"
          ]
        },
        {
          "name": "raised_hands",
          "count": 2,
          "users": [
            "U03HVCK66P8",
            "U03HTHW18UX"
          ]
        },
        {
          "name": "wave",
          "count": 1,
          "users": [
            "U03HZ55TA69"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "lbk",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "broadcast",
                  "range": "here"
                },
                {
                  "type": "text",
                  "text": " "
                },
                {
                  "type": "text",
                  "text": "Join us in 30 minutes ",
                  "style": {
                    "bold": true
                  }
                },
                {
                  "type": "text",
                  "text": "for "
                },
                {
                  "type": "text",
                  "text": "Q\u0026A: Camera capture",
                  "style": {
                    "italic": true
                  }
                },
                {
                  "type": "text",
                  "text": "\nHi, all! We have assembled a great team of engineers from the Camera Capture team to answer your questions and engage in lively discussion regarding all things related to camera usage in your apps. Don't hesitate to submit your questions via the workflow whether they are related to existing APIs or the new camera features announced yesterday. See you soon!"
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "d329205b-8c35-4118-a391-3b13daa13918",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": "Developers, developers, developers,\nWelcome all to *Q\u0026amp;A: Camera Capture*, our first of two camera-focused Q\u0026amp;A sessions! I'm Brad from the Camera Software Engineering team. We’ll get started promptly at 10 AM PDT. Hit us with your toughest camera questions. We can take it. (Easy questions are good too.) :smile:\nHere’s how to ask: Select the:heavy_plus_sign:icon from the lower left, and find the _Ask A Question_ workflow. Type in your question and it will be delivered directly to the team. We’ll answer as many questions as we can. While it’s unlikely we’ll be able to address every question, we’ll do our best. Thanks in advance for all your submissions. They’re all valuable! Feedback too! We love to hear what’s working (or not) for you.  :rocket:",
      "ts": "1654620505.975969",
      "team": "T031SG5MZ7U",
      "reactions": [
        {
          "name": "partying_face",
          "count": 2,
          "users": [
            "U03JRP87THN",
            "U03K8L1DCSU"
          ]
        },
        {
          "name": "wave",
          "count": 2,
          "users": [
            "U03HZ55TA69",
            "U03J4DJHVL3"
          ]
        },
        {
          "name": "face_with_rolling_eyes",
          "count": 1,
          "users": [
            "U03J1UHET0B"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "8vVLp",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Developers, developers, developers,\nWelcome all to "
                },
                {
                  "type": "text",
                  "text": "Q\u0026A: Camera Capture",
                  "style": {
                    "bold": true
                  }
                },
                {
                  "type": "text",
                  "text": ", our first of two camera-focused Q\u0026A sessions! I'm Brad from the Camera Software Engineering team. We’ll get started promptly at 10 AM PDT. Hit us with your toughest camera questions. We can take it. (Easy questions are good too.) "
                },
                {
                  "type": "emoji",
                  "name": "smile",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": "\nHere’s how to ask: Select the"
                },
                {
                  "type": "emoji",
                  "name": "heavy_plus_sign",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": "icon from the lower left, and find the "
                },
                {
                  "type": "text",
                  "text": "Ask A Question",
                  "style": {
                    "italic": true
                  }
                },
                {
                  "type": "text",
                  "text": " workflow. Type in your question and it will be delivered directly to the team. We’ll answer as many questions as we can. While it’s unlikely we’ll be able to address every question, we’ll do our best. Thanks in advance for all your submissions. They’re all valuable! Feedback too! We love to hear what’s working (or not) for you.  "
                },
                {
                  "type": "emoji",
                  "name": "rocket",
                  "skin_tone": 0
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "2baf6d95-a960-41e2-a2a6-f7a778b813f9",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": "All righty, let’s kick it off! 🪩",
      "ts": "1654621220.691489",
      "thread_ts": "1654621220.691489",
      "reply_count": 1,
      "latest_reply": "1654621597.922939",
      "team": "T031SG5MZ7U",
      "reactions": [
        {
          "name": "soccer",
          "count": 1,
          "users": [
            "U03HMD6DW15"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "VYScW",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "All righty, let’s kick it off! 🪩"
                }
              ]
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "198ae4ee-a502-42f9-84be-0ae1b9e6792d",
          "type": "message",
          "user": "U03JG9JF529",
          "text": "I can’t see the workflows for this channel like other WWDC channels",
          "ts": "1654621597.922939",
          "thread_ts": "1654621220.691489",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "EHfe2",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I can’t see the workflows for this channel like other WWDC channels"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "366ba816-3153-4fd2-9788-686bd10bb77f",
      "type": "message",
      "user": "U03DJTBMHFF",
      "text": "*Thanks for your patience.* Sorry for the delay in getting Q\u0026amp;A rolling. We are activating the workflow. We'll be up and running shortly.",
      "ts": "1654621604.696149",
      "team": "T031SG5MZ7U",
      "reactions": [
        {
          "name": "raised_hands",
          "count": 2,
          "users": [
            "U03JRP87THN",
            "U03JG9JF529"
          ]
        },
        {
          "name": "+1",
          "count": 1,
          "users": [
            "U03JBMMB10A"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "1WE",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Thanks for your patience. ",
                  "style": {
                    "bold": true
                  }
                },
                {
                  "type": "text",
                  "text": "Sorry for the delay in getting Q\u0026A rolling. We are activating the workflow. We'll be up and running shortly."
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "41d8c565-df25-4e70-9842-80c46a38c60a",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": "We're rolling now. Feel free to submit your questions.",
      "ts": "1654621832.604159",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "ajzp",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "We're rolling now. Feel free to submit your questions."
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03JBMMB10A\u003e asked\n\u0026gt; Hello,\n\u0026gt; \n\u0026gt; I pretty new at video in general and I was wondering where to get started with video processing, specifically how do I rewrite multiple videos next to each other for side by side 3D?\n\u0026gt; \n\u0026gt; Thank you!",
      "ts": "1654621939.733119",
      "thread_ts": "1654621939.733119",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 7,
      "latest_reply": "1654623635.230569",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "ROwh",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03JBMMB10A"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Hello,\\n\\nI pretty new at video in general and I was wondering where to get started with video processing, specifically how do I rewrite multiple videos next to each other for side by side 3D?\\n\\nThank you!\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "15929c55-e74e-4eaf-900b-c10e72eb4ddc",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Would you like to record a video with two video tracks? Composite two together? Blend two together? Producing a stereo effect? Give us a little more info.",
          "ts": "1654621971.072449",
          "thread_ts": "1654621939.733119",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "UcL",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Would you like to record a video with two video tracks? Composite two together? Blend two together? Producing a stereo effect? Give us a little more info."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "0b6b9eba-09ca-4d8b-bfb5-d2772581f108",
          "type": "message",
          "user": "U03JBMMB10A",
          "text": "I’d like to take already recoded videos (left and right) and position them side by side not overlapping, like in a VR headset.",
          "ts": "1654622104.298239",
          "thread_ts": "1654621939.733119",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "v=W",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I’d like to take already recoded videos (left and right) and position them side by side not overlapping, like in a VR headset."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "5575c6e2-19c0-490c-a732-0736f25c96a3",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "AVMutableComposition should do the trick. You can use that to composite two movies together and write a new one. It would have an extra wide video track.",
          "ts": "1654622256.297739",
          "thread_ts": "1654621939.733119",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "iRI3m",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "AVMutableComposition should do the trick. You can use that to composite two movies together and write a new one. It would have an extra wide video track."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "5b1f10a2-6275-4977-a1a8-0106ea15c6e9",
          "type": "message",
          "user": "U03JBMMB10A",
          "text": "Great, thank you!",
          "ts": "1654622401.113239",
          "thread_ts": "1654621939.733119",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "oeX1",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Great, thank you!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "719a3401-9bff-4d41-95a1-78a05d4dc3c0",
          "type": "message",
          "user": "U03J5SJL6MT",
          "text": "Just to piggyback on \u003c@U03JBMMB10A\u003e question, What are the examples out there of doing composition with multiple video tracks,  I know a little about layer instructions, but is there any examples of using the frames directly?",
          "ts": "1654622571.266629",
          "thread_ts": "1654621939.733119",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "YFE+d",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Just to piggyback on "
                    },
                    {
                      "type": "user",
                      "user_id": "U03JBMMB10A"
                    },
                    {
                      "type": "text",
                      "text": " question, What are the examples out there of doing composition with multiple video tracks,  I know a little about layer instructions, but is there any examples of using the frames directly?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "4ebb781c-5e76-41f4-b8b3-986856396f4f",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Have you checked out AVMulticamPiP? \u003chttps://developer.apple.com/documentation/avfoundation/capture_setup/avmulticampip_capturing_from_multiple_cameras\u003e",
          "ts": "1654623625.923289",
          "thread_ts": "1654621939.733119",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "G5F",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Have you checked out AVMulticamPiP? "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/avfoundation/capture_setup/avmulticampip_capturing_from_multiple_cameras",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "7b640ab9-56b4-4ba9-9714-864da17bb99d",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "This composites front and rear camera into a single video track.",
          "ts": "1654623635.230569",
          "thread_ts": "1654621939.733119",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "O6zF",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "This composites front and rear camera into a single video track."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03HZ5T63N1\u003e asked\n\u0026gt; Can there be more than one iPhone connected via Continuity Camera?",
      "ts": "1654621985.302269",
      "thread_ts": "1654621985.302269",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 6,
      "latest_reply": "1654622431.559539",
      "reactions": [
        {
          "name": "eyes",
          "count": 1,
          "users": [
            "U03JJL10VHP"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "gn0B8",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03HZ5T63N1"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Can there be more than one iPhone connected via Continuity Camera?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "c0edbc2f-84f5-4b3b-9276-32719b2f516d",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Only one active stream at a time, but multiple iPhones can be discovered. So you can switch between them, but only one can be streaming actively at a time.",
          "ts": "1654622019.844339",
          "thread_ts": "1654621985.302269",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "39x",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Only one active stream at a time, but multiple iPhones can be discovered. So you can switch between them, but only one can be streaming actively at a time."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "73b6c747-0b01-4df3-bdee-f7356bd47118",
          "type": "message",
          "user": "U03HZ5T63N1",
          "text": "I would like to add this as a feature request.",
          "ts": "1654622058.641859",
          "thread_ts": "1654621985.302269",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "dAz",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I would like to add this as a feature request."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "ab64e9fd-f295-4b90-af43-401bf471b9ca",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "We have limited bandwidth over WiFi. 1080p video ain't cheap. :slightly_smiling_face:",
          "ts": "1654622286.330009",
          "thread_ts": "1654621985.302269",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "/y=2",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "We have limited bandwidth over WiFi. 1080p video ain't cheap. "
                    },
                    {
                      "type": "emoji",
                      "name": "slightly_smiling_face",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "084fc01a-d7cc-4b87-bc0a-c5711c2720db",
          "type": "message",
          "user": "U03K50PT6L8",
          "text": "Will it utilize usb if plugged in?",
          "ts": "1654622396.109349",
          "thread_ts": "1654621985.302269",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "eFw",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Will it utilize usb if plugged in?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "79cc22d9-eed0-46a9-a8d5-c790f90698b9",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Yes it will.",
          "ts": "1654622415.888799",
          "thread_ts": "1654621985.302269",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "raised_hands",
              "count": 1,
              "users": [
                "U03K50PT6L8"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "bWz",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Yes it will."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "93c7f993-dc20-41b6-8925-672b431da599",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "USB has bandwidth constraints too. :slightly_smiling_face:",
          "ts": "1654622431.559539",
          "thread_ts": "1654621985.302269",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "white_check_mark",
              "count": 1,
              "users": [
                "U03K50PT6L8"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "drTt5",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "USB has bandwidth constraints too. "
                    },
                    {
                      "type": "emoji",
                      "name": "slightly_smiling_face",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03J1TZUPC3\u003e asked\n\u0026gt; Hi Brad, I have a dumb question. I still use UIKit for using the camera with AVFoundation. Did I miss it that you can make a camera app in SwiftUI?",
      "ts": "1654622083.934639",
      "thread_ts": "1654622083.934639",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 15,
      "latest_reply": "1654630911.450339",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "E0NwG",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03J1TZUPC3"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Hi Brad, I have a dumb question. I still use UIKit for using the camera with AVFoundation. Did I miss it that you can make a camera app in SwiftUI?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "50bfc533-a2e2-4668-b35d-158e37b2cff4",
          "type": "message",
          "user": "U03HHA1D44F",
          "text": "Yes, you can use SwiftUI with AVFoundation. See this sample app we just released for Continuity Camera that shows this:\n\n\u003chttps://developer.apple.com/documentation/avfoundation/capture_setup/supporting_continuity_camera_in_your_macos_app?language=objc\u003e",
          "ts": "1654622338.925039",
          "thread_ts": "1654622083.934639",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "66jH",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Yes, you can use SwiftUI with AVFoundation. See this sample app we just released for Continuity Camera that shows this:\n\n"
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/avfoundation/capture_setup/supporting_continuity_camera_in_your_macos_app?language=objc",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "359778be-8147-415d-9a4b-203b67d65fe7",
          "type": "message",
          "user": "U03J1TZUPC3",
          "text": "Thanks. So, this is new this year?",
          "ts": "1654622432.770979",
          "thread_ts": "1654622083.934639",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "FUWg",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks. So, this is new this year?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "07b44153-2ab4-4607-adb0-bf8f19ab41d7",
          "type": "message",
          "user": "U03HHA1D44F",
          "text": "You have been able to use SwiftUI with AVFoundation since SwiftUI's introduction. But this is our first sample released showing SwiftUI with AVFoundation",
          "ts": "1654622516.732839",
          "thread_ts": "1654622083.934639",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "8yB",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "You have been able to use SwiftUI with AVFoundation since SwiftUI's introduction. But this is our first sample released showing SwiftUI with AVFoundation"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "6df41295-fa1c-4210-8bb3-b0c80044c979",
          "type": "message",
          "user": "U03HHA1D44F",
          "text": "By using `UIViewRepresentable`, you can use an `AVCaptureVideoPreviewLayer` in SwiftUI",
          "ts": "1654622557.602049",
          "thread_ts": "1654622083.934639",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "7nju",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "By using "
                    },
                    {
                      "type": "text",
                      "text": "UIViewRepresentable",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": ", you can use an "
                    },
                    {
                      "type": "text",
                      "text": "AVCaptureVideoPreviewLayer",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " in SwiftUI"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "d8f61c26-c481-4e22-8aec-15628b256638",
          "type": "message",
          "user": "U03HHA1D44F",
          "text": "The sample app shows this",
          "ts": "1654622561.783559",
          "thread_ts": "1654622083.934639",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "7HF",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "The sample app shows this"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "4425c783-b948-4cb1-8a9d-fec911f04ed3",
          "type": "message",
          "user": "U03J1TZUPC3",
          "text": "But that is not native SwiftUI, is it? That is creating a UIView in SwitftUI. I do that for MapKit as well.",
          "ts": "1654623088.951469",
          "thread_ts": "1654622083.934639",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "+bc",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "But that is not native SwiftUI, is it? That is creating a UIView in SwitftUI. I do that for MapKit as well."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "f087f90d-1681-40fc-8caf-4bb89be0192c",
          "type": "message",
          "user": "U03J1TZUPC3",
          "text": "Actually, a UIView Layer",
          "ts": "1654623454.982649",
          "thread_ts": "1654622083.934639",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "fkt3A",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Actually, a UIView Layer"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "39bb1671-3c5b-4ab6-baa5-94a0d8aa399c",
          "type": "message",
          "user": "U03JDTS6RKP",
          "text": "Hi Paul, just chiming in cause I had a heck of a time figuring this out, but totally doable going back to first SwiftUI release (although I require iOS 14+ for my app because of an issue encountered in 13 related to this, can't remember what it was though *Edit: I think it was related to viewfinder not stretching to bounds properly*).\n\nHave yet to look at the sample mentioned above, but solution is probably similar. At a high level you have your normal CameraViewController. You then create a UIViewControllerRepresentable, lets call it CameraVCSwiftUIView, with a CameraViewController as a member. This CameraVCSwiftUIView is now usable in SwiftUI as your CameraViewController / video preview :slightly_smiling_face:",
          "ts": "1654626215.905439",
          "thread_ts": "1654622083.934639",
          "edited": {
            "user": "U03JDTS6RKP",
            "ts": "1654626271.000000"
          },
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "F//",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi Paul, just chiming in cause I had a heck of a time figuring this out, but totally doable going back to first SwiftUI release (although I require iOS 14+ for my app because of an issue encountered in 13 related to this, can't remember what it was though "
                    },
                    {
                      "type": "text",
                      "text": "Edit: I think it was related to viewfinder not stretching to bounds properly",
                      "style": {
                        "bold": true
                      }
                    },
                    {
                      "type": "text",
                      "text": ").\n\nHave yet to look at the sample mentioned above, but solution is probably similar. At a high level you have your normal CameraViewController. You then create a UIViewControllerRepresentable, lets call it CameraVCSwiftUIView, with a CameraViewController as a member. This CameraVCSwiftUIView is now usable in SwiftUI as your CameraViewController / video preview "
                    },
                    {
                      "type": "emoji",
                      "name": "slightly_smiling_face",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "788a99ec-1e7b-4747-828a-f560432fb16c",
          "type": "message",
          "user": "U03HHA1D44F",
          "text": "Correct, there is not a native SwiftUI solution for AVCaptureVideoPreviewLayer",
          "ts": "1654626339.960539",
          "thread_ts": "1654622083.934639",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "i1F",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Correct, there is not a native SwiftUI solution for AVCaptureVideoPreviewLayer"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "22250b26-ddd5-46b6-9436-60b5758eafbd",
          "type": "message",
          "user": "U03HHA1D44F",
          "text": "Check out CameraPreview.swift in the sample app, ContinuityCam",
          "ts": "1654626383.376909",
          "thread_ts": "1654622083.934639",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "fVdHM",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Check out CameraPreview.swift in the sample app, ContinuityCam"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "af535784-453d-49cf-9f7d-fa145aa93a06",
          "type": "message",
          "user": "U03J1TZUPC3",
          "text": "Hi Edward, I have this now in my app. The app was originally build in 2015 based on UIKit. Now that I am adding new functionalities and the integration with the Apple watch, I'm also starting to move some code to SwiftUI. Currently, I wrapped the CameraViewController in a UIViewControllerRepresentable. I was, however, more curious to learn, when the AVFoundation camera would natively work in SwiftUI.",
          "ts": "1654626518.974529",
          "thread_ts": "1654622083.934639",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "1fqd",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi Edward, I have this now in my app. The app was originally build in 2015 based on UIKit. Now that I am adding new functionalities and the integration with the Apple watch, I'm also starting to move some code to SwiftUI. Currently, I wrapped the CameraViewController in a UIViewControllerRepresentable. I was, however, more curious to learn, when the AVFoundation camera would natively work in SwiftUI."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "d2fefd31-d4c5-47c5-ae95-dd184d776143",
          "type": "message",
          "user": "U03J1TZUPC3",
          "text": "I know how to build a camera app and how to integrate UIKit code into SwiftUI. That is not my problem.",
          "ts": "1654626571.448159",
          "thread_ts": "1654622083.934639",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "elH",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I know how to build a camera app and how to integrate UIKit code into SwiftUI. That is not my problem."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "876d5b00-5cc4-477e-9176-f8d5e8fd3526",
          "type": "message",
          "user": "U03J1TZUPC3",
          "text": "Hi Nikolas, that is too bad, but also gives me time to focus on other things. Thanks.",
          "ts": "1654626612.324109",
          "thread_ts": "1654622083.934639",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "RWfC",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi Nikolas, that is too bad, but also gives me time to focus on other things. Thanks."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "3dfc83fa-9631-47b3-a976-0c3f4a6dee56",
          "type": "message",
          "user": "U03JDTS6RKP",
          "text": "My guess is it probably won't be brought to SwiftUI, just cause of the architecture -- how would one handle pipeline config, state changes, etc in a way that makes sense in a SwiftUI context? (I'm new to SwiftUI so I could be missing something)",
          "ts": "1654630680.141559",
          "thread_ts": "1654622083.934639",
          "edited": {
            "user": "U03JDTS6RKP",
            "ts": "1654630723.000000"
          },
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "/6i",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "My guess is it probably won't be brought to SwiftUI, just cause of the architecture -- how would one handle pipeline config, state changes, etc in a way that makes sense in a SwiftUI context? (I'm new to SwiftUI so I could be missing something)"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "041df817-aeb7-4948-a871-d4e2f6ef829b",
          "type": "message",
          "user": "U03J1TZUPC3",
          "text": "I think the problem is the AVCaptureVideoPReviewLayer that is used to capture the image/video. The rest is pretty straight forward.",
          "ts": "1654630911.450339",
          "thread_ts": "1654622083.934639",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "lpGkg",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I think the problem is the AVCaptureVideoPReviewLayer that is used to capture the image/video. The rest is pretty straight forward."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03HZ5T63N1\u003e asked\n\u0026gt; Many schools use iPads as cameras. Would be cool if this could also be made to use with iPad.",
      "ts": "1654622109.756789",
      "thread_ts": "1654622109.756789",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 4,
      "latest_reply": "1654622475.058359",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "pt/",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03HZ5T63N1"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Many schools use iPads as cameras. Would be cool if this could also be made to use with iPad.\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "9e648e70-4782-4f3f-acec-ee519f230043",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "True. iPad form factor is a little unwieldy as a Continuity Camera, as it needs to be facing away from you to use the rear facing cameras. We're just supporting iPhones for now.",
          "ts": "1654622157.801669",
          "thread_ts": "1654622109.756789",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "GHSE+",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "True. iPad form factor is a little unwieldy as a Continuity Camera, as it needs to be facing away from you to use the rear facing cameras. We're just supporting iPhones for now."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "3e8b004c-0b0e-47c2-88a7-2eb944cd034d",
          "type": "message",
          "user": "U03HZ5T63N1",
          "text": "Imagine the device as an external camera. So many use cases in creative areas.",
          "ts": "1654622210.151409",
          "thread_ts": "1654622109.756789",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "MFDm",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Imagine the device as an external camera. So many use cases in creative areas."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "ca4222d8-b20b-40c8-a11c-4fcb66b83e9e",
          "type": "message",
          "user": "U03HZ5T63N1",
          "text": "And all the sensors of the iPhone/iPad as external sensors to be used from the Mac.",
          "ts": "1654622235.493259",
          "thread_ts": "1654622109.756789",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "RBC+G",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "And all the sensors of the iPhone/iPad as external sensors to be used from the Mac."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "041f011d-da08-4d69-842b-afe20572d929",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Yep, Continuity Camera is very powerful.",
          "ts": "1654622475.058359",
          "thread_ts": "1654622109.756789",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "1ciWR",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Yep, Continuity Camera is very powerful."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03JDTS6RKP\u003e asked\n\u0026gt; Hello,\n\u0026gt; \n\u0026gt; I've noticed the viewfinder gets stretched at the left and bottom edges when LivePhoto is enabled, and AVCaptureDevice.DeviceType is set to .builtInUltraWideCamera. Is this a known issue, and is there a workaround?\n\u0026gt; \n\u0026gt; Thank you for your time!",
      "ts": "1654622211.436409",
      "thread_ts": "1654622211.436409",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 10,
      "latest_reply": "1654637589.687679",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "YNZ+",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03JDTS6RKP"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Hello,\\n\\nI've noticed the viewfinder gets stretched at the left and bottom edges when LivePhoto is enabled, and AVCaptureDevice.DeviceType is set to .builtInUltraWideCamera. Is this a known issue, and is there a workaround?\\n\\nThank you for your time!\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "f964782d-b4ba-4fad-b1d1-dd7702741193",
          "type": "message",
          "user": "U03HR8XVATG",
          "text": "Hi Edward, are you only seeing this when LivePhoto is enabled? Or do you always see this when using the .buildInUltraWideCamera? If it's the latter then I suspect it's simply the distortion of this ultra wide angle camera lens that you're seeing.",
          "ts": "1654622297.703449",
          "thread_ts": "1654622211.436409",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "CYg",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi Edward, are you only seeing this when LivePhoto is enabled? Or do you always see this when using the .buildInUltraWideCamera? If it's the latter then I suspect it's simply the distortion of this ultra wide angle camera lens that you're seeing."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "55577d16-9db5-4f31-8fc5-977b89289061",
          "type": "message",
          "user": "U03HR8XVATG",
          "text": "But you should be seeing that in all 4 corners of the image.",
          "ts": "1654622316.068919",
          "thread_ts": "1654622211.436409",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "lTrAw",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "But you should be seeing that in all 4 corners of the image."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "3cb6d090-3eef-4485-8842-fff2db759a49",
          "type": "message",
          "user": "U03JDTS6RKP",
          "text": "Thank you for your reply! Happens only when LivePhoto is enabled. See image below",
          "ts": "1654622502.134119",
          "thread_ts": "1654622211.436409",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Rdb",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thank you for your reply! Happens only when LivePhoto is enabled. See image below"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "aa243789-9393-403a-8c24-21a88e876111",
          "type": "message",
          "user": "U03JDTS6RKP",
          "ts": "1654622527.135279",
          "thread_ts": "1654622211.436409",
          "files": [
            {
              "id": "F03JK8D703F",
              "created": 1654622523,
              "timestamp": 1654622523,
              "name": "IMG_2379.jpg",
              "title": "IMG_2379.jpg",
              "mimetype": "image/jpeg",
              "image_exif_rotation": 0,
              "filetype": "jpg",
              "pretty_type": "JPEG",
              "user": "U03JDTS6RKP",
              "mode": "hosted",
              "editable": false,
              "is_external": false,
              "external_type": "",
              "size": 372494,
              "url": "",
              "url_download": "",
              "url_private": "https://files.slack.com/files-pri/T01PTBJ95PS-F03JK8D703F/img_2379.jpg",
              "url_private_download": "https://files.slack.com/files-pri/T01PTBJ95PS-F03JK8D703F/download/img_2379.jpg",
              "original_h": 2532,
              "original_w": 1170,
              "thumb_64": "https://files.slack.com/files-tmb/T01PTBJ95PS-F03JK8D703F-63dddc1a2b/img_2379_64.jpg",
              "thumb_80": "https://files.slack.com/files-tmb/T01PTBJ95PS-F03JK8D703F-63dddc1a2b/img_2379_80.jpg",
              "thumb_160": "https://files.slack.com/files-tmb/T01PTBJ95PS-F03JK8D703F-63dddc1a2b/img_2379_160.jpg",
              "thumb_360": "https://files.slack.com/files-tmb/T01PTBJ95PS-F03JK8D703F-63dddc1a2b/img_2379_360.jpg",
              "thumb_360_gif": "",
              "thumb_360_w": 166,
              "thumb_360_h": 360,
              "thumb_480": "https://files.slack.com/files-tmb/T01PTBJ95PS-F03JK8D703F-63dddc1a2b/img_2379_480.jpg",
              "thumb_480_w": 222,
              "thumb_480_h": 480,
              "thumb_720": "https://files.slack.com/files-tmb/T01PTBJ95PS-F03JK8D703F-63dddc1a2b/img_2379_720.jpg",
              "thumb_720_w": 333,
              "thumb_720_h": 720,
              "thumb_960": "https://files.slack.com/files-tmb/T01PTBJ95PS-F03JK8D703F-63dddc1a2b/img_2379_960.jpg",
              "thumb_960_w": 444,
              "thumb_960_h": 960,
              "thumb_1024": "https://files.slack.com/files-tmb/T01PTBJ95PS-F03JK8D703F-63dddc1a2b/img_2379_1024.jpg",
              "thumb_1024_w": 473,
              "thumb_1024_h": 1024,
              "permalink": "https://appleevents.enterprise.slack.com/files/U03JDTS6RKP/F03JK8D703F/img_2379.jpg",
              "permalink_public": "https://slack-files.com/T01PTBJ95PS-F03JK8D703F-d7deadc2b5",
              "edit_link": "",
              "preview": "",
              "preview_highlight": "",
              "lines": 0,
              "lines_more": 0,
              "is_public": false,
              "public_url_shared": false,
              "channels": null,
              "groups": null,
              "ims": null,
              "initial_comment": {},
              "comments_count": 0,
              "num_stars": 0,
              "is_starred": false,
              "shares": {
                "public": null,
                "private": null
              }
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": null
        },
        {
          "client_msg_id": "691d0b92-68ac-467f-9f94-a0301e7b6601",
          "type": "message",
          "user": "U03HR8XVATG",
          "text": "that doesn't look expected. Could you file a bug report with that screenshot and repro steps? Is this only happening with iOS 16?",
          "ts": "1654622591.783389",
          "thread_ts": "1654622211.436409",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "fBug",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "that doesn't look expected. Could you file a bug report with that screenshot and repro steps? Is this only happening with iOS 16?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "56122eb0-50ff-4832-8c89-833e32e63d9c",
          "type": "message",
          "user": "U03JDTS6RKP",
          "text": "I believe it started in iOS 15, but can't be sure. This is the bug report that was filed a while back :slightly_smiling_face:  FB9983221",
          "ts": "1654622893.263989",
          "thread_ts": "1654622211.436409",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "8S4RK",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I believe it started in iOS 15, but can't be sure. This is the bug report that was filed a while back "
                    },
                    {
                      "type": "emoji",
                      "name": "slightly_smiling_face",
                      "skin_tone": 0
                    },
                    {
                      "type": "text",
                      "text": "  FB9983221"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "ee6e09e1-9b37-4417-84ce-cc3153d2fe5e",
          "type": "message",
          "user": "U03HR8XVATG",
          "text": "thanks, I just found the report. It's with our team. The screenshot you sent here is very informative, I've attached it to the bug report.",
          "ts": "1654623680.432459",
          "thread_ts": "1654622211.436409",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "pZV",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "thanks, I just found the report. It's with our team. The screenshot you sent here is very informative, I've attached it to the bug report."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "aaedafb0-b4bc-4e81-916b-449448b00178",
          "type": "message",
          "user": "U03JDTS6RKP",
          "text": "Thank you so much!!",
          "ts": "1654624790.796839",
          "thread_ts": "1654622211.436409",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "B6b",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thank you so much!!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "7374875E-04C9-465A-B2AA-03B98EBABD89",
          "type": "message",
          "user": "U03HVE4BEBY",
          "text": "I've had a couple of users report this issue too! Haven't been able to replicate it myself ",
          "ts": "1654633869.274069",
          "thread_ts": "1654622211.436409",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "vli",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I've "
                    },
                    {
                      "type": "text",
                      "text": "had"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "a"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "couple"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "of"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "users"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "report"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "this"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "issue"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "too!"
                    },
                    {
                      "type": "text",
                      "text": " Haven't "
                    },
                    {
                      "type": "text",
                      "text": "been"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "able"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "to"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "replicate"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "it"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "myself"
                    },
                    {
                      "type": "text",
                      "text": " "
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "1dc0821e-f441-4312-8a0c-51cb1aeb35c0",
          "type": "message",
          "user": "U03JDTS6RKP",
          "text": "Its there on the 12 Pro, but not on the 13 Pro as far as I can tell. Been there through most of iOS 15, and is still there on 15.4.1",
          "ts": "1654637589.687679",
          "thread_ts": "1654622211.436409",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "6SW3",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Its there on the 12 Pro, but not on the 13 Pro as far as I can tell. Been there through most of iOS 15, and is still there on 15.4.1"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03DJTBMHFF\u003e added a workflow to this channel: *Photos and Camera - Idea Submission*.",
      "ts": "1654622334.171329",
      "subtype": "bot_message",
      "bot_id": "B03JAB6KMDX",
      "username": "Photos and Camera - Idea Submission",
      "replace_original": false,
      "delete_original": false,
      "blocks": null
    },
    {
      "type": "message",
      "text": "\u003c@U03HMCT187R\u003e asked\n\u0026gt; Easy question for you! Is UIImagePickerController still the best way to allow people to take photos inside your app, if you're not building a completely camera interface? (The camera mode isn't deprecated, just the photoLibrary one has been?)",
      "ts": "1654622351.576949",
      "thread_ts": "1654622351.576949",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 7,
      "latest_reply": "1654797970.619369",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "Sgyp",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03HMCT187R"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Easy question for you! Is UIImagePickerController still the best way to allow people to take photos inside your app, if you're not building a completely camera interface? (The camera mode isn't deprecated, just the photoLibrary one has been?)\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "051c011b-6480-4de0-8cde-63b02fe6e406",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "I'd say UIImagePickerController is the easiest way to make a quick video or photo. Whether it's the best will depend on the feature set you need. It's a canned view, so you have little work to do.",
          "ts": "1654622397.441619",
          "thread_ts": "1654622351.576949",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U03HMCT187R"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "/tsi",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I'd say UIImagePickerController is the easiest way to make a quick video or photo. Whether it's the best will depend on the feature set you need. It's a canned view, so you have little work to do."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "7a03351f-3b36-496e-8d66-1c18c59e9f9d",
          "type": "message",
          "user": "U03JMC610GH",
          "text": "Late reply, but you have it exactly right — `UIImagePickerController` with the `camera` source for capture, and `PHPicker` for selecting existing assets is the recommended combination here.",
          "ts": "1654796235.467559",
          "thread_ts": "1654622351.576949",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "anj",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Late reply, but you have it exactly right — "
                    },
                    {
                      "type": "text",
                      "text": "UIImagePickerController",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " with the "
                    },
                    {
                      "type": "text",
                      "text": "camera",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " source for capture, and "
                    },
                    {
                      "type": "text",
                      "text": "PHPicker",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " for selecting existing assets is the recommended combination here."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "e23307eb-ca58-4cc0-bbb6-cce1163badcf",
          "type": "message",
          "user": "U03HMCT187R",
          "text": "Awesome thanks!",
          "ts": "1654796459.027859",
          "thread_ts": "1654622351.576949",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "raised_hands",
              "count": 1,
              "users": [
                "U03JMC610GH"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "CBL3",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Awesome thanks!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "f2b6ee1b-2098-4165-8ff3-f2312936f7b3",
          "type": "message",
          "user": "U03HMCT187R",
          "text": "Looking forward to a future WWDC where there’s an all new camera API to replace `UIImagePickerController` :smirk:",
          "ts": "1654796498.521479",
          "thread_ts": "1654622351.576949",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "NlRYD",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Looking forward to a future WWDC where there’s an all new camera API to replace "
                    },
                    {
                      "type": "text",
                      "text": "UIImagePickerController",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "emoji",
                      "name": "smirk",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "22a994d9-1c49-484c-9a3a-4a20174b0442",
          "type": "message",
          "user": "U03JMC610GH",
          "text": "Please do file feedback with any particular use cases / camera features / etc. that you'd like to see in a new API and feel free to drop the FB # here!",
          "ts": "1654796545.608719",
          "thread_ts": "1654622351.576949",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "jl8",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Please do file feedback with any particular use cases / camera features / etc. that you'd like to see in a new API and feel free to drop the FB # here!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "e9f4611c-d69d-4d5b-b883-0a0b728e5a11",
          "type": "message",
          "user": "U03HMCT187R",
          "text": "I might just have to compose all my thoughts on that!",
          "ts": "1654796647.959579",
          "thread_ts": "1654622351.576949",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "memo",
              "count": 1,
              "users": [
                "U03JMC610GH"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "TwX",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I might just have to compose all my thoughts on that!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "893570af-6447-4bfa-b9be-b14f0dbad767",
          "type": "message",
          "user": "U03HMCT187R",
          "text": "FB10136910: Modern camera API desired to replace UIImagePickerController",
          "ts": "1654797970.619369",
          "thread_ts": "1654622351.576949",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "pray",
              "count": 1,
              "users": [
                "U03JMC610GH"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "2IXo",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "FB10136910: Modern camera API desired to replace UIImagePickerController"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03K8L1DCSU\u003e asked\n\u0026gt; What is the best way to write a live video stream into a file (via AVAssetWriter) with custom FPS (e.g 18) but in the same time updating AVCaptureVideoPreviewLayer with 30 FPS?",
      "ts": "1654622534.232669",
      "thread_ts": "1654622534.232669",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 1,
      "latest_reply": "1654622601.374989",
      "reactions": [
        {
          "name": "+1",
          "count": 1,
          "users": [
            "U03KBCLJVR6"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "ME03H",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03K8L1DCSU"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"What is the best way to write a live video stream into a file (via AVAssetWriter) with custom FPS (e.g 18) but in the same time updating AVCaptureVideoPreviewLayer with 30 FPS?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "3282c2e3-a7e9-4ba0-a37c-bb03abc261fc",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "On macOS, you can set your frame rate on individual connections, so you can have one frame rate going to preview and one going to video data output. On iOS, you can't. It's just one frame rate dictated by the AVCaptureDevice, so if you want a lower frame rate to your asset writer, you'll need to do your own frame dropping in your VDO.",
          "ts": "1654622601.374989",
          "thread_ts": "1654622534.232669",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "pray",
              "count": 1,
              "users": [
                "U03K8L1DCSU"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "m9M",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "On macOS, you can set your frame rate on individual connections, so you can have one frame rate going to preview and one going to video data output. On iOS, you can't. It's just one frame rate dictated by the AVCaptureDevice, so if you want a lower frame rate to your asset writer, you'll need to do your own frame dropping in your VDO."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "193a283f-9d8c-4d9d-8e86-3277ba702ddb",
      "type": "message",
      "user": "U03DJTBMHFF",
      "text": "\u003c!here\u003e While we sort out the small technical glitch, let's get the discussion rolling. What would you like to discuss related to camera capture? Answer in the thread. :thread:",
      "ts": "1654622559.848829",
      "thread_ts": "1654622559.848829",
      "reply_count": 3,
      "latest_reply": "1654622701.558749",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "sDq",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "broadcast",
                  "range": "here"
                },
                {
                  "type": "text",
                  "text": " While we sort out the small technical glitch, let's get the discussion rolling. What would you like to discuss related to camera capture? Answer in the thread. "
                },
                {
                  "type": "emoji",
                  "name": "thread",
                  "skin_tone": 0
                }
              ]
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "7fdc0bf7-86aa-4ff7-bcf1-252b7d128927",
          "type": "message",
          "user": "U03JG9JF529",
          "text": "Are there ways to efficiently capture depth data to be able to replay it in tests?",
          "ts": "1654622626.455549",
          "thread_ts": "1654622559.848829",
          "parent_user_id": "U03DJTBMHFF",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "XHj",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Are there ways to efficiently capture depth data to be able to replay it in tests?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "2e47c74c-f350-435b-b8b8-db094c38a27d",
          "type": "message",
          "user": "U03JRPTG8BS",
          "text": "In iOS 16 it now seems possible to capture high resolution photos during an ARKit session.\nWhat camera properties can and can not be configured during an active ARKit session?\nCan we:\n- lock/set the exposure, white balance, and control the focus distance?\n- enable/disable multi-exposure fusion and tone mapping?\n- capture images with \u0026gt; 8bit depth?\n- capture Pro RAW images (presumably not)?",
          "ts": "1654622672.457419",
          "thread_ts": "1654622559.848829",
          "parent_user_id": "U03DJTBMHFF",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "NN98t",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "In iOS 16 it now seems possible to capture high resolution photos during an ARKit session.\nWhat camera properties can and can not be configured during an active ARKit session?\nCan we:\n- lock/set the exposure, white balance, and control the focus distance?\n- enable/disable multi-exposure fusion and tone mapping?\n- capture images with \u003e 8bit depth?\n- capture Pro RAW images (presumably not)?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "c08acd53-a848-4ecc-b0de-d9d0b313c7db",
          "type": "message",
          "user": "U03HZ5T63N1",
          "text": "More and more cameras are going to be more software than hardware. Continuity Camera is a very good example of this. I hope the APIs will make that available to devs more and more.",
          "ts": "1654622701.558749",
          "thread_ts": "1654622559.848829",
          "parent_user_id": "U03DJTBMHFF",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "MwoSN",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "More and more cameras are going to be more software than hardware. Continuity Camera is a very good example of this. I hope the APIs will make that available to devs more and more."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03JRPTG8BS\u003e asked\n\u0026gt; In iOS 16 it now seems possible to capture high resolution photos during an ARKit session. \n\u0026gt; What camera properties can and can not be configured during an active ARKit session? \n\u0026gt; Can we: \n\u0026gt; - lock/set the exposure, white balance, and control the focus distance? \n\u0026gt; - enable/disable multi-exposure fusion and tone mapping? \n\u0026gt; - capture images with \u0026gt; 8bit depth?\n\u0026gt; - capture Pro RAW images (presumably not)?",
      "ts": "1654622701.198159",
      "thread_ts": "1654622701.198159",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 4,
      "latest_reply": "1654624071.922649",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "5+IP6",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03JRPTG8BS"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"In iOS 16 it now seems possible to capture high resolution photos during an ARKit session. \\nWhat camera properties can and can not be configured during an active ARKit session? \\nCan we: \\n- lock\\/set the exposure, white balance, and control the focus distance? \\n- enable\\/disable multi-exposure fusion and tone mapping? \\n- capture images with \u003e 8bit depth?\\n- capture Pro RAW images (presumably not)?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "6a007466-8543-4027-9a57-a353ff6f2e44",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "You'll need to check with the ARKit team on what features they support. I don't believe you can do any of the things you've mentioned here.",
          "ts": "1654622840.228759",
          "thread_ts": "1654622701.198159",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Fjy",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "You'll need to check with the ARKit team on what features they support. I don't believe you can do any of the things you've mentioned here."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "5bef1423-cbf0-4004-bb53-e16daf5ac66d",
          "type": "message",
          "user": "U03JRPTG8BS",
          "text": "They do provide access to the AVCaptureDevice now\n\u003chttps://developer.apple.com/documentation/arkit/arconfiguration/3930045-configurablecapturedeviceforprim?changes=latest_minor\u003e",
          "ts": "1654623343.776849",
          "thread_ts": "1654622701.198159",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "NBr=",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "They do provide access to the AVCaptureDevice now\n"
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/arkit/arconfiguration/3930045-configurablecapturedeviceforprim?changes=latest_minor",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "0f73cf0d-fcb6-40b0-8b4d-37e8fef2474c",
          "type": "message",
          "user": "U03JRPTG8BS",
          "text": "But yes, I guess it is more a question for the ARKit team",
          "ts": "1654623394.211469",
          "thread_ts": "1654622701.198159",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Lffi",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "But yes, I guess it is more a question for the ARKit team"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "de42a1b4-9d84-4063-b934-811ca716558e",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "If they're providing direct access to AVCaptureDevice, you can certainly set properties on it directly, but I don't know how that will interact with the algorithms they're running.",
          "ts": "1654624071.922649",
          "thread_ts": "1654622701.198159",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "D4qPL",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "If they're providing direct access to AVCaptureDevice, you can certainly set properties on it directly, but I don't know how that will interact with the algorithms they're running."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03JRP87THN\u003e asked\n\u0026gt; The Continuity Camera's desk view is really interesting and amazing! How does it work?",
      "ts": "1654622711.614989",
      "thread_ts": "1654622711.614989",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 3,
      "latest_reply": "1654622862.622739",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "GwDL1",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03JRP87THN"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"The Continuity Camera's desk view is really interesting and amazing! How does it work?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "21da7d92-990d-475e-bfcb-fd8cb0256638",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "It uses the ultrawide lens of your iPhone. The field of view is wide enough to capture both your head and the desk in front of you. The desk view is warped and flipped with some pretty tricky distortion correction to make it appear rectilinear / flat, as if the camera were overhead instead of in front of it.",
          "ts": "1654622780.208999",
          "thread_ts": "1654622711.614989",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "+1",
              "count": 4,
              "users": [
                "U03JW240FB3",
                "U03JRP87THN",
                "U03KB8G0ENL",
                "U03HVD7HFGW"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "2Dz",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "It uses the ultrawide lens of your iPhone. The field of view is wide enough to capture both your head and the desk in front of you. The desk view is warped and flipped with some pretty tricky distortion correction to make it appear rectilinear / flat, as if the camera were overhead instead of in front of it."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "53721d81-683c-4ff0-abb4-4475ebcfb391",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "You'll want to watch the session \"Bringing Continuity Camera to your app\" Already available!",
          "ts": "1654622797.529489",
          "thread_ts": "1654622711.614989",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U03JRP87THN"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "p+h4",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "You'll want to watch the session \"Bringing Continuity Camera to your app\" Already available!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "b3b8b0be-0d28-4341-b3fd-bc22bb68b54d",
          "type": "message",
          "user": "U03JRP87THN",
          "text": "Thank you very much! Will definitely watch it.",
          "ts": "1654622862.622739",
          "thread_ts": "1654622711.614989",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "MFBAT",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thank you very much! Will definitely watch it."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03HZ462JCV\u003e asked\n\u0026gt; I'm trying to build an app for iPadOS to provide a portable video streaming setup, and wonder if there is a way to make a USB UVC camera appear in `AVCaptureDevice.DiscoverySession`?",
      "ts": "1654622879.431809",
      "thread_ts": "1654622879.431809",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 4,
      "latest_reply": "1654624026.500309",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "nVXzv",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03HZ462JCV"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"I'm trying to build an app for iPadOS to provide a portable video streaming setup, and wonder if there is a way to make a USB UVC camera appear in `AVCaptureDevice.DiscoverySession`?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "8e57fc95-d9d0-4aaf-b8ec-869bc50477d5",
          "type": "message",
          "user": "U03HXTE9N4S",
          "text": "I would have to say no since we don't support UVC camera on iPadOS",
          "ts": "1654622915.976219",
          "thread_ts": "1654622879.431809",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "4d/",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I would have to say no since we don't support UVC camera on iPadOS"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "54efa590-a68b-461c-8c76-281f822c9d2b",
          "type": "message",
          "user": "U03HZ462JCV",
          "text": "Thank you ^^",
          "ts": "1654622972.964829",
          "thread_ts": "1654622879.431809",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "0Oce",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thank you ^^"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "de97805d-4b7f-417e-bfa9-eceba86545e0",
          "type": "message",
          "user": "U03HZ462JCV",
          "text": "FB10074848 for potential future enhancements :pray:",
          "ts": "1654623765.221189",
          "thread_ts": "1654622879.431809",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U03HXTE9N4S"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "t7Wsd",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "FB10074848 for potential future enhancements "
                    },
                    {
                      "type": "emoji",
                      "name": "pray",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "e76f5f81-ac2c-44c6-8abc-f615acca8537",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Thanks, Tian!",
          "ts": "1654624026.500309",
          "thread_ts": "1654622879.431809",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "=GoFf",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks, Tian!"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03K8L1DCSU\u003e asked\n\u0026gt; How to speed up session start time and prevent drop of first frames? For example Snapchat works very fast (almost immediately), pausing and restarting are invisible and have no glitches. Even system Camera, Instagram, Facebook, Apple's demo app spend some time to configure the session and draw the first frame.",
      "ts": "1654622906.668299",
      "thread_ts": "1654622906.668299",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 5,
      "latest_reply": "1654624040.421289",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "oYgYF",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03K8L1DCSU"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"How to speed up session start time and prevent drop of first frames? For example Snapchat works very fast (almost immediately), pausing and restarting are invisible and have no glitches. Even system Camera, Instagram, Facebook, Apple's demo app spend some time to configure the session and draw the first frame.\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "8fe97ef5-c687-49e2-9338-c4b32932d480",
          "type": "message",
          "user": "U03HV023K2R",
          "text": "Creating the session with just the necessary outputs, e.g. only AVCaptureVideoDataOutput helps speed up the session startup. You can also try configuring everything upfront in the app user flow so the startup time is less noticeable to users.",
          "ts": "1654622921.841329",
          "thread_ts": "1654622906.668299",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "A6A/",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Creating the session with just the necessary outputs, e.g. only AVCaptureVideoDataOutput helps speed up the session startup. You can also try configuring everything upfront in the app user flow so the startup time is less noticeable to users."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "0bc958d8-5e58-40ba-8bb9-511634b10e36",
          "type": "message",
          "user": "U03K8L1DCSU",
          "text": "Is there a performance difference between wrapping any single output configuration into `beginConfiguration` and `commitConfiguration` and using only one `begin-commit` operation to batch outputs configurations?",
          "ts": "1654623231.245669",
          "thread_ts": "1654622906.668299",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "llg",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Is there a performance difference between wrapping any single output configuration into "
                    },
                    {
                      "type": "text",
                      "text": "beginConfiguration",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " and "
                    },
                    {
                      "type": "text",
                      "text": "commitConfiguration",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " and using only one "
                    },
                    {
                      "type": "text",
                      "text": "begin-commit",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " operation to batch outputs configurations?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "931c657a-0a63-4ab6-b236-2346121f0d37",
          "type": "message",
          "user": "U03HV023K2R",
          "text": "Batching all your configurations into one `begin-commit` is more efficient.",
          "ts": "1654623424.427489",
          "thread_ts": "1654622906.668299",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "=7ek",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Batching all your configurations into one "
                    },
                    {
                      "type": "text",
                      "text": "begin-commit",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " is more efficient."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "bf2de58b-a36c-4943-8e86-405b1b7eeba5",
          "type": "message",
          "user": "U03HHA1D44F",
          "text": "`beginConfiguration`'s documentation also states:\n\n\u0026gt; You can nest `beginConfiguration` and `commitConfiguration` pairs, and the system applies the changes when you call the outermost commit.\nThis may be helpful if you want to take care of different configuration aspects in different methods\n\nSee: \u003chttps://developer.apple.com/documentation/avfoundation/avcapturesession/1389174-beginconfiguration?language=objc\u003e",
          "ts": "1654623570.369879",
          "thread_ts": "1654622906.668299",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "reat1",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "beginConfiguration",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "'s documentation also states:\n\n"
                    }
                  ]
                },
                {
                  "Type": "rich_text_quote",
                  "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"You can nest \"},{\"type\":\"text\",\"text\":\"beginConfiguration\",\"style\":{\"code\":true}},{\"type\":\"text\",\"text\":\" and \"},{\"type\":\"text\",\"text\":\"commitConfiguration\",\"style\":{\"code\":true}},{\"type\":\"text\",\"text\":\" pairs, and the system applies the changes when you call the outermost commit.\"}]}"
                },
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "\nThis may be helpful if you want to take care of different configuration aspects in different methods\n\nSee: "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/avfoundation/avcapturesession/1389174-beginconfiguration?language=objc",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "2185fb25-f907-4d14-96a9-844795dd47d5",
          "type": "message",
          "user": "U03K8L1DCSU",
          "text": "Thanks",
          "ts": "1654624040.421289",
          "thread_ts": "1654622906.668299",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "rtDk",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03JG9JF529\u003e asked\n\u0026gt; Is it possible to efficiently write the AVDepthData from the cameras (front and back) using AVAssetWriter?",
      "ts": "1654622955.222659",
      "thread_ts": "1654622955.222659",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 4,
      "latest_reply": "1654624138.121559",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "g0yK",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03JG9JF529"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Is it possible to efficiently write the AVDepthData from the cameras (front and back) using AVAssetWriter?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "90bcd5d4-480d-482a-8756-5f261251065a",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "There is no API support in AVAssetWriter for writing depth at this time, though it is supported in the QuickTime spec as an auxiliary video track. You can read up on it in the official QuickTime spec, and a good example of this spec in action is Cinematic Video captured in \u003chttp://Camera.app|Camera.app\u003e.",
          "ts": "1654623017.021649",
          "thread_ts": "1654622955.222659",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "jcb",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "There is no API support in AVAssetWriter for writing depth at this time, though it is supported in the QuickTime spec as an auxiliary video track. You can read up on it in the official QuickTime spec, and a good example of this spec in action is Cinematic Video captured in Camera.app."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "f1e04ae1-cf2c-4a23-803a-e8fc3cdf6e75",
          "type": "message",
          "user": "U03JG9JF529",
          "text": "Thanks, is that the system Camera app on the iPhone 13 Pros?",
          "ts": "1654623078.249799",
          "thread_ts": "1654622955.222659",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "D+0",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks, is that the system Camera app on the iPhone 13 Pros?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "ef14cb0d-38bf-492c-b68e-dd6a47ae44f8",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Yes, correct.",
          "ts": "1654623998.919029",
          "thread_ts": "1654622955.222659",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "DY1X",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Yes, correct."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "1526350f-69d7-4c51-8711-4c6af0387712",
          "type": "message",
          "user": "U03JG9JF529",
          "text": "Is it publicly available in the quicktime spec? I can’t see the \u003chttps://twitter.com/jankais3r/status/1442466943697489923?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1442466943697489923%7Ctwgr%5E%7Ctwcon%5Es1_\u0026amp;ref_url=https%3A%2F%2Fnofilmschool.com%2Fdepth-map-new-iphone-cinematic-mode|identifiers listed from the cinematic video\u003e in the \u003chttps://developer.apple.com/library/archive/documentation/QuickTime/QTFF/Metadata/Metadata.html#//apple_ref/doc/uid/TP40000939-CH1-SW37|spec here\u003e",
          "ts": "1654624138.121559",
          "thread_ts": "1654622955.222659",
          "attachments": [
            {
              "fallback": "Metadata",
              "id": 1,
              "title": "Metadata",
              "title_link": "https://developer.apple.com/library/archive/documentation/QuickTime/QTFF/Metadata/Metadata.html#//apple_ref/doc/uid/TP40000939-CH1-SW37",
              "text": "Describes the file format and internal data structures of QuickTime movies.",
              "service_name": "developer.apple.com",
              "service_icon": "https://developer.apple.com/favicon.ico",
              "from_url": "https://developer.apple.com/library/archive/documentation/QuickTime/QTFF/Metadata/Metadata.html#//apple_ref/doc/uid/TP40000939-CH1-SW37",
              "original_url": "https://developer.apple.com/library/archive/documentation/QuickTime/QTFF/Metadata/Metadata.html#//apple_ref/doc/uid/TP40000939-CH1-SW37",
              "blocks": null
            }
          ],
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "UkRFu",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Is it publicly available in the quicktime spec? I can’t see the "
                    },
                    {
                      "type": "link",
                      "url": "https://twitter.com/jankais3r/status/1442466943697489923?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1442466943697489923%7Ctwgr%5E%7Ctwcon%5Es1_\u0026ref_url=https%3A%2F%2Fnofilmschool.com%2Fdepth-map-new-iphone-cinematic-mode",
                      "text": "identifiers listed from the cinematic video"
                    },
                    {
                      "type": "text",
                      "text": " in the "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/library/archive/documentation/QuickTime/QTFF/Metadata/Metadata.html#//apple_ref/doc/uid/TP40000939-CH1-SW37",
                      "text": "spec here"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03J20E7UBV\u003e asked\n\u0026gt; Is there a way to use Continuity Camera on iPadOS rather than macOS?  Specifically, could the iPhone camera be used as the camera in an app like FaceTime or Zoom?",
      "ts": "1654623037.098099",
      "thread_ts": "1654623037.098099",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 1,
      "latest_reply": "1654623092.521419",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "e2BW",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03J20E7UBV"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Is there a way to use Continuity Camera on iPadOS rather than macOS?  Specifically, could the iPhone camera be used as the camera in an app like FaceTime or Zoom?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "d252df2e-df92-4a8b-bf8d-c0f73bf73b46",
          "type": "message",
          "user": "U03JMLKUF1N",
          "text": "Hi Brandon, Continuity Camera is only available on macOS currently, so iPad apps won't be able to see these new cameras.",
          "ts": "1654623092.521419",
          "thread_ts": "1654623037.098099",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U03J20E7UBV"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "=vo",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi Brandon, Continuity Camera is only available on macOS currently, so iPad apps won't be able to see these new cameras."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03J21HNQAE\u003e asked\n\u0026gt; Thanks for the Q\u0026amp;A!  I notice there may be a session on this tomorrow, but is there a way to continue running an AVCaptureSession in slide over and split view? :grin:",
      "ts": "1654623063.703609",
      "thread_ts": "1654623063.703609",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 4,
      "latest_reply": "1654623872.974239",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "jA9Pk",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03J21HNQAE"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Thanks for the Q\u0026A!  I notice there may be a session on this tomorrow, but is there a way to continue running an AVCaptureSession in slide over and split view? \"},{\"type\":\"emoji\",\"name\":\"grin\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "8de7ce20-b0b7-4e8e-8bba-84ff87ed5855",
          "type": "message",
          "user": "U03HHA1D44F",
          "text": "Yes! In tomorrow's session we describe new API that you can use to allow your app to use the camera while multitasking",
          "ts": "1654623096.822519",
          "thread_ts": "1654623063.703609",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "fPl",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Yes! In tomorrow's session we describe new API that you can use to allow your app to use the camera while multitasking"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "59cbb7bc-1328-47a0-860b-fd32e0ff8d61",
          "type": "message",
          "user": "U03HHA1D44F",
          "text": "There are 2 new properties on AVCaptureSession: isMultitaskingCameraAccessSupported and isMultitaskingCameraAccessEnabled",
          "ts": "1654623115.176189",
          "thread_ts": "1654623063.703609",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "VN=",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "There are 2 new properties on AVCaptureSession: isMultitaskingCameraAccessSupported and isMultitaskingCameraAccessEnabled"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "d5f6314d-a762-4f19-a48b-5b6d6bea737c",
          "type": "message",
          "user": "U03HHA1D44F",
          "text": "The session refers to this article which you can read in advance of the session being released:\n\n\u003chttps://developer.apple.com/documentation/avkit/accessing_the_camera_while_multitasking?language=objc\u003e",
          "ts": "1654623140.516199",
          "thread_ts": "1654623063.703609",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "zmDY",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "The session refers to this article which you can read in advance of the session being released:\n\n"
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/avkit/accessing_the_camera_while_multitasking?language=objc",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "e0701a62-50a5-4d70-9f0d-6b83ae7a7aab",
          "type": "message",
          "user": "U03J21HNQAE",
          "text": "This is awesome!  Thanks so much for developing this and the detailed doc :grin:",
          "ts": "1654623872.974239",
          "thread_ts": "1654623063.703609",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Jkd98",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "This is awesome!  Thanks so much for developing this and the detailed doc "
                    },
                    {
                      "type": "emoji",
                      "name": "grin",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03JM9TRBB3\u003e asked\n\u0026gt; Do the updates for iPads with M1 to support custom USB drivers with DriverKit mean that I can use external cameras and other capture devices (like an Elgato UBS capture card, for example) with my application through AVFoundation?",
      "ts": "1654623130.503749",
      "thread_ts": "1654623130.503749",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 2,
      "latest_reply": "1654626435.890139",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "v44K5",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03JM9TRBB3"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Do the updates for iPads with M1 to support custom USB drivers with DriverKit mean that I can use external cameras and other capture devices (like an Elgato UBS capture card, for example) with my application through AVFoundation?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "5c3be24f-c7d2-43ae-ac83-e4bfc7a399b2",
          "type": "message",
          "user": "U03HHA1DV9D",
          "text": "Currently only internal cameras on the iPad are supported in AVFoundation.",
          "ts": "1654623255.013699",
          "thread_ts": "1654623130.503749",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "/aJnc",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Currently only internal cameras on the iPad are supported in AVFoundation."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "d8cf7752-aeca-46a7-86b2-1f246350e16e",
          "type": "message",
          "user": "U03JM9TRBB3",
          "text": "Okay, I’ve got FB9948623 filed as an enhancement request for this for tracking purposes.",
          "ts": "1654626435.890139",
          "thread_ts": "1654623130.503749",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Sdld",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Okay, I’ve got FB9948623 filed as an enhancement request for this for tracking purposes."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03HZ5T63N1\u003e asked\n\u0026gt; Did I understand this correctly? You will be able to capture high res stills while still seeing the live video feed?",
      "ts": "1654623156.492599",
      "thread_ts": "1654623156.492599",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 2,
      "latest_reply": "1654623199.356609",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "ZQqMl",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03HZ5T63N1"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Did I understand this correctly? You will be able to capture high res stills while still seeing the live video feed?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "8cc9e76c-7e9f-469b-9304-adc5f2c78b34",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "speaking of Continuity Camera, yes? That's correct. Stills can be taken while doing live video.",
          "ts": "1654623180.419969",
          "thread_ts": "1654623156.492599",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "NR4/B",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "speaking of Continuity Camera, yes? That's correct. Stills can be taken while doing live video."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "db717ece-b856-452a-b2a1-8546dcae535b",
          "type": "message",
          "user": "U03HZ5T63N1",
          "text": "Awesome!",
          "ts": "1654623199.356609",
          "thread_ts": "1654623156.492599",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "4Oe",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Awesome!"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03HZ5T63N1\u003e asked\n\u0026gt; Can you please also add the depth info to the stream? And iPhone telemetry? (Orientation, position, velocity)",
      "ts": "1654623295.748469",
      "thread_ts": "1654623295.748469",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 3,
      "latest_reply": "1654623356.366499",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "sQYak",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03HZ5T63N1"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Can you please also add the depth info to the stream? And iPhone telemetry? (Orientation, position, velocity)\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "ecd6d506-4b95-4dcf-a4ae-bbbeca19fc59",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Tell us more about this. You can already add your own telemetry as metadata in timed metadata tracks in QuickTime movies using AVCaptureMetadataInput.",
          "ts": "1654623326.322469",
          "thread_ts": "1654623295.748469",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "to=8",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Tell us more about this. You can already add your own telemetry as metadata in timed metadata tracks in QuickTime movies using AVCaptureMetadataInput."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "1beb9e35-ab2a-46b1-afa4-817753333a77",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "We do support streaming depth as AVDepthData objects in AVCaptureDepthDataOutput.",
          "ts": "1654623341.844789",
          "thread_ts": "1654623295.748469",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "wjz",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "We do support streaming depth as AVDepthData objects in AVCaptureDepthDataOutput."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "eba655eb-898c-4903-80df-01dcb214fea6",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "We do not currently support writing depth to movies via asset writer or AVCaptureMovieFileOutput though.",
          "ts": "1654623356.366499",
          "thread_ts": "1654623295.748469",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "3xn2l",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "We do not currently support writing depth to movies via asset writer or AVCaptureMovieFileOutput though."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03J20E7UBV\u003e asked\n\u0026gt; For a few releases now, I've been \"warming up\" my AVAssetWriter as soon as my app launches, then cancelling the writing session before actually starting to write.  If I don't do this, I end up with black frames at the beginning of the AVAssetWriter.  Is this the suggested step to take or is this a different issue I'm facing?",
      "ts": "1654623423.990289",
      "thread_ts": "1654623423.990289",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 12,
      "latest_reply": "1654624646.774419",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "gv1p",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03J20E7UBV"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"For a few releases now, I've been \\\"warming up\\\" my AVAssetWriter as soon as my app launches, then cancelling the writing session before actually starting to write.  If I don't do this, I end up with black frames at the beginning of the AVAssetWriter.  Is this the suggested step to take or is this a different issue I'm facing?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "acde0398-0c41-4a05-a693-8d4593912fc5",
          "type": "message",
          "user": "U03HHA1DV9D",
          "text": "Hrm... it would seem like this would happen if the movie also has audio that starts at an earlier time.",
          "ts": "1654623444.308749",
          "thread_ts": "1654623423.990289",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "tARTQ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hrm... it would seem like this would happen if the movie also has audio that starts at an earlier time."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "47b82536-3d17-42ae-baaa-d622fc39bd7f",
          "type": "message",
          "user": "U03HHA1DV9D",
          "text": "Have you looked at the movie for edits.",
          "ts": "1654623474.918389",
          "thread_ts": "1654623423.990289",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "HL3QY",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Have you looked at the movie for edits."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "24185658-34cd-434a-9548-0e7f18a2695d",
          "type": "message",
          "user": "U03J20E7UBV",
          "text": "Thanks, \u003c@U03HHA1DV9D\u003e.  In my scenario, that is not the case, as I am not recording audio.  I'm usually recording very short clips (1-3 seconds), but can almost consistently replicate the issue, if I don't \"warm up\" the AVAssetWriter in advance.  I can file a bug report on it if it's not a common/known topic!",
          "ts": "1654623537.092899",
          "thread_ts": "1654623423.990289",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "w3/u",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks, "
                    },
                    {
                      "type": "user",
                      "user_id": "U03HHA1DV9D"
                    },
                    {
                      "type": "text",
                      "text": ".  In my scenario, that is not the case, as I am not recording audio.  I'm usually recording very short clips (1-3 seconds), but can almost consistently replicate the issue, if I don't \"warm up\" the AVAssetWriter in advance.  I can file a bug report on it if it's not a common/known topic!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "2f7c1f5d-15df-484e-b771-1a8ad38adf6a",
          "type": "message",
          "user": "U03HHA1DV9D",
          "text": "I haven't heard of this before.  What exactly are you doing to warm up the assetwriter?",
          "ts": "1654623581.506439",
          "thread_ts": "1654623423.990289",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "dd5M",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I haven't heard of this before.  What exactly are you doing to warm up the assetwriter?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "61eecd03-952a-4f22-9b2f-8bb2ae72f665",
          "type": "message",
          "user": "U03HHA1DV9D",
          "text": "(Before I forget, if you do file a bug report please include one of the clips.)",
          "ts": "1654623675.096289",
          "thread_ts": "1654623423.990289",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "vHGC",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "(Before I forget, if you do file a bug report please include one of the clips.)"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "2f58a604-3614-4ce1-898d-b55ee623ea05",
          "type": "message",
          "user": "U03J20E7UBV",
          "text": "I am instantiating an AVAssetWriter as soon as the app launches, starting a session at `.zero`, then adding a delay of 0.5 seconds, and then calling `.cancelWriting()` on the session.  If I do that once, typically as soon as the app launches, I can negate the issue altogether.\n\nI got the suggestion from \u003chttps://stackoverflow.com/questions/44135223/record-video-with-avassetwriter-first-frames-are-black|this\u003e post, though it feels like a workaround, for sure.",
          "ts": "1654623882.674849",
          "thread_ts": "1654623423.990289",
          "attachments": [
            {
              "fallback": "Stack Overflow: Record video with AVAssetWriter: first frames are black",
              "id": 1,
              "title": "Record video with AVAssetWriter: first frames are black",
              "title_link": "https://stackoverflow.com/questions/44135223/record-video-with-avassetwriter-first-frames-are-black",
              "text": "I am recording video (the user also can switch to audio only) with AVAssetWriter. I start the recording when the app is launched. But the first frames are black (or very dark). This also happens wh...",
              "thumb_url": "https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon@2.png?v=73d79a89bded",
              "service_name": "Stack Overflow",
              "service_icon": "https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon.png?v=c78bd457575a",
              "from_url": "https://stackoverflow.com/questions/44135223/record-video-with-avassetwriter-first-frames-are-black",
              "original_url": "https://stackoverflow.com/questions/44135223/record-video-with-avassetwriter-first-frames-are-black",
              "blocks": null
            }
          ],
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "liL",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I am instantiating an AVAssetWriter as soon as the app launches, starting a session at "
                    },
                    {
                      "type": "text",
                      "text": ".zero",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": ", then adding a delay of 0.5 seconds, and then calling "
                    },
                    {
                      "type": "text",
                      "text": ".cancelWriting()",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " on the session.  If I do that once, typically as soon as the app launches, I can negate the issue altogether.\n\nI got the suggestion from "
                    },
                    {
                      "type": "link",
                      "url": "https://stackoverflow.com/questions/44135223/record-video-with-avassetwriter-first-frames-are-black",
                      "text": "this"
                    },
                    {
                      "type": "text",
                      "text": " post, though it feels like a workaround, for sure."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "fe2d5e2a-7f97-43f8-9aa2-edf8dffd7cc6",
          "type": "message",
          "user": "U03HHA1DV9D",
          "text": "The advice in that link sounds good.",
          "ts": "1654624128.499619",
          "thread_ts": "1654623423.990289",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "veGJz",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "The advice in that link sounds good."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "a461d4d3-f1f2-4c80-b389-739f3baec2da",
          "type": "message",
          "user": "U03HHA1DV9D",
          "text": "I think the confusion is around starting at zero but not actually writing with the first frame.",
          "ts": "1654624155.379319",
          "thread_ts": "1654623423.990289",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "lC+Pb",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I think the confusion is around starting at zero but not actually writing with the first frame."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "d4f56b5e-bdc7-49bc-a4d0-5ab5aefdd2e4",
          "type": "message",
          "user": "U03HHA1DV9D",
          "text": "Did you ever measure how long the period of black frames was?",
          "ts": "1654624193.392249",
          "thread_ts": "1654623423.990289",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Zfs",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Did you ever measure how long the period of black frames was?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "8ad2378f-387c-4a96-9765-1d1b848bb768",
          "type": "message",
          "user": "U03J20E7UBV",
          "text": "It's typically brief, though that's a great troubleshooting step to take.  I can definitely measure the time; maybe it's consistent and I can use that to troubleshoot.  Maybe I'm misunderstanding, but should I not be starting at `.zero`?  I had thought that was writing the timecode to start at 00:00:00, but perhaps I'm misunderstanding here.",
          "ts": "1654624412.622499",
          "thread_ts": "1654623423.990289",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "QGmm",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "It's typically brief, though that's a great troubleshooting step to take.  I can definitely measure the time; maybe it's consistent and I can use that to troubleshoot.  Maybe I'm misunderstanding, but should I not be starting at "
                    },
                    {
                      "type": "text",
                      "text": ".zero",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "?  I had thought that was writing the timecode to start at 00:00:00, but perhaps I'm misunderstanding here."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "80efc330-f506-4bc7-a351-d2b1dc2377df",
          "type": "message",
          "user": "U03HHA1DV9D",
          "text": "If you end up looking at the presentation times given by media samples read back from a movie file, you'll find that the timeline of every movie file starts at zero.",
          "ts": "1654624553.434319",
          "thread_ts": "1654623423.990289",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "05D",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "If you end up looking at the presentation times given by media samples read back from a movie file, you'll find that the timeline of every movie file starts at zero."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "39908833-d5ae-4529-8c39-6a5ea43b8158",
          "type": "message",
          "user": "U03HHA1DV9D",
          "text": "The presentation times of the incoming samples are shifted.  I'm not super-expert with AVAssetWriter, but I have the feeling that when you set the session to start at zero you are nullifying this normal adjustment.",
          "ts": "1654624646.774419",
          "thread_ts": "1654623423.990289",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "s7T3U",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "The presentation times of the incoming samples are shifted.  I'm not super-expert with AVAssetWriter, but I have the feeling that when you set the session to start at zero you are nullifying this normal adjustment."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "ba6a2799-d6cb-4a2f-b11b-0aedbb60d62c",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": "We've been getting some great questions! We've got about 20 minutes left. I encourage you all to sign up for a lab slot if you've got an in-depth question that you don't get answered here.",
      "ts": "1654623695.296459",
      "team": "T031SG5MZ7U",
      "reactions": [
        {
          "name": "raised_hands",
          "count": 1,
          "users": [
            "U03HHD1DN6B"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "u17",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "We've been getting some great questions! We've got about 20 minutes left. I encourage you all to sign up for a lab slot if you've got an in-depth question that you don't get answered here."
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "452fe7b0-35cc-48e6-b673-1b9607793d35",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": "Our lab times are Wednesday 2-5 PM PDT, and Friday morning, 9 AM - 12 PM.",
      "ts": "1654623721.155949",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "m/q0",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Our lab times are Wednesday 2-5 PM PDT, and Friday morning, 9 AM - 12 PM."
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03JRPTG8BS\u003e asked\n\u0026gt; We are using the camera to take photos for photogrammetric reconstruction. What are some tips and best practices for getting the best results (in terms of configuring the camera and capture settings)?\n\u0026gt; In this use case we want to use the camera as a light measuring instruments. So we do not want any tone mapping, and a predictable mapping from linear intensities (photon counts) to recorded pixel values, so that we can invert it and get back to linear intensities. \n\u0026gt; Pro RAW seems potentially ideal(?), but is only supported on a small percentage of devices, and would be too large a format for us to send to servers for reconstruction.",
      "ts": "1654623793.487159",
      "thread_ts": "1654623793.487159",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 21,
      "latest_reply": "1654755056.535719",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "=ME",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03JRPTG8BS"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"We are using the camera to take photos for photogrammetric reconstruction. What are some tips and best practices for getting the best results (in terms of configuring the camera and capture settings)?\\nIn this use case we want to use the camera as a light measuring instruments. So we do not want any tone mapping, and a predictable mapping from linear intensities (photon counts) to recorded pixel values, so that we can invert it and get back to linear intensities. \\nPro RAW seems potentially ideal(?), but is only supported on a small percentage of devices, and would be too large a format for us to send to servers for reconstruction.\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "300d8cc8-8385-4609-aefc-ce9b77556482",
          "type": "message",
          "user": "U03HR90DADU",
          "text": "Hi!  This is a deep question.  Capturing Pro RAW (or Bayer RAW) is your best option to get access to non-tone mapped data, but as you mention the formats supporting these are large, and Pro RAW is not supported on all devices.",
          "ts": "1654624013.135659",
          "thread_ts": "1654623793.487159",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "yrgYQ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi!  This is a deep question.  Capturing Pro RAW (or Bayer RAW) is your best option to get access to non-tone mapped data, but as you mention the formats supporting these are large, and Pro RAW is not supported on all devices."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "1b6aaa55-74fb-43a2-bb7c-23eb2f888083",
          "type": "message",
          "user": "U03HR90DADU",
          "text": "I encourage you to try -[AVCaptureDevice globalToneMappingEnabled] to at least avoid local tone mapping.",
          "ts": "1654624093.547259",
          "thread_ts": "1654623793.487159",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "HOnE",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I encourage you to try -[AVCaptureDevice globalToneMappingEnabled] to at least avoid local tone mapping."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "a6c5cd03-34cd-4465-a604-e9b716104949",
          "type": "message",
          "user": "U03JRPTG8BS",
          "text": "Thank you! But is that not just for global (non-local) tone mapping, judging by the name?",
          "ts": "1654624229.979989",
          "thread_ts": "1654623793.487159",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "gMs",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thank you! But is that not just for global (non-local) tone mapping, judging by the name?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "9b51b3bb-5c1b-48e9-81e5-52c049530682",
          "type": "message",
          "user": "U03JRPTG8BS",
          "text": "I looked at the documentation and I think I understand. Turning this on disables local tonemapping.",
          "ts": "1654624348.247919",
          "thread_ts": "1654623793.487159",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "9vMP",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I looked at the documentation and I think I understand. Turning this on disables local tonemapping."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "4fa8c234-c2ab-4a86-b9f7-0a65898d4162",
          "type": "message",
          "user": "U03HR90DADU",
          "text": "Yes, it will give you data that is globally tone mapped.  Currently it’s not possible capture linear data, or something that can be converted into linear data.",
          "ts": "1654624380.223619",
          "thread_ts": "1654623793.487159",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "WbHs1",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Yes, it will give you data that is globally tone mapped.  Currently it’s not possible capture linear data, or something that can be converted into linear data."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "a6094892-6c08-42de-bc08-e6c382740795",
          "type": "message",
          "user": "U03JRPTG8BS",
          "text": "But if I use an sRGB color space, could I not then use the known sRGB formula to get back to linear intensities?",
          "ts": "1654624418.178869",
          "thread_ts": "1654623793.487159",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "UWVLJ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "But if I use an sRGB color space, could I not then use the known sRGB formula to get back to linear intensities?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "222ef27d-db33-4043-9ed3-84016c8b37c8",
          "type": "message",
          "user": "U03HR90DADU",
          "text": "Are you interesting in streaming data?",
          "ts": "1654624425.975959",
          "thread_ts": "1654623793.487159",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "f3u=",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Are you interesting in streaming data?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "649ab6dc-0051-4cc4-97e2-787b70092b54",
          "type": "message",
          "user": "U03JRPTG8BS",
          "text": "Or are there other unknown global tone mapping operators happening?",
          "ts": "1654624434.567879",
          "thread_ts": "1654623793.487159",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "xh5A",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Or are there other unknown global tone mapping operators happening?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "e470994c-1d50-410b-a305-0fc0185171f8",
          "type": "message",
          "user": "U03JRPTG8BS",
          "text": "No, I am interested in discrete images taken during an ARKit session.",
          "ts": "1654624463.047179",
          "thread_ts": "1654623793.487159",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "lbqT",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "No, I am interested in discrete images taken during an ARKit session."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "60062835-9f72-4177-addb-0c5d1623b56a",
          "type": "message",
          "user": "U03HR90DADU",
          "text": "Yes, there’s a scene dependent global tone mapping applied",
          "ts": "1654624464.386349",
          "thread_ts": "1654623793.487159",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "U6Nc",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Yes, there’s a scene dependent global tone mapping applied"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "cd4af076-a39c-40aa-a6bb-457b19c162ae",
          "type": "message",
          "user": "U03JRPTG8BS",
          "text": "And no way to get that mapping I assume?",
          "ts": "1654624493.732089",
          "thread_ts": "1654623793.487159",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "R=fNC",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "And no way to get that mapping I assume?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "20b63419-aca1-4098-add7-7fe5903b8180",
          "type": "message",
          "user": "U03HR90DADU",
          "text": "Correct.",
          "ts": "1654624545.580649",
          "thread_ts": "1654623793.487159",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "uDX",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Correct."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "3ca62b99-47fc-4e9f-ad78-8e04fcb32d18",
          "type": "message",
          "user": "U03JRPTG8BS",
          "text": ":pensive:",
          "ts": "1654624562.614379",
          "thread_ts": "1654623793.487159",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "mcsjX",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "emoji",
                      "name": "pensive",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "2c949cb3-d180-4957-ae35-9a3f3c6d2161",
          "type": "message",
          "user": "U03HR90DADU",
          "text": "It would be good if you could file a feedback request with your use case.",
          "ts": "1654624605.419859",
          "thread_ts": "1654623793.487159",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "da2u",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "It would be good if you could file a feedback request with your use case."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "4e5162cd-fe32-4bef-9caf-a51c1ff244f9",
          "type": "message",
          "user": "U03JRPTG8BS",
          "text": "Will do. Thank you for the insights.",
          "ts": "1654624621.442249",
          "thread_ts": "1654623793.487159",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "PVgg",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Will do. Thank you for the insights."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "62507d78-e905-4b42-b33f-30ee9e75ca39",
          "type": "message",
          "user": "U03JRPTG8BS",
          "text": "Where available Pro RAW should be exactly what I want, right? (Except for file size)",
          "ts": "1654624640.490699",
          "thread_ts": "1654623793.487159",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "ywn",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Where available Pro RAW should be exactly what I want, right? (Except for file size)"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "be2740dc-1179-4651-95c6-c3b6d4d1055e",
          "type": "message",
          "user": "U03HR90DADU",
          "text": "This is a common request.  Please drop my name in the feedback request.",
          "ts": "1654624650.469159",
          "thread_ts": "1654623793.487159",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "P9eJ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "This is a common request.  Please drop my name in the feedback request."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "94be8d18-e0fd-4dde-a758-c3bca15e9224",
          "type": "message",
          "user": "U03HR90DADU",
          "text": "Yes.  Pro RAW should give you want you want.",
          "ts": "1654624686.610859",
          "thread_ts": "1654623793.487159",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "bKPN",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Yes.  Pro RAW should give you want you want."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "e648666f-c090-4226-af45-2a677fb42ac4",
          "type": "message",
          "user": "U03JRPTG8BS",
          "text": "I think we actually had a nice lab conversation last year. Nice to meet you again!",
          "ts": "1654624702.419009",
          "thread_ts": "1654623793.487159",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "khlqo",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I think we actually had a nice lab conversation last year. Nice to meet you again!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "0364822e-bf41-4f76-8535-b4308f71569e",
          "type": "message",
          "user": "U03HR90DADU",
          "text": "You too!  Quite a different topic last year IIRC",
          "ts": "1654625241.561639",
          "thread_ts": "1654623793.487159",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "m9Q",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "You too!  Quite a different topic last year IIRC"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "c55afb18-1f5e-415a-b286-eb2ee4dc5a1b",
          "type": "message",
          "user": "U03JRPTG8BS",
          "text": "\u003c@U03HR90DADU\u003e Yes, last year we talked about minimizing camera shake blur and latency (after the shutter press) while taking photos for a computer vision application.",
          "ts": "1654755056.535719",
          "thread_ts": "1654623793.487159",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "AaDE",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "user",
                      "user_id": "U03HR90DADU"
                    },
                    {
                      "type": "text",
                      "text": " Yes, last year we talked about minimizing camera shake blur and latency (after the shutter press) while taking photos for a computer vision application."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03HVDF8N6A\u003e asked\n\u0026gt; How can I get the Mac webcam in a Catalyst application? Using the iOS code, the camera looks cropped.",
      "ts": "1654623893.792979",
      "thread_ts": "1654623893.792979",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 2,
      "latest_reply": "1654624209.302749",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "0lL",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03HVDF8N6A"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"How can I get the Mac webcam in a Catalyst application? Using the iOS code, the camera looks cropped.\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "b7384741-2163-428c-932d-0a6ead239a71",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "This is probably because your app is declaring that it supports the portait mode, so we have to crop in on the camera frames to make them fill your app's preview. If you support landscape orientation, we should give you an uncropped view.",
          "ts": "1654623953.256079",
          "thread_ts": "1654623893.792979",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "heart",
              "count": 1,
              "users": [
                "U03HVDF8N6A"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "tyA=",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "This is probably because your app is declaring that it supports the portait mode, so we have to crop in on the camera frames to make them fill your app's preview. If you support landscape orientation, we should give you an uncropped view."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "1E1383D8-50DF-460A-83B5-55820DC431DE",
          "type": "message",
          "user": "U03HVDF8N6A",
          "text": "Will look in to that. Thanks (: great work!!",
          "ts": "1654624209.302749",
          "thread_ts": "1654623893.792979",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "s9R",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Will"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "look"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "in"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "to"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "that. Thanks"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "(:"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "great"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "work!!"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03K8L1DCSU\u003e asked\n\u0026gt; I'm using `.photo` sessionPreset to capture fullRes photos. But at the same time I want to record video via AVAssetWriter in 1920x1080 (without any session's reconfiguration). How can I configure AVCaptureVideoDataOutput to get from the delegate sampleBuffers with correct sizes (1920x1080)? I know about `automaticallyConfiguresOutputBufferDimensions` and `deliversPreviewSizedOutputBuffers` properties. But their combinations produces 1284x1712 or 3024x4032 outputs.",
      "ts": "1654624161.605459",
      "thread_ts": "1654624161.605459",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 7,
      "latest_reply": "1654624545.805849",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "C4CUa",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03K8L1DCSU"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"I'm using `.photo` sessionPreset to capture fullRes photos. But at the same time I want to record video via AVAssetWriter in 1920x1080 (without any session's reconfiguration). How can I configure AVCaptureVideoDataOutput to get from the delegate sampleBuffers with correct sizes (1920x1080)? I know about `automaticallyConfiguresOutputBufferDimensions` and `deliversPreviewSizedOutputBuffers` properties. But their combinations produces 1284x1712 or 3024x4032 outputs.\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "cd3197fd-325e-4d04-99cd-0b96a72c5e89",
          "type": "message",
          "user": "U03HHA1D44F",
          "text": "In tomorrow's session \"Discover advancements in iOS camera capture\" we go over how to do this in iOS 16.\n\nYou can set the width and height in the `videoSettings` property on an AVCaptureVideoDataOutput to receive custom dimensions.\n\nSee: \u003chttps://developer.apple.com/videos/play/wwdc2022/110429\u003e",
          "ts": "1654624211.579229",
          "thread_ts": "1654624161.605459",
          "attachments": [
            {
              "fallback": "Apple Developer: Discover advancements in iOS camera capture: Depth, focus, and multitasking - WWDC22 - Videos - Apple Developer",
              "id": 1,
              "title": "Discover advancements in iOS camera capture: Depth, focus, and multitasking - WWDC22 - Videos - Apple Developer",
              "title_link": "https://developer.apple.com/videos/play/wwdc2022/110429",
              "text": "Discover how you can take advantage of advanced camera capture features in your app. We'll show you how to use the LiDAR scanner to...",
              "image_url": "https://devimages-cdn.apple.com/wwdc-services/images/124/6790/6790_wide_250x141_2x.jpg",
              "service_name": "Apple Developer",
              "service_icon": "https://developer.apple.com/favicon.ico",
              "from_url": "https://developer.apple.com/videos/play/wwdc2022/110429",
              "original_url": "https://developer.apple.com/videos/play/wwdc2022/110429",
              "blocks": null
            }
          ],
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "LAp",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "In tomorrow's session \"Discover advancements in iOS camera capture\" we go over how to do this in iOS 16.\n\nYou can set the width and height in the "
                    },
                    {
                      "type": "text",
                      "text": "videoSettings",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " property on an AVCaptureVideoDataOutput to receive custom dimensions.\n\nSee: "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/videos/play/wwdc2022/110429",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "5de463ec-ff6c-48f5-b9aa-82ca3a392382",
          "type": "message",
          "user": "U03HHA1D44F",
          "text": "You can specify the width and height width `kCVPixelBufferWidthKey` and `kCVPixelBufferHeightKey`, respectively",
          "ts": "1654624318.042279",
          "thread_ts": "1654624161.605459",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "IWnZ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "You can specify the width and height width "
                    },
                    {
                      "type": "text",
                      "text": "kCVPixelBufferWidthKey",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " and "
                    },
                    {
                      "type": "text",
                      "text": "kCVPixelBufferHeightKey",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": ", respectively"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "84ea912c-5039-4bf0-9886-dd761e5072b0",
          "type": "message",
          "user": "U03K8L1DCSU",
          "text": "\u003c@U03HHA1D44F\u003e Am I correct that `kCVPixelBufferWidthKey` and `kCVPixelBufferHeightKey` don't work on iOS \u0026lt; 16?",
          "ts": "1654624488.310909",
          "thread_ts": "1654624161.605459",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Svty3",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "user",
                      "user_id": "U03HHA1D44F"
                    },
                    {
                      "type": "text",
                      "text": " Am I correct that "
                    },
                    {
                      "type": "text",
                      "text": "kCVPixelBufferWidthKey",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " and "
                    },
                    {
                      "type": "text",
                      "text": "kCVPixelBufferHeightKey",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " don't work on iOS \u003c 16?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "8f6ef41a-eefb-4edb-b0be-7af50a4cfd92",
          "type": "message",
          "user": "U03HHA1D44F",
          "text": "correct",
          "ts": "1654624497.058109",
          "thread_ts": "1654624161.605459",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "lLTa",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "correct"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "08cc3f49-4dda-46ae-a771-b448b8748785",
          "type": "message",
          "user": "U03K8L1DCSU",
          "text": "Thanks",
          "ts": "1654624508.917289",
          "thread_ts": "1654624161.605459",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "qlTS",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "3a4a416b-df15-47d7-9c10-cb0cd6c5c5fe",
          "type": "message",
          "user": "U03HHA1D44F",
          "text": "However, it's important to note that you cannot receive 1920x1080 when using the photo session preset as that resolution is 4:3, often 4032x3024.\n\nWhen specifying the width and height in the AVCaptureVideoDataOutput's videoSettings. The aspect ratio must match the aspect ratio of the source camera's format",
          "ts": "1654624531.171329",
          "thread_ts": "1654624161.605459",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "nY37V",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "However, it's important to note that you cannot receive 1920x1080 when using the photo session preset as that resolution is 4:3, often 4032x3024.\n\nWhen specifying the width and height in the AVCaptureVideoDataOutput's videoSettings. The aspect ratio must match the aspect ratio of the source camera's format"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "90461d3d-f7bc-4dfb-b31e-25d1a2984feb",
          "type": "message",
          "user": "U03HHA1D44F",
          "text": "So you could request 1920x1440, which is 4:3, when using the photo session preset",
          "ts": "1654624545.805849",
          "thread_ts": "1654624161.605459",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "=dYC2",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "So you could request 1920x1440, which is 4:3, when using the photo session preset"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "85e04090-0b8e-494c-9010-5442c9dac4a7",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": "Coming up!!! At 11:00 AM (in 9 minutes), we'll transition this channel to our watch party of \"Bring Continuity Camera to your macOS app\".\n\u003chttps://developer.apple.com/videos/play/wwdc2022/10018/\u003e",
      "ts": "1654624333.261789",
      "attachments": [
        {
          "fallback": "Apple Developer: Bring Continuity Camera to your macOS app - WWDC22 - Videos - Apple Developer",
          "id": 1,
          "title": "Bring Continuity Camera to your macOS app - WWDC22 - Videos - Apple Developer",
          "title_link": "https://developer.apple.com/videos/play/wwdc2022/10018/",
          "text": "Discover how you can use iPhone as an external camera in any Mac app with Continuity Camera. Whether you're building video conferencing...",
          "image_url": "https://devimages-cdn.apple.com/wwdc-services/images/124/6511/6511_wide_250x141_2x.jpg",
          "service_name": "Apple Developer",
          "service_icon": "https://developer.apple.com/favicon.ico",
          "from_url": "https://developer.apple.com/videos/play/wwdc2022/10018/",
          "original_url": "https://developer.apple.com/videos/play/wwdc2022/10018/",
          "blocks": null
        }
      ],
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "4ItP",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Coming up!!! At 11:00 AM (in 9 minutes), we'll transition this channel to our watch party of \"Bring Continuity Camera to your macOS app\".\n"
                },
                {
                  "type": "link",
                  "url": "https://developer.apple.com/videos/play/wwdc2022/10018/",
                  "text": ""
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03HVDF8N6A\u003e asked\n\u0026gt; Tô use my camera app on Sideview on iPad, I need special entitlements? Anyone can get it or is a bit restrict?",
      "ts": "1654624372.853169",
      "thread_ts": "1654624372.853169",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 4,
      "latest_reply": "1654624480.573829",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "NXj",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03HVDF8N6A"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"T\\u00f4 use my camera app on Sideview on iPad, I need special entitlements? Anyone can get it or is a bit restrict?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "cba3b7a4-56d8-4858-a99e-aeb4db8f0a59",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Before iOS 16, yes, there's an entitlement granting process that requires filling out a form. In iOS 16 and later, there's API to opt in for multitasking support (sideview/slideover).",
          "ts": "1654624421.171809",
          "thread_ts": "1654624372.853169",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "dBV4",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Before iOS 16, yes, there's an entitlement granting process that requires filling out a form. In iOS 16 and later, there's API to opt in for multitasking support (sideview/slideover)."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "0D108810-BC0A-4257-AB1E-444E9FFB8EC3",
          "type": "message",
          "user": "U03HVDF8N6A",
          "text": "Nice. Thanks!!",
          "ts": "1654624450.878189",
          "thread_ts": "1654624372.853169",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "D7dsQ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Nice"
                    },
                    {
                      "type": "text",
                      "text": "."
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "Thanks!!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "c28d805b-281f-4560-bfbd-fd2f22b349e9",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "There's a session dropping tomorrow that you'll want to watch called \"Discover advancements in iOS camera capture: Depth, focus, and multitasking\"",
          "ts": "1654624461.850279",
          "thread_ts": "1654624372.853169",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U03HVDF8N6A"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Jck",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "There's a session dropping tomorrow that you'll want to watch called \"Discover advancements in iOS camera capture: Depth, focus, and multitasking\""
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "0392837E-E828-420C-AC56-4E07D5650071",
          "type": "message",
          "user": "U03HVDF8N6A",
          "text": "Going to check it. ",
          "ts": "1654624480.573829",
          "thread_ts": "1654624372.853169",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "4G1",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Going"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "to"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "check"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "it. "
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03JSKKS65P\u003e asked\n\u0026gt; I found that I have to access `inputNode` of `AVAudioEngine` before starting the engine to be able to use it. This means the permission dialog will be presented before the engine is running and also the recording indication in the status bar is present. Is there any way to start using the input node later, when the engine is already running. I found I get mostly sample rate mismatch errors if I don't access the input node beforehand. I was not able to find a combination, any tips on how to solve this?",
      "ts": "1654624490.283459",
      "thread_ts": "1654624490.283459",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 1,
      "latest_reply": "1654624526.364359",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "CdT",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03JSKKS65P"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"I found that I have to access `inputNode` of `AVAudioEngine` before starting the engine to be able to use it. This means the permission dialog will be presented before the engine is running and also the recording indication in the status bar is present. Is there any way to start using the input node later, when the engine is already running. I found I get mostly sample rate mismatch errors if I don't access the input node beforehand. I was not able to find a combination, any tips on how to solve this?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "8ed831fc-cc71-4495-856c-adb6d5ffd242",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "This is a great question to ask over in the \u003c#C03H9J5AW4U|\u003e. We don't have any AVAudioEngine experts in the room right now.",
          "ts": "1654624526.364359",
          "thread_ts": "1654624490.283459",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U03JSKKS65P"
              ]
            },
            {
              "name": "heart",
              "count": 1,
              "users": [
                "U03JSKKS65P"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "HRV",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "This is a great question to ask over in the "
                    },
                    {
                      "type": "channel",
                      "channel_id": "C03H9J5AW4U"
                    },
                    {
                      "type": "text",
                      "text": ". We don't have any AVAudioEngine experts in the room right now."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "111e77aa-80cc-433e-a275-3a98211c65af",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": "All righty, thanks all for participating in our first Q\u0026amp;A Camera session. There will be another on Thursday morning from 10 - 11 AM PDT. Hope to see you there.",
      "ts": "1654624782.799419",
      "team": "T031SG5MZ7U",
      "reactions": [
        {
          "name": "raised_hands",
          "count": 4,
          "users": [
            "U03JDTS6RKP",
            "U03HZ5T63N1",
            "U03K8L1DCSU",
            "U03JBMMB10A"
          ]
        },
        {
          "name": "heart",
          "count": 3,
          "users": [
            "U03JELU9E5P",
            "U03HMBG02AK",
            "U03JKQJ4SA0"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "XAi",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "All righty, thanks all for participating in our first Q\u0026A Camera session. There will be another on Thursday morning from 10 - 11 AM PDT. Hope to see you there."
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "0580ab17-f44a-4c9b-9859-ed84c4219caf",
      "type": "message",
      "user": "U03DJTBMHFF",
      "text": "\u003c!here\u003e We're keeping the workflow active to take your questions during our next activity. *_Meet the Presenters: Bring Continuity Camera to your macOS app_.* We'll all hit play together on the video in 5 minutes. Here's the link to get it queued up: \u003chttps://developer.apple.com/videos/play/wwdc2022-10018\u003e",
      "ts": "1654624899.805159",
      "attachments": [
        {
          "fallback": "Apple Developer: Bring Continuity Camera to your macOS app - WWDC22 - Videos - Apple Developer",
          "id": 1,
          "title": "Bring Continuity Camera to your macOS app - WWDC22 - Videos - Apple Developer",
          "title_link": "https://developer.apple.com/videos/play/wwdc2022-10018",
          "text": "Discover how you can use iPhone as an external camera in any Mac app with Continuity Camera. Whether you're building video conferencing...",
          "image_url": "https://devimages-cdn.apple.com/wwdc-services/images/124/6511/6511_wide_250x141_2x.jpg",
          "service_name": "Apple Developer",
          "service_icon": "https://developer.apple.com/favicon.ico",
          "from_url": "https://developer.apple.com/videos/play/wwdc2022-10018",
          "original_url": "https://developer.apple.com/videos/play/wwdc2022-10018",
          "blocks": null
        }
      ],
      "team": "T031SG5MZ7U",
      "reactions": [
        {
          "name": "slightly_smiling_face",
          "count": 2,
          "users": [
            "U03JELU9E5P",
            "U03HVDEEETG"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "Tumup",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "broadcast",
                  "range": "here"
                },
                {
                  "type": "text",
                  "text": " We're keeping the workflow active to take your questions during our next activity. "
                },
                {
                  "type": "text",
                  "text": "Meet the Presenters: Bring Continuity Camera to your macOS app",
                  "style": {
                    "bold": true,
                    "italic": true
                  }
                },
                {
                  "type": "text",
                  "text": ". ",
                  "style": {
                    "bold": true
                  }
                },
                {
                  "type": "text",
                  "text": "We'll all hit play together on the video in 5 minutes. Here's the link to get it queued up: "
                },
                {
                  "type": "link",
                  "url": "https://developer.apple.com/videos/play/wwdc2022-10018",
                  "text": ""
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "4fe14e76-a5f6-4d0b-85c9-bc13f28aeeb6",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": "Developers, developers, developers,\n\nWelcome to *Meet the Presenter: Bring Continuity Camera to your macOS app*! We are so happy to have you all here! I’m Brad from the Camera Software Engineering team. In this hour, we invite everyone to watch the “Bring Continuity Camera to your macOS app” session together! Here’s how it works. Queue up the video and get ready to hit play at 11:05 am PDT.  \u003chttps://developer.apple.com/videos/play/wwdc2022/10018/|(\u003eSee Eric's link above)\n\nWe’ve got the session’s presenter, \u003c@U03HV023K2R\u003e, in the room with us. (Hi, Karen! :wave:) We're also joined here by our team of Camera software engineers who are ready to answer your questions!\n\nThere's a lot of us here, so we're going to do our best to keep things organized. As the video progresses, I'll be creating threads associated with each section of the talk, where everyone can chat and ask questions.\n\nWhen the video finishes, we will have some time left over for additional targeted Q\u0026amp;A, which I'll explain when we get there. So for the next few minutes, grab your popcorn, get comfortable, and get ready to hit the play button!",
      "ts": "1654624965.252119",
      "team": "T031SG5MZ7U",
      "reactions": [
        {
          "name": "raised_hands",
          "count": 6,
          "users": [
            "U03JSKKS65P",
            "U03HVDEEETG",
            "U03HHA1D44F",
            "U03J5SM2VUJ",
            "U03JYHSL6AD",
            "U03HVD7HFGW"
          ]
        },
        {
          "name": "camera_with_flash",
          "count": 3,
          "users": [
            "U03JSKKS65P",
            "U03JJKNRZ8S",
            "U03HVD7HFGW"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "TAsnf",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Developers, developers, developers,\n\nWelcome to "
                },
                {
                  "type": "text",
                  "text": "Meet the Presenter: Bring Continuity Camera to your macOS app",
                  "style": {
                    "bold": true
                  }
                },
                {
                  "type": "text",
                  "text": "! We are so happy to have you all here! I’m Brad from the Camera Software Engineering team. In this hour, we invite everyone to watch the “Bring Continuity Camera to your macOS app” session together! Here’s how it works. Queue up the video and get ready to hit play at 11:05 am PDT.  "
                },
                {
                  "type": "link",
                  "url": "https://developer.apple.com/videos/play/wwdc2022/10018/",
                  "text": "("
                },
                {
                  "type": "text",
                  "text": "See Eric's link above)\n\nWe’ve got the session’s presenter, "
                },
                {
                  "type": "user",
                  "user_id": "U03HV023K2R"
                },
                {
                  "type": "text",
                  "text": ", in the room with us. (Hi, Karen! "
                },
                {
                  "type": "emoji",
                  "name": "wave",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": ") We're also joined here by our team of Camera software engineers who are ready to answer your questions!\n\nThere's a lot of us here, so we're going to do our best to keep things organized. As the video progresses, I'll be creating threads associated with each section of the talk, where everyone can chat and ask questions.\n\nWhen the video finishes, we will have some time left over for additional targeted Q\u0026A, which I'll explain when we get there. So for the next few minutes, grab your popcorn, get comfortable, and get ready to hit the play button!"
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "cd7e9bc7-9d69-4338-8b05-9957d09988b0",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": "5..4..3..2..1.. Unleash the hounds!",
      "ts": "1654625094.370779",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "5/=K",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "5..4..3..2..1.. Unleash the hounds!"
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "11f606c0-d7c3-475c-8d5c-3257e2cefc14",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": "Feel free to use the Ask a Question or Post an Idea workflow to ask questions.",
      "ts": "1654625163.292099",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "53F",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Feel free to use the Ask a Question or Post an Idea workflow to ask questions."
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "4c642faa-8248-4af9-b724-277f4241082a",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": ":thread: Questions about device compatibility",
      "ts": "1654625374.734189",
      "thread_ts": "1654625374.734189",
      "reply_count": 3,
      "latest_reply": "1654625537.923849",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "9Xuf",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "emoji",
                  "name": "thread",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": " Questions about device compatibility"
                }
              ]
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "12274582-0837-4fd6-8fc4-44ad1a8009b0",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Only works with iPhone -\u0026gt; macOS.",
          "ts": "1654625397.430049",
          "thread_ts": "1654625374.734189",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "KNSr",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Only works with iPhone -\u003e macOS."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "ddb4823f-1e96-48d2-a5a6-f12cb4c3abf5",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Both accounts must be on the same iCloud account.",
          "ts": "1654625409.629959",
          "thread_ts": "1654625374.734189",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "YdZ4K",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Both accounts must be on the same iCloud account."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "963687fc-b724-4fa8-9346-9c6b883abd61",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Other questions?",
          "ts": "1654625537.923849",
          "thread_ts": "1654625374.734189",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "uoFM",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Other questions?"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "53625f9c-b1c3-4ee6-bd4c-40f87c3bdf28",
      "type": "message",
      "user": "U03HV023K2R",
      "text": "Hi :wave: Karen here. Excited to hear your feedback and questions on Continuity Camera :slightly_smiling_face:",
      "ts": "1654625638.994999",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "jr3",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Hi "
                },
                {
                  "type": "emoji",
                  "name": "wave",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": " Karen here. Excited to hear your feedback and questions on Continuity Camera "
                },
                {
                  "type": "emoji",
                  "name": "slightly_smiling_face",
                  "skin_tone": 0
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "42d46efb-755e-4170-a4b5-cfc28130cdba",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": ":thread: Questions about `systemPreferredCamera` and `userPreferredCamera`",
      "ts": "1654625679.670229",
      "thread_ts": "1654625679.670229",
      "reply_count": 1,
      "latest_reply": "1654625748.320879",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "Bdo/",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "emoji",
                  "name": "thread",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": " Questions about "
                },
                {
                  "type": "text",
                  "text": "systemPreferredCamera",
                  "style": {
                    "code": true
                  }
                },
                {
                  "type": "text",
                  "text": " and "
                },
                {
                  "type": "text",
                  "text": "userPreferredCamera",
                  "style": {
                    "code": true
                  }
                }
              ]
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "e05e8ee8-9dc5-498a-810b-748c62bd6362",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "We strongly encourage everyone to update their apps to use these two APIs, rather than manage camera picking with your own custom logic. Feel free to ask questions about it here.",
          "ts": "1654625748.320879",
          "thread_ts": "1654625679.670229",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "gPwBC",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "We strongly encourage everyone to update their apps to use these two APIs, rather than manage camera picking with your own custom logic. Feel free to ask questions about it here."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "7610b857-4214-4b19-a1ec-5b22f5cddd83",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": ":thread: Questions about Continuity Camera Video Effects",
      "ts": "1654625773.748999",
      "thread_ts": "1654625773.748999",
      "reply_count": 1,
      "latest_reply": "1654625808.451589",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "pmz3+",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "emoji",
                  "name": "thread",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": " Questions about Continuity Camera Video Effects"
                }
              ]
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "b85d67d7-1595-4a29-9121-b6b59f4e76d8",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "We currently support Portrait mode, Center Stage, and the new Studio Light effect in Continuity Camera! Fee free to ask your questions here about these features.",
          "ts": "1654625808.451589",
          "thread_ts": "1654625773.748999",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "DKO",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "We currently support Portrait mode, Center Stage, and the new Studio Light effect in Continuity Camera! Fee free to ask your questions here about these features."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03HVDF8N6A\u003e asked\n\u0026gt; iPhone can be free from the Mac or need to be “mounted” on the top? Can I walk with the Phone for example?",
      "ts": "1654625821.954079",
      "thread_ts": "1654625821.954079",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 10,
      "latest_reply": "1654633730.347869",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "vgXr1",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03HVDF8N6A"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"iPhone can be free from the Mac or need to be \\u201cmounted\\u201d on the top? Can I walk with the Phone for example?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "18c9d651-950f-4ff4-97ca-43d444427aa4",
          "type": "message",
          "user": "U03HV023K2R",
          "text": "The specific placement, orientation of the phone is required for automatic switching. But yes, you can use Continuity Camera when walking with your phone.",
          "ts": "1654625843.838279",
          "thread_ts": "1654625821.954079",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "heart",
              "count": 1,
              "users": [
                "U03HVDF8N6A"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Wxs",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "The specific placement, orientation of the phone is required for automatic switching. But yes, you can use Continuity Camera when walking with your phone."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "140229F0-15AE-4D13-BFBF-0DA4360AF58A",
          "type": "message",
          "user": "U03HVDF8N6A",
          "text": "Thanks Karen",
          "ts": "1654625866.965659",
          "thread_ts": "1654625821.954079",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "VcZ1G",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks "
                    },
                    {
                      "type": "text",
                      "text": "Karen"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "275c2408-bfea-4111-9203-915a33bedf4c",
          "type": "message",
          "user": "U03DJTBMHFF",
          "text": "FYI: We actually show a demo of exactly that in the _What's new in Create ML_ session which dropped today.",
          "ts": "1654625907.352839",
          "thread_ts": "1654625821.954079",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U03HVDF8N6A"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "f9K",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "FYI: We actually show a demo of exactly that in the "
                    },
                    {
                      "type": "text",
                      "text": "What's new in Create ML",
                      "style": {
                        "italic": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " session which dropped today."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "186fe2ad-197b-4dd5-a32f-9f5ce1ee4b39",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "If your phone is not in a stand, it will still be offered in the list of cameras, but it won't be designated at the `systemPreferredCamera` until you place it in a stand.",
          "ts": "1654626039.454669",
          "thread_ts": "1654625821.954079",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "9q8T",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "If your phone is not in a stand, it will still be offered in the list of cameras, but it won't be designated at the "
                    },
                    {
                      "type": "text",
                      "text": "systemPreferredCamera",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " until you place it in a stand."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "c617a02d-09ba-485d-be20-79325fd71b08",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "By the way, it doesn't need to be clipped to the top of a macbook. It can be in any stand of your choosing, as long as it's landscape, stationary, screen off, and close by to the mac.",
          "ts": "1654626095.024929",
          "thread_ts": "1654625821.954079",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U03HVDF8N6A"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "F/x",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "By the way, it doesn't need to be clipped to the top of a macbook. It can be in any stand of your choosing, as long as it's landscape, stationary, screen off, and close by to the mac."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "937A130F-D722-4D11-AF32-2472F0E54249",
          "type": "message",
          "user": "U03HVDF8N6A",
          "text": "Go it. The stand needs to have some chip? Or only checks for proximity and orientation?",
          "ts": "1654626125.998649",
          "thread_ts": "1654625821.954079",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "cxT1",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Go"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "it."
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "The"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "stand"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "needs"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "to"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "have"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "some"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "chip?"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "Or"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "only"
                    },
                    {
                      "type": "text",
                      "text": " c"
                    },
                    {
                      "type": "text",
                      "text": "hecks"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "for"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "proximity"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "and"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "orientation?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "901A299A-8741-4D52-85FD-436AE9A47332",
          "type": "message",
          "user": "U03HVDF8N6A",
          "text": "Nice. Great to know",
          "ts": "1654626147.325359",
          "thread_ts": "1654625821.954079",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "pRy05",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Nice."
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "Great"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "to"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "know"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "572af5b7-7b26-417f-bb44-53a7f7c29a0d",
          "type": "message",
          "user": "U03HV023K2R",
          "text": "We check phone's proximity and orientation. No chip in stands :slightly_smiling_face:",
          "ts": "1654626170.986569",
          "thread_ts": "1654625821.954079",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "heart",
              "count": 1,
              "users": [
                "U03HVDF8N6A"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "MM=C+",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "We check phone's proximity and orientation. No chip in stands "
                    },
                    {
                      "type": "emoji",
                      "name": "slightly_smiling_face",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "type": "message",
          "user": "U03HHA1D44F",
          "text": "\u003c@U03DJTBMHFF\u003e, Create ML demonstrated Wombat?",
          "ts": "1654633161.212329",
          "thread_ts": "1654625821.954079",
          "subtype": "moderated",
          "replace_original": false,
          "delete_original": false,
          "blocks": null
        },
        {
          "type": "message",
          "user": "U03HHA1D44F",
          "text": "I don't see Wombat in this video\n\n\u003chttps://developer.apple.com/videos/play/wwdc2022/110332/\u003e",
          "ts": "1654633730.347869",
          "thread_ts": "1654625821.954079",
          "subtype": "moderated",
          "replace_original": false,
          "delete_original": false,
          "blocks": null
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03HZ4B0S1K\u003e asked\n\u0026gt; Is it possible to connect multiple iOS devices to the same mac, and use continuity camera to capture multiple video streams simultaneously?",
      "ts": "1654625848.914999",
      "thread_ts": "1654625848.914999",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 4,
      "latest_reply": "1654626333.298769",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "IHG3v",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03HZ4B0S1K"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Is it possible to connect multiple iOS devices to the same mac, and use continuity camera to capture multiple video streams simultaneously?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "6f104782-fcd8-433c-9f64-200a66b36112",
          "type": "message",
          "user": "U03HV023K2R",
          "text": "It doesn't support streaming multiple continuity cameras at the same time right now. But you can have multiple iOS devices around and switch between devices.",
          "ts": "1654625891.941619",
          "thread_ts": "1654625848.914999",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "XLM",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "It doesn't support streaming multiple continuity cameras at the same time right now. But you can have multiple iOS devices around and switch between devices."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "F6533461-7A55-4D97-BD7B-1D2508776D0C",
          "type": "message",
          "user": "U03HZ4B0S1K",
          "text": "would love the ability to stream multiple devices at once, we're doing this at \u003chttps://detail.co%F0%9F%99%82|https://detail.co\u003e:slightly_smiling_face:",
          "ts": "1654626045.120509",
          "thread_ts": "1654625848.914999",
          "attachments": [
            {
              "fallback": "Detail – Cinematic video made simple",
              "id": 1,
              "title": "Detail – Cinematic video made simple",
              "title_link": "https://detail.co/",
              "text": "Produce, stream, record, and edit high-quality videos on your Mac. Detail works with your iPhone, iPad, built-in webcam, or any other camera.",
              "image_url": "https://framerusercontent.com/modules/KS8AFfMxPWZqRwF2qsGL/DC4bC9VPvCIVMNy9f54M/assets/jmVp9FUSzGIw7bXLpGd4Uzngak.jpg",
              "service_name": "detail.co",
              "service_icon": "https://framerusercontent.com/modules/BQZm3b0SqeP6dmtTd1Ph/cSCXfDOUXN8e4bztGu1P/assets/FfRrjY6su1Vv7CpAY2xo6MdY8jU.png",
              "from_url": "https://detail.co/",
              "original_url": "https://detail.co",
              "blocks": null
            }
          ],
          "edited": {
            "user": "U03HZ4B0S1K",
            "ts": "1654626062.000000"
          },
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "7RIA5",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "would love the ability to stream multiple devices at once, we're doing this at "
                    },
                    {
                      "type": "link",
                      "url": "https://detail.co%F0%9F%99%82",
                      "text": "https://detail.co"
                    },
                    {
                      "type": "emoji",
                      "name": "slightly_smiling_face",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "f424234e-b391-4bbf-8f0b-d37fba20573a",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Neat!",
          "ts": "1654626135.515369",
          "thread_ts": "1654625848.914999",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "0CJYX",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Neat!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "8edde2ad-e8bc-4a65-a283-6800ea29d914",
          "type": "message",
          "user": "U03JKQJ4SA0",
          "text": "Will Managed AppleIDs work with this feature? Despite Continuity in full NOT  being a feature supported with MAIDs?",
          "ts": "1654626333.298769",
          "thread_ts": "1654625848.914999",
          "edited": {
            "user": "U03JKQJ4SA0",
            "ts": "1654626365.000000"
          },
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "aXX",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Will Managed AppleIDs work with this feature? Despite Continuity in full NOT  being a feature supported with MAIDs?"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "5975d5a3-317e-4438-b307-619760d3664a",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": ":thread: Questions about Desk View API",
      "ts": "1654626213.551779",
      "thread_ts": "1654626213.551779",
      "reply_count": 1,
      "latest_reply": "1654626280.379889",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "xVXv/",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "emoji",
                  "name": "thread",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": " Questions about Desk View API"
                }
              ]
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "c67224fc-01e7-4257-9264-6ae8d5e35867",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Fun fact about Desk View. Continuity Cameras are meant to be discovered in all shipping macOS camera apps with no changes. But DeskView camera has a different DeviceType. You won't find it unless you specifically look for it using `AVCaptureDeviceDiscoverySession`.",
          "ts": "1654626280.379889",
          "thread_ts": "1654626213.551779",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "rLe8I",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Fun fact about Desk View. Continuity Cameras are meant to be discovered in all shipping macOS camera apps with no changes. But DeskView camera has a different DeviceType. You won't find it unless you specifically look for it using "
                    },
                    {
                      "type": "text",
                      "text": "AVCaptureDeviceDiscoverySession",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "244f3cce-aa17-4a7e-870b-928c460a4aca",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": "OK! Now that we've watched it, let's dig in on the questions.",
      "ts": "1654626296.723849",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "wJvw",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "OK! Now that we've watched it, let's dig in on the questions."
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "41b8f086-0af0-4ce3-b4f2-7fb9b13d3f79",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": "I've started a few threads with sample feature areas. Feel free to ask questions there, or, ask your own questions.",
      "ts": "1654626335.666009",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "w+YUq",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "I've started a few threads with sample feature areas. Feel free to ask questions there, or, ask your own questions."
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "aba6f18b-3bf2-404d-ae9b-41410ed009b2",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": "Karen and the team will answer questions until 12:00 PM PDT.",
      "ts": "1654626382.794599",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "wsXyF",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Karen and the team will answer questions until 12:00 PM PDT."
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "404632cc-9d8d-4c56-9546-8990b4894245",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": ":thread: New APIs to bring to your app — Zoom! High Res Stills! Real-time Metadata! Flash captures! Oh my!",
      "ts": "1654626521.433849",
      "thread_ts": "1654626521.433849",
      "reply_count": 1,
      "latest_reply": "1654626547.143869",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "kfBJ",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "emoji",
                  "name": "thread",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": " New APIs to bring to your app — Zoom! High Res Stills! Real-time Metadata! Flash captures! Oh my!"
                }
              ]
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "a887db99-0048-4be3-aaf4-d47667330d78",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "We've brought over a number of previously iPhone only camera features to mac with Continuity Camera. Any questions on how they work?",
          "ts": "1654626547.143869",
          "thread_ts": "1654626521.433849",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "zZC",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "We've brought over a number of previously iPhone only camera features to mac with Continuity Camera. Any questions on how they work?"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "05221626-da4e-4331-aab6-ccc4442f8e7c",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": "\u003c@U03HV023K2R\u003e we've seen a lot of general buzz around Continuity Camera since the announcement yesterday. One question folks were asking is, how close does your phone need to be to your mac in order to show up as a camera?",
      "ts": "1654626813.337789",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "J2AD",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03HV023K2R"
                },
                {
                  "type": "text",
                  "text": " we've seen a lot of general buzz around Continuity Camera since the announcement yesterday. One question folks were asking is, how close does your phone need to be to your mac in order to show up as a camera?"
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03J7MQP71R\u003e asked\n\u0026gt; Seems there is a slight lip sync issue when Karen is using Continuity Camera, so which mic is used from iPhone or from the Mac? Is it configurable through API?",
      "ts": "1654626953.136009",
      "thread_ts": "1654626953.136009",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 3,
      "latest_reply": "1654627294.111429",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "ptln",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03J7MQP71R"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Seems there is a slight lip sync issue when Karen is using Continuity Camera, so which mic is used from iPhone or from the Mac? Is it configurable through API?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "027d272c-08d6-4393-a92b-b4b7ec75a75b",
          "type": "message",
          "user": "U03HV023K2R",
          "text": "The audio in the session is from filming. You can use either built-in mic or Continuity Camera mic with the Continuity Camera. The Continuity mic can be found with both AVAudioSession and AVCapture APIs.",
          "ts": "1654627131.727779",
          "thread_ts": "1654626953.136009",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "I8b",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "The audio in the session is from filming. You can use either built-in mic or Continuity Camera mic with the Continuity Camera. The Continuity mic can be found with both AVAudioSession and AVCapture APIs."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "5e3f1ef3-f292-4ca0-aa89-70dc7b43cf69",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "And the A/V sync is good! :slightly_smiling_face: Whether you use a built in mic or the iPhone's microphone, we take care of it for you.",
          "ts": "1654627233.517439",
          "thread_ts": "1654626953.136009",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "FMP",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "And the A/V sync is good! "
                    },
                    {
                      "type": "emoji",
                      "name": "slightly_smiling_face",
                      "skin_tone": 0
                    },
                    {
                      "type": "text",
                      "text": " Whether you use a built in mic or the iPhone's microphone, we take care of it for you."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "a72f1bcf-c7ce-4876-9b74-ce46c561b393",
          "type": "message",
          "user": "U03J7MQP71R",
          "text": "I see, thanks :slightly_smiling_face:",
          "ts": "1654627294.111429",
          "thread_ts": "1654626953.136009",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "e0I",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I see, thanks "
                    },
                    {
                      "type": "emoji",
                      "name": "slightly_smiling_face",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03JKQJ4SA0\u003e asked\n\u0026gt; Continuity features (so far at least) have not been supported for Managed AppleIDs - does the Camera Continuity adhere to the same restriction?",
      "ts": "1654627161.410669",
      "thread_ts": "1654627161.410669",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 2,
      "latest_reply": "1654627227.480599",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "4JmYb",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03JKQJ4SA0"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Continuity features (so far at least) have not been supported for Managed AppleIDs - does the Camera Continuity adhere to the same restriction?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "15d7457e-99e8-40e6-aaf1-5fe49d7d3e96",
          "type": "message",
          "user": "U03HV023K2R",
          "text": "Yes, it has the same restrictions as other continuity features.",
          "ts": "1654627205.587879",
          "thread_ts": "1654627161.410669",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "ioiCZ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Yes, it has the same restrictions as other continuity features."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "aeddd5eb-1bb2-47cd-bb69-22ecd6bf5826",
          "type": "message",
          "user": "U03JKQJ4SA0",
          "text": ":disappointed: Thank you",
          "ts": "1654627227.480599",
          "thread_ts": "1654627161.410669",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "PCMWW",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "emoji",
                      "name": "disappointed",
                      "skin_tone": 0
                    },
                    {
                      "type": "text",
                      "text": " Thank you"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "235fcf52-3b57-46ca-b99c-a8b2c8d775b5",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": "Hi everyone — we'll take questions until 11:50 and then wrap up a bit early. Any burning questions? Let's hear 'em.",
      "ts": "1654627460.849509",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "EVV",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Hi everyone — we'll take questions until 11:50 and then wrap up a bit early. Any burning questions? Let's hear 'em."
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "e2595363-deb5-4587-8bf4-5a8907c294eb",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": "\u003c@U03HV023K2R\u003e in our previous hour's Q\u0026amp;A session, one developer asked if Continuity Camera works over USB as well as WiFi. Does it?",
      "ts": "1654627591.326099",
      "thread_ts": "1654627591.326099",
      "reply_count": 1,
      "latest_reply": "1654627636.520459",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "vyS",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03HV023K2R"
                },
                {
                  "type": "text",
                  "text": " in our previous hour's Q\u0026A session, one developer asked if Continuity Camera works over USB as well as WiFi. Does it?"
                }
              ]
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "2723539c-28c2-451b-ae79-41c13e097f83",
          "type": "message",
          "user": "U03HV023K2R",
          "text": "Yes it works with both USB and WiFi!",
          "ts": "1654627636.520459",
          "thread_ts": "1654627591.326099",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "raised_hands",
              "count": 2,
              "users": [
                "U03JMNR97J7",
                "U03J22YQMK4"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "wjd",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Yes it works with both USB and WiFi!"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03HZ4B0S1K\u003e asked\n\u0026gt; Do continuity camera sample buffer timestamps account for network delay? If you use a continuity camera and a macOS connected USB microphone, will the timing between them match up?",
      "ts": "1654627663.708039",
      "thread_ts": "1654627663.708039",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 2,
      "latest_reply": "1654627813.529559",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "O===p",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03HZ4B0S1K"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Do continuity camera sample buffer timestamps account for network delay? If you use a continuity camera and a macOS connected USB microphone, will the timing between them match up?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "d6a3b5d4-ec0e-4963-bd6e-3d1ca864335e",
          "type": "message",
          "user": "U03HV023K2R",
          "text": "Yes, it's all covered! The buffer timestamps from continuity camera will reflect capture time on the phone converted to mac's timeline.",
          "ts": "1654627793.754169",
          "thread_ts": "1654627663.708039",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "gS/",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Yes, it's all covered! The buffer timestamps from continuity camera will reflect capture time on the phone converted to mac's timeline."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "d90d0ae9-d375-4737-9873-eff4a3b4f58b",
          "type": "message",
          "user": "U03HZ4B0S1K",
          "text": "Great, thanks Karen!",
          "ts": "1654627813.529559",
          "thread_ts": "1654627663.708039",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "GjV",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Great, thanks Karen!"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03HZ4B0S1K\u003e asked\n\u0026gt; Is there any lossy compression/encoding applied to the iOS camera stream that would result in lower quality recordings compared to recording on-iOS device?",
      "ts": "1654627939.683199",
      "thread_ts": "1654627939.683199",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 1,
      "latest_reply": "1654627983.053799",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "zJjcs",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03HZ4B0S1K"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Is there any lossy compression\\/encoding applied to the iOS camera stream that would result in lower quality recordings compared to recording on-iOS device?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "b4d86fce-55ad-4847-8d72-e3ca76a1ab1b",
          "type": "message",
          "user": "U03HV023K2R",
          "text": "Technically there's a lossy compression applied during transport. But it's sufficiently high bit rate that we think you won't notice quality loss.",
          "ts": "1654627983.053799",
          "thread_ts": "1654627939.683199",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "compression",
              "count": 1,
              "users": [
                "U03HZ4B0S1K"
              ]
            },
            {
              "name": "bow",
              "count": 1,
              "users": [
                "U03HZ4B0S1K"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "TPG",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Technically there's a lossy compression applied during transport. But it's sufficiently high bit rate that we think you won't notice quality loss."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "8a982dac-afdf-4215-a5ac-ce9d23871893",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": "Thanks everyone for participating in our Meet the Presenter session for the new Continuity Camera feature! It’s a lot to take in. You may still be processing. We’ll be around for several more events during the week.\nWednesday 2-5 PM PDT: Camera Capture Lab #1. Sign up by end of day today if you’d like a slot.\nThursday 10-11 AM PDT: Q\u0026amp;A Camera session #2. Right here!\nFriday 9 AM - 12 PM PDT: Camera Capture Lab #2. Sign up by end of Thursday with your questions.",
      "ts": "1654628018.473779",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "i75",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Thanks everyone for participating in our Meet the Presenter session for the new Continuity Camera feature! It’s a lot to take in. You may still be processing. We’ll be around for several more events during the week.\nWednesday 2-5 PM PDT: Camera Capture Lab #1. Sign up by end of day today if you’d like a slot.\nThursday 10-11 AM PDT: Q\u0026A Camera session #2. Right here!\nFriday 9 AM - 12 PM PDT: Camera Capture Lab #2. Sign up by end of Thursday with your questions."
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "883601a9-a662-489a-98cf-f1a7af90c678",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": "We’ll also have two more Meet the Presenter Digital Lounge Sessions:\nWednesday 10 AM: Discover advancements in iOS camera capture\nThursday 11 AM: Create camera extensions with CoreMediaIO\nWe hope to see you there. :wave: :pray:",
      "ts": "1654628084.418899",
      "team": "T031SG5MZ7U",
      "reactions": [
        {
          "name": "pray",
          "count": 5,
          "users": [
            "U03HZ4B0S1K",
            "U03HVDF8N6A",
            "U03JMNR97J7",
            "U03JRP87THN",
            "U03J22YQMK4"
          ]
        },
        {
          "name": "bow",
          "count": 4,
          "users": [
            "U03HZ4B0S1K",
            "U03JRQ81NEL",
            "U03JMNR97J7",
            "U03J22YQMK4"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "LO5",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "We’ll also have two more Meet the Presenter Digital Lounge Sessions:\nWednesday 10 AM: Discover advancements in iOS camera capture\nThursday 11 AM: Create camera extensions with CoreMediaIO\nWe hope to see you there. "
                },
                {
                  "type": "emoji",
                  "name": "wave",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": " "
                },
                {
                  "type": "emoji",
                  "name": "pray",
                  "skin_tone": 0
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03JMNR97J7\u003e asked\n\u0026gt; Does Continuity Camera allow access to the LiDaR scanner as well? Can it be used to support ARKit effects on Mac?\n\u0026gt; \n\u0026gt; Thanks!",
      "ts": "1654628181.206099",
      "thread_ts": "1654628181.206099",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 2,
      "latest_reply": "1654628459.534009",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "/A65p",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03JMNR97J7"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Does Continuity Camera allow access to the LiDaR scanner as well? Can it be used to support ARKit effects on Mac?\\n\\nThanks!\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "51002c9b-3ac5-4101-896e-2f0c540dde46",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Currently we only support the wide angle RGB camera (the one with the best quality!). We do internally switch to the Ultrawide camera when Center Stage is enabled. And DeskView also uses the Ultrawide camera. There is currently no access to the telephoto lens (if present) or LiDAR camera (if present).",
          "ts": "1654628245.741949",
          "thread_ts": "1654628181.206099",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U03JMNR97J7"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "voF",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Currently we only support the wide angle RGB camera (the one with the best quality!). We do internally switch to the Ultrawide camera when Center Stage is enabled. And DeskView also uses the Ultrawide camera. There is currently no access to the telephoto lens (if present) or LiDAR camera (if present)."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "3939f5e3-ec43-46a1-a6d3-52d7767d0c44",
          "type": "message",
          "user": "U03JMNR97J7",
          "text": "Ah, alrighty, understood! Thanks for the quick response Brad. I’m so excited for this feature, it was something that I didn’t even realize how much I needed. If you ever do get telephoto/LiDAR access going that would be huge in my opinion. :wink:\n\nThanks so much to yourself and team!",
          "ts": "1654628459.534009",
          "thread_ts": "1654628181.206099",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "point_up",
              "count": 2,
              "users": [
                "U03J22YQMK4",
                "U03JMB7160Z"
              ]
            },
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U03HZ5T63N1"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "gTF=",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Ah, alrighty, understood! Thanks for the quick response Brad. I’m so excited for this feature, it was something that I didn’t even realize how much I needed. If you ever do get telephoto/LiDAR access going that would be huge in my opinion. "
                    },
                    {
                      "type": "emoji",
                      "name": "wink",
                      "skin_tone": 0
                    },
                    {
                      "type": "text",
                      "text": "\n\nThanks so much to yourself and team!"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "a92725bd-a4ea-4bb0-95c8-1d101609fba5",
      "type": "message",
      "user": "U03DJTBMHFF",
      "text": "Thank you Brad, Karen, and the whole engineering team that joined this morning. And thank all of *you* for the great questions. We'll be opening up the workflow on this channel again tomorrow.",
      "ts": "1654628384.631509",
      "team": "T031SG5MZ7U",
      "reactions": [
        {
          "name": "+1",
          "count": 3,
          "users": [
            "U03JMNR97J7",
            "U03JDTS6RKP",
            "U03J5SM2VUJ"
          ]
        },
        {
          "name": "100",
          "count": 2,
          "users": [
            "U03JMNR97J7",
            "U03JBEQUEAJ"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "2pFR",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Thank you Brad, Karen, and the whole engineering team that joined this morning. And thank all of "
                },
                {
                  "type": "text",
                  "text": "you",
                  "style": {
                    "bold": true
                  }
                },
                {
                  "type": "text",
                  "text": " for the great questions. We'll be opening up the workflow on this channel again tomorrow."
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "1888a87d-38da-47c1-9379-8917ecf65825",
      "type": "message",
      "user": "U03DJTBMHFF",
      "text": "*\u003c!here\u003e* *Welcome to WWDC22 Day 3!* We have some great activities in this lounge this morning.\n• At 9:00 AM we kick it off with _*Q\u0026amp;A: Core Image*_. Join us to ask your questions of the Core Image engineering team and engage in what is sure to be a lively conversation.\n• Then at 10:00 AM, will all hit play together for a watch party with _*Meet the Presenter: Discover advancements in iOS camera capture*_. Nikolas Gelo will be in the room along with a whole host of engineers from the Camera team to talk with you about LiDAR Depth, face-driven autoexposure and autofocus, camera multitasking, and more. Not one to miss!\nSee you all in 10 minutes…",
      "ts": "1654703557.897249",
      "team": "T031SG5MZ7U",
      "reactions": [
        {
          "name": "swift-blue",
          "count": 3,
          "users": [
            "U03J97B2WSZ",
            "U03J20RJQ2X",
            "U03J8B88VE1"
          ]
        },
        {
          "name": "raised_hands",
          "count": 6,
          "users": [
            "U03JRP87THN",
            "U03K6CZC8LQ",
            "U03J97B2WSZ",
            "U03HZ4BPHPX",
            "U03HVE4BEBY",
            "U03J8B88VE1"
          ]
        },
        {
          "name": "+1",
          "count": 3,
          "users": [
            "U03HB0AV6S3",
            "U03HVD5TM7G",
            "U03J8B88VE1"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "bRopg",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "broadcast",
                  "range": "here"
                },
                {
                  "type": "text",
                  "text": " "
                },
                {
                  "type": "text",
                  "text": "Welcome to WWDC22 Day 3!",
                  "style": {
                    "bold": true
                  }
                },
                {
                  "type": "text",
                  "text": " We have some great activities in this lounge this morning.\n"
                }
              ]
            },
            {
              "Type": "rich_text_list",
              "Raw": "{\"type\":\"rich_text_list\",\"elements\":[{\"type\":\"rich_text_section\",\"elements\":[{\"type\":\"text\",\"text\":\"At 9:00 AM we kick it off with \"},{\"type\":\"text\",\"text\":\"Q\u0026A: Core Image\",\"style\":{\"bold\":true,\"italic\":true}},{\"type\":\"text\",\"text\":\". Join us to ask your questions of the Core Image engineering team and engage in what is sure to be a lively conversation.\"}]},{\"type\":\"rich_text_section\",\"elements\":[{\"type\":\"text\",\"text\":\"Then at 10:00 AM, will all hit play together for a watch party with \"},{\"type\":\"text\",\"text\":\"Meet the Presenter: Discover advancements in iOS camera capture\",\"style\":{\"bold\":true,\"italic\":true}},{\"type\":\"text\",\"text\":\". Nikolas Gelo will be in the room along with a whole host of engineers from the Camera team to talk with you about LiDAR Depth, face-driven autoexposure and autofocus, camera multitasking, and more. Not one to miss!\"}]}],\"style\":\"bullet\",\"indent\":0,\"border\":0}"
            },
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "See you all in 10 minutes…"
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "e053386e-f5f7-4644-91e5-222f82d42dad",
      "type": "message",
      "user": "U03DJTBMHFF",
      "text": "\u003c!here\u003e *Let's get the party started!* Workflows are enabled now for you to submit your questions to the Core Image engineering team. And if you've got an idea or feature request, there's a workflow for that as well. Use the \"+\" button to submit. Also, all are welcome to comment and ask follow-up questions in threads. Let's have a fun, active conversation for the next hour.",
      "ts": "1654704092.028799",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "qy=",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "broadcast",
                  "range": "here"
                },
                {
                  "type": "text",
                  "text": " "
                },
                {
                  "type": "text",
                  "text": "Let's get the party started! ",
                  "style": {
                    "bold": true
                  }
                },
                {
                  "type": "text",
                  "text": "Workflows are enabled now for you to submit your questions to the Core Image engineering team. And if you've got an idea or feature request, there's a workflow for that as well. Use the \"+\" button to submit. Also, all are welcome to comment and ask follow-up questions in threads. Let's have a fun, active conversation for the next hour."
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "5594f5fa-6b65-437a-9e7a-dd5d6c9cd4ee",
      "type": "message",
      "user": "U03DJTBMHFF",
      "text": "*Open Discussion:* Core Image is capable of a vast number of things. It is of course tremendously useful in image editing apps and video-based apps, and it can also play a vital roll in image understanding and machine-learning based apps. What do you use Core Image for in your apps? :thread:",
      "ts": "1654704353.522229",
      "thread_ts": "1654704353.522229",
      "reply_count": 1,
      "latest_reply": "1654704552.272869",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "Igs0p",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Open Discussion: ",
                  "style": {
                    "bold": true
                  }
                },
                {
                  "type": "text",
                  "text": "Core Image is capable of a vast number of things. It is of course tremendously useful in image editing apps and video-based apps, and it can also play a vital roll in image understanding and machine-learning based apps. What do you use Core Image for in your apps? "
                },
                {
                  "type": "emoji",
                  "name": "thread",
                  "skin_tone": 0
                }
              ]
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "42a30e70-386d-4819-9dc5-d7f437fb4164",
          "type": "message",
          "user": "U03HVD5TM7G",
          "text": "Our apps turn images (and videos) into pieces of art with artistic filters like oil painting, watercolor, comic, and pencil hatching. We rely heavily on Core Image and custom Metal-based kernels and the quality and performance we achieve with that is absolutely amazing! :smiley:",
          "ts": "1654704552.272869",
          "thread_ts": "1654704353.522229",
          "parent_user_id": "U03DJTBMHFF",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "heart",
              "count": 2,
              "users": [
                "U03DJTBMHFF",
                "U03J20RJQ2X"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "t1nc",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Our apps turn images (and videos) into pieces of art with artistic filters like oil painting, watercolor, comic, and pencil hatching. We rely heavily on Core Image and custom Metal-based kernels and the quality and performance we achieve with that is absolutely amazing! "
                    },
                    {
                      "type": "emoji",
                      "name": "smiley",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03HVD5TM7G\u003e asked\n\u0026gt; Can we leverage the increase-memory-limit entitlement within an image \u0026amp; video processing app? Can we give Core Image access to more memory for processing and caching?",
      "ts": "1654704369.790999",
      "thread_ts": "1654704369.790999",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 1,
      "latest_reply": "1654704471.524749",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "OnD1",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03HVD5TM7G"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Can we leverage the increase-memory-limit entitlement within an image \u0026 video processing app? Can we give Core Image access to more memory for processing and caching?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "e1c3208c-719a-4fd3-aee9-f862d893b01f",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "We are actively working on this.  Feel free to also file an enhancement request if you need a specific need addressed.",
          "ts": "1654704471.524749",
          "thread_ts": "1654704369.790999",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U03HVD5TM7G"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "G4PRX",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "We are actively working on this.  Feel free to also file an enhancement request if you need a specific need addressed."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03JG9JF529\u003e asked\n\u0026gt; Is it possible to write a CoreImage filter for compute, rather than render? I'd like to perform compute operations on the CVPixelBuffer of a depth map, which I can represent as a CIImage.",
      "ts": "1654704538.162659",
      "thread_ts": "1654704538.162659",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 12,
      "latest_reply": "1654706226.896379",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "t3op",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03JG9JF529"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Is it possible to write a CoreImage filter for compute, rather than render? I'd like to perform compute operations on the CVPixelBuffer of a depth map, which I can represent as a CIImage.\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "de20da4c-fda5-4ce1-a77d-bf49091fcd94",
          "type": "message",
          "user": "U03HRLP9NSX",
          "text": "Hi, CoreImage does use Metal compute pipeline states to perform the chained CIKernel operations you apply to the image. When you encode renders with CI, it dispatches compute commands instead of render commands.",
          "ts": "1654704666.144029",
          "thread_ts": "1654704538.162659",
          "edited": {
            "user": "U03HRLP9NSX",
            "ts": "1654704684.000000"
          },
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "hb5",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi, CoreImage does use Metal compute pipeline states to perform the chained CIKernel operations you apply to the image. When you encode renders with CI, it dispatches compute commands instead of render commands."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "18943a70-5342-4cad-9820-30bba1e93a46",
          "type": "message",
          "user": "U03JG9JF529",
          "text": "When I have tried this my values get mutated between what is returned in my metal code and what is rendered. Are there settings we need to change in the CIContext to prevent things like premultiplied alpha, and any other settings that might change / clamp / remap the outputs?",
          "ts": "1654704770.432209",
          "thread_ts": "1654704538.162659",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "IXAO",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "When I have tried this my values get mutated between what is returned in my metal code and what is rendered. Are there settings we need to change in the CIContext to prevent things like premultiplied alpha, and any other settings that might change / clamp / remap the outputs?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "6a9800be-c626-4e93-add7-39d3bf19c575",
          "type": "message",
          "user": "U03HRMK2074",
          "text": "These might be helpful",
          "ts": "1654704909.134529",
          "thread_ts": "1654704538.162659",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "uupy",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "These might be helpful"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "efa893d0-9e60-4558-b506-ed557e8d1986",
          "type": "message",
          "user": "U03HRMK2074",
          "text": "\u003chttps://developer.apple.com/documentation/coreimage/cirenderdestination/2875443-alphamode?language=objc\u003e",
          "ts": "1654704913.003449",
          "thread_ts": "1654704538.162659",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "204vC",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/coreimage/cirenderdestination/2875443-alphamode?language=objc",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "b97796bd-e469-494e-a731-207b9bf84cd7",
          "type": "message",
          "user": "U03HRMK2074",
          "text": "\u003chttps://developer.apple.com/documentation/coreimage/cirenderdestination/2875451-clamped?language=objc\u003e",
          "ts": "1654704926.720999",
          "thread_ts": "1654704538.162659",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "y3BRM",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/coreimage/cirenderdestination/2875451-clamped?language=objc",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "604a4726-5576-4d6e-aaf4-93136da5812e",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "Also if you want, you can tell CI to disable color management using the the context option `kCIContextWorkingColorSpace : [NSNull null]` but use that with caution.",
          "ts": "1654705005.749739",
          "thread_ts": "1654704538.162659",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "or5LH",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Also if you want, you can tell CI to disable color management using the the context option "
                    },
                    {
                      "type": "text",
                      "text": "kCIContextWorkingColorSpace : [NSNull null]",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " but use that with caution."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "34b3f4f5-7cea-4683-9cd9-251ee6388c0f",
          "type": "message",
          "user": "U03HRLP9NSX",
          "text": "In addition to what Baljit mentioned, mutated pixel values could be due to color management. CVPixelBuffers often are tagged with color space metadata and CI by default would color manage the input data to the CIContext's 'working space' and then convert to the output destination's color space when the image is rendered. This is on by default since it is usually desirable. But you do have the option to disable color management  if you choose to. In the case of the depth map I think you'd want the data to remain linear. So either you can turn off color management as David suggested above, or set the render destination's color space to match the input.",
          "ts": "1654705079.328149",
          "thread_ts": "1654704538.162659",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "OAkU",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "In addition to what Baljit mentioned, mutated pixel values could be due to color management. CVPixelBuffers often are tagged with color space metadata and CI by default would color manage the input data to the CIContext's 'working space' and then convert to the output destination's color space when the image is rendered. This is on by default since it is usually desirable. But you do have the option to disable color management  if you choose to. In the case of the depth map I think you'd want the data to remain linear. So either you can turn off color management as David suggested above, or set the render destination's color space to match the input."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "2b6023d7-2ea5-4102-80b2-23c0a90b3043",
          "type": "message",
          "user": "U03JG9JF529",
          "text": "Thank you all :slightly_smiling_face: I will investigate these options",
          "ts": "1654705107.059909",
          "thread_ts": "1654704538.162659",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "cCA",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thank you all "
                    },
                    {
                      "type": "emoji",
                      "name": "slightly_smiling_face",
                      "skin_tone": 0
                    },
                    {
                      "type": "text",
                      "text": " I will investigate these options"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "ab1c088d-bea5-4b7a-ad05-397582e3a5fd",
          "type": "message",
          "user": "U03JG9JF529",
          "text": "Is there much performance overhead in rendering this (e.g. to bytes) from a CIContext to inspect the values, vs creating a metal buffer and inspecting them there? And does this change if I am using other `CIFilter`s such as masks",
          "ts": "1654705364.953569",
          "thread_ts": "1654704538.162659",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "0/e",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Is there much performance overhead in rendering this (e.g. to bytes) from a CIContext to inspect the values, vs creating a metal buffer and inspecting them there? And does this change if I am using other "
                    },
                    {
                      "type": "text",
                      "text": "CIFilter",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "s such as masks"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "0c0f566b-1b28-449b-8b36-8a9a29092aba",
          "type": "message",
          "user": "U03HRLP9NSX",
          "text": "I don't think we offer an API to render to a MTLBuffer. If you're comparing rendering to bytes vs rendering to texture, I think the difference should be fairly minimal on devices with unified memory architecture. Synchronization between the GPU memory and system memory is required in both cases so I think it should be fairly close.",
          "ts": "1654705597.568559",
          "thread_ts": "1654704538.162659",
          "edited": {
            "user": "U03HRLP9NSX",
            "ts": "1654705624.000000"
          },
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "5b3cW",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I don't think we offer an API to render to a MTLBuffer. If you're comparing rendering to bytes vs rendering to texture, I think the difference should be fairly minimal on devices with unified memory architecture. Synchronization between the GPU memory and system memory is required in both cases so I think it should be fairly close."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "3b88b350-11ad-49ec-8c5f-c3e18c8fab5a",
          "type": "message",
          "user": "U03JG9JF529",
          "text": "Thanks",
          "ts": "1654706080.757569",
          "thread_ts": "1654704538.162659",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "5iQ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "830e18d8-d2e9-4519-b4fc-4caa31c38ff8",
          "type": "message",
          "user": "U03JG9JF529",
          "text": "There is a render to metal texture \u003chttps://developer.apple.com/documentation/coreimage/cicontext/1438026-render|function\u003e. I wondered if it would be quicker than to bytes",
          "ts": "1654706226.896379",
          "thread_ts": "1654704538.162659",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "f4H",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "There is a render to metal texture "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/coreimage/cicontext/1438026-render",
                      "text": "function"
                    },
                    {
                      "type": "text",
                      "text": ". I wondered if it would be quicker than to bytes"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03JG9JF529\u003e asked\n\u0026gt; We have `CIFilter.personSegmentation()`. Is there a way to generate the other segmentation mattes (skin, hair) from AVPhotoCapture on demand using CIImages?",
      "ts": "1654704615.625859",
      "thread_ts": "1654704615.625859",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 6,
      "latest_reply": "1654706129.077249",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "NVj",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03JG9JF529"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"We have `CIFilter.personSegmentation()`. Is there a way to generate the other segmentation mattes (skin, hair) from AVPhotoCapture on demand using CIImages?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "9d2d0a88-0f5f-4159-afbe-fd27e44b4041",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "Please file an enhancement request for that.  That said some Jpeg/Heic/ProRaw images already contain \"aux images\" for other segmentations.  You can get at these either though ImageIO or CoreImage APIs",
          "ts": "1654704719.978229",
          "thread_ts": "1654704615.625859",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "t=/8H",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Please file an enhancement request for that.  That said some Jpeg/Heic/ProRaw images already contain \"aux images\" for other segmentations.  You can get at these either though ImageIO or CoreImage APIs"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "7ece5186-8954-44c2-aa0e-7768bd9cd57b",
          "type": "message",
          "user": "U03JG9JF529",
          "text": "Thanks, I will do. I was hoping to be able to apply this to video so can’t access those file types",
          "ts": "1654704825.010879",
          "thread_ts": "1654704615.625859",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "00oYE",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks, I will do. I was hoping to be able to apply this to video so can’t access those file types"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "1aee7b55-fee0-4f14-8f4b-137d820ad6af",
          "type": "message",
          "user": "U03J20RJQ2X",
          "text": "Does the person segmentation filter return the same results as a VNGeneratePersonSegmentationRequest? I just learned they added a filter as well",
          "ts": "1654705572.044809",
          "thread_ts": "1654704615.625859",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "9f1lc",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Does the person segmentation filter return the same results as a VNGeneratePersonSegmentationRequest? I just learned they added a filter as well"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "7f65abe9-b279-4567-9a8b-4d1df5d99bfc",
          "type": "message",
          "user": "U03JG9JF529",
          "text": "It seems to do from my experiments",
          "ts": "1654705854.028039",
          "thread_ts": "1654704615.625859",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "vz2e5",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "It seems to do from my experiments"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "23bbaefc-673e-4812-81d1-d63d94b5cfd1",
          "type": "message",
          "user": "U03JG9JF529",
          "text": "The quality parameters give the same sized buffers as results",
          "ts": "1654705871.163679",
          "thread_ts": "1654704615.625859",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "ADFz",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "The quality parameters give the same sized buffers as results"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "02f49a18-f06f-4d4a-9b50-9f7186899979",
          "type": "message",
          "user": "U03J20RJQ2X",
          "text": "\u003c@U03JG9JF529\u003e Interesting, I’ll have to give that a try!",
          "ts": "1654706129.077249",
          "thread_ts": "1654704615.625859",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "84Z",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "user",
                      "user_id": "U03JG9JF529"
                    },
                    {
                      "type": "text",
                      "text": " Interesting, I’ll have to give that a try!"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03HVE4BEBY\u003e asked\n\u0026gt; Is there any chance of seeing a CIFilter for film grain, that’s more natural looking than the CIRandonGenerator?",
      "ts": "1654704788.419849",
      "thread_ts": "1654704788.419849",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 4,
      "latest_reply": "1654706478.686419",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "qa1",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03HVE4BEBY"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Is there any chance of seeing a CIFilter for film grain, that\\u2019s more natural looking than the CIRandonGenerator?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "461c37df-53f8-43fa-8d23-7d9d80777ff6",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "Please file an enhancement request.  That would be great to add.",
          "ts": "1654704846.779259",
          "thread_ts": "1654704788.419849",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "bz1",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Please file an enhancement request.  That would be great to add."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "F0CE63FF-24FD-4514-9C62-3C957312566A",
          "type": "message",
          "user": "U03HVE4BEBY",
          "text": "Will do!",
          "ts": "1654704856.479649",
          "thread_ts": "1654704788.419849",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "R02Q",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Will"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "do!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "bf40ac09-d604-4fd0-b314-4151edf3e112",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "You may also want to try the `CIDither` filter.",
          "ts": "1654706214.571339",
          "thread_ts": "1654704788.419849",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "MNM",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "You may also want to try the "
                    },
                    {
                      "type": "text",
                      "text": "CIDither",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " filter."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "1B729980-5F8C-4347-9CB7-A03F594212FF",
          "type": "message",
          "user": "U03HVE4BEBY",
          "text": "I’ll have a look at combining that with the random noise maybe, though I'm hoping to filter a live camera feed, hopefully it'll be performant enough. (Also CIDither doesn't seem to be listed on the Core Image Filter Reference page)",
          "ts": "1654706478.686419",
          "thread_ts": "1654704788.419849",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Etcv",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I’ll"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "have"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "a"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "look"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "at"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "combining"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "that"
                    },
                    {
                      "type": "text",
                      "text": " with "
                    },
                    {
                      "type": "text",
                      "text": "the"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "random"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "noise"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "maybe,"
                    },
                    {
                      "type": "text",
                      "text": " though I'm "
                    },
                    {
                      "type": "text",
                      "text": "hoping"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "to"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "filter"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "a"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "live"
                    },
                    {
                      "type": "text",
                      "text": " camera "
                    },
                    {
                      "type": "text",
                      "text": "feed,"
                    },
                    {
                      "type": "text",
                      "text": " hopefully it'll "
                    },
                    {
                      "type": "text",
                      "text": "be"
                    },
                    {
                      "type": "text",
                      "text": " performan"
                    },
                    {
                      "type": "text",
                      "text": "t"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "enough. (Also"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "CIDither"
                    },
                    {
                      "type": "text",
                      "text": " doesn't "
                    },
                    {
                      "type": "text",
                      "text": "seem"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "to"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "be"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "listed"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "on"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "the"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "Core"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "Image"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "Filter"
                    },
                    {
                      "type": "text",
                      "text": " Reference "
                    },
                    {
                      "type": "text",
                      "text": "page)"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "91b86742-de7a-4543-9e80-10bfa82c6715",
      "type": "message",
      "user": "U03DJTBMHFF",
      "text": "*Idea Submission: \u003c@U03HVD5TM7G\u003e* shared this.\n\u0026gt; It would be great if CIImageAccumulator would support single-channel formats in addition to RGBA. We are using it to let the user draw parameter masks which would only require a single .Rh channel. But since only RGBA is allowed, we are wasting a lot of memory. Thanks!\n:thread:",
      "ts": "1654705363.695589",
      "thread_ts": "1654705363.695589",
      "reply_count": 13,
      "latest_reply": "1654706404.464839",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "767",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Idea Submission: ",
                  "style": {
                    "bold": true
                  }
                },
                {
                  "type": "user",
                  "user_id": "U03HVD5TM7G",
                  "style": {
                    "bold": true
                  }
                },
                {
                  "type": "text",
                  "text": " ",
                  "style": {
                    "bold": true
                  }
                },
                {
                  "type": "text",
                  "text": "shared this.\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"It would be great if CIImageAccumulator would support single-channel formats in addition to RGBA. We are using it to let the user draw parameter masks which would only require a single .Rh channel. But since only RGBA is allowed, we are wasting a lot of memory. Thanks!\"}]}"
            },
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "emoji",
                  "name": "thread",
                  "skin_tone": 0
                }
              ]
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "f9fd501c-b0a8-4f1e-a982-3e7584296dbe",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "This is a great enhancement request for `CIImageAccumulator`.  In the meet time you can use a Rh IOSurface-backed `CIRenderDestination` as an alternative API.",
          "ts": "1654705545.427139",
          "thread_ts": "1654705363.695589",
          "parent_user_id": "U03DJTBMHFF",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "SqR",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "This is a great enhancement request for "
                    },
                    {
                      "type": "text",
                      "text": "CIImageAccumulator",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": ".  In the meet time you can use a Rh IOSurface-backed "
                    },
                    {
                      "type": "text",
                      "text": "CIRenderDestination",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " as an alternative API."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "a12a73f5-30a7-4eb1-8a59-1b1fb670657f",
          "type": "message",
          "user": "U03HVD5TM7G",
          "text": "Ah, good idea! But then I would need to do the rendering (that otherwise happens in setImage) myself… I’ll give it a try!",
          "ts": "1654705669.694789",
          "thread_ts": "1654705363.695589",
          "parent_user_id": "U03DJTBMHFF",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "CAg",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Ah, good idea! But then I would need to do the rendering (that otherwise happens in setImage) myself… I’ll give it a try!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "bce1e996-16ac-41ab-bb3c-b56f839dc0db",
          "type": "message",
          "user": "U03HVD5TM7G",
          "text": "Enhancement request is filed under FB9061252.",
          "ts": "1654705704.722949",
          "thread_ts": "1654705363.695589",
          "parent_user_id": "U03DJTBMHFF",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "DOF",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Enhancement request is filed under FB9061252."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "09c97ad2-80f2-4c25-8a8f-25c953aaabf1",
          "type": "message",
          "user": "U03HRMK2074",
          "text": "Would configuring a blendKernel for the CIRenderDestination be useful in this case?",
          "ts": "1654705721.871059",
          "thread_ts": "1654705363.695589",
          "parent_user_id": "U03DJTBMHFF",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U03HVD5TM7G"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "LBi",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Would configuring a blendKernel for the CIRenderDestination be useful in this case?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "49c98bf1-a7b9-44f6-a710-8dd559fa86c5",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "Yes.  Setting the `.blendKernel` is useful in this scenario of using a `CIrenderDestination` to \"accumulate\" a brushing.",
          "ts": "1654705850.430259",
          "thread_ts": "1654705363.695589",
          "parent_user_id": "U03DJTBMHFF",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "wWL",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Yes.  Setting the "
                    },
                    {
                      "type": "text",
                      "text": ".blendKernel",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " is useful in this scenario of using a "
                    },
                    {
                      "type": "text",
                      "text": "CIrenderDestination",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " to \"accumulate\" a brushing."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "144738e3-dd97-4cd0-90ea-5f3d5aab7a83",
          "type": "message",
          "user": "U03HVD5TM7G",
          "text": "Does `CIImageAccumulator` maintain its own `CIContext` ?",
          "ts": "1654705875.627409",
          "thread_ts": "1654705363.695589",
          "parent_user_id": "U03DJTBMHFF",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Iu/",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Does "
                    },
                    {
                      "type": "text",
                      "text": "CIImageAccumulator",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " maintain its own "
                    },
                    {
                      "type": "text",
                      "text": "CIContext",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " ?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "3bc998e9-b3f3-431e-92b5-795ec8cd29b4",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "Yes.",
          "ts": "1654705883.618529",
          "thread_ts": "1654705363.695589",
          "parent_user_id": "U03DJTBMHFF",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "NhDi",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Yes."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "4b00d93d-773d-47b6-a6d3-585419d8edb7",
          "type": "message",
          "user": "U03HVD5TM7G",
          "text": "Ok, then I can probably re-implement its behavior this way. Thanks!",
          "ts": "1654705918.568309",
          "thread_ts": "1654705363.695589",
          "parent_user_id": "U03DJTBMHFF",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "UxTKb",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Ok, then I can probably re-implement its behavior this way. Thanks!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "b91bf010-ded8-4efe-8939-aa2dbdaf151f",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "If you have further question, schedule a lab session on Friday.",
          "ts": "1654706005.237549",
          "thread_ts": "1654705363.695589",
          "parent_user_id": "U03DJTBMHFF",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "white_check_mark",
              "count": 1,
              "users": [
                "U03HVD5TM7G"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "gKYnc",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "If you have further question, schedule a lab session on Friday."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "d75cc266-8499-4cf1-b320-db3afe21e60f",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "One trick is to use `CIRadialGradient` as image to render as \"brush\" to \"accumulate\"",
          "ts": "1654706084.364299",
          "thread_ts": "1654705363.695589",
          "parent_user_id": "U03DJTBMHFF",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "lT7b",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "One trick is to use "
                    },
                    {
                      "type": "text",
                      "text": "CIRadialGradient",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " as image to render as \"brush\" to \"accumulate\""
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "de4dce92-fa2b-417e-b48a-f61c66063f89",
          "type": "message",
          "user": "U03HVD5TM7G",
          "text": "Yes, found that in the old CIMicroPaint demo. Works great!",
          "ts": "1654706170.068389",
          "thread_ts": "1654705363.695589",
          "parent_user_id": "U03DJTBMHFF",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "g1L",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Yes, found that in the old CIMicroPaint demo. Works great!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "4abd9a11-2a68-448f-abd2-4ac3a351db8a",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "(At some point I made a fork of the CIMicroPaint sample that uses a Rh CIRenderDestination instead and it is even faster)",
          "ts": "1654706346.994859",
          "thread_ts": "1654705363.695589",
          "parent_user_id": "U03DJTBMHFF",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "TMX9",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "(At some point I made a fork of the CIMicroPaint sample that uses a Rh CIRenderDestination instead and it is even faster)"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "b9d97c6d-2c4a-4a80-b217-a4f0bb7bd315",
          "type": "message",
          "user": "U03HVD5TM7G",
          "text": "(It would be great seeing that in action :wink:)",
          "ts": "1654706404.464839",
          "thread_ts": "1654705363.695589",
          "parent_user_id": "U03DJTBMHFF",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "100",
              "count": 1,
              "users": [
                "U03HB0AV6S3"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "c6P",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "(It would be great seeing that in action "
                    },
                    {
                      "type": "emoji",
                      "name": "wink",
                      "skin_tone": 0
                    },
                    {
                      "type": "text",
                      "text": ")"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03J20RJQ2X\u003e asked\n\u0026gt; I'm trying to blur the background of a photo, similar to what Portrait Mode does, using a matte of the person. What's a good approach to filling the area inside the subject so that there's no halo around the person when blurring the image?",
      "ts": "1654706388.813939",
      "thread_ts": "1654706388.813939",
      "edited": {
        "user": "B03J03EENBE",
        "ts": "1654706497.000000"
      },
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 10,
      "latest_reply": "1654707046.872719",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "irlW=",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03J20RJQ2X"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"I'm trying to blur the background of a photo, similar to what Portrait Mode does, using a matte of the person. What's a good approach to filling the area inside the subject so that there's no halo around the person when blurring the image?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "be273d3f-2712-46f5-a234-079fb025fe73",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "The simplest approach is to:",
          "ts": "1654706508.406179",
          "thread_ts": "1654706388.813939",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "D8P1",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "The simplest approach is to:"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "2cdc0303-5e6c-43e7-83d0-4325f9ead94d",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "• make a CIImage from the image where the foreground pixels are made transparent",
          "ts": "1654706574.875859",
          "thread_ts": "1654706388.813939",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "TiK1",
              "elements": [
                {
                  "Type": "rich_text_list",
                  "Raw": "{\"type\":\"rich_text_list\",\"elements\":[{\"type\":\"rich_text_section\",\"elements\":[{\"type\":\"text\",\"text\":\"make a CIImage from the image where the foreground pixels are made transparent\"}]}],\"style\":\"bullet\",\"indent\":0,\"border\":0}"
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "d119dbbe-06c8-400a-ad1c-751254bb0b05",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "• blur that image",
          "ts": "1654706583.483749",
          "thread_ts": "1654706388.813939",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "yXsg",
              "elements": [
                {
                  "Type": "rich_text_list",
                  "Raw": "{\"type\":\"rich_text_list\",\"elements\":[{\"type\":\"rich_text_section\",\"elements\":[{\"type\":\"text\",\"text\":\"blur that image\"}]}],\"style\":\"bullet\",\"indent\":0,\"border\":0}"
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "84d4f397-dc95-41ef-a9e2-a111babfba17",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "• device that image by its alpha channel ",
          "ts": "1654706606.303179",
          "thread_ts": "1654706388.813939",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "5Cb4",
              "elements": [
                {
                  "Type": "rich_text_list",
                  "Raw": "{\"type\":\"rich_text_list\",\"elements\":[{\"type\":\"rich_text_section\",\"elements\":[{\"type\":\"text\",\"text\":\"device that image by its alpha channel \"}]}],\"style\":\"bullet\",\"indent\":0,\"border\":0}"
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "712bf2d9-08fb-4fdf-944f-5d907e01b632",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "• use SourceOverCompositing to put the foreground image over the above result.",
          "ts": "1654706644.606009",
          "thread_ts": "1654706388.813939",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "3qk3",
              "elements": [
                {
                  "Type": "rich_text_list",
                  "Raw": "{\"type\":\"rich_text_list\",\"elements\":[{\"type\":\"rich_text_section\",\"elements\":[{\"type\":\"text\",\"text\":\"use SourceOverCompositing to put the foreground image over the above result.\"}]}],\"style\":\"bullet\",\"indent\":0,\"border\":0}"
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "b3a4c66c-81b6-4a3a-b2f2-36fd4f8615b2",
          "type": "message",
          "user": "U03J20RJQ2X",
          "text": "\u003c@U03HB0AV6S3\u003e thanks for the reply! By “device that image by its alpha channel”, do you mean making the transparent pixels opaque? That sounds like a good approach, I’ll give that a try",
          "ts": "1654706990.383799",
          "thread_ts": "1654706388.813939",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Fz/QJ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "user",
                      "user_id": "U03HB0AV6S3"
                    },
                    {
                      "type": "text",
                      "text": " thanks for the reply! By “device that image by its alpha channel”, do you mean making the transparent pixels opaque? That sounds like a good approach, I’ll give that a try"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "dab08473-21e3-40c8-a92c-af4246c22390",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "I meant to type \"devide that image by its alpha channel\"",
          "ts": "1654707011.571099",
          "thread_ts": "1654706388.813939",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "4NH53",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I meant to type \"devide that image by its alpha channel\""
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "b0a8d665-284f-4bc7-80a5-ca03c75ea8ae",
          "type": "message",
          "user": "U03J20RJQ2X",
          "text": "Oh of course! Thanks!",
          "ts": "1654707042.986089",
          "thread_ts": "1654706388.813939",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "hqSn6",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Oh of course! Thanks!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "d66ab0c5-1de0-480d-85b2-f03f12a7ad28",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "WIth a custom CIKernel like this:",
          "ts": "1654707044.823949",
          "thread_ts": "1654706388.813939",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "a8C/",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "WIth a custom CIKernel like this:"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "527e4c9c-a3e0-4196-821d-f9847ce3fb1c",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "```    float4 alpha_denorm (sample_t i)\n    {\n        if (i.a \u0026gt; 0.001)\n            return float4(i.rgb / i.a, 1.0);\n        return i;\n    }```",
          "ts": "1654707046.872719",
          "thread_ts": "1654706388.813939",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "raised_hands",
              "count": 1,
              "users": [
                "U03J20RJQ2X"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "d8+",
              "elements": [
                {
                  "Type": "rich_text_preformatted",
                  "Raw": "{\"type\":\"rich_text_preformatted\",\"elements\":[{\"type\":\"text\",\"text\":\"    float4 alpha_denorm (sample_t i)\\n    {\\n        if (i.a \u003e 0.001)\\n            return float4(i.rgb \\/ i.a, 1.0);\\n        return i;\\n    }\"}],\"border\":0}"
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "4fc4003b-68e1-43bf-8f57-2d6e8e52c964",
      "type": "message",
      "user": "U03DJTBMHFF",
      "text": "\u003c!here\u003e *Great questions! Keep 'em coming.* We'll be live for approximately 10 more minutes with questions to the Core Image team. We'll then need to pause to get ready for the next activity.",
      "ts": "1654706870.432129",
      "thread_ts": "1654706870.432129",
      "reply_count": 1,
      "latest_reply": "1654707248.423179",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "fmsLY",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "broadcast",
                  "range": "here"
                },
                {
                  "type": "text",
                  "text": " "
                },
                {
                  "type": "text",
                  "text": "Great questions! Keep 'em coming.",
                  "style": {
                    "bold": true
                  }
                },
                {
                  "type": "text",
                  "text": " We'll be live for approximately 10 more minutes with questions to the Core Image team. We'll then need to pause to get ready for the next activity."
                }
              ]
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "bda5947f-f786-49cb-a149-1ca17500fdae",
          "type": "message",
          "user": "U03J4DE10P6",
          "text": "Is it possible to have video previews of all four cameras simultaneously in a SwiftUI application? I’ve tried modifying the sample SwiftUI camera app, but have only been able to get one camera (or two previews of the same camera) showing up at the same time.",
          "ts": "1654707248.423179",
          "thread_ts": "1654706870.432129",
          "parent_user_id": "U03DJTBMHFF",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "al8",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Is it possible to have video previews of all four cameras simultaneously in a SwiftUI application? I’ve tried modifying the sample SwiftUI camera app, but have only been able to get one camera (or two previews of the same camera) showing up at the same time."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03JRQ486FJ\u003e asked\n\u0026gt; Since CIFilters aren't thread safe, what would be the recommended way to structure a render pipeline if I want to use Swift concurrency? Especially when one wants to initialize the filter once and reuse it for multiple renders.",
      "ts": "1654707165.564579",
      "thread_ts": "1654707165.564579",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 6,
      "latest_reply": "1654708766.522079",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "Frb",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03JRQ486FJ"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Since CIFilters aren't thread safe, what would be the recommended way to structure a render pipeline if I want to use Swift concurrency? Especially when one wants to initialize the filter once and reuse it for multiple renders.\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "7e936a24-7440-4fbc-ae92-764560097848",
          "type": "message",
          "user": "U03HRMK2074",
          "text": "It is safe to render CIImage output of CIFilter on mulitple threads (and will be concurrent if you use different instances of CIContext)",
          "ts": "1654707302.301409",
          "thread_ts": "1654707165.564579",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "T9B",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "It is safe to render CIImage output of CIFilter on mulitple threads (and will be concurrent if you use different instances of CIContext)"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "b75ac5d5-9111-41dc-a1ba-590090af785e",
          "type": "message",
          "user": "U03JRQ486FJ",
          "text": "Thanks! Yes but initializing a filter from a raw file takes quite a while, so I would like to reuse the first instance when adjusting. I assume the filter will always have to be on the same thread?",
          "ts": "1654707454.949879",
          "thread_ts": "1654707165.564579",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "A3Al",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks! Yes but initializing a filter from a raw file takes quite a while, so I would like to reuse the first instance when adjusting. I assume the filter will always have to be on the same thread?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "b3867577-56a7-4b85-aafd-c2f5c3ef21a0",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "If I recall correctly, the CIRawFilter implements the `copy` method.  That should be faster.",
          "ts": "1654708125.836379",
          "thread_ts": "1654707165.564579",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "9Sl",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "If I recall correctly, the CIRawFilter implements the "
                    },
                    {
                      "type": "text",
                      "text": "copy",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " method.  That should be faster."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "47db055d-269e-4eb7-88b5-d0e692a6572d",
          "type": "message",
          "user": "U03JRQ486FJ",
          "text": "Yes I tried the copy method but renders became unfortunately corrupt when using the copied version.",
          "ts": "1654708289.510229",
          "thread_ts": "1654707165.564579",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "FYoa",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Yes I tried the copy method but renders became unfortunately corrupt when using the copied version."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "d8559f03-e4ff-4cd1-8d40-2f21a883291a",
          "type": "message",
          "user": "U03HRMK2074",
          "text": "We would appreciate a feedback/bug report for that",
          "ts": "1654708482.569649",
          "thread_ts": "1654707165.564579",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "0kRk",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "We would appreciate a feedback/bug report for that"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "a1321dcf-69a9-44c0-9a23-cbeab2029898",
          "type": "message",
          "user": "U03JRQ486FJ",
          "text": "I will file a report. Good to know that the copy method should work. Would love to further discuss different options during a lab session.",
          "ts": "1654708766.522079",
          "thread_ts": "1654707165.564579",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Dim7y",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I will file a report. Good to know that the copy method should work. Would love to further discuss different options during a lab session."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03JRQ486FJ\u003e asked\n\u0026gt; Which CI filters would you recommend running in linear space?",
      "ts": "1654707198.320089",
      "thread_ts": "1654707198.320089",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 5,
      "latest_reply": "1654707899.479939",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "5ZgnX",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03JRQ486FJ"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Which CI filters would you recommend running in linear space?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "3ab556ba-ef16-46b9-a591-15795b893a26",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "Most CIFilters are designed to work in linear space.  The notable exceptions are the the Blend filters and Compositing filters.  These can work in linear space by may artists are more familiar using them in a perceptual colorspace.",
          "ts": "1654707366.853939",
          "thread_ts": "1654707198.320089",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "j=T",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Most CIFilters are designed to work in linear space.  The notable exceptions are the the Blend filters and Compositing filters.  These can work in linear space by may artists are more familiar using them in a perceptual colorspace."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "734279a5-91d7-4ff6-a326-db58bea238aa",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "(eg. CIScreenBlendMode and others)",
          "ts": "1654707405.819939",
          "thread_ts": "1654707198.320089",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "gvtwh",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "(eg. CIScreenBlendMode and others)"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "6ad63eca-65ac-45fd-8db3-8618a8b47b15",
          "type": "message",
          "user": "U03JRQ486FJ",
          "text": "Thanks! Would the recommendation be to run most filters in the linearSpaceFilter with a RAW file? And change the context working space to linear when working with non-raws?",
          "ts": "1654707557.951609",
          "thread_ts": "1654707198.320089",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "07Kb",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks! Would the recommendation be to run most filters in the linearSpaceFilter with a RAW file? And change the context working space to linear when working with non-raws?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "33a2f9a5-87d6-4e8c-9634-9965c66422c4",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "I would (with some exceptions) use linear for raw and non raw image.  Feel free to schedule a Lab to discuss further.",
          "ts": "1654707718.597419",
          "thread_ts": "1654707198.320089",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Xrg",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I would (with some exceptions) use linear for raw and non raw image.  Feel free to schedule a Lab to discuss further."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "3ff52d3c-e137-47a4-b6eb-236f06fc77cf",
          "type": "message",
          "user": "U03JRQ486FJ",
          "text": "I wasn't aware that I could use the linearSpaceFilter for non raw's. Will try that! A lab has already been requested :slightly_smiling_face:",
          "ts": "1654707899.479939",
          "thread_ts": "1654707198.320089",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "JnZP",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I wasn't aware that I could use the linearSpaceFilter for non raw's. Will try that! A lab has already been requested "
                    },
                    {
                      "type": "emoji",
                      "name": "slightly_smiling_face",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03JHAD6E3T\u003e asked\n\u0026gt; Can I use CIAreaAverage to get the average color except transparent areas?",
      "ts": "1654707439.305759",
      "thread_ts": "1654707439.305759",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 2,
      "latest_reply": "1654707630.676099",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "5jo",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03JHAD6E3T"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Can I use CIAreaAverage to get the average color except transparent areas?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "55975162-f9d3-42d4-bb96-4f1bdf968321",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "Yes the `CIAreaAverage` filter is essentially an alpha-weighted average.",
          "ts": "1654707502.809589",
          "thread_ts": "1654707439.305759",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "5MSP",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Yes the "
                    },
                    {
                      "type": "text",
                      "text": "CIAreaAverage",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " filter is essentially an alpha-weighted average."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "5b344600-d46a-42f3-8885-2a42158e60ba",
          "type": "message",
          "user": "U03JHAD6E3T",
          "text": "Oh, alpha-weighted average! Thanks!",
          "ts": "1654707630.676099",
          "thread_ts": "1654707439.305759",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "xxZ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Oh, alpha-weighted average! Thanks!"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03J20RJQ2X\u003e asked\n\u0026gt; Is there a good approach to color matching two photos with core image? Such as when superimposing a person on a different background, so the photo's hue, saturation, maybe contrast and brightness, somewhat match the new background",
      "ts": "1654707442.174619",
      "thread_ts": "1654707442.174619",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 1,
      "latest_reply": "1654707617.407459",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "zRJ19",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03J20RJQ2X"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Is there a good approach to color matching two photos with core image? Such as when superimposing a person on a different background, so the photo's hue, saturation, maybe contrast and brightness, somewhat match the new background\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "2c91a03a-e18e-4aab-9d8e-73d6ffb8160d",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "You might consider using the Reduction filters such as CIAreaAverage or CIAreaHistogram to collect some stats on the two images. You can then use this stats to make one better match the other.",
          "ts": "1654707617.407459",
          "thread_ts": "1654707442.174619",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "IcVX",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "You might consider using the Reduction filters such as CIAreaAverage or CIAreaHistogram to collect some stats on the two images. You can then use this stats to make one better match the other."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "d48f8f66-6996-4550-ab77-b4c95606c97a",
      "type": "message",
      "user": "U03DJTBMHFF",
      "text": "\u003c!here\u003e *Thank you all!* That was some great discussion this past hour. We're going to pivot now to the next activity _*Meet the Presenter: Discover advances in iOS camera capture*_. As for Core Image, this wasn't your only chance to ask question. The team is taking 1:1 lab appointments on Friday from 9:00 to Noon. Get your appointment requests in now if you haven't already.",
      "ts": "1654707569.033429",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "m=Q",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "broadcast",
                  "range": "here"
                },
                {
                  "type": "text",
                  "text": " "
                },
                {
                  "type": "text",
                  "text": "Thank you all!",
                  "style": {
                    "bold": true
                  }
                },
                {
                  "type": "text",
                  "text": " That was some great discussion this past hour. We're going to pivot now to the next activity "
                },
                {
                  "type": "text",
                  "text": "Meet the Presenter: Discover advances in iOS camera capture",
                  "style": {
                    "bold": true,
                    "italic": true
                  }
                },
                {
                  "type": "text",
                  "text": ". As for Core Image, this wasn't your only chance to ask question. The team is taking 1:1 lab appointments on Friday from 9:00 to Noon. Get your appointment requests in now if you haven't already."
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "e236f48f-83ee-4f53-81c2-7be799246376",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": "Developers, developers, developers,\nWelcome to *Meet the Presenter: Discover advancements in iOS camera capture*! We are so happy to have you all here! I’m Brad from the Camera Software Engineering team. In this hour, we invite everyone to watch the “Discover advancements in iOS camera capture” session together! Here’s how it works. Queue up the video and get ready to hit play at 10:05 am PDT.  \u003chttps://developer.apple.com/videos/play/wwdc2022/110429/\u003e\n\nWe’ve got the session’s presenter, Nik Gelo, in the room with us. (Hi, Nik! :wave:) We're also joined here by our team of Camera software engineers who are ready to answer your questions!\n\nThere's a lot of us here, so we're going to do our best to keep things organized. As the video progresses, I'll be creating threads associated with each section of the talk, where everyone can chat and ask questions.\n\nWhen the video finishes, we will have some time left over for additional targeted Q\u0026amp;A. So for the next few minutes, grab your popcorn, get comfortable, and get ready to hit the play button!",
      "ts": "1654707634.077219",
      "attachments": [
        {
          "fallback": "Apple Developer: Discover advancements in iOS camera capture: Depth, focus, and multitasking - WWDC22 - Videos - Apple Developer",
          "id": 1,
          "title": "Discover advancements in iOS camera capture: Depth, focus, and multitasking - WWDC22 - Videos - Apple Developer",
          "title_link": "https://developer.apple.com/videos/play/wwdc2022/110429/",
          "text": "Discover how you can take advantage of advanced camera capture features in your app. We'll show you how to use the LiDAR scanner to...",
          "image_url": "https://devimages-cdn.apple.com/wwdc-services/images/124/6790/6790_wide_250x141_2x.jpg",
          "service_name": "Apple Developer",
          "service_icon": "https://developer.apple.com/favicon.ico",
          "from_url": "https://developer.apple.com/videos/play/wwdc2022/110429/",
          "original_url": "https://developer.apple.com/videos/play/wwdc2022/110429/",
          "blocks": null
        }
      ],
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "LtvO",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Developers, developers, developers,\nWelcome to "
                },
                {
                  "type": "text",
                  "text": "Meet the Presenter: Discover advancements in iOS camera capture",
                  "style": {
                    "bold": true
                  }
                },
                {
                  "type": "text",
                  "text": "! We are so happy to have you all here! I’m Brad from the Camera Software Engineering team. In this hour, we invite everyone to watch the “Discover advancements in iOS camera capture” session together! Here’s how it works. Queue up the video and get ready to hit play at 10:05 am PDT.  "
                },
                {
                  "type": "link",
                  "url": "https://developer.apple.com/videos/play/wwdc2022/110429/",
                  "text": ""
                },
                {
                  "type": "text",
                  "text": "\n\nWe’ve got the session’s presenter, Nik Gelo, in the room with us. (Hi, Nik! "
                },
                {
                  "type": "emoji",
                  "name": "wave",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": ") We're also joined here by our team of Camera software engineers who are ready to answer your questions!\n\nThere's a lot of us here, so we're going to do our best to keep things organized. As the video progresses, I'll be creating threads associated with each section of the talk, where everyone can chat and ask questions.\n\nWhen the video finishes, we will have some time left over for additional targeted Q\u0026A. So for the next few minutes, grab your popcorn, get comfortable, and get ready to hit the play button!"
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "e0c1f4fa-6618-4362-92b0-5681d8964359",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": "On your mark…..get set…..go! :runner:",
      "ts": "1654707902.437119",
      "thread_ts": "1654707902.437119",
      "reply_count": 4,
      "latest_reply": "1654708151.698599",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "BPlx",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "On your mark…..get set…..go! "
                },
                {
                  "type": "emoji",
                  "name": "runner",
                  "skin_tone": 0
                }
              ]
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "EDF71022-CC58-4D61-9900-0F5110498829",
          "type": "message",
          "user": "U03HMD6JHAT",
          "text": "Can the LiDAR be used independently from all the other cameras? Thanks \n`New in iOS 15.4, your app can access the LiDAR Scanner with AVFoundation.` ",
          "ts": "1654708002.877789",
          "thread_ts": "1654707902.437119",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "OX5",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Can"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "the"
                    },
                    {
                      "type": "text",
                      "text": " LiDAR "
                    },
                    {
                      "type": "text",
                      "text": "be"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "used"
                    },
                    {
                      "type": "text",
                      "text": " independently "
                    },
                    {
                      "type": "text",
                      "text": "from"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "all"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "the"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "other"
                    },
                    {
                      "type": "text",
                      "text": " cameras"
                    },
                    {
                      "type": "text",
                      "text": "?"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "Thanks"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "\n"
                    },
                    {
                      "type": "text",
                      "text": "New in iOS 15.4, your app can access the LiDAR Scanner with AVFoundation. ",
                      "style": {
                        "code": true
                      }
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "1c137d15-e99c-4ecd-b1c2-b452ebf392b7",
          "type": "message",
          "user": "U03HHA1D44F",
          "text": "yes, you can use the LiDAR Depth Camera with the Ultra Wide and Telephoto cameras. Or with the front camera.",
          "ts": "1654708032.998249",
          "thread_ts": "1654707902.437119",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "RjFB",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "yes, you can use the LiDAR Depth Camera with the Ultra Wide and Telephoto cameras. Or with the front camera."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "b43bead5-1f16-4d01-a845-d29d72b4d8ab",
          "type": "message",
          "user": "U03HHA1D44F",
          "text": "The LiDAR Depth Camera AVCaptureDevice uses the LiDAR and the Wide Angle Camera",
          "ts": "1654708061.821499",
          "thread_ts": "1654707902.437119",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "bX76",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "The LiDAR Depth Camera AVCaptureDevice uses the LiDAR and the Wide Angle Camera"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "AED7F761-6E6C-4525-A998-2E7585DD3AF0",
          "type": "message",
          "user": "U03HMD6JHAT",
          "text": "So only with another camera :camera:, not just by itself? Thanks :relaxed: ",
          "ts": "1654708151.698599",
          "thread_ts": "1654707902.437119",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "KZME",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "So"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "only"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "with"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "another"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "camera"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "emoji",
                      "name": "camera",
                      "skin_tone": 0
                    },
                    {
                      "type": "text",
                      "text": ","
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "not"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "just"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "by"
                    },
                    {
                      "type": "text",
                      "text": " itself"
                    },
                    {
                      "type": "text",
                      "text": "?"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "Thanks"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "emoji",
                      "name": "relaxed",
                      "skin_tone": 0
                    },
                    {
                      "type": "text",
                      "text": " "
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "e1cdfc1a-36e9-416a-9ede-02f1e06d5a1e",
      "type": "message",
      "user": "U03HHA1D44F",
      "text": "Hi everyone!",
      "ts": "1654707911.072809",
      "team": "T031SG5MZ7U",
      "reactions": [
        {
          "name": "swift-orange",
          "count": 1,
          "users": [
            "U03HMD6JHAT"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "fla+",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Hi everyone!"
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "8cea1045-3289-46fb-8ee0-415d3579648e",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": ":thread: Questions about *LiDAR Depth Scanner* (LiDAR Depth Camera)",
      "ts": "1654708104.901609",
      "thread_ts": "1654708104.901609",
      "reply_count": 20,
      "latest_reply": "1654711235.307489",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "sDgq",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "emoji",
                  "name": "thread",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": " Questions about "
                },
                {
                  "type": "text",
                  "text": "LiDAR Depth Scanner ",
                  "style": {
                    "bold": true
                  }
                },
                {
                  "type": "text",
                  "text": "(LiDAR Depth Camera)"
                }
              ]
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "b7edf57b-c0c7-445e-8d85-f4a38319a667",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Feel free to post questions here about LiDAR Depth Camera.",
          "ts": "1654708115.773389",
          "thread_ts": "1654708104.901609",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "7snjt",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Feel free to post questions here about LiDAR Depth Camera."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "625fc132-a108-40fe-9187-ad47fd174ee0",
          "type": "message",
          "user": "U03HHA1D44F",
          "text": "\u003c@U03HMD6JHAT\u003e You can use the LiDAR Depth Camera by itself. Under the hood it uses the Wide camera and LiDAR Scanner. Check out around 4:50 in the video where it highlights the cameras used for the various virtual AVCaptureDevices",
          "ts": "1654708230.339889",
          "thread_ts": "1654708104.901609",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "star-struck",
              "count": 1,
              "users": [
                "U03HMD6JHAT"
              ]
            },
            {
              "name": "raised_hands",
              "count": 1,
              "users": [
                "U03HMD6JHAT"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "HQn",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "user",
                      "user_id": "U03HMD6JHAT"
                    },
                    {
                      "type": "text",
                      "text": " You can use the LiDAR Depth Camera by itself. Under the hood it uses the Wide camera and LiDAR Scanner. Check out around 4:50 in the video where it highlights the cameras used for the various virtual AVCaptureDevices"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "dac4273d-a376-4f13-a316-852ae54eed71",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "A little more color — it wouldn't be very useful to use the LiDAR hardware alone, as it produces a sparse point cloud. The RGB wide camera is used to \"densify\" the sparse point cloud produced by the time of flight hardware, to give you a fuller picture.",
          "ts": "1654708361.577399",
          "thread_ts": "1654708104.901609",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Faw9S",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "A little more color — it wouldn't be very useful to use the LiDAR hardware alone, as it produces a sparse point cloud. The RGB wide camera is used to \"densify\" the sparse point cloud produced by the time of flight hardware, to give you a fuller picture."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "c276de9e-0403-4026-a9ba-124441460b52",
          "type": "message",
          "user": "U03HVD5TM7G",
          "text": "\u003c@U03HHA1D44F\u003e Will the :guitar: spotlight demo you showed be available as sample project? :sunglasses:",
          "ts": "1654708383.922649",
          "thread_ts": "1654708104.901609",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "w+E",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "user",
                      "user_id": "U03HHA1D44F"
                    },
                    {
                      "type": "text",
                      "text": " Will the "
                    },
                    {
                      "type": "emoji",
                      "name": "guitar",
                      "skin_tone": 0
                    },
                    {
                      "type": "text",
                      "text": " spotlight demo you showed be available as sample project? "
                    },
                    {
                      "type": "emoji",
                      "name": "sunglasses",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "8dd07fb7-e9e8-4215-83e9-d774c31232f2",
          "type": "message",
          "user": "U03HHA1D44F",
          "text": "Unfortunately not :disappointed:",
          "ts": "1654708461.697339",
          "thread_ts": "1654708104.901609",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "pleading_face",
              "count": 2,
              "users": [
                "U03HVD5TM7G",
                "U03HMD6JHAT"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "FXl",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Unfortunately not "
                    },
                    {
                      "type": "emoji",
                      "name": "disappointed",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "74787ce3-fa9e-4a3b-9d76-bd2795979b6f",
          "type": "message",
          "user": "U03KBCLJVR6",
          "text": "Would be interested to know more about how Depth data filtering is able to reduce noise, is there any more info on that?",
          "ts": "1654708618.637979",
          "thread_ts": "1654708104.901609",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "77Ex",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Would be interested to know more about how Depth data filtering is able to reduce noise, is there any more info on that?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "44f3bfa0-0194-4239-8692-1cb53abec2c3",
          "type": "message",
          "user": "U03JLPLT8HK",
          "text": "I would be interested to know regarding if I can access the depthData using dual-wide-camera in iPadPro?",
          "ts": "1654708664.885299",
          "thread_ts": "1654708104.901609",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "rx/v",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I would be interested to know regarding if I can access the depthData using dual-wide-camera in iPadPro?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "776910bd-9b15-4016-bf43-baaf408917ce",
          "type": "message",
          "user": "U03JLPLT8HK",
          "text": "Another question I've it that if I use LiDAR depth, what it would be use more resource like memory, CPU etc.?",
          "ts": "1654708723.601739",
          "thread_ts": "1654708104.901609",
          "edited": {
            "user": "U03JLPLT8HK",
            "ts": "1654708751.000000"
          },
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "rff",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Another question I've it that if I use LiDAR depth, what it would be use more resource like memory, CPU etc.?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "50a75cb1-614c-455a-9ea6-1f1a5d440a46",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "\u003c@U03KBCLJVR6\u003e Depth data filtering attempts to fill in \"holes\" in the depth using other techniques, such as ML networks to fill in missing depth based on surrounding points and inferences from the pixels in the RGB camera. You should turn it off if you need scientifically precise points and don't want any inferred ones. Beware though that this will result in a depth map with holes in it (NaN pixel values).",
          "ts": "1654708899.937169",
          "thread_ts": "1654708104.901609",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "heart",
              "count": 1,
              "users": [
                "U03KBCLJVR6"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "mL2",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "user",
                      "user_id": "U03KBCLJVR6"
                    },
                    {
                      "type": "text",
                      "text": " Depth data filtering attempts to fill in \"holes\" in the depth using other techniques, such as ML networks to fill in missing depth based on surrounding points and inferences from the pixels in the RGB camera. You should turn it off if you need scientifically precise points and don't want any inferred ones. Beware though that this will result in a depth map with holes in it (NaN pixel values)."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "4c07a9cb-5b45-4af0-8473-9b03b690e244",
          "type": "message",
          "user": "U03J20E7UBV",
          "text": "Is there any way to get access to the raw point cloud from the `.lidarDepthCamera`?",
          "ts": "1654708934.256769",
          "thread_ts": "1654708104.901609",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U03JGGVRMTM"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "f+I",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Is there any way to get access to the raw point cloud from the "
                    },
                    {
                      "type": "text",
                      "text": ".lidarDepthCamera",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "7f1a9e62-de4b-4972-9c4a-ee98a4318745",
          "type": "message",
          "user": "U03JRR26EU8",
          "text": "I was told the resolution of LiDAR depth data from ARKit had been for objects the size of a ~table leg for identifying a table in a room, or accuracy within a few inches. With ARFoundation having more depth resolution, is there a kind of rule-of-thumb in terms of accuracy down to set distance, or an object size like a tooth?",
          "ts": "1654709036.714899",
          "thread_ts": "1654708104.901609",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "8Upl",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I was told the resolution of LiDAR depth data from ARKit had been for objects the size of a ~table leg for identifying a table in a room, or accuracy within a few inches. With ARFoundation having more depth resolution, is there a kind of rule-of-thumb in terms of accuracy down to set distance, or an object size like a tooth?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "57f7b531-a672-4727-b8e3-97cd2a1e98a1",
          "type": "message",
          "user": "U03HHA1D44F",
          "text": "Hi \u003c@U03JLPLT8HK\u003e, with an iPad Pro that has a Wide and Ultra Wide camera the `AVCaptureDevice.DeviceType.builtInDualWideCamera` can be used to capture depth. It uses the Wide and Ultra Wide cameras to deliver depth",
          "ts": "1654709064.941079",
          "thread_ts": "1654708104.901609",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "/YkU",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi "
                    },
                    {
                      "type": "user",
                      "user_id": "U03JLPLT8HK"
                    },
                    {
                      "type": "text",
                      "text": ", with an iPad Pro that has a Wide and Ultra Wide camera the "
                    },
                    {
                      "type": "text",
                      "text": "AVCaptureDevice.DeviceType.builtInDualWideCamera",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " can be used to capture depth. It uses the Wide and Ultra Wide cameras to deliver depth"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "e0ca0ec2-26ed-44c2-8f28-0aefaec607b3",
          "type": "message",
          "user": "U03JLPLT8HK",
          "text": "\u003c@U03HHA1D44F\u003e, I've tried using it.  but `photoOutput.isDepthDataDeliverySupported`  always return false for my iPadPro 12",
          "ts": "1654709190.465869",
          "thread_ts": "1654708104.901609",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "ZnJF",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "user",
                      "user_id": "U03HHA1D44F"
                    },
                    {
                      "type": "text",
                      "text": ", I've tried using it.  but "
                    },
                    {
                      "type": "text",
                      "text": "photoOutput.isDepthDataDeliverySupported",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "  always return false for my iPadPro 12"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "16ddb339-8e24-4ee0-b64a-b5de677bce47",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Hi \u003c@U03JLPLT8HK\u003e iPad Pro models with wide and ultrawide cameras may not support depth data delivery through their DualWide camera.",
          "ts": "1654709749.888339",
          "thread_ts": "1654708104.901609",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "QKC",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi "
                    },
                    {
                      "type": "user",
                      "user_id": "U03JLPLT8HK"
                    },
                    {
                      "type": "text",
                      "text": " iPad Pro models with wide and ultrawide cameras may not support depth data delivery through their DualWide camera."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "410c564f-56de-494f-b9a0-6b39a1c77073",
          "type": "message",
          "user": "U03JLPLT8HK",
          "text": "Thank you \u003c@U03HXTBNYBC\u003e to clarifying this. If I use LiDAR depth, would it be use more resources compared to dual-wide-camera?",
          "ts": "1654709848.159479",
          "thread_ts": "1654708104.901609",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "NEQ8D",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thank you "
                    },
                    {
                      "type": "user",
                      "user_id": "U03HXTBNYBC"
                    },
                    {
                      "type": "text",
                      "text": " to clarifying this. If I use LiDAR depth, would it be use more resources compared to dual-wide-camera?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "fee88f42-1366-4b27-8c95-d0e52c4c3793",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "\u003c@U03JLPLT8HK\u003e regarding the cost of LiDAR depth: Yes, running the LiDAR depth camera does come with a power cost. That's one of the reasons we only support up to 30 fps (AVFoundation does higher resolution depth maps than ARKit using LiDAR). You should definitely pay attention to your session's `systemPressureCost` while running LiDAR camera, especially in a multicam use case (such as with the front camera).",
          "ts": "1654709906.912009",
          "thread_ts": "1654708104.901609",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "heart",
              "count": 1,
              "users": [
                "U03JLPLT8HK"
              ]
            },
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U03HMD6JHAT"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "XxUK7",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "user",
                      "user_id": "U03JLPLT8HK"
                    },
                    {
                      "type": "text",
                      "text": " regarding the cost of LiDAR depth: Yes, running the LiDAR depth camera does come with a power cost. That's one of the reasons we only support up to 30 fps (AVFoundation does higher resolution depth maps than ARKit using LiDAR). You should definitely pay attention to your session's "
                    },
                    {
                      "type": "text",
                      "text": "systemPressureCost",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " while running LiDAR camera, especially in a multicam use case (such as with the front camera)."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "388a36a5-88dc-4128-aa56-9ed28d4439dc",
          "type": "message",
          "user": "U03JLPLT8HK",
          "text": "Thank you so much \u003c@U03HXTBNYBC\u003e!!",
          "ts": "1654709953.297109",
          "thread_ts": "1654708104.901609",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "4XEA",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thank you so much "
                    },
                    {
                      "type": "user",
                      "user_id": "U03HXTBNYBC"
                    },
                    {
                      "type": "text",
                      "text": "!!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "abdf593a-4e59-42ea-a992-358110a2e4f7",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "\u003c@U03JRR26EU8\u003e regarding your question on resolution and distance accuracy, we don't have the right people in the room to answer that, but can do a little research. We invite you to ask that again tomorrow in our 10 AM Q\u0026amp;A session, and we should have an answer by then.",
          "ts": "1654710967.646669",
          "thread_ts": "1654708104.901609",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "pray",
              "count": 1,
              "users": [
                "U03JRR26EU8"
              ]
            },
            {
              "name": "raised_hands",
              "count": 1,
              "users": [
                "U03HMD6JHAT"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "H5GJ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "user",
                      "user_id": "U03JRR26EU8"
                    },
                    {
                      "type": "text",
                      "text": " regarding your question on resolution and distance accuracy, we don't have the right people in the room to answer that, but can do a little research. We invite you to ask that again tomorrow in our 10 AM Q\u0026A session, and we should have an answer by then."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "b5ed0d55-103c-43d9-8f4b-3ea9658c6da1",
          "type": "message",
          "user": "U03HHA1D44F",
          "text": "Brad, thanks for clarifying `AVCaptureDevice.DeviceType.builtInDualWideCamera`'s depth support on iPad Pro. I was mistaken with iPhone's capabilities.",
          "ts": "1654711115.933669",
          "thread_ts": "1654708104.901609",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "dRR3",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Brad, thanks for clarifying "
                    },
                    {
                      "type": "text",
                      "text": "AVCaptureDevice.DeviceType.builtInDualWideCamera",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "'s depth support on iPad Pro. I was mistaken with iPhone's capabilities."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "e3bb745c-3014-487a-8aec-891f949648d6",
          "type": "message",
          "user": "U03JRR26EU8",
          "text": "\u003c@U03HXTBNYBC\u003e Thank you so much for considering that and the conscientiousness to say it’s a question for others, (I’m actually hoping to build a business that relies on the level of precision!) Yes I will happily come to tomorrow’s Q\u0026amp;A. Thanks again for all you guys do bringing this technology forward.",
          "ts": "1654711235.307489",
          "thread_ts": "1654708104.901609",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "rikwz",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "user",
                      "user_id": "U03HXTBNYBC"
                    },
                    {
                      "type": "text",
                      "text": " Thank you so much for considering that and the conscientiousness to say it’s a question for others, (I’m actually hoping to build a business that relies on the level of precision!) Yes I will happily come to tomorrow’s Q\u0026A. Thanks again for all you guys do bringing this technology forward."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "1b60d8f5-0d98-4a17-ac97-dfcde4653abc",
      "type": "message",
      "user": "U03HHA1D44F",
      "text": "For more \"depth\" puns, see \u003c@U03HXTBNYBC\u003e’s session called \"Capturing Depth in iPhone Photography\" from 2017!",
      "ts": "1654708384.446339",
      "team": "T031SG5MZ7U",
      "reactions": [
        {
          "name": "joy",
          "count": 2,
          "users": [
            "U03HVD5TM7G",
            "U03DJTBMHFF"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "LqUD",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "For more \"depth\" puns, see "
                },
                {
                  "type": "user",
                  "user_id": "U03HXTBNYBC"
                },
                {
                  "type": "text",
                  "text": "’s session called \"Capturing Depth in iPhone Photography\" from 2017!"
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "8a746de8-a47c-4b85-9fca-d611c326d8d6",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": ":thread: Questions about *Face Driven Auto Focus and Auto Exposure* API",
      "ts": "1654708494.374949",
      "thread_ts": "1654708494.374949",
      "reply_count": 7,
      "latest_reply": "1654710953.170249",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "MN73",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "emoji",
                  "name": "thread",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": " Questions about "
                },
                {
                  "type": "text",
                  "text": "Face Driven Auto Focus and Auto Exposure ",
                  "style": {
                    "bold": true
                  }
                },
                {
                  "type": "text",
                  "text": "API"
                }
              ]
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "9d72c5d9-48ab-4b37-a430-b31376e695d7",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Feel free to post your questions here.",
          "ts": "1654708506.388789",
          "thread_ts": "1654708494.374949",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "agg+/",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Feel free to post your questions here."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "30124284-e19a-4785-bede-caf5b63b6b7a",
          "type": "message",
          "user": "U03KBCLJVR6",
          "text": "What happens when there are multiple faces in the scene? Does it average out and balance across all detected?",
          "ts": "1654708716.048569",
          "thread_ts": "1654708494.374949",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "3pB7m",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "What happens when there are multiple faces in the scene? Does it average out and balance across all detected?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "B5B1F9B7-ECFE-4859-894D-F4CA56E588C8",
          "type": "message",
          "user": "U03HME2GM7Z",
          "text": "What is hardware/battery cost?",
          "ts": "1654708725.514819",
          "thread_ts": "1654708494.374949",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "V4U8",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "What"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "is"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "hardware/"
                    },
                    {
                      "type": "text",
                      "text": "battery "
                    },
                    {
                      "type": "text",
                      "text": "cost?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "c5f9b6e0-b58a-4151-8bcf-8ce16ef02641",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "\u003c@U03KBCLJVR6\u003e Face driven AF/AE uses the largest face in the frame to drive focus or exposure.",
          "ts": "1654709152.352269",
          "thread_ts": "1654708494.374949",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "U9W",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "user",
                      "user_id": "U03KBCLJVR6"
                    },
                    {
                      "type": "text",
                      "text": " Face driven AF/AE uses the largest face in the frame to drive focus or exposure."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "00a22a01-8d50-49fd-8425-d7384ad86415",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "\u003c@U03HME2GM7Z\u003e The hardware/battery cost of enabling Face driven AE/AF is miniscule. Face detection is performed on Apple's Neural Engine, and it's frequently turned on for other feature uses anyway.",
          "ts": "1654709253.682089",
          "thread_ts": "1654708494.374949",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "heart",
              "count": 1,
              "users": [
                "U03KBCLJVR6"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "zV/V",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "user",
                      "user_id": "U03HME2GM7Z"
                    },
                    {
                      "type": "text",
                      "text": " The hardware/battery cost of enabling Face driven AE/AF is miniscule. Face detection is performed on Apple's Neural Engine, and it's frequently turned on for other feature uses anyway."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "D3557DF7-6E49-46BF-96F2-2035F2EBB8C5",
          "type": "message",
          "user": "U03HME2GM7Z",
          "text": "In terms of long running stream sessions and heat/battery. Lower fps have more impact then disabling face AF/AE?",
          "ts": "1654709438.092959",
          "thread_ts": "1654708494.374949",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "b8lLn",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "In"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "terms"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "of"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "long"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "running"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "stream"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "sessions"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "and"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "heat/battery. Lower"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "fps"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "have"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "more"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "impact"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "then"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "disabling"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "face"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "AF/AE?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "dbf8f495-7114-4eb3-a0c2-64bf0e8b39f4",
          "type": "message",
          "user": "U03HHA1D44F",
          "text": "Yes, in the \"Accessing the camera while multitasking article\" we discuss strategies for lowering your app's footprint on the system:\n\n\u003chttps://developer.apple.com/documentation/avkit/accessing_the_camera_while_multitasking\u003e\n\n\u0026gt; Apps reduce their footprint on the system by lowering the frame rate or requesting lower-resolution, binned, or non-HDR formats.\nThese are our recommended strategies for maintaining performance especially while multitasking",
          "ts": "1654710953.170249",
          "thread_ts": "1654708494.374949",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "loEI",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Yes, in the \"Accessing the camera while multitasking article\" we discuss strategies for lowering your app's footprint on the system:\n\n"
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/avkit/accessing_the_camera_while_multitasking",
                      "text": ""
                    },
                    {
                      "type": "text",
                      "text": "\n\n"
                    }
                  ]
                },
                {
                  "Type": "rich_text_quote",
                  "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Apps reduce their footprint on the system by lowering the frame rate or requesting lower-resolution, binned, or non-HDR formats.\"}]}"
                },
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "\nThese are our recommended strategies for maintaining performance especially while multitasking"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "408515ab-ad1f-4820-aa87-48d49e796fdf",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": ":thread: Questions about *Multiple Video Data Output* Support",
      "ts": "1654708595.199489",
      "thread_ts": "1654708595.199489",
      "reply_count": 6,
      "latest_reply": "1654714740.556259",
      "team": "T031SG5MZ7U",
      "reactions": [
        {
          "name": "partying_face",
          "count": 2,
          "users": [
            "U03JRP87THN",
            "U03JDTS6RKP"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "0gYA",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "emoji",
                  "name": "thread",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": " Questions about "
                },
                {
                  "type": "text",
                  "text": "Multiple Video Data Output ",
                  "style": {
                    "bold": true
                  }
                },
                {
                  "type": "text",
                  "text": "Support"
                }
              ]
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "a3cf5c9c-7171-4fd6-95f7-7383ddbba4e4",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "It's been one of our most requested features!",
          "ts": "1654708624.777739",
          "thread_ts": "1654708595.199489",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "WPOiU",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "It's been one of our most requested features!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "06cac25b-266a-4dad-9f70-8760fa3f6815",
          "type": "message",
          "user": "U03JRR26EU8",
          "text": "Is an advantage of using multiple video data outputs also the ability to increase the depth data?\n\nMeaning if I am trying to capture depth of a very small object and am using a virtual camera like the LiDAR + wide angle, can output file’s accuracy be increased further by combining it with a triple camera, or are these multiple video outputs mostly to distinguish between what is shown live on the phone vs the quality of the file saved?",
          "ts": "1654709416.133909",
          "thread_ts": "1654708595.199489",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "3P8",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Is an advantage of using multiple video data outputs also the ability to increase the depth data?\n\nMeaning if I am trying to capture depth of a very small object and am using a virtual camera like the LiDAR + wide angle, can output file’s accuracy be increased further by combining it with a triple camera, or are these multiple video outputs mostly to distinguish between what is shown live on the phone vs the quality of the file saved?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "da18c03a-1ee3-4174-94de-a71ed025faa5",
          "type": "message",
          "user": "U03JMLKUF1N",
          "text": "Hi Rob, the `AVCaptureDeviceTypeBuiltInLiDARDepthCamera` consists of the back wide and the LiDAR scanner, and that's the case regardless of whether it's used in combination with other cameras.",
          "ts": "1654709713.699039",
          "thread_ts": "1654708595.199489",
          "edited": {
            "user": "U03JMLKUF1N",
            "ts": "1654709758.000000"
          },
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Hzz",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi Rob, the "
                    },
                    {
                      "type": "text",
                      "text": "AVCaptureDeviceTypeBuiltInLiDARDepthCamera",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " consists of the back wide and the LiDAR scanner, and that's the case regardless of whether it's used in combination with other cameras."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "b65eb9bc-859d-4725-944a-1d4aa33bfd13",
          "type": "message",
          "user": "U03JMLKUF1N",
          "text": "Therefore, the depth quality will not be any different if it's used in a multi-cam session with other cameras.",
          "ts": "1654709747.713769",
          "thread_ts": "1654708595.199489",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U03JRR26EU8"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "4U5X",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Therefore, the depth quality will not be any different if it's used in a multi-cam session with other cameras."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "901ce29a-f798-4d2f-b43d-52cec1cc6695",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Examples of uses of multiple video data outputs:\n• you need a real time preview, at screen resolution, no latency.\n• you need a HD res output with aggressive video stabilization applied for recording to a movie\n• you need a smaller resolution representation that can be sent to the cloud or streamed, perhaps with less aggressive stabilization, or lower res effects applied.\nBefore multiple VDO support, you could pick just one of these and the other two cases would suffer. Now you can have your cake, and your pie, and your donut, and eat all three.",
          "ts": "1654710814.750469",
          "thread_ts": "1654708595.199489",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "raised_hands",
              "count": 3,
              "users": [
                "U03HHA1D44F",
                "U03JRR26EU8",
                "U03JDTS6RKP"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "sPHU",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Examples of uses of multiple video data outputs:\n"
                    }
                  ]
                },
                {
                  "Type": "rich_text_list",
                  "Raw": "{\"type\":\"rich_text_list\",\"elements\":[{\"type\":\"rich_text_section\",\"elements\":[{\"type\":\"text\",\"text\":\"you need a real time preview, at screen resolution, no latency.\"}]},{\"type\":\"rich_text_section\",\"elements\":[{\"type\":\"text\",\"text\":\"you need a HD res output with aggressive video stabilization applied for recording to a movie\"}]},{\"type\":\"rich_text_section\",\"elements\":[{\"type\":\"text\",\"text\":\"you need a smaller resolution representation that can be sent to the cloud or streamed, perhaps with less aggressive stabilization, or lower res effects applied.\"}]}],\"style\":\"bullet\",\"indent\":0,\"border\":0}"
                },
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Before multiple VDO support, you could pick just one of these and the other two cases would suffer. Now you can have your cake, and your pie, and your donut, and eat all three."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "1ab0b9a2-3116-4b9c-983f-f7a87a0802dd",
          "type": "message",
          "user": "U03JDTS6RKP",
          "text": "So happy and thankful for your efforts in adding this! Can't wait to use it!",
          "ts": "1654714740.556259",
          "thread_ts": "1654708595.199489",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "+y8QG",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "So happy and thankful for your efforts in adding this! Can't wait to use it!"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "0f7eec49-19b2-4dee-9338-dd6edf581f34",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": ":thread: Questions about *Multitasking Camera Support*",
      "ts": "1654708937.684909",
      "thread_ts": "1654708937.684909",
      "reply_count": 5,
      "latest_reply": "1654710732.569709",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "fiRQ8",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "emoji",
                  "name": "thread",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": " Questions about "
                },
                {
                  "type": "text",
                  "text": "Multitasking Camera Support",
                  "style": {
                    "bold": true
                  }
                }
              ]
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "3e801e7f-b569-47f2-a890-5f9c3d7b0a1c",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Now your camera app can run while multitasking on iPad!",
          "ts": "1654708953.094049",
          "thread_ts": "1654708937.684909",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "raised_hands",
              "count": 1,
              "users": [
                "U03JRP87THN"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "ffvTJ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Now your camera app can run while multitasking on iPad!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "877e2834-662f-4289-aa01-1d9b4bea88f4",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "\u003c@U03HHA1D44F\u003e what's the story on multitasking support for developers who want to use it prior to iOS 16?",
          "ts": "1654710333.986229",
          "thread_ts": "1654708937.684909",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "wjW3",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "user",
                      "user_id": "U03HHA1D44F"
                    },
                    {
                      "type": "text",
                      "text": " what's the story on multitasking support for developers who want to use it prior to iOS 16?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "6444cae1-917c-47a0-816e-4ecc63777307",
          "type": "message",
          "user": "U03HHA1D44F",
          "text": "Prior to iOS 16, developers that want to use the camera while multitasking must have the `com.apple.developer.avfoundation.multitasking-camera-access` entitlement: \u003chttps://developer.apple.com/documentation/bundleresources/entitlements/com_apple_developer_avfoundation_multitasking-camera-access\u003e.\n\nTo use it, you must request access to the entitlement using this form linked on the entitlement's documentation page: \u003chttps://developer.apple.com/contact/request/multitasking-camera-access/\u003e\n\nAs the documentation states, \"This entitlement is for video-calling and video-conferencing apps and doesn’t support video recording.\" When you request access using the form, it will ask you questions about your apps purpose",
          "ts": "1654710513.004679",
          "thread_ts": "1654708937.684909",
          "attachments": [
            {
              "fallback": "Sign In - Apple",
              "id": 1,
              "title": "Sign In - Apple",
              "title_link": "https://developer.apple.com/contact/request/multitasking-camera-access/",
              "text": "Sign in with your Apple ID",
              "service_name": "idmsa.apple.com",
              "service_icon": "https://appleid.cdn-apple.com/daw/IDMSWebAuth/static/20Apr2022/images/favicon.ico",
              "from_url": "https://developer.apple.com/contact/request/multitasking-camera-access/",
              "original_url": "https://developer.apple.com/contact/request/multitasking-camera-access/",
              "blocks": null
            }
          ],
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "26J",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Prior to iOS 16, developers that want to use the camera while multitasking must have the "
                    },
                    {
                      "type": "text",
                      "text": "com.apple.developer.avfoundation.multitasking-camera-access",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " entitlement: "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/bundleresources/entitlements/com_apple_developer_avfoundation_multitasking-camera-access",
                      "text": ""
                    },
                    {
                      "type": "text",
                      "text": ".\n\nTo use it, you must request access to the entitlement using this form linked on the entitlement's documentation page: "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/contact/request/multitasking-camera-access/",
                      "text": ""
                    },
                    {
                      "type": "text",
                      "text": "\n\nAs the documentation states, \"This entitlement is for video-calling and video-conferencing apps and doesn’t support video recording.\" When you request access using the form, it will ask you questions about your apps purpose"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "3071ec3a-7d97-4521-b4d3-f77d0f970582",
          "type": "message",
          "user": "U03HHA1D44F",
          "text": "The entitlement is useful for apps that want to deploy back to iOS 13.5",
          "ts": "1654710528.716039",
          "thread_ts": "1654708937.684909",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "wik",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "The entitlement is useful for apps that want to deploy back to iOS 13.5"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "3d91ba12-d2a0-4b2f-982b-c13b430a1335",
          "type": "message",
          "user": "U03HHA1D44F",
          "text": "One difference to note is that with the API, `AVCaptureSession.isMultitaskingCameraAccessSupported` returns `true` for iPad Pro (4th generation), iPad Pro (5th generation) and iPad Air (5th generation) whereas the entitlement allows you to use the camera while multitasking on more devices like iPhones",
          "ts": "1654710732.569709",
          "thread_ts": "1654708937.684909",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "2Og",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "One difference to note is that with the API, "
                    },
                    {
                      "type": "text",
                      "text": "AVCaptureSession.isMultitaskingCameraAccessSupported",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " returns "
                    },
                    {
                      "type": "text",
                      "text": "true",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " for iPad Pro (4th generation), iPad Pro (5th generation) and iPad Air (5th generation) whereas the entitlement allows you to use the camera while multitasking on more devices like iPhones"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "1589a53a-057e-46c1-a059-65fe3df002bd",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": "Thanks all for watching with us. Now that you've seen the content and are processing, feel free to hit us up with your questions. We'll be here until 11:00 AM PDT.",
      "ts": "1654709048.110699",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "2nn",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Thanks all for watching with us. Now that you've seen the content and are processing, feel free to hit us up with your questions. We'll be here until 11:00 AM PDT."
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "c49290f9-c412-47d4-b3c8-6fcb374024a5",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": "If you'd like to ask a question unrelated to the threads, please use the + button and click \"Ask a Question\". We'll get to as many as we can.",
      "ts": "1654709076.756499",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "vcj6x",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "If you'd like to ask a question unrelated to the threads, please use the + button and click \"Ask a Question\". We'll get to as many as we can."
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "0b463f0a-8614-4e10-acec-347fdeb37e24",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": "Thanks for the lively discussion so far!",
      "ts": "1654709082.316379",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "7EY/6",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Thanks for the lively discussion so far!"
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03J20E7UBV\u003e asked\n\u0026gt; Is the LiDAR-based depth data capable of being embedded in a HEIC, similar to how disparity-based depth data is?",
      "ts": "1654709276.314469",
      "thread_ts": "1654709276.314469",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 1,
      "latest_reply": "1654709366.730889",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "Hr/v",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03J20E7UBV"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Is the LiDAR-based depth data capable of being embedded in a HEIC, similar to how disparity-based depth data is?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "d35c2c7d-123b-42c6-b0ff-cb9e3c19a4a9",
          "type": "message",
          "user": "U03JMLKUF1N",
          "text": "Hi Brandon, yes. Depth generated with the `AVCaptureDeviceTypeBuiltInLiDARDepthCamera` can be embedded in HEIC just like depth generated from other cameras.",
          "ts": "1654709366.730889",
          "thread_ts": "1654709276.314469",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "sQeNn",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi Brandon, yes. Depth generated with the "
                    },
                    {
                      "type": "text",
                      "text": "AVCaptureDeviceTypeBuiltInLiDARDepthCamera",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " can be embedded in HEIC just like depth generated from other cameras."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03J20E7UBV\u003e asked\n\u0026gt; Is it possible to get the raw point cloud representation from the LiDAR camera through AVFoundation, rather than an ARKit/Metal-based session?",
      "ts": "1654709299.199699",
      "thread_ts": "1654709299.199699",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 5,
      "latest_reply": "1654712314.381209",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "uAa1T",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03J20E7UBV"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Is it possible to get the raw point cloud representation from the LiDAR camera through AVFoundation, rather than an ARKit\\/Metal-based session?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "91fb5165-bdf1-4716-ad20-fe71def70a8b",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Unfortunately no. The closest thing to it would be to turn off depthDataFiltering on the AVCaptureDepthDataOutput and then get depth data objects which will contain the full field of view of the wide camera / LiDAR camera, but will have holes (NaN pixels) where LiDAR spots were unavailable.",
          "ts": "1654709385.400189",
          "thread_ts": "1654709299.199699",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "IYGUJ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Unfortunately no. The closest thing to it would be to turn off depthDataFiltering on the AVCaptureDepthDataOutput and then get depth data objects which will contain the full field of view of the wide camera / LiDAR camera, but will have holes (NaN pixels) where LiDAR spots were unavailable."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "19d4f5eb-568b-44b0-80ce-9aa085c90623",
          "type": "message",
          "user": "U03J20E7UBV",
          "text": "Thanks, \u003c@U03HXTBNYBC\u003e!  There's something very fun and magical about capturing point clouds lol, and am always curious of the technologies that allow for this.  Appreciate your help and hard work on this new technology!",
          "ts": "1654709474.350319",
          "thread_ts": "1654709299.199699",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "raised_hands",
              "count": 1,
              "users": [
                "U03HXTBNYBC"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "puBJ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks, "
                    },
                    {
                      "type": "user",
                      "user_id": "U03HXTBNYBC"
                    },
                    {
                      "type": "text",
                      "text": "!  There's something very fun and magical about capturing point clouds lol, and am always curious of the technologies that allow for this.  Appreciate your help and hard work on this new technology!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "f48f486a-72cf-4975-87de-6058970a977d",
          "type": "message",
          "user": "U03JMB7160Z",
          "text": "It's point clouds all the way down. :nerd_face:",
          "ts": "1654710358.031329",
          "thread_ts": "1654709299.199699",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "grinning",
              "count": 1,
              "users": [
                "U03J20E7UBV"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "ZCf",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "It's point clouds all the way down. "
                    },
                    {
                      "type": "emoji",
                      "name": "nerd_face",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "7785005d-6399-4f0f-8582-73891c3ae8cb",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "To \u003c@U03J20E7UBV\u003e’s last comment, it really does help to understand that AVFoundation's LiDARCam is really a marriage between time of flight technology and machine learning \"hallucinated\" depth — guided by the LiDAR spots. It just wouldn't be that useful with the LiDAR hardware alone. Together, they really advance the state of the art for depth data acquisition on iOS products. They give you great video quality, high resolution depth, and real-world scale, all in one package. They're also faced away from you, unlike the TrueDepth camera, so now you've got real-world scale options in both directions.",
          "ts": "1654710557.344579",
          "thread_ts": "1654709299.199699",
          "edited": {
            "user": "U03HXTBNYBC",
            "ts": "1654710607.000000"
          },
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "LjN",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "To "
                    },
                    {
                      "type": "user",
                      "user_id": "U03J20E7UBV"
                    },
                    {
                      "type": "text",
                      "text": "’s last comment, it really does help to understand that AVFoundation's LiDARCam is really a marriage between time of flight technology and machine learning \"hallucinated\" depth — guided by the LiDAR spots. It just wouldn't be that useful with the LiDAR hardware alone. Together, they really advance the state of the art for depth data acquisition on iOS products. They give you great video quality, high resolution depth, and real-world scale, all in one package. They're also faced away from you, unlike the TrueDepth camera, so now you've got real-world scale options in both directions."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "26bbca0e-e488-480a-ac8e-fb2f453899da",
          "type": "message",
          "user": "U03J20E7UBV",
          "text": "Thanks, \u003c@U03HXTBNYBC\u003e!  It's always been super cool to be able to get depth data from our devices, but having that added accuracy and high-resolution depth, alongside now higher capture quality, is really huge!",
          "ts": "1654712314.381209",
          "thread_ts": "1654709299.199699",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Vk8sP",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks, "
                    },
                    {
                      "type": "user",
                      "user_id": "U03HXTBNYBC"
                    },
                    {
                      "type": "text",
                      "text": "!  It's always been super cool to be able to get depth data from our devices, but having that added accuracy and high-resolution depth, alongside now higher capture quality, is really huge!"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03HVE4BEBY\u003e asked\n\u0026gt; The multitasking camera features seem geared towards video chat apps. Are you expecting pro camera apps to adopt this, and will the native camera app adopt this behaviour?",
      "ts": "1654709709.939659",
      "thread_ts": "1654709709.939659",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 3,
      "latest_reply": "1654709870.951269",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "LCea",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03HVE4BEBY"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"The multitasking camera features seem geared towards video chat apps. Are you expecting pro camera apps to adopt this, and will the native camera app adopt this behaviour?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "9c158d21-157c-4259-be84-49c9d26d434c",
          "type": "message",
          "user": "U03HHA1D44F",
          "text": "Multitasking Camera Access is often used by video chat apps. But it can be used by other apps. The built in Camera app requires itself to be full screen. But you can have a Slide Over app on top of it to multitask. Like opening Notes on top",
          "ts": "1654709759.031799",
          "thread_ts": "1654709709.939659",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "RqTZ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Multitasking Camera Access is often used by video chat apps. But it can be used by other apps. The built in Camera app requires itself to be full screen. But you can have a Slide Over app on top of it to multitask. Like opening Notes on top"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "af0f193b-d5b8-4f74-9e89-f291912a7ae4",
          "type": "message",
          "user": "U03HHA1D44F",
          "text": "See for example this screenshot from the video. This is Apple's built in Camera app",
          "ts": "1654709803.564979",
          "thread_ts": "1654709709.939659",
          "files": [
            {
              "id": "F03JRFXV1AR",
              "created": 1654709785,
              "timestamp": 1654709785,
              "name": "Screen Shot 2022-06-08 at 10.36.21 AM.png",
              "title": "Screen Shot 2022-06-08 at 10.36.21 AM.png",
              "mimetype": "image/png",
              "image_exif_rotation": 0,
              "filetype": "png",
              "pretty_type": "PNG",
              "user": "U03HHA1D44F",
              "mode": "hosted",
              "editable": false,
              "is_external": false,
              "external_type": "",
              "size": 11795649,
              "url": "",
              "url_download": "",
              "url_private": "https://files.slack.com/files-pri/T01PTBJ95PS-F03JRFXV1AR/screen_shot_2022-06-08_at_10.36.21_am.png",
              "url_private_download": "https://files.slack.com/files-pri/T01PTBJ95PS-F03JRFXV1AR/download/screen_shot_2022-06-08_at_10.36.21_am.png",
              "original_h": 3384,
              "original_w": 6016,
              "thumb_64": "https://files.slack.com/files-tmb/T01PTBJ95PS-F03JRFXV1AR-88bd5cd6d7/screen_shot_2022-06-08_at_10.36.21_am_64.png",
              "thumb_80": "https://files.slack.com/files-tmb/T01PTBJ95PS-F03JRFXV1AR-88bd5cd6d7/screen_shot_2022-06-08_at_10.36.21_am_80.png",
              "thumb_160": "https://files.slack.com/files-tmb/T01PTBJ95PS-F03JRFXV1AR-88bd5cd6d7/screen_shot_2022-06-08_at_10.36.21_am_160.png",
              "thumb_360": "https://files.slack.com/files-tmb/T01PTBJ95PS-F03JRFXV1AR-88bd5cd6d7/screen_shot_2022-06-08_at_10.36.21_am_360.png",
              "thumb_360_gif": "",
              "thumb_360_w": 360,
              "thumb_360_h": 203,
              "thumb_480": "https://files.slack.com/files-tmb/T01PTBJ95PS-F03JRFXV1AR-88bd5cd6d7/screen_shot_2022-06-08_at_10.36.21_am_480.png",
              "thumb_480_w": 480,
              "thumb_480_h": 270,
              "thumb_720": "https://files.slack.com/files-tmb/T01PTBJ95PS-F03JRFXV1AR-88bd5cd6d7/screen_shot_2022-06-08_at_10.36.21_am_720.png",
              "thumb_720_w": 720,
              "thumb_720_h": 405,
              "thumb_960": "https://files.slack.com/files-tmb/T01PTBJ95PS-F03JRFXV1AR-88bd5cd6d7/screen_shot_2022-06-08_at_10.36.21_am_960.png",
              "thumb_960_w": 960,
              "thumb_960_h": 540,
              "thumb_1024": "https://files.slack.com/files-tmb/T01PTBJ95PS-F03JRFXV1AR-88bd5cd6d7/screen_shot_2022-06-08_at_10.36.21_am_1024.png",
              "thumb_1024_w": 1024,
              "thumb_1024_h": 576,
              "permalink": "https://appleevents.enterprise.slack.com/files/U03HHA1D44F/F03JRFXV1AR/screen_shot_2022-06-08_at_10.36.21_am.png",
              "permalink_public": "https://slack-files.com/T01PTBJ95PS-F03JRFXV1AR-79ba1f8a92",
              "edit_link": "",
              "preview": "",
              "preview_highlight": "",
              "lines": 0,
              "lines_more": 0,
              "is_public": false,
              "public_url_shared": false,
              "channels": null,
              "groups": null,
              "ims": null,
              "initial_comment": {},
              "comments_count": 0,
              "num_stars": 0,
              "is_starred": false,
              "shares": {
                "public": null,
                "private": null
              }
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "e4i3",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "See for example this screenshot from the video. This is Apple's built in Camera app"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "DC2040F9-AA5D-4BEA-BA89-5E4E60A39ED9",
          "type": "message",
          "user": "U03HVE4BEBY",
          "text": "Got it! Thank you. ",
          "ts": "1654709870.951269",
          "thread_ts": "1654709709.939659",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "XRmi",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Got"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "it!"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "Thank"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "you. "
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "d5e5245f-cc17-486a-be8c-78345cf5baf9",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": "\u003c@U03HHA1D44F\u003e I'd like to know more about the technology you used to shrink that second guitar down to AntMan size.",
      "ts": "1654710065.631089",
      "team": "T031SG5MZ7U",
      "reactions": [
        {
          "name": "joy",
          "count": 2,
          "users": [
            "U03HHA1D44F",
            "U03HVE4BEBY"
          ]
        },
        {
          "name": "guitar",
          "count": 2,
          "users": [
            "U03HHA1D44F",
            "U03JMLKUF1N"
          ]
        },
        {
          "name": "ant",
          "count": 1,
          "users": [
            "U03JMLKUF1N"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "WwS",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03HHA1D44F"
                },
                {
                  "type": "text",
                  "text": " I'd like to know more about the technology you used to shrink that second guitar down to AntMan size."
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "b410a58b-8c57-4a7c-b396-753d041ee2f0",
      "type": "message",
      "user": "U03HHA1D44F",
      "text": "You'll have to see my next video \"Discover advancements in iOS shrinking technology\"",
      "ts": "1654710147.880369",
      "team": "T031SG5MZ7U",
      "reactions": [
        {
          "name": "eyes",
          "count": 4,
          "users": [
            "U03JMB7160Z",
            "U03HVE4BEBY",
            "U03JGJESMS5",
            "U03JELDBMT3"
          ]
        },
        {
          "name": "+1",
          "count": 1,
          "users": [
            "U03HZ49R0CV"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "awtm",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "You'll have to see my next video \"Discover advancements in iOS shrinking technology\""
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "f533d24d-658a-401a-8a27-e531da48b572",
      "type": "message",
      "user": "U03HHA1D44F",
      "text": "Speaking of guitars -- I assembled that green guitar used in the app demo. Bought the body, neck, and other hardware and installed the components myself. It was a fun project. It was cool that the WWDC team let me use my guitars in the video.",
      "ts": "1654710235.582949",
      "team": "T031SG5MZ7U",
      "reactions": [
        {
          "name": "raised_hands",
          "count": 4,
          "users": [
            "U03JMB7160Z",
            "U03JDTS6RKP",
            "U03JELM0ZNV",
            "U03KBCLJVR6"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "eEVxs",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Speaking of guitars -- I assembled that green guitar used in the app demo. Bought the body, neck, and other hardware and installed the components myself. It was a fun project. It was cool that the WWDC team let me use my guitars in the video."
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "9f33286a-3d18-44e5-a5ca-3744ce2bfada",
      "type": "message",
      "user": "U03HHA1D44F",
      "text": "And actually, the production team during the recording day suggested I say the \"I hope your WWDC rocks\" as my sign off. It wasn't originally in my script but we thought it would be fun to add!",
      "ts": "1654710288.328929",
      "thread_ts": "1654710288.328929",
      "reply_count": 6,
      "latest_reply": "1654710615.250409",
      "team": "T031SG5MZ7U",
      "reactions": [
        {
          "name": "wink",
          "count": 1,
          "users": [
            "U03JMB7160Z"
          ]
        },
        {
          "name": "the_horns",
          "count": 4,
          "users": [
            "U03JRR26EU8",
            "U03JDTS6RKP",
            "U03HMD6JHAT",
            "U03J4CVE1U4"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "Vly1h",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "And actually, the production team during the recording day suggested I say the \"I hope your WWDC rocks\" as my sign off. It wasn't originally in my script but we thought it would be fun to add!"
                }
              ]
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "1FE77196-E9AA-4189-9031-77340787100E",
          "type": "message",
          "user": "U03HVE4BEBY",
          "text": "It was very well presented, knowing that makes it even better :grinning:",
          "ts": "1654710365.881409",
          "thread_ts": "1654710288.328929",
          "parent_user_id": "U03HHA1D44F",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "kETYQ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "It"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "was"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "very"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "well"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "presented,"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "knowing"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "that"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "makes"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "it"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "even"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "better"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "emoji",
                      "name": "grinning",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "086DDE7C-B8AC-45B8-A1FB-67B43F810F76",
          "type": "message",
          "user": "U03HVE4BEBY",
          "text": "And I'm glad you continued the time honoured tradition of making depth puns :ok_hand:",
          "ts": "1654710411.893819",
          "thread_ts": "1654710288.328929",
          "parent_user_id": "U03HHA1D44F",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "JyK/7",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "And"
                    },
                    {
                      "type": "text",
                      "text": " I'm "
                    },
                    {
                      "type": "text",
                      "text": "glad"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "you"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "continued"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "the"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "time"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "honoured"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "tradition"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "of"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "making"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "depth"
                    },
                    {
                      "type": "text",
                      "text": " puns "
                    },
                    {
                      "type": "emoji",
                      "name": "ok_hand",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "3c14c902-340b-47ad-b01f-84963565826d",
          "type": "message",
          "user": "U03HHA1D44F",
          "text": "Thank you!",
          "ts": "1654710544.686849",
          "thread_ts": "1654710288.328929",
          "parent_user_id": "U03HHA1D44F",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "WuACt",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thank you!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "0cad6726-9a23-408f-af42-6147c3ee8e5e",
          "type": "message",
          "user": "U03J20E7UBV",
          "text": "There were more depth puns than I think any of us realize :slightly_smiling_face:",
          "ts": "1654710567.172129",
          "thread_ts": "1654710288.328929",
          "parent_user_id": "U03HHA1D44F",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "WMjPr",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "There were more depth puns than I think any of us realize "
                    },
                    {
                      "type": "emoji",
                      "name": "slightly_smiling_face",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "15439AD6-4A25-4515-A604-938DB4A1AB40",
          "type": "message",
          "user": "U03HVE4BEBY",
          "text": "It's depth puns all the way down!",
          "ts": "1654710593.867239",
          "thread_ts": "1654710288.328929",
          "parent_user_id": "U03HHA1D44F",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "OTQSY",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "It's "
                    },
                    {
                      "type": "text",
                      "text": "depth"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "puns"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "all"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "the"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "way"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "down!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "2187271d-63ad-4acf-a362-b88427088683",
          "type": "message",
          "user": "U03HHA1D44F",
          "text": "Hah yes -- many of our team members requested I sprinkle in some depth puns. I knew I couldn't be as clever as \u003c@U03HXTBNYBC\u003e so I tried to find the right time to put one in",
          "ts": "1654710615.250409",
          "thread_ts": "1654710288.328929",
          "parent_user_id": "U03HHA1D44F",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "/dKP",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hah yes -- many of our team members requested I sprinkle in some depth puns. I knew I couldn't be as clever as "
                    },
                    {
                      "type": "user",
                      "user_id": "U03HXTBNYBC"
                    },
                    {
                      "type": "text",
                      "text": " so I tried to find the right time to put one in"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "335db1a5-de35-4eca-8ab9-4d6c1c2fe481",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": "Folks, we'll wrap it up in 5 minutes. Any lingering *deep* questions? Now's the time to ask.",
      "ts": "1654711057.448599",
      "team": "T031SG5MZ7U",
      "reactions": [
        {
          "name": "ok_hand",
          "count": 3,
          "users": [
            "U03HVE4BEBY",
            "U03JLPLT8HK",
            "U03J108Q0HL"
          ]
        },
        {
          "name": "camera",
          "count": 2,
          "users": [
            "U03HHA1D44F",
            "U03JMB7160Z"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "1zM6",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Folks, we'll wrap it up in 5 minutes. Any lingering "
                },
                {
                  "type": "text",
                  "text": "deep",
                  "style": {
                    "bold": true
                  }
                },
                {
                  "type": "text",
                  "text": " questions? Now's the time to ask."
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "7c1527b3-6308-4227-afa1-4dc53fbd880c",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": "We’ll be around for several more events during the week.\nWednesday 2-5 PM PDT: Camera Capture Lab #1. If you haven't already signed up, it's too late. :cry:\nThursday 10-11 AM PDT: Q\u0026amp;A Camera session #2. Right here!\nFriday 9 AM - 12 PM PDT: Camera Capture Lab #2. Sign up by end of Thursday with your questions.",
      "ts": "1654711118.792169",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "H1CZ",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "We’ll be around for several more events during the week.\nWednesday 2-5 PM PDT: Camera Capture Lab #1. If you haven't already signed up, it's too late. "
                },
                {
                  "type": "emoji",
                  "name": "cry",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": "\nThursday 10-11 AM PDT: Q\u0026A Camera session #2. Right here!\nFriday 9 AM - 12 PM PDT: Camera Capture Lab #2. Sign up by end of Thursday with your questions."
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "0c553ef0-c7aa-4868-8d0c-a1cbb0e16544",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": "There's also another \"Meet the Presenter\" tomorrow morning at 11:00 AM — come check out \"Create camera extensions with CoreMediaIO\".",
      "ts": "1654711158.471919",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "ryBK",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "There's also another \"Meet the Presenter\" tomorrow morning at 11:00 AM — come check out \"Create camera extensions with CoreMediaIO\"."
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "49d20a4f-a542-4920-867c-9e930aa8673a",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": "THANK YOU for all the great questions and the interest. Can't wait to see what experiences you build around these new camera features in iOS 16. Thanks to \u003c@U03HHA1D44F\u003e for hanging out with us, and to the Camera team. We'll see you later.",
      "ts": "1654711237.709149",
      "team": "T031SG5MZ7U",
      "reactions": [
        {
          "name": "raised_hands",
          "count": 3,
          "users": [
            "U03JMB7160Z",
            "U03HHA1D44F",
            "U03JRP87THN"
          ]
        },
        {
          "name": "+1",
          "count": 1,
          "users": [
            "U03JBMMB10A"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "gFY",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "THANK YOU for all the great questions and the interest. Can't wait to see what experiences you build around these new camera features in iOS 16. Thanks to "
                },
                {
                  "type": "user",
                  "user_id": "U03HHA1D44F"
                },
                {
                  "type": "text",
                  "text": " for hanging out with us, and to the Camera team. We'll see you later."
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03HXTBNYBC\u003e added a workflow to this channel: *Photos and Camera - Ask a Question*.",
      "ts": "1654755556.320909",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "replace_original": false,
      "delete_original": false,
      "blocks": null
    },
    {
      "type": "message",
      "text": "\u003c@U03HXTBNYBC\u003e added a workflow to this channel: *Photos and Camera - Idea Submission*.",
      "ts": "1654755566.657539",
      "subtype": "bot_message",
      "bot_id": "B03JAB6KMDX",
      "username": "Photos and Camera - Idea Submission",
      "replace_original": false,
      "delete_original": false,
      "blocks": null
    },
    {
      "client_msg_id": "fde4c538-a8a1-40ff-a677-86e769e7eea1",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": "Hi everyone :wave: , we’re going to try something different for our friends outside of the US... we’re going to leave the :workflowbolt: enabled so you can go ahead and submit your questions for any of our lounge topics tomorrow.  We’re all going to sign off for the night but we’ll answer your questions throughout the day tomorrow so you can check back when you wake up! Cheers!",
      "ts": "1654755624.380519",
      "team": "T031SG5MZ7U",
      "reactions": [
        {
          "name": "full_moon_with_face",
          "count": 1,
          "users": [
            "U03HEF3RZKN"
          ]
        },
        {
          "name": "raised_hands",
          "count": 7,
          "users": [
            "U03JG9JF529",
            "U03JASKNME1",
            "U03J4CT515Y",
            "U03HZ5T63N1",
            "U03HVE4BEBY",
            "U03JRP87THN",
            "U03JPN0896J"
          ]
        },
        {
          "name": "gratitude-thank-you",
          "count": 2,
          "users": [
            "U03JRR288HE",
            "U03JRP87THN"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "6=N",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Hi everyone "
                },
                {
                  "type": "emoji",
                  "name": "wave",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": " , we’re going to try something different for our friends outside of the US... we’re going to leave the "
                },
                {
                  "type": "emoji",
                  "name": "workflowbolt",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": " enabled so you can go ahead and submit your questions for any of our lounge topics tomorrow.  We’re all going to sign off for the night but we’ll answer your questions throughout the day tomorrow so you can check back when you wake up! Cheers!"
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03HMD7BXPZ\u003e asked\n\u0026gt; Hi! I've watched the video to live text interaction and i was wondering, if the quick actions can be customized to add own functions?",
      "ts": "1654792372.898249",
      "thread_ts": "1654792372.898249",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 2,
      "latest_reply": "1654812740.611489",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "OWPC",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03HMD7BXPZ"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Hi! I've watched the video to live text interaction and i was wondering, if the quick actions can be customized to add own functions?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "c305e503-7111-4666-85ca-c6df08d0cdd0",
          "type": "message",
          "user": "U03DJTBMHFF",
          "text": "Excellent question. The quick actions are all driven by built-in data detectors. There is no opportunity for extending that or customizing those at this time. That said, we'd love to hear what kind of customizations you were hoping to provide.",
          "ts": "1654792465.610759",
          "thread_ts": "1654792372.898249",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "rh1",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Excellent question. The quick actions are all driven by built-in data detectors. There is no opportunity for extending that or customizing those at this time. That said, we'd love to hear what kind of customizations you were hoping to provide."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "abe902b0-7e40-4aa4-ae94-a70d97851a62",
          "type": "message",
          "user": "U03HMD7BXPZ",
          "text": "Thanks for the answer. It would be great to just add functions like “Apply for the textfield” or “Generate new case/entry” and the recognized text can just be added to own textfields or used as titles.",
          "ts": "1654812740.611489",
          "thread_ts": "1654792372.898249",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "kt6t",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks for the answer. It would be great to just add functions like “Apply for the textfield” or “Generate new case/entry” and the recognized text can just be added to own textfields or used as titles."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "95ac6179-8e34-4874-85ae-f523cfdb5a4d",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": "Good morning, west coasters,\nWelcome to *Q\u0026amp;A: Camera Capture*, our second of two camera-focused Q\u0026amp;A sessions! We’ll get started promptly at 10 AM PDT. Hit us with your toughest camera questions. We can take it. (Easy questions are good too.) :smile: \nHere’s how to ask: Select the:heavy_plus_sign:icon from the lower left, and find the _Ask A Question_ workflow. Type in your question and it will be delivered directly to the team. We’ll answer as many questions as we can. While it’s unlikely we’ll be able to address every question, we’ll do our best. Thanks in advance for all your submissions. They’re all valuable! Feedback too! We love to hear what’s working (or not) for you.  :rocket:",
      "ts": "1654793327.954699",
      "team": "T031SG5MZ7U",
      "reactions": [
        {
          "name": "+1",
          "count": 1,
          "users": [
            "U03HXSHBJ8K"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "8Tl",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Good morning, west coasters,\nWelcome to "
                },
                {
                  "type": "text",
                  "text": "Q\u0026A: Camera Capture",
                  "style": {
                    "bold": true
                  }
                },
                {
                  "type": "text",
                  "text": ", our second of two camera-focused Q\u0026A sessions! We’ll get started promptly at 10 AM PDT. Hit us with your toughest camera questions. We can take it. (Easy questions are good too.) "
                },
                {
                  "type": "emoji",
                  "name": "smile",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": " \nHere’s how to ask: Select the"
                },
                {
                  "type": "emoji",
                  "name": "heavy_plus_sign",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": "icon from the lower left, and find the "
                },
                {
                  "type": "text",
                  "text": "Ask A Question",
                  "style": {
                    "italic": true
                  }
                },
                {
                  "type": "text",
                  "text": " workflow. Type in your question and it will be delivered directly to the team. We’ll answer as many questions as we can. While it’s unlikely we’ll be able to address every question, we’ll do our best. Thanks in advance for all your submissions. They’re all valuable! Feedback too! We love to hear what’s working (or not) for you.  "
                },
                {
                  "type": "emoji",
                  "name": "rocket",
                  "skin_tone": 0
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03HVE4BEBY\u003e asked\n\u0026gt; Will we ever see a public API for using the hardware volume buttons to capture photos? The current.. workarounds are less than ideal :unamused:",
      "ts": "1654793555.663219",
      "thread_ts": "1654793555.663219",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 3,
      "latest_reply": "1654793736.872019",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "cdd",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03HVE4BEBY"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Will we ever see a public API for using the hardware volume buttons to capture photos? The current.. workarounds are less than ideal \"},{\"type\":\"emoji\",\"name\":\"unamused\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "23a58aa1-886a-43d7-a689-657ea424a690",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Magic eightball says: \"Outlook uncertain\".",
          "ts": "1654793582.834459",
          "thread_ts": "1654793555.663219",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "FgvI",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Magic eightball says: \"Outlook uncertain\"."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "176d63a5-5a75-4c0c-aafa-07e945cb0365",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Thanks for the feedback, Ben. We're asked about that a lot. Have you filed a request through Feedback Assistant?",
          "ts": "1654793615.810869",
          "thread_ts": "1654793555.663219",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "scoYr",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks for the feedback, Ben. We're asked about that a lot. Have you filed a request through Feedback Assistant?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "4e2db1b8-6d07-47a4-a7bf-f9f5ebf8e781",
          "type": "message",
          "user": "U03HVE4BEBY",
          "text": "If I have it wasn't recently! But I brought it up in a lab yesterday, so I'll submit one now to hopefully give a little boost in priority",
          "ts": "1654793736.872019",
          "thread_ts": "1654793555.663219",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "+1",
              "count": 2,
              "users": [
                "U03JMB7160Z",
                "U03HXTBNYBC"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "fpR",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "If I have it wasn't recently! But I brought it up in a lab yesterday, so I'll submit one now to hopefully give a little boost in priority"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03JASKNME1\u003e asked\n\u0026gt; There’s an API to get tagged faces out of a photo (at least the region within the photo where there’s a face, not sure about the persons name..). I thought there might be a way to manually tag faces that the auto Apple tagging hadn’t picked up, but I couldn’t find a way to do this, is it possible? Something you’d consider adding to either the api or the photos app if not?",
      "ts": "1654793731.969829",
      "thread_ts": "1654793731.969829",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 3,
      "latest_reply": "1654845098.364889",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "xBZx",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03JASKNME1"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"There\\u2019s an API to get tagged faces out of a photo (at least the region within the photo where there\\u2019s a face, not sure about the persons name..). I thought there might be a way to manually tag faces that the auto Apple tagging hadn\\u2019t picked up, but I couldn\\u2019t find a way to do this, is it possible? Something you\\u2019d consider adding to either the api or the photos app if not?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "a5c2e336-a352-48a8-beee-66ea9f51acf0",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Using the ImageIO APIs \u0026lt;ImageIO/CGImageProperties.h\u0026gt; you can load up an image on disk and inspect its metadata. Detected faces are held within the `kCGImagePropertyExifAuxDictionary` 's @\"Regions\".",
          "ts": "1654793928.645839",
          "thread_ts": "1654793731.969829",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Ki2",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Using the ImageIO APIs \u003cImageIO/CGImageProperties.h\u003e you can load up an image on disk and inspect its metadata. Detected faces are held within the "
                    },
                    {
                      "type": "text",
                      "text": "kCGImagePropertyExifAuxDictionary",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " 's @\"Regions\"."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "2ec46352-ea8f-4b60-a31d-d7aca9d7baf6",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Is that what you had in mind by \"tagging\", or something else?",
          "ts": "1654793953.031839",
          "thread_ts": "1654793731.969829",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "wMA",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Is that what you had in mind by \"tagging\", or something else?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "AA401A5F-8195-4B87-92D7-505B528BF98D",
          "type": "message",
          "user": "U03JASKNME1",
          "text": "That's probably where I found the data, but it didn't seem possible to add to it and update it so the photos app would show those additions?",
          "ts": "1654845098.364889",
          "thread_ts": "1654793731.969829",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "VNh",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "That's "
                    },
                    {
                      "type": "text",
                      "text": "probably"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "where"
                    },
                    {
                      "type": "text",
                      "text": " I "
                    },
                    {
                      "type": "text",
                      "text": "found"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "the"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "data,"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "but"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "it"
                    },
                    {
                      "type": "text",
                      "text": " didn't "
                    },
                    {
                      "type": "text",
                      "text": "seem"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "possible"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "to"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "add"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "to"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "it"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "and"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "update"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "it"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "so"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "the"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "photos"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "app"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "would"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "show"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "those"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "additions?"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "12065714-226f-40a6-9869-f212321a625b",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": "\u003c@U03JPN0896J\u003e has submitted:\n\u0026gt; My Rec Time Movie app only works with iOS 15.2 and newer. What should I change to make it work with earlier versions of iOS?\n",
      "ts": "1654794031.891889",
      "thread_ts": "1654794031.891889",
      "reply_count": 6,
      "latest_reply": "1654824599.802819",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "yE25",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03JPN0896J"
                },
                {
                  "type": "text",
                  "text": " has submitted:\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"My Rec Time Movie app only works with iOS 15.2 and newer. What should I change to make it work with earlier versions of iOS?\"}]}"
            },
            {
              "type": "rich_text_section",
              "elements": []
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "4760bc71-f07e-4540-9ebb-bf6a6caae48d",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "\u003c@U03JPN0896J\u003e Does your movie app require features that are only available in 15.2 or later? By default, Xcode will build your app against the SDK it's currently using. If you want your app to be backward compatible with earlier SDKs, you need to set your Deployment Target to something earlier.",
          "ts": "1654794192.134309",
          "thread_ts": "1654794031.891889",
          "parent_user_id": "U03HXTBNYBC",
          "files": [
            {
              "id": "F03JXLMGA2H",
              "created": 1654794188,
              "timestamp": 1654794188,
              "name": "Screenshot 2022-06-09 at 10.03.03 AM.png",
              "title": "Screenshot 2022-06-09 at 10.03.03 AM.png",
              "mimetype": "image/png",
              "image_exif_rotation": 0,
              "filetype": "png",
              "pretty_type": "PNG",
              "user": "U03HXTBNYBC",
              "mode": "hosted",
              "editable": false,
              "is_external": false,
              "external_type": "",
              "size": 92651,
              "url": "",
              "url_download": "",
              "url_private": "https://files.slack.com/files-pri/T01PTBJ95PS-F03JXLMGA2H/screenshot_2022-06-09_at_10.03.03_am.png",
              "url_private_download": "https://files.slack.com/files-pri/T01PTBJ95PS-F03JXLMGA2H/download/screenshot_2022-06-09_at_10.03.03_am.png",
              "original_h": 338,
              "original_w": 1442,
              "thumb_64": "https://files.slack.com/files-tmb/T01PTBJ95PS-F03JXLMGA2H-26b432d9ef/screenshot_2022-06-09_at_10.03.03_am_64.png",
              "thumb_80": "https://files.slack.com/files-tmb/T01PTBJ95PS-F03JXLMGA2H-26b432d9ef/screenshot_2022-06-09_at_10.03.03_am_80.png",
              "thumb_160": "https://files.slack.com/files-tmb/T01PTBJ95PS-F03JXLMGA2H-26b432d9ef/screenshot_2022-06-09_at_10.03.03_am_160.png",
              "thumb_360": "https://files.slack.com/files-tmb/T01PTBJ95PS-F03JXLMGA2H-26b432d9ef/screenshot_2022-06-09_at_10.03.03_am_360.png",
              "thumb_360_gif": "",
              "thumb_360_w": 360,
              "thumb_360_h": 84,
              "thumb_480": "https://files.slack.com/files-tmb/T01PTBJ95PS-F03JXLMGA2H-26b432d9ef/screenshot_2022-06-09_at_10.03.03_am_480.png",
              "thumb_480_w": 480,
              "thumb_480_h": 113,
              "thumb_720": "https://files.slack.com/files-tmb/T01PTBJ95PS-F03JXLMGA2H-26b432d9ef/screenshot_2022-06-09_at_10.03.03_am_720.png",
              "thumb_720_w": 720,
              "thumb_720_h": 169,
              "thumb_960": "https://files.slack.com/files-tmb/T01PTBJ95PS-F03JXLMGA2H-26b432d9ef/screenshot_2022-06-09_at_10.03.03_am_960.png",
              "thumb_960_w": 960,
              "thumb_960_h": 225,
              "thumb_1024": "https://files.slack.com/files-tmb/T01PTBJ95PS-F03JXLMGA2H-26b432d9ef/screenshot_2022-06-09_at_10.03.03_am_1024.png",
              "thumb_1024_w": 1024,
              "thumb_1024_h": 240,
              "permalink": "https://appleevents.enterprise.slack.com/files/U03HXTBNYBC/F03JXLMGA2H/screenshot_2022-06-09_at_10.03.03_am.png",
              "permalink_public": "https://slack-files.com/T01PTBJ95PS-F03JXLMGA2H-e7f7d513b4",
              "edit_link": "",
              "preview": "",
              "preview_highlight": "",
              "lines": 0,
              "lines_more": 0,
              "is_public": false,
              "public_url_shared": false,
              "channels": null,
              "groups": null,
              "ims": null,
              "initial_comment": {},
              "comments_count": 0,
              "num_stars": 0,
              "is_starred": false,
              "shares": {
                "public": null,
                "private": null
              }
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "vd6",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "user",
                      "user_id": "U03JPN0896J"
                    },
                    {
                      "type": "text",
                      "text": " Does your movie app require features that are only available in 15.2 or later? By default, Xcode will build your app against the SDK it's currently using. If you want your app to be backward compatible with earlier SDKs, you need to set your Deployment Target to something earlier."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "B1F00598-35EB-4006-857F-172926067FB0",
          "type": "message",
          "user": "U03JPN0896J",
          "text": "If I expose earlier versions, the application crashes.",
          "ts": "1654821660.997109",
          "thread_ts": "1654794031.891889",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "51QxG",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "If I expose earlier versions, the application crashes."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "568b955d-f140-4908-a7dc-423207efef1a",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Where does it crash? What's the backtrace?",
          "ts": "1654824227.726899",
          "thread_ts": "1654794031.891889",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "8l1/",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Where does it crash? What's the backtrace?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "018CCEFC-D855-4843-AFC0-E264A81D9F4D",
          "type": "message",
          "user": "U03JPN0896J",
          "text": "Falls on iPone.",
          "ts": "1654824379.276589",
          "thread_ts": "1654794031.891889",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "HiW",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Falls on iPone"
                    },
                    {
                      "type": "text",
                      "text": "."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "2FFA853E-7A02-4C17-BC9F-7844612BFBB4",
          "type": "message",
          "user": "U03JPN0896J",
          "text": "Version for 15.2 is already in the App store.",
          "ts": "1654824570.225979",
          "thread_ts": "1654794031.891889",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "dmBw",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Version for 15.2 is already in the App store"
                    },
                    {
                      "type": "text",
                      "text": "."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "196CCE40-7C7A-4958-A9F4-58CE5EAD4853",
          "type": "message",
          "user": "U03JPN0896J",
          "text": "\u003chttps://apps.apple.com/kz/app/rec-time-movie/id1597426954|https://apps.apple.com/kz/app/rec-time-movie/id1597426954\u003e",
          "ts": "1654824599.802819",
          "thread_ts": "1654794031.891889",
          "attachments": [
            {
              "fallback": "App Store: ‎Rec Time Movie",
              "id": 1,
              "title": "‎Rec Time Movie",
              "title_link": "https://apps.apple.com/kz/app/rec-time-movie/id1597426954",
              "text": "‎1. Displaying the remaining video recording time. 2. Battery level display. 3. Video format management. 4. Camera function control.",
              "image_url": "https://is2-ssl.mzstatic.com/image/thumb/Purple116/v4/cc/de/b8/ccdeb86d-bcad-960e-dafe-a96777f4d808/AppIcon-1x_U007emarketing-0-7-0-85-220.png/1200x630wa.png",
              "service_name": "App Store",
              "service_icon": "https://apps.apple.com/favicon.ico",
              "from_url": "https://apps.apple.com/kz/app/rec-time-movie/id1597426954",
              "original_url": "https://apps.apple.com/kz/app/rec-time-movie/id1597426954",
              "blocks": null
            }
          ],
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "8O2Ed",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "link",
                      "url": "https://apps.apple.com/kz/app/rec-time-movie/id1597426954",
                      "text": "https://apps.apple.com/kz/app/rec-time-movie/id1597426954"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03HVDWU0ES\u003e asked\n\u0026gt; This is about AVCaptureDevice.  Will there be a public API to check on the lens power of the camera?  This would be exceedingly useful if the device is a telephoto camera (that is, is it 2.0x optical power, or 2.5x or 3.0x, or some future power?)  This would be great for any camera app where the user manually selects the lens to use (no virtual device)  as well as set manual shutter speed \u0026amp; ISO.  Thanks!",
      "ts": "1654794203.046779",
      "thread_ts": "1654794203.046779",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 34,
      "latest_reply": "1654888932.520949",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "+hvNx",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03HVDWU0ES"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"This is about AVCaptureDevice.  Will there be a public API to check on the lens power of the camera?  This would be exceedingly useful if the device is a telephoto camera (that is, is it 2.0x optical power, or 2.5x or 3.0x, or some future power?)  This would be great for any camera app where the user manually selects the lens to use (no virtual device)  as well as set manual shutter speed \u0026 ISO.  Thanks!\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "A096EB58-9444-4050-82D6-F270FAF486B9",
          "type": "message",
          "user": "U03HVE4BEBY",
          "text": "Seconded! This is definitely more awkward than it should be",
          "ts": "1654794301.289759",
          "thread_ts": "1654794203.046779",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "R5z",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Seconded!"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "This"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "is"
                    },
                    {
                      "type": "text",
                      "text": " definitely "
                    },
                    {
                      "type": "text",
                      "text": "more"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "awkward"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "than"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "it"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "should"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "be"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "f01658a4-ca18-4704-a055-26121cbd26fc",
          "type": "message",
          "user": "U03HR8XVATG",
          "text": "Hi Eric, Ben. could you clarify what you mean with \"lens power\"? Are you referring to the focal length / native zoom?",
          "ts": "1654794358.343069",
          "thread_ts": "1654794203.046779",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "btHh",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi Eric, Ben. could you clarify what you mean with \"lens power\"? Are you referring to the focal length / native zoom?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "fd6187c4-fc75-4a8c-9cbe-18e0a336a329",
          "type": "message",
          "user": "U03HVDWU0ES",
          "text": "Hi Ben.  What I mean is, say I don't know if the user has the iPhone 12 Pro that has the 2.5x telephoto, or the iPhone 13 Pro that has the 3.0x tele.  It would be wonderful to look at one get variable to see if it's a 2.5x or 3.0x, instead of doing the cumbersome task of determining that the user does have say an iPhone 12",
          "ts": "1654794596.834109",
          "thread_ts": "1654794203.046779",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "fQmIj",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi Ben.  What I mean is, say I don't know if the user has the iPhone 12 Pro that has the 2.5x telephoto, or the iPhone 13 Pro that has the 3.0x tele.  It would be wonderful to look at one get variable to see if it's a 2.5x or 3.0x, instead of doing the cumbersome task of determining that the user does have say an iPhone 12"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "661bab8e-1988-489f-a440-4408b721cd46",
          "type": "message",
          "user": "U03HR8XVATG",
          "text": "The `-[AVCaptureDevice virtualDeviceSwitchOverVideoZoomFactors]` property tells the relative zoom factors between the cameras. So if you're looking to build a UI around these switch-over zoom factors, then you'll want to use that.",
          "ts": "1654794610.672509",
          "thread_ts": "1654794203.046779",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "point_up_2",
              "count": 1,
              "users": [
                "U03HXTBNYBC"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "tcCb",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "The "
                    },
                    {
                      "type": "text",
                      "text": "-[AVCaptureDevice virtualDeviceSwitchOverVideoZoomFactors]",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " property tells the relative zoom factors between the cameras. So if you're looking to build a UI around these switch-over zoom factors, then you'll want to use that."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "8240ed37-ddb3-44ad-9bcc-3d3eb54d35e2",
          "type": "message",
          "user": "U03HVE4BEBY",
          "text": "In order to know if the telephoto camera is 2×, 2.5× or 3× (and display it to the user), you have to get the video field of view, then work out how that angle translates to a focal length, and how that focal length gets generalised",
          "ts": "1654794666.051899",
          "thread_ts": "1654794203.046779",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "e+Fw",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "In order to know if the telephoto camera is 2×, 2.5× or 3× (and display it to the user), you have to get the video field of view, then work out how that angle translates to a focal length, and how that focal length gets generalised"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "a8043eeb-1c43-4e28-a470-6a4c0b816172",
          "type": "message",
          "user": "U03HVDWU0ES",
          "text": "I did check that variable and it reads empty brackets if there is no virtual device.  I'm having the user manually select whether to use the wide lens or the telephoto, not rely on a virtual camera to do that.",
          "ts": "1654794736.258329",
          "thread_ts": "1654794203.046779",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "rpCi",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I did check that variable and it reads empty brackets if there is no virtual device.  I'm having the user manually select whether to use the wide lens or the telephoto, not rely on a virtual camera to do that."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "1fe41ae3-201c-49a5-a3b5-eb2d9ded1d97",
          "type": "message",
          "user": "U03HVE4BEBY",
          "text": "This is how I handle it in my app",
          "ts": "1654794793.287129",
          "thread_ts": "1654794203.046779",
          "files": [
            {
              "id": "F03JU1K8WT0",
              "created": 1654794747,
              "timestamp": 1654794747,
              "name": "Screenshot 2022-06-09 at 18.11.48.png",
              "title": "Screenshot 2022-06-09 at 18.11.48.png",
              "mimetype": "image/png",
              "image_exif_rotation": 0,
              "filetype": "png",
              "pretty_type": "PNG",
              "user": "U03HVE4BEBY",
              "mode": "hosted",
              "editable": false,
              "is_external": false,
              "external_type": "",
              "size": 22881,
              "url": "",
              "url_download": "",
              "url_private": "https://files.slack.com/files-pri/T01PTBJ95PS-F03JU1K8WT0/screenshot_2022-06-09_at_18.11.48.png",
              "url_private_download": "https://files.slack.com/files-pri/T01PTBJ95PS-F03JU1K8WT0/download/screenshot_2022-06-09_at_18.11.48.png",
              "original_h": 188,
              "original_w": 408,
              "thumb_64": "https://files.slack.com/files-tmb/T01PTBJ95PS-F03JU1K8WT0-d281b8d795/screenshot_2022-06-09_at_18.11.48_64.png",
              "thumb_80": "https://files.slack.com/files-tmb/T01PTBJ95PS-F03JU1K8WT0-d281b8d795/screenshot_2022-06-09_at_18.11.48_80.png",
              "thumb_160": "https://files.slack.com/files-tmb/T01PTBJ95PS-F03JU1K8WT0-d281b8d795/screenshot_2022-06-09_at_18.11.48_160.png",
              "thumb_360": "https://files.slack.com/files-tmb/T01PTBJ95PS-F03JU1K8WT0-d281b8d795/screenshot_2022-06-09_at_18.11.48_360.png",
              "thumb_360_gif": "",
              "thumb_360_w": 360,
              "thumb_360_h": 166,
              "thumb_480": "",
              "thumb_480_w": 0,
              "thumb_480_h": 0,
              "thumb_720": "",
              "thumb_720_w": 0,
              "thumb_720_h": 0,
              "thumb_960": "",
              "thumb_960_w": 0,
              "thumb_960_h": 0,
              "thumb_1024": "",
              "thumb_1024_w": 0,
              "thumb_1024_h": 0,
              "permalink": "https://appleevents.enterprise.slack.com/files/U03HVE4BEBY/F03JU1K8WT0/screenshot_2022-06-09_at_18.11.48.png",
              "permalink_public": "https://slack-files.com/T01PTBJ95PS-F03JU1K8WT0-d1972042cd",
              "edit_link": "",
              "preview": "",
              "preview_highlight": "",
              "lines": 0,
              "lines_more": 0,
              "is_public": false,
              "public_url_shared": false,
              "channels": null,
              "groups": null,
              "ims": null,
              "initial_comment": {},
              "comments_count": 0,
              "num_stars": 0,
              "is_starred": false,
              "shares": {
                "public": null,
                "private": null
              }
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "b2EDj",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "This is how I handle it in my app"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "f210cc68-965a-4b89-8055-280954337322",
          "type": "message",
          "user": "U03HR8XVATG",
          "text": "You can programmatically pick the virtual camera device and then query that property. It's a static property on the device in question, so it does not change depending on whether the device is connected to a session or not.",
          "ts": "1654794795.053959",
          "thread_ts": "1654794203.046779",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "cwG",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "You can programmatically pick the virtual camera device and then query that property. It's a static property on the device in question, so it does not change depending on whether the device is connected to a session or not."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "50544ede-9913-4063-815c-3ac8bde70307",
          "type": "message",
          "user": "U03HVE4BEBY",
          "text": "(I feel like we may be trying to solve slightly different problems, apologies for hijacking!)",
          "ts": "1654794847.643959",
          "thread_ts": "1654794203.046779",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "hHsS",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "(I feel like we may be trying to solve slightly different problems, apologies for hijacking!)"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "b56da236-edae-4fb3-8ae6-c0916f4c815e",
          "type": "message",
          "user": "U03HR8XVATG",
          "text": "Also note that the zoom factor of the widest FOV constituent device is always defined as 1x. If you want to build something similar to \u003chttp://Camera.app|Camera.app\u003e where the wide-angle camera is defined as 1x then you'll want to divide the zoom factors by the wide-angle camera's switch-over zoom factor.",
          "ts": "1654794877.114759",
          "thread_ts": "1654794203.046779",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "O8o9",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Also note that the zoom factor of the widest FOV constituent device is always defined as 1x. If you want to build something similar to Camera.app where the wide-angle camera is defined as 1x then you'll want to divide the zoom factors by the wide-angle camera's switch-over zoom factor."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "7ad4c10c-cded-4589-a689-9dfa2d175feb",
          "type": "message",
          "user": "U03HR8XVATG",
          "text": "One more note, on iPhone X, the telephoto camera's switch-over zoom factor is actually 1.8x (despite \u003chttp://Camera.app|Camera.app\u003e showing 2x).",
          "ts": "1654794936.466649",
          "thread_ts": "1654794203.046779",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "thinking_face",
              "count": 1,
              "users": [
                "U03HVE4BEBY"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "qtUga",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "One more note, on iPhone X, the telephoto camera's switch-over zoom factor is actually 1.8x (despite Camera.app showing 2x)."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "f39975c7-64e1-4d8c-be34-065ff4d213b3",
          "type": "message",
          "user": "U03HR8XVATG",
          "text": "We didn't want to confuse users with too much technical detail, so we use 2x in the UI.",
          "ts": "1654794988.535369",
          "thread_ts": "1654794203.046779",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "uMn",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "We didn't want to confuse users with too much technical detail, so we use 2x in the UI."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "6b15a087-fefc-41b2-b93e-78cac7f2b3b7",
          "type": "message",
          "user": "U03HR8XVATG",
          "text": "Eric, Ben, did this help answer your question(s)?",
          "ts": "1654795155.257699",
          "thread_ts": "1654794203.046779",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "sfS9h",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Eric, Ben, did this help answer your question(s)?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "6B8B13CC-8744-4BA5-A4A2-533C2976C808",
          "type": "message",
          "user": "U03HVE4BEBY",
          "text": "Querying the virtual camera is probably cleaner than what I'm doing, but it would still be nicer to just have it as a property on each camera device. In my case I'm using the individual cameras to enable raw, manual WB, etc ",
          "ts": "1654795352.746189",
          "thread_ts": "1654794203.046779",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "u5aCx",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Querying "
                    },
                    {
                      "type": "text",
                      "text": "the"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "virtual"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "camera"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "is"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "probably"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "cleaner"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "than"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "what"
                    },
                    {
                      "type": "text",
                      "text": " I'm doing"
                    },
                    {
                      "type": "text",
                      "text": ","
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "but"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "it"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "would"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "still"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "be"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "nicer"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "to"
                    },
                    {
                      "type": "text",
                      "text": " just "
                    },
                    {
                      "type": "text",
                      "text": "have"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "it"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "as"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "a"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "property"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "on"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "each"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "camera"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "device. In"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "my"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "case"
                    },
                    {
                      "type": "text",
                      "text": " I'm "
                    },
                    {
                      "type": "text",
                      "text": "using"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "the"
                    },
                    {
                      "type": "text",
                      "text": " individual "
                    },
                    {
                      "type": "text",
                      "text": "cameras"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "to"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "enable"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "raw,"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "manual"
                    },
                    {
                      "type": "text",
                      "text": " WB"
                    },
                    {
                      "type": "text",
                      "text": ","
                    },
                    {
                      "type": "text",
                      "text": " etc "
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "f5f96ce0-f299-4d58-bed2-e17c8964bf83",
          "type": "message",
          "user": "U03HVDWU0ES",
          "text": "Hi Jozef, thanks for the answers.  But in my app users not only have a zoom control, they also have push buttons to manually select what lens to use.  So for the iPhone 11 Pro I present three buttons:  0.5x, 1x, and 2.0x.  For the iPhone 13 Pro I present these:  0.5x, 1x, and 3.0x.  Right now I do a roundabout way to know whether to call the button that connects to the telephoto camera a 2.0x or 3.0x.",
          "ts": "1654795444.238399",
          "thread_ts": "1654794203.046779",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "9Vp5",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi Jozef, thanks for the answers.  But in my app users not only have a zoom control, they also have push buttons to manually select what lens to use.  So for the iPhone 11 Pro I present three buttons:  0.5x, 1x, and 2.0x.  For the iPhone 13 Pro I present these:  0.5x, 1x, and 3.0x.  Right now I do a roundabout way to know whether to call the button that connects to the telephoto camera a 2.0x or 3.0x."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "b4b64b52-2c9b-4083-a5df-a12a5461a387",
          "type": "message",
          "user": "U03HR8XVATG",
          "text": "I believe the API I mentioned solves both of these problems. Just query for it on the Triple Camera device and you have all the zoom factors you need.",
          "ts": "1654795533.662599",
          "thread_ts": "1654794203.046779",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "cED",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I believe the API I mentioned solves both of these problems. Just query for it on the Triple Camera device and you have all the zoom factors you need."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "4221bc25-c161-443f-821a-55bfb722e2a7",
          "type": "message",
          "user": "U03HR8XVATG",
          "text": "Ben, the problem is that these zoom factors are relative to each other, so they only make sense in the context of a virtual camera. Note that you get different numbers from the Triple Camera than from the Dual Camera because the baseline is different. On the Triple Camera the wide-angle camera is typically 2x while on the Dual Camera it's 1x. This is why this is a property on the virtual cameras and not on the physical ones.",
          "ts": "1654795615.453669",
          "thread_ts": "1654794203.046779",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "V2azA",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Ben, the problem is that these zoom factors are relative to each other, so they only make sense in the context of a virtual camera. Note that you get different numbers from the Triple Camera than from the Dual Camera because the baseline is different. On the Triple Camera the wide-angle camera is typically 2x while on the Dual Camera it's 1x. This is why this is a property on the virtual cameras and not on the physical ones."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "c0140364-144e-4d8f-87a3-c5376083a4ca",
          "type": "message",
          "user": "U03HVDWU0ES",
          "text": "Hi Josef, the key thing is that property is just for the virtual cameras.  I'm using only the physical cameras, and I just ask for a get variable that is valid only for the physical devices.",
          "ts": "1654795865.895739",
          "thread_ts": "1654794203.046779",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "7WL",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi Josef, the key thing is that property is just for the virtual cameras.  I'm using only the physical cameras, and I just ask for a get variable that is valid only for the physical devices."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "5567dbfb-556a-435d-b259-ed87de6dd76d",
          "type": "message",
          "user": "U03HR8XVATG",
          "text": "I understand, but you can still use the virtual camera's property for this.",
          "ts": "1654795958.123019",
          "thread_ts": "1654794203.046779",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "gAcM",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I understand, but you can still use the virtual camera's property for this."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "1d74d0e5-0a78-484e-8f3c-d17d627e33ce",
          "type": "message",
          "user": "U03HVDWU0ES",
          "text": "I propose that such a variable would read nothing if a virtual device is used to avoid confusing those who use the virtual camera.",
          "ts": "1654796024.729139",
          "thread_ts": "1654794203.046779",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "LRh",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I propose that such a variable would read nothing if a virtual device is used to avoid confusing those who use the virtual camera."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "0bdedd25-5701-4bf9-98d0-522cbe951e9b",
          "type": "message",
          "user": "U03HR8XVATG",
          "text": "I'm sorry, I don't quite understand what you mean. Could you clarify?",
          "ts": "1654796090.162749",
          "thread_ts": "1654794203.046779",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "mCdP",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I'm sorry, I don't quite understand what you mean. Could you clarify?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "148c30bb-2599-4e13-93b9-615358e87bac",
          "type": "message",
          "user": "U03HVDWU0ES",
          "text": "I suppose I can load the virtual camera, read the property, then discard the device and load the physical device....",
          "ts": "1654796096.580379",
          "thread_ts": "1654794203.046779",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "8Ui8",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I suppose I can load the virtual camera, read the property, then discard the device and load the physical device...."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "042bb321-87e9-4bd5-9439-8fb4ec46c810",
          "type": "message",
          "user": "U03HR8XVATG",
          "text": "Yes, that's exactly what I was proposing.",
          "ts": "1654796112.756489",
          "thread_ts": "1654794203.046779",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "apPyd",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Yes, that's exactly what I was proposing."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "bc73f757-c5a1-4121-9efb-249a80863492",
          "type": "message",
          "user": "U03HR8XVATG",
          "text": "And for what it's worth, all AVCaptureDevices get instantiated at the same time. So there's really no such thing as loading/discarding them.",
          "ts": "1654796137.674809",
          "thread_ts": "1654794203.046779",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "M3x3",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "And for what it's worth, all AVCaptureDevices get instantiated at the same time. So there's really no such thing as loading/discarding them."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "6e0d12ea-a4c2-4f09-93f1-7d56f05a8361",
          "type": "message",
          "user": "U03HVDWU0ES",
          "text": "I have my project open, I'll give it a try, thanks!",
          "ts": "1654796191.788289",
          "thread_ts": "1654794203.046779",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "PND",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I have my project open, I'll give it a try, thanks!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "c2503332-b611-4e5d-80ca-a1ab656b4e29",
          "type": "message",
          "user": "U03HR8XVATG",
          "text": "Sure thing!",
          "ts": "1654796201.458409",
          "thread_ts": "1654794203.046779",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "RgR8z",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Sure thing!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "41E26F0F-CF79-40F7-AE48-821C22AA5671",
          "type": "message",
          "user": "U03HVE4BEBY",
          "text": "The issue is not knowing what the zoom factors are relative to each, but that the user understands 0.5x, 1x, 3x as shorthand to refer to the physical cameras because they're used in Apple’s marketing in this way",
          "ts": "1654796249.527539",
          "thread_ts": "1654794203.046779",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "JFP1",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "The"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "issue"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "is"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "not"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "knowing"
                    },
                    {
                      "type": "text",
                      "text": " w"
                    },
                    {
                      "type": "text",
                      "text": "hat"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "the"
                    },
                    {
                      "type": "text",
                      "text": " zoom "
                    },
                    {
                      "type": "text",
                      "text": "factors"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "are"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "relative"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "to"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "each,"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "but"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "that"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "the"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "user"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "understands"
                    },
                    {
                      "type": "text",
                      "text": " 0"
                    },
                    {
                      "type": "text",
                      "text": ".5x,"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "1x,"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "3x"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "as"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "shorthand"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "to"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "refer"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "to"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "the"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "physical"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "cameras"
                    },
                    {
                      "type": "text",
                      "text": " b"
                    },
                    {
                      "type": "text",
                      "text": "ecause"
                    },
                    {
                      "type": "text",
                      "text": " they're "
                    },
                    {
                      "type": "text",
                      "text": "used"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "in"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "Apple’s"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "marketing"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "in"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "this"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "way"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "3bd1bc60-c085-4b74-b311-a771fed0c73e",
          "type": "message",
          "user": "U03HR8XVATG",
          "text": "If you want to use the wide-angle camera as the 1x, then you can just query this property on the Dual Camera. Either that, or you can query it on the Triple Camera and divide all of them by the wide-angle camera's switch-over zoom factor. Both options should yield the same result.",
          "ts": "1654796321.781879",
          "thread_ts": "1654794203.046779",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "NHqrL",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "If you want to use the wide-angle camera as the 1x, then you can just query this property on the Dual Camera. Either that, or you can query it on the Triple Camera and divide all of them by the wide-angle camera's switch-over zoom factor. Both options should yield the same result."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "691ca0d9-046c-4285-bd88-e6c3ac6348cc",
          "type": "message",
          "user": "U03HR8XVATG",
          "text": "The switch-over zoom factors are always relative to the widest FOV camera in the virtual device. So for the Triple Camera the ultra-wide camera is the base (1x), while for the Dual Camera the wide-angle one is the base (1x).",
          "ts": "1654796377.319779",
          "thread_ts": "1654794203.046779",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "3Doi",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "The switch-over zoom factors are always relative to the widest FOV camera in the virtual device. So for the Triple Camera the ultra-wide camera is the base (1x), while for the Dual Camera the wide-angle one is the base (1x)."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "1ad22d81-8f89-4bdd-a800-589a028fffd1",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Sounds like, \u003c@U03HVE4BEBY\u003e, you should file a feedbackassistant request for us to provide an API that maps the actual zoom factors to \"marketing friendly\" zoom factors that match Apple's built in camera app.",
          "ts": "1654796441.280749",
          "thread_ts": "1654794203.046779",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "reYU",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Sounds like, "
                    },
                    {
                      "type": "user",
                      "user_id": "U03HVE4BEBY"
                    },
                    {
                      "type": "text",
                      "text": ", you should file a feedbackassistant request for us to provide an API that maps the actual zoom factors to \"marketing friendly\" zoom factors that match Apple's built in camera app."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "8e0b4475-9e77-46d5-ac92-f56bd959edaf",
          "type": "message",
          "user": "U03HVE4BEBY",
          "text": "I think using the virtual cam zoom factors is definitely cleaner than my approach of using the field of view, so I'll switch to that as you've suggested \u003c@U03HR8XVATG\u003e but also yes I'll file a feedback to be able to check for a quick and basic \"label\" \u003c@U03HXTBNYBC\u003e Thank you both!",
          "ts": "1654796623.991439",
          "thread_ts": "1654794203.046779",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U03HR8XVATG"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "e2d2h",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I think using the virtual cam zoom factors is definitely cleaner than my approach of using the field of view, so I'll switch to that as you've suggested "
                    },
                    {
                      "type": "user",
                      "user_id": "U03HR8XVATG"
                    },
                    {
                      "type": "text",
                      "text": " but also yes I'll file a feedback to be able to check for a quick and basic \"label\" "
                    },
                    {
                      "type": "user",
                      "user_id": "U03HXTBNYBC"
                    },
                    {
                      "type": "text",
                      "text": " Thank you both!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "590deb55-4b91-453c-8369-dd37ba254c54",
          "type": "message",
          "user": "U03HVDWU0ES",
          "text": "Hi Brad,  it sounds like the solution I had in mind in starting this thread.  You expressed it perfectly, I'll file a feedback myself too, thanks!  And Ben, thanks for your input!",
          "ts": "1654796727.846939",
          "thread_ts": "1654794203.046779",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U03HVE4BEBY"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "dZD",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi Brad,  it sounds like the solution I had in mind in starting this thread.  You expressed it perfectly, I'll file a feedback myself too, thanks!  And Ben, thanks for your input!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "937f6975-ec1e-443b-9295-19e11bcecc2c",
          "type": "message",
          "user": "U03J22YQMK4",
          "text": "I appreciate all of you talking this through and answering my questions w/o me having to ask :smile:",
          "ts": "1654797635.080959",
          "thread_ts": "1654794203.046779",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Lf2j0",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I appreciate all of you talking this through and answering my questions w/o me having to ask "
                    },
                    {
                      "type": "emoji",
                      "name": "smile",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "ee33eb7a-2f6b-4e27-8bd8-28038ea1fce2",
          "type": "message",
          "user": "U03HVDWU0ES",
          "text": "My thanks to the Camera team for a couple of great digital lounges this week! I just wanted to provide the team with the number of a new Feedback Assistant request, FB10137353,  that addresses what was discussed in this long thread. It’s the proposed API to map a ‘marketing friendly’ zoom factor for a physical AVCaptureDevice.  It has the solution that was well voiced by Brad Ford in the wrap up to this discussion.\n\nAgain, many thanks!",
          "ts": "1654888932.520949",
          "thread_ts": "1654794203.046779",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "raised_hands",
              "count": 1,
              "users": [
                "U03J22YQMK4"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "+NPzB",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "My thanks to the Camera team for a couple of great digital lounges this week! I just wanted to provide the team with the number of a new Feedback Assistant request, FB10137353,  that addresses what was discussed in this long thread. It’s the proposed API to map a ‘marketing friendly’ zoom factor for a physical AVCaptureDevice.  It has the solution that was well voiced by Brad Ford in the wrap up to this discussion.\n\nAgain, many thanks!"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03JV9KH3G9\u003e asked\n\u0026gt; How would you recommend to detect a blurry image? The image can be of any resolution allowed by a camera, or may be imported into Photos. Live photos and videos are excluded.",
      "ts": "1654794248.585719",
      "thread_ts": "1654794248.585719",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 9,
      "latest_reply": "1654797079.683699",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "xa6",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03JV9KH3G9"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"How would you recommend to detect a blurry image? The image can be of any resolution allowed by a camera, or may be imported into Photos. Live photos and videos are excluded.\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "0e0d30e1-06c7-4235-80c2-6e51891d1d1a",
          "type": "message",
          "user": "U03DJTBMHFF",
          "text": "Hi, Kiril. I think that Core ML may be your friend here. There are many models floating around in research circles like this one: \u003chttps://arxiv.org/abs/2010.07936\u003e",
          "ts": "1654794304.027249",
          "thread_ts": "1654794248.585719",
          "attachments": [
            {
              "fallback": "arXiv.org: Convolutional Neural Network for Blur Images Detection as an...",
              "id": 1,
              "title": "Convolutional Neural Network for Blur Images Detection as an...",
              "title_link": "https://arxiv.org/abs/2010.07936",
              "text": "With the prevalence of digital cameras, the number of digital images increases quickly, which raises the demand for non-manual image quality assessment. While there are many methods considered...",
              "thumb_url": "https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png",
              "service_name": "arXiv.org",
              "service_icon": "https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon.ico",
              "from_url": "https://arxiv.org/abs/2010.07936",
              "original_url": "https://arxiv.org/abs/2010.07936",
              "blocks": null
            }
          ],
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U03JV9KH3G9"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "FppeD",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi, Kiril. I think that Core ML may be your friend here. There are many models floating around in research circles like this one: "
                    },
                    {
                      "type": "link",
                      "url": "https://arxiv.org/abs/2010.07936",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "c12470ee-8e79-4373-92a0-932c65227e76",
          "type": "message",
          "user": "U03JV9KH3G9",
          "text": "Thanks!",
          "ts": "1654794338.269929",
          "thread_ts": "1654794248.585719",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "pUwhG",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "686fda18-1454-412c-8b58-896c9c122de1",
          "type": "message",
          "user": "U03DJTBMHFF",
          "text": "Using coremltools, you could convert the model to Core ML format and then use it inside the Vision framework to get your predictions of image quality.",
          "ts": "1654794350.338199",
          "thread_ts": "1654794248.585719",
          "edited": {
            "user": "U03DJTBMHFF",
            "ts": "1654794360.000000"
          },
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "GOyah",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Using coremltools, you could convert the model to Core ML format and then use it inside the Vision framework to get your predictions of image quality."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "299e9dc4-87ed-472c-a3e0-9078352c028a",
          "type": "message",
          "user": "U03DJTBMHFF",
          "text": "If you want to dive into this a bit further with Core ML Engineering, there are lab appointments available tomorrow.",
          "ts": "1654794444.812339",
          "thread_ts": "1654794248.585719",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "2phfX",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "If you want to dive into this a bit further with Core ML Engineering, there are lab appointments available tomorrow."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "522d6344-558e-487f-878f-d6b2671d7104",
          "type": "message",
          "user": "U03JV9KH3G9",
          "text": "Got it Thank you very much",
          "ts": "1654794464.982239",
          "thread_ts": "1654794248.585719",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "tcn",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Got it Thank you very much"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "ef26f1c7-6c09-42f0-86c6-b99528499e3c",
          "type": "message",
          "user": "U03HY66772A",
          "text": "If you need get least blurry image from a video / sequence of images, you can compute laplacian (MPSImageLaplacian), and than compute maximum using MPSImageStatisticsMinAndMax. Then, image with the smallest resulting value should be least blurry.\n\nYou can try to get a treshold, below which you can consider image blurry, but it may fail in some cases, e.g. when you take a picture of a wall with no obvious edges.",
          "ts": "1654794714.528319",
          "thread_ts": "1654794248.585719",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Cnnjo",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "If you need get least blurry image from a video / sequence of images, you can compute laplacian (MPSImageLaplacian), and than compute maximum using MPSImageStatisticsMinAndMax. Then, image with the smallest resulting value should be least blurry.\n\nYou can try to get a treshold, below which you can consider image blurry, but it may fail in some cases, e.g. when you take a picture of a wall with no obvious edges."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "e0a93f8f-19d4-441d-87d2-18f17d82029f",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "You could also do this in Core Image by taking a `CIAreaHistogram` of a `CIGaborGradients`.",
          "ts": "1654795770.267619",
          "thread_ts": "1654794248.585719",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "q7K",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "You could also do this in Core Image by taking a "
                    },
                    {
                      "type": "text",
                      "text": "CIAreaHistogram",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " of a "
                    },
                    {
                      "type": "text",
                      "text": "CIGaborGradients",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "02d97efc-5dab-4c68-a2f9-d95896ac6b08",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "Or perhaps `CIAreaAverage` of `CIGaborGradients` which would be faster.",
          "ts": "1654795825.127159",
          "thread_ts": "1654794248.585719",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "yI2e",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Or perhaps "
                    },
                    {
                      "type": "text",
                      "text": "CIAreaAverage",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " of "
                    },
                    {
                      "type": "text",
                      "text": "CIGaborGradients",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " which would be faster."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "7dc5cf6f-936f-4fea-88c3-ce291465c15a",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "I would recommend using Gabor over Laplacian because even a blurry image will contain noise.  Gabor (a 5x5 convolution) is less affected by noise than Laplacian (a 3x3 convolution).  In fact you my want to consider a 7x7 Gabor.",
          "ts": "1654797079.683699",
          "thread_ts": "1654794248.585719",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "ScNU7",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I would recommend using Gabor over Laplacian because even a blurry image will contain noise.  Gabor (a 5x5 convolution) is less affected by noise than Laplacian (a 3x3 convolution).  In fact you my want to consider a 7x7 Gabor."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03JDS776JH\u003e asked\n\u0026gt; in the Creating Camera Extensions session, you said that CMIO Extensions can be video sinks, but these sinks don't have an AVCapture interface, we have to use the C APIs. Which APIs are these? I cannot find any examples of *using* a DAL plug-in this way. We have *implemented* DAL plug-ins as virtual cameras, but we *use* them through their AVCapture interfaces.\n\u0026gt; From my app, I can find the CMIObject corresponding to my Camera Extension, (it is of class 'aplg', isExtension is true, and it has the correct bundle ID). But how do I go from that to making an API call to feed frames from my app to the extension?",
      "ts": "1654794332.807009",
      "thread_ts": "1654794332.807009",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 23,
      "latest_reply": "1654796671.219519",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "7ACg",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03JDS776JH"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"in the Creating Camera Extensions session, you said that CMIO Extensions can be video sinks, but these sinks don't have an AVCapture interface, we have to use the C APIs. Which APIs are these? I cannot find any examples of *using* a DAL plug-in this way. We have *implemented* DAL plug-ins as virtual cameras, but we *use* them through their AVCapture interfaces.\\nFrom my app, I can find the CMIObject corresponding to my Camera Extension, (it is of class 'aplg', isExtension is true, and it has the correct bundle ID). But how do I go from that to making an API call to feed frames from my app to the extension?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "06db22a6-48c8-4f24-a5ad-5436a2ac63f1",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Hi Stuart. The C APIs to which I referred are the CoreMediaIO interfaces called by apps (rather than extension / plug in developers).\nCMIOHardware.h, CMIOHardwareDevice.h, CMIOHardwareStream.h",
          "ts": "1654794441.778799",
          "thread_ts": "1654794332.807009",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "eIm",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi Stuart. The C APIs to which I referred are the CoreMediaIO interfaces called by apps (rather than extension / plug in developers).\nCMIOHardware.h, CMIOHardwareDevice.h, CMIOHardwareStream.h"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "68e389ae-d555-4bd8-aac2-07d49a3bd251",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "CMIOHardwareSystem introduces the concept of a \"System\" object (`kCMIOObjectSystemObject`) that can be queried for its devices (`kCMIOHardwarePropertyDevices`).",
          "ts": "1654794507.685499",
          "thread_ts": "1654794332.807009",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Zy8h3",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "CMIOHardwareSystem introduces the concept of a \"System\" object ("
                    },
                    {
                      "type": "text",
                      "text": "kCMIOObjectSystemObject",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": ") that can be queried for its devices ("
                    },
                    {
                      "type": "text",
                      "text": "kCMIOHardwarePropertyDevices",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": ")."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "b1bfc9ee-889f-4e95-a1c3-6386243c8e4b",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Once you've got the list of devices, you can query them for various properties, such as unique ID, or streams. You can, for instance, see if it has streams on its output scope (output streams instead of input streams).",
          "ts": "1654794556.867619",
          "thread_ts": "1654794332.807009",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "RBYs",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Once you've got the list of devices, you can query them for various properties, such as unique ID, or streams. You can, for instance, see if it has streams on its output scope (output streams instead of input streams)."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "0eb22191-8707-499b-9ead-d9fc815cb854",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "You push sample buffers to output streams, and these are outputted to a video deck or some other external piece of hardware that accepts a stream of video.",
          "ts": "1654794598.942919",
          "thread_ts": "1654794332.807009",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "3FbcB",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "You push sample buffers to output streams, and these are outputted to a video deck or some other external piece of hardware that accepts a stream of video."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "73fdc1e0-f56e-4369-9790-8c066a370861",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "It may help your mental model, \u003c@U03JDS776JH\u003e, to know that the AVCapture* APIs on macOS are clients of the CMIOHardware* APIs. They wrap the functionality in a more modern, friendly, swift/obj-c compatible way, and they hide some of the complexity one takes on when dealing with the CoreMediaIO APIs directly.",
          "ts": "1654794985.565159",
          "thread_ts": "1654794332.807009",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "ZqHge",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "It may help your mental model, "
                    },
                    {
                      "type": "user",
                      "user_id": "U03JDS776JH"
                    },
                    {
                      "type": "text",
                      "text": ", to know that the AVCapture* APIs on macOS are clients of the CMIOHardware* APIs. They wrap the functionality in a more modern, friendly, swift/obj-c compatible way, and they hide some of the complexity one takes on when dealing with the CoreMediaIO APIs directly."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "b80b33e2-19cd-45ec-82fe-630692624dc3",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "To be clear, you don't need to search for your DAL plugin (the plugin object), unless there's a property that you want to set on the plug-in itself. For instance, if you had some property that's global to your entire extension, and all devices it vends. Typically, you'd just ask the system object for the list of CMIODeviceIDs, and then iterate through them, searching for the characteristics that fit your criteria.",
          "ts": "1654795082.109049",
          "thread_ts": "1654794332.807009",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "nVU",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "To be clear, you don't need to search for your DAL plugin (the plugin object), unless there's a property that you want to set on the plug-in itself. For instance, if you had some property that's global to your entire extension, and all devices it vends. Typically, you'd just ask the system object for the list of CMIODeviceIDs, and then iterate through them, searching for the characteristics that fit your criteria."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "bd015af8-a71b-410a-a60f-dd580e6628ea",
          "type": "message",
          "user": "U03JDS776JH",
          "text": "ok. So I query the system object for its kCMIOHardwarePropertyDevices, query those objects for their kCMIODevicePropertyStreams, querty those objects for their kCMIOStreamPropertyDirection etc. But I’m unclear what the API is to push buffers to the stream. Also, “input” and “output” are from the point of view of the extension itself, right?",
          "ts": "1654795093.761379",
          "thread_ts": "1654794332.807009",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "nIZls",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "ok. So I query the system object for its kCMIOHardwarePropertyDevices, query those objects for their kCMIODevicePropertyStreams, querty those objects for their kCMIOStreamPropertyDirection etc. But I’m unclear what the API is to push buffers to the stream. Also, “input” and “output” are from the point of view of the extension itself, right?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "d78e91b9-a688-4e10-89e9-c7278bcd83df",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "AVCaptureDevice APIs hide CMIODeviceIDs that only contain output streams.",
          "ts": "1654795097.919019",
          "thread_ts": "1654794332.807009",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "mTEB",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "AVCaptureDevice APIs hide CMIODeviceIDs that only contain output streams."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "f5571544-5b69-44a8-a591-6703fab23180",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "You don't need to query them for their direction.",
          "ts": "1654795121.369109",
          "thread_ts": "1654794332.807009",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "J/64",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "You don't need to query them for their direction."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "9163a9c8-042d-482d-b91c-657c5098efbd",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "That property is there for legacy stuff like DV cameras, which can be input or output streams, depending on what mode you've set the camera to be in (playback mode or recording mode).",
          "ts": "1654795159.463759",
          "thread_ts": "1654794332.807009",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "ElJ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "That property is there for legacy stuff like DV cameras, which can be input or output streams, depending on what mode you've set the camera to be in (playback mode or recording mode)."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "8c36cfe2-6e54-4c85-8fe6-45bf312af5a6",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Just search for streams on the *output* scope rather than the *input* scope.",
          "ts": "1654795173.746789",
          "thread_ts": "1654794332.807009",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "mog",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Just search for streams on the "
                    },
                    {
                      "type": "text",
                      "text": "output",
                      "style": {
                        "bold": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " scope rather than the "
                    },
                    {
                      "type": "text",
                      "text": "input",
                      "style": {
                        "bold": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " scope."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "07f57ac3-c74a-4ada-b140-ce5037e0eb80",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "That will give you the exclusively *sink* streams.",
          "ts": "1654795190.862849",
          "thread_ts": "1654794332.807009",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "xXiW",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "That will give you the exclusively "
                    },
                    {
                      "type": "text",
                      "text": "sink",
                      "style": {
                        "bold": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " streams."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "eddccad7-0c6e-4708-9d8d-0ee4f442c703",
          "type": "message",
          "user": "U03JDS776JH",
          "text": "that’s good to know (output==sink)! But still, what’s the API to push a frame to CMIOObject?",
          "ts": "1654795250.372679",
          "thread_ts": "1654794332.807009",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "0D/m",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "that’s good to know (output==sink)! But still, what’s the API to push a frame to CMIOObject?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "b81a014c-db52-40a1-9877-38495b4f634d",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "You push frames to a CMIOStream.",
          "ts": "1654795361.481669",
          "thread_ts": "1654794332.807009",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "r+/M",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "You push frames to a CMIOStream."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "20b4a73e-776b-4a0a-8afe-53a391fe0bfd",
          "type": "message",
          "user": "U03JDS776JH",
          "text": "with CMIOStreamCopyBufferQueue to get the queue, then I push somethings onto that queue? And why would I want queueAlteredProc?",
          "ts": "1654795446.216669",
          "thread_ts": "1654794332.807009",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "NAwY=",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "with CMIOStreamCopyBufferQueue to get the queue, then I push somethings onto that queue? And why would I want queueAlteredProc?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "0349f468-36d2-45d7-b6ec-4b025139b7b7",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Call `CMIOStreamCopyBufferQueue` to get its simple queue. You can add frames to that queue when you're ready. (If it's an input stream, you'd listen for when the queue was altered and dequeue the new frame or frames).",
          "ts": "1654795447.738609",
          "thread_ts": "1654794332.807009",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "zK0Wr",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Call "
                    },
                    {
                      "type": "text",
                      "text": "CMIOStreamCopyBufferQueue",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " to get its simple queue. You can add frames to that queue when you're ready. (If it's an input stream, you'd listen for when the queue was altered and dequeue the new frame or frames)."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "fc190a14-1bda-4071-ab92-63605a3aee93",
          "type": "message",
          "user": "U03HHA1DV9D",
          "text": "There are also some other handy stream properties:",
          "ts": "1654795485.274649",
          "thread_ts": "1654794332.807009",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "8Zz",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "There are also some other handy stream properties:"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "ba8db8f4-faf8-461a-8b37-0e791d19aaf3",
          "type": "message",
          "user": "U03HHA1DV9D",
          "text": "kCMIOStreamPropertyOutputBufferUnderrunCount, kCMIOStreamPropertyOutputBufferRepeatCount, kCMIOStreamPropertyOutputBufferQueueSize, kCMIOStreamPropertyOutputBuffersRequiredForStartup, kCMIOStreamPropertyOutputBuffersNeededForThrottledPlayback, and kCMIOStreamPropertyFirstOutputPresentationTimeStamp.",
          "ts": "1654795550.102579",
          "thread_ts": "1654794332.807009",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "+Sy5",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "kCMIOStreamPropertyOutputBufferUnderrunCount, kCMIOStreamPropertyOutputBufferRepeatCount, kCMIOStreamPropertyOutputBufferQueueSize, kCMIOStreamPropertyOutputBuffersRequiredForStartup, kCMIOStreamPropertyOutputBuffersNeededForThrottledPlayback, and kCMIOStreamPropertyFirstOutputPresentationTimeStamp."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "54fea97c-7d98-40de-a9c6-ca20c06d7401",
          "type": "message",
          "user": "U03HHA1DV9D",
          "text": "Also:",
          "ts": "1654795578.470539",
          "thread_ts": "1654794332.807009",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "90N",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Also:"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "132659f6-f381-4d35-9900-f52f62432470",
          "type": "message",
          "user": "U03HHA1DV9D",
          "text": "kCMIOStreamPropertyScheduledOutputNotificationProc",
          "ts": "1654795590.160599",
          "thread_ts": "1654794332.807009",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "4n4",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "kCMIOStreamPropertyScheduledOutputNotificationProc"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "2f9471c3-5332-4b2b-8a3d-5624593da8ad",
          "type": "message",
          "user": "U03JDS776JH",
          "text": "thank you this all extremely helpful. I have to run to a lab now but I posted another question on a slightly different topic. I hope to see you at a lab tomorrow",
          "ts": "1654795701.435409",
          "thread_ts": "1654794332.807009",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "oOTJ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "thank you this all extremely helpful. I have to run to a lab now but I posted another question on a slightly different topic. I hope to see you at a lab tomorrow"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "29b9c08e-427f-48ec-9003-e3eaf2f39a90",
          "type": "message",
          "user": "U03HZ4B0S1K",
          "text": "If we want to do something like OBS where we have an application that renders video frames and passes them to a DAL plugin for people to select as a virtual webcam, is the recommended approach to create both a source and sink stream, and route frames in the extension from the sink to the source.  Then in the app send frames to the sink?",
          "ts": "1654795802.032099",
          "thread_ts": "1654794332.807009",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "hnl",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "If we want to do something like OBS where we have an application that renders video frames and passes them to a DAL plugin for people to select as a virtual webcam, is the recommended approach to create both a source and sink stream, and route frames in the extension from the sink to the source.  Then in the app send frames to the sink?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "09330d9b-b0d9-424f-af22-9a30327db965",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "That's one approach. In the CMIOExtensions video (available now! and....watch party in 10 minutes), I describe a different technique where you can run physical streams from other cameras right within your CMIOExtension. We call this case \"creative camera\".",
          "ts": "1654796671.219519",
          "thread_ts": "1654794332.807009",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "kbNpM",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "That's one approach. In the CMIOExtensions video (available now! and....watch party in 10 minutes), I describe a different technique where you can run physical streams from other cameras right within your CMIOExtension. We call this case \"creative camera\"."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03JV9KH3G9\u003e asked\n\u0026gt; There are currently 3 frameworks for image processing: Accelerate, CoreImage filters, and Metal. For example, if we take a \"black \u0026amp; white conversion\" of the image: we can use Accelerate to accomplish it, a `CIFilter` (e.g. `CIColorMonochrome`), or create a Metal shader. \n\u0026gt; What are your recommendations for using each framework? E.g. in which cases each framework is preferable to others, or should be avoided? And is it OK mixing them, or should that (as a general rule) be avoided?",
      "ts": "1654794634.704589",
      "thread_ts": "1654794634.704589",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 8,
      "latest_reply": "1654796790.207129",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "K+TI2",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03JV9KH3G9"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"There are currently 3 frameworks for image processing: Accelerate, CoreImage filters, and Metal. For example, if we take a \\\"black \u0026 white conversion\\\" of the image: we can use Accelerate to accomplish it, a `CIFilter` (e.g. `CIColorMonochrome`), or create a Metal shader. \\nWhat are your recommendations for using each framework? E.g. in which cases each framework is preferable to others, or should be avoided? And is it OK mixing them, or should that (as a general rule) be avoided?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "fce8ba07-7e94-4579-a746-c818f88ab1d9",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "As you say, there are several ways to achieve the same \"monochrome\" result.  The best will likely depend on what else you want to do and other factors.  For example if you want to combine monochrome with other effects you want to pick a strategy that that avoids switching back and forth.  Switching say between CPU and GPU will introduce stalls and increase memory.  Another thing to consider is if you need to deal with imaged that are large sizes or with HDR color spaces.  In that case a higher lave framework will have that built in.",
          "ts": "1654794994.071959",
          "thread_ts": "1654794634.704589",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "+qQ+",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "As you say, there are several ways to achieve the same \"monochrome\" result.  The best will likely depend on what else you want to do and other factors.  For example if you want to combine monochrome with other effects you want to pick a strategy that that avoids switching back and forth.  Switching say between CPU and GPU will introduce stalls and increase memory.  Another thing to consider is if you need to deal with imaged that are large sizes or with HDR color spaces.  In that case a higher lave framework will have that built in."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "456bb553-8b0b-4bba-9fd6-66b40e4a7d3e",
          "type": "message",
          "user": "U03JV9KH3G9",
          "text": "I guess the main reason for me to look for CI alternatives was that conversion from CIImage (with several filters) to CGImage or to JPEG representation of the image took a very long time (5-10 sec) and a lot of memory (for larger images especially). Is that generally a point where you'd say: yes, in those cases switch to Accelerate or Metal, or could it be related to a particular (possibly incorrect) use of CIFilters?",
          "ts": "1654795438.331219",
          "thread_ts": "1654794634.704589",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "EZkGo",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I guess the main reason for me to look for CI alternatives was that conversion from CIImage (with several filters) to CGImage or to JPEG representation of the image took a very long time (5-10 sec) and a lot of memory (for larger images especially). Is that generally a point where you'd say: yes, in those cases switch to Accelerate or Metal, or could it be related to a particular (possibly incorrect) use of CIFilters?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "59b57af4-a0ab-4687-affa-e5c0db44b7a1",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "You might want to try going directly from `CIImage` to JPEG using API like `JPEGRepresentationOfImage:colorSpace:options:`.  A time of 5 to 10 seconds seems very slow.  How big is the image?",
          "ts": "1654795632.341869",
          "thread_ts": "1654794634.704589",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "=3+S",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "You might want to try going directly from "
                    },
                    {
                      "type": "text",
                      "text": "CIImage",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " to JPEG using API like "
                    },
                    {
                      "type": "text",
                      "text": "JPEGRepresentationOfImage:colorSpace:options:",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": ".  A time of 5 to 10 seconds seems very slow.  How big is the image?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "959b096b-704f-4a72-830f-04197f37cb73",
          "type": "message",
          "user": "U03JV9KH3G9",
          "text": "raw image taken on iphone 10 for example",
          "ts": "1654795730.489339",
          "thread_ts": "1654794634.704589",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "eRIY",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "raw image taken on iphone 10 for example"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "7c59e6d2-c601-406a-9670-1297a8a7860b",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "For a RAW image using CoreImage is the fastest/easiest way to produce a demosaiced and denoised result.  This is non trivial but 5 to 10 seconds seems slow to me.  Here are some suggestions:\n• use the `CIRAWFilter` API to have more control (for example you can set `.scaleFactor` if you just want a half sized image.",
          "ts": "1654796090.582759",
          "thread_ts": "1654794634.704589",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "ihHX0",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "For a RAW image using CoreImage is the fastest/easiest way to produce a demosaiced and denoised result.  This is non trivial but 5 to 10 seconds seems slow to me.  Here are some suggestions:\n"
                    }
                  ]
                },
                {
                  "Type": "rich_text_list",
                  "Raw": "{\"type\":\"rich_text_list\",\"elements\":[{\"type\":\"rich_text_section\",\"elements\":[{\"type\":\"text\",\"text\":\"use the \"},{\"type\":\"text\",\"text\":\"CIRAWFilter\",\"style\":{\"code\":true}},{\"type\":\"text\",\"text\":\" API to have more control (for example you can set \"},{\"type\":\"text\",\"text\":\".scaleFactor\",\"style\":{\"code\":true}},{\"type\":\"text\",\"text\":\" if you just want a half sized image.\"}]}],\"style\":\"bullet\",\"indent\":0,\"border\":0}"
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "f3f08370-e359-40e6-a7cb-5e9bbc482eb5",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "• create the `CIContext` with the option `kCIContextCacheIntermediates` set to `@NO` to minimize memory usage.",
          "ts": "1654796155.258569",
          "thread_ts": "1654794634.704589",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "ntc",
              "elements": [
                {
                  "Type": "rich_text_list",
                  "Raw": "{\"type\":\"rich_text_list\",\"elements\":[{\"type\":\"rich_text_section\",\"elements\":[{\"type\":\"text\",\"text\":\"create the \"},{\"type\":\"text\",\"text\":\"CIContext\",\"style\":{\"code\":true}},{\"type\":\"text\",\"text\":\" with the option \"},{\"type\":\"text\",\"text\":\"kCIContextCacheIntermediates\",\"style\":{\"code\":true}},{\"type\":\"text\",\"text\":\" set to \"},{\"type\":\"text\",\"text\":\"@NO\",\"style\":{\"code\":true}},{\"type\":\"text\",\"text\":\" to minimize memory usage.\"}]}],\"style\":\"bullet\",\"indent\":0,\"border\":0}"
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "7d244938-9122-4c22-81d5-249e436f89ed",
          "type": "message",
          "user": "U03JV9KH3G9",
          "text": "Great suggestions, thanks. I wasn't using either - hence probably the timing and memory.",
          "ts": "1654796235.346379",
          "thread_ts": "1654794634.704589",
          "edited": {
            "user": "U03JV9KH3G9",
            "ts": "1654796307.000000"
          },
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "sBkQi",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Great suggestions, thanks. I wasn't using either - hence probably the timing and memory."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "c9c136ee-f8df-498f-a3bb-8bd13fe05fa5",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "FYI: there's another question/discussion about `CIRAWFilter` in this channel today.",
          "ts": "1654796790.207129",
          "thread_ts": "1654794634.704589",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U03JV9KH3G9"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "R7NuQ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "FYI: there's another question/discussion about "
                    },
                    {
                      "type": "text",
                      "text": "CIRAWFilter",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " in this channel today."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03HY66772A\u003e asked\n\u0026gt; Is there a way to get a transform from original frame to a stabilized one? We have custom AR content overlaying video, and wanted to preview non-stabilized video for less latency, and write cinematic stabilization to a disk. However, as we need to render AR stuff over video, and we don't want to run pipeline twice, and with transforms we could just transform what we rendered once to a stabilized frame.",
      "ts": "1654794775.107279",
      "thread_ts": "1654794775.107279",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 7,
      "latest_reply": "1654798171.904469",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "e9T",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03HY66772A"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Is there a way to get a transform from original frame to a stabilized one? We have custom AR content overlaying video, and wanted to preview non-stabilized video for less latency, and write cinematic stabilization to a disk. However, as we need to render AR stuff over video, and we don't want to run pipeline twice, and with transforms we could just transform what we rendered once to a stabilized frame.\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "219d2888-78b3-4921-9147-e180cd42796f",
          "type": "message",
          "user": "U03HV023K2R",
          "text": "This is an interesting one! There's currently no API to perform video stabilization but only expose stabilization transform without applying it onto frames. Could you file a feature request for this?",
          "ts": "1654794787.242989",
          "thread_ts": "1654794775.107279",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "342=",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "This is an interesting one! There's currently no API to perform video stabilization but only expose stabilization transform without applying it onto frames. Could you file a feature request for this?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "9A71968A-2EB4-4C4D-8E50-558A213E5725",
          "type": "message",
          "user": "U03HY66772A",
          "text": "So there is a way to expose stabilization transform? (Without applying stabilization)",
          "ts": "1654794873.628129",
          "thread_ts": "1654794775.107279",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "vk7WS",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "So there is a way to expose stabilization transform? (Without applying stabilization)"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "CE33EFB1-F108-4E51-B3EE-E17A28537ED2",
          "type": "message",
          "user": "U03HY66772A",
          "text": "Sorry for asking, but could you direct me where should I file this request?",
          "ts": "1654794913.532029",
          "thread_ts": "1654794775.107279",
          "edited": {
            "user": "U03HY66772A",
            "ts": "1654794924.000000"
          },
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "BIdLX",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Sorry for asking, but could you direct me where should I file this request?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "d51a24e5-3b51-4d1f-8672-228bc2827b2d",
          "type": "message",
          "user": "U03HV023K2R",
          "text": "Hi Viacheslav, exposing stabilization transform is currently not supported. You can file feature request here \u003chttp://feedbackassistant.apple.com|feedbackassistant.apple.com\u003e.",
          "ts": "1654795338.629109",
          "thread_ts": "1654794775.107279",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Qh+h",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi Viacheslav, exposing stabilization transform is currently not supported. You can file feature request here "
                    },
                    {
                      "type": "link",
                      "url": "http://feedbackassistant.apple.com",
                      "text": "feedbackassistant.apple.com"
                    },
                    {
                      "type": "text",
                      "text": "."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "e2a9507d-0932-448f-9784-5853cd7d9820",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "\u003c@U03HY66772A\u003e are you familiar with the new feature in iOS 16 which allows you to run *multiple* video data outputs? You can run one with no stabilization for preview, and run a separate one *with* stabilization for writing to disk. This would require running the pipeline twice, but you could potentially run a lower quality algorithm for the realtime feed, and a higher quality version of it for the one being written to disk.",
          "ts": "1654796219.309349",
          "thread_ts": "1654794775.107279",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "v96",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "user",
                      "user_id": "U03HY66772A"
                    },
                    {
                      "type": "text",
                      "text": " are you familiar with the new feature in iOS 16 which allows you to run "
                    },
                    {
                      "type": "text",
                      "text": "multiple",
                      "style": {
                        "bold": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " video data outputs? You can run one with no stabilization for preview, and run a separate one "
                    },
                    {
                      "type": "text",
                      "text": "with",
                      "style": {
                        "bold": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " stabilization for writing to disk. This would require running the pipeline twice, but you could potentially run a lower quality algorithm for the realtime feed, and a higher quality version of it for the one being written to disk."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "ceb8330f-ef35-4cae-9169-ab7ce9f64727",
          "type": "message",
          "user": "U03HY66772A",
          "text": "Sadly, we are running on the edge of performance targets, and rendering twise would mean waiting for video to process after the fact for some time for our users",
          "ts": "1654798099.305579",
          "thread_ts": "1654794775.107279",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Coi",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Sadly, we are running on the edge of performance targets, and rendering twise would mean waiting for video to process after the fact for some time for our users"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "e2eb4fb0-3d9b-40f4-a814-0cb41856e887",
          "type": "message",
          "user": "U03HY66772A",
          "text": "But you definetly could run two connections with different stabilization options before? At least for preview and for writing on disk. (I think that’s how Apple Camera app works)",
          "ts": "1654798171.904469",
          "thread_ts": "1654794775.107279",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "1D/HM",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "But you definetly could run two connections with different stabilization options before? At least for preview and for writing on disk. (I think that’s how Apple Camera app works)"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03JBH50UAE\u003e asked\n\u0026gt; Question about CIRAWFilter - does `scaleFactor` do the same thing as in `CIFilter` with RAW options? \n\u0026gt; \n\u0026gt; ```\n\u0026gt; let ciImage = CIImage(data: self.imageData)!\n\u0026gt; let ciFilter = CIFilter(imageData: self.imageData, options: [ .scaleFactor: 0.25 ])!\n\u0026gt; let ciRawFilter = CIRAWFilter(imageData: self.imageData, identifierHint: \"com.adobe.raw-image\")!\n\u0026gt; ciRawFilter.scaleFactor = 0.25\n\u0026gt; print(\"CIImage\", ciImage.extent)\n\u0026gt; print(\"CIFilter\", ciFilter.outputImage?.extent)\n\u0026gt; print(\"CIRAWFilter\", ciRawFilter.outputImage?.extent)\n\u0026gt; ```\n\u0026gt; Prints\n\u0026gt; ```\n\u0026gt; CIImage (0.0, 0.0, 5952.0, 3968.0)\n\u0026gt; CIFilter Optional((0.0, 0.0, 1488.0, 992.0))\n\u0026gt; CIRAWFilter Optional((0.0, 0.0, 5952.0, 3968.0))\n\u0026gt; ```\n\u0026gt; \n\u0026gt; See that the `CIFilter` version scaled the extent but the `CIRAWFilter` did not. \n\u0026gt; \n\u0026gt; More importantly, is scaling here an effective way to improve performance of RAW editing? Any other options or things to keep in mind for performance specifically?",
      "ts": "1654795070.894939",
      "thread_ts": "1654795070.894939",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 12,
      "latest_reply": "1654797855.520419",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "CHnqQ",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03JBH50UAE"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Question about CIRAWFilter - does `scaleFactor` do the same thing as in `CIFilter` with RAW options? \\n\\n```\\nlet ciImage = CIImage(data: self.imageData)!\\nlet ciFilter = CIFilter(imageData: self.imageData, options: [ .scaleFactor: 0.25 ])!\\nlet ciRawFilter = CIRAWFilter(imageData: self.imageData, identifierHint: \\\"com.adobe.raw-image\\\")!\\nciRawFilter.scaleFactor = 0.25\\nprint(\\\"CIImage\\\", ciImage.extent)\\nprint(\\\"CIFilter\\\", ciFilter.outputImage?.extent)\\nprint(\\\"CIRAWFilter\\\", ciRawFilter.outputImage?.extent)\\n```\\nPrints\\n```\\nCIImage (0.0, 0.0, 5952.0, 3968.0)\\nCIFilter Optional((0.0, 0.0, 1488.0, 992.0))\\nCIRAWFilter Optional((0.0, 0.0, 5952.0, 3968.0))\\n```\\n\\nSee that the `CIFilter` version scaled the extent but the `CIRAWFilter` did not. \\n\\nMore importantly, is scaling here an effective way to improve performance of RAW editing? Any other options or things to keep in mind for performance specifically?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "732ac432-ec6a-4e43-9d24-9d43c780f72c",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "Big yes.  Using the `.scaleFactor` on the `CIRAWFilter` class will give a big benefit in performance.  It reduces the amount of memory needed as well and reduces the amount of noise reduction that is needed.",
          "ts": "1654795268.492809",
          "thread_ts": "1654795070.894939",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "rsiU",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Big yes.  Using the "
                    },
                    {
                      "type": "text",
                      "text": ".scaleFactor",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " on the "
                    },
                    {
                      "type": "text",
                      "text": "CIRAWFilter",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " class will give a big benefit in performance.  It reduces the amount of memory needed as well and reduces the amount of noise reduction that is needed."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "e687435d-6673-41b5-981b-606136894b7a",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "Asking the filter for `.nativeSize` will always give the full size of the asset.",
          "ts": "1654795341.032329",
          "thread_ts": "1654795070.894939",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "y0rs",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Asking the filter for "
                    },
                    {
                      "type": "text",
                      "text": ".nativeSize",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " will always give the full size of the asset."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "33d121bf-4a13-40dd-a42c-0c025caeda9b",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "Asking the filter for `.outputImage.extent` should give the scaled size (assuming that you set `.scaleFactor` before)",
          "ts": "1654795399.386769",
          "thread_ts": "1654795070.894939",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "RRV",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Asking the filter for "
                    },
                    {
                      "type": "text",
                      "text": ".outputImage.extent",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " should give the scaled size (assuming that you set "
                    },
                    {
                      "type": "text",
                      "text": ".scaleFactor",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " before)"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "a6efad4f-65f8-44e9-ba74-92efc7e8ae39",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "Please file a bug report on the `ciRawFilter.scaleFactor` / `ciRawFilter.outputImage?.extent` issue.  That should give you the smaller extent.",
          "ts": "1654796416.242949",
          "thread_ts": "1654795070.894939",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "DtGy",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Please file a bug report on the "
                    },
                    {
                      "type": "text",
                      "text": "ciRawFilter.scaleFactor",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " / "
                    },
                    {
                      "type": "text",
                      "text": "ciRawFilter.outputImage?.extent",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " issue.  That should give you the smaller extent."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "b7cdfff8-0101-45c5-be3b-eceb85ab018a",
          "type": "message",
          "user": "U03JBH50UAE",
          "text": "Thanks \u003c@U03HB0AV6S3\u003e! Will do.",
          "ts": "1654797362.853119",
          "thread_ts": "1654795070.894939",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "HUo",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks "
                    },
                    {
                      "type": "user",
                      "user_id": "U03HB0AV6S3"
                    },
                    {
                      "type": "text",
                      "text": "! Will do."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "3563f0ff-70a3-4bd6-bd9c-62c2fd848bae",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "You might try toggling one of the other properties to see if that helps.",
          "ts": "1654797415.774959",
          "thread_ts": "1654795070.894939",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "zYxu",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "You might try toggling one of the other properties to see if that helps."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "71a46cb1-0e25-4273-8841-a4b955ebe7be",
          "type": "message",
          "user": "U03JBH50UAE",
          "text": "Is there any workaround to scale using CIRAWFilter? Or have to fall back to CIFilter for now?",
          "ts": "1654797419.503809",
          "thread_ts": "1654795070.894939",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "FYEet",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Is there any workaround to scale using CIRAWFilter? Or have to fall back to CIFilter for now?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "97d17d0c-3365-430a-883e-61b25fb82b7d",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "Try setting `.orientation` to a different value and then back again?",
          "ts": "1654797514.104769",
          "thread_ts": "1654795070.894939",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "QhOux",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Try setting "
                    },
                    {
                      "type": "text",
                      "text": ".orientation",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " to a different value and then back again?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "6b2cea7c-ea95-4a3a-a2cc-af45866f6f89",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "That property also alters `ciRawFilter.outputImage?.extent`",
          "ts": "1654797561.112049",
          "thread_ts": "1654795070.894939",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Jj6",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "That property also alters "
                    },
                    {
                      "type": "text",
                      "text": "ciRawFilter.outputImage?.extent",
                      "style": {
                        "code": true
                      }
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "f514b5ed-f812-4d4c-924f-6557eab9acc6",
          "type": "message",
          "user": "U03JBH50UAE",
          "text": "No luck. Setting `ciRawFilter.orientation = .left` swapped the dimensions but still at full size. I tried both orders of orientation, scaleFactor",
          "ts": "1654797699.771679",
          "thread_ts": "1654795070.894939",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "GQS6",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "No luck. Setting "
                    },
                    {
                      "type": "text",
                      "text": "ciRawFilter.orientation = .left",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " swapped the dimensions but still at full size. I tried both orders of orientation, scaleFactor"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "29f8e4c3-e653-4480-b826-3cd80e78a813",
          "type": "message",
          "user": "U03HB0AV6S3",
          "text": "If we find a workaround we will note it in your bug report.",
          "ts": "1654797810.050479",
          "thread_ts": "1654795070.894939",
          "edited": {
            "user": "U03HB0AV6S3",
            "ts": "1654797822.000000"
          },
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "jtQDR",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "If we find a workaround we will note it in your bug report."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "c82399f6-edf9-4953-9186-bd8dfcdce4bb",
          "type": "message",
          "user": "U03JBH50UAE",
          "text": "much appreciated! I’ll file that asap",
          "ts": "1654797855.520419",
          "thread_ts": "1654795070.894939",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "5H94u",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "much appreciated! I’ll file that asap"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03JRR26EU8\u003e asked\n\u0026gt; I was told the resolution of LiDAR depth data from ARKit had been for accuracy down to around the size of a table leg, or accuracy within a few inches. With AVFoundation having greater depth resolution, is there a kind of rule-of-thumb in terms of accuracy down to set distance, or down an object size, like a tooth?",
      "ts": "1654795264.141979",
      "thread_ts": "1654795264.141979",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 5,
      "latest_reply": "1654796660.085439",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "xmpu",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03JRR26EU8"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"I was told the resolution of LiDAR depth data from ARKit had been for accuracy down to around the size of a table leg, or accuracy within a few inches. With AVFoundation having greater depth resolution, is there a kind of rule-of-thumb in terms of accuracy down to set distance, or down an object size, like a tooth?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "89c0a412-7fef-4751-ac90-7cfffcb01a9d",
          "type": "message",
          "user": "U03JMLKUF1N",
          "text": "Hi Rob, unfortunately we don’t have a hard and fast rule for how small the objects can be at a given distance, but in general the AVFoundation LiDAR Depth Camera can detect finer details — for example the edge of table will be straighter/sharper than ARKit due to the increase in pixel resolution.",
          "ts": "1654795333.000519",
          "thread_ts": "1654795264.141979",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "nc/HX",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi Rob, unfortunately we don’t have a hard and fast rule for how small the objects can be at a given distance, but in general the AVFoundation LiDAR Depth Camera can detect finer details — for example the edge of table will be straighter/sharper than ARKit due to the increase in pixel resolution."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "99771861-cd27-4fc0-b70d-ca8c024e56cd",
          "type": "message",
          "user": "U03JMLKUF1N",
          "text": "A tooth at 5m from the camera is probably too small.",
          "ts": "1654795361.321469",
          "thread_ts": "1654795264.141979",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "yEtc",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "A tooth at 5m from the camera is probably too small."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "f580252e-cc6b-4402-a5c4-3744512b3ff4",
          "type": "message",
          "user": "U03JRR26EU8",
          "text": "That makes sense, thank you. Just so I’m understanding, that’s 5 meters or 5 millimeters?",
          "ts": "1654795450.248119",
          "thread_ts": "1654795264.141979",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "7K1",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "That makes sense, thank you. Just so I’m understanding, that’s 5 meters or 5 millimeters?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "48a714a9-24d7-4f0a-9038-d47ad799db71",
          "type": "message",
          "user": "U03JMLKUF1N",
          "text": "That's in meters.",
          "ts": "1654796045.829209",
          "thread_ts": "1654795264.141979",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "pray",
              "count": 1,
              "users": [
                "U03JRR26EU8"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Gg4",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "That's in meters."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "2059f89a-bae3-48c3-bbc3-373b6a5a0e7f",
          "type": "message",
          "user": "U03JMLKUF1N",
          "text": "You're welcome!",
          "ts": "1654796660.085439",
          "thread_ts": "1654795264.141979",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "s3q",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "You're welcome!"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03JDTS6RKP\u003e asked\n\u0026gt; Hello! I understand this one is a bit tricky, but what does the magic 8-ball say about .builtInTripleCamera one day supporting ExposureMode.custom and manual focus? :innocent:",
      "ts": "1654795690.989509",
      "thread_ts": "1654795690.989509",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 4,
      "latest_reply": "1654797394.167899",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "+7RqV",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03JDTS6RKP"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Hello! I understand this one is a bit tricky, but what does the magic 8-ball say about .builtInTripleCamera one day supporting ExposureMode.custom and manual focus? \"},{\"type\":\"emoji\",\"name\":\"innocent\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "973cf19e-d419-4bf9-87cc-3a021991f125",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Hah! The problem with supporting custom exposure modes is that each constituent camera in the virtual camera has a different min and max iso and shutter speed. Apps written for the past ~10 years are not prepared for min and max ranges to suddenly jump or shift. We would certainly crash a lot of apps if we did this. Also, zoom level is not the only factor that might cause the virtual camera to switch from one constituent camera to another. For instance, on the iPhone 13 Pro, the ultrawide lens is preferred up close because it has such a small minimum focus distance.",
          "ts": "1654795886.507349",
          "thread_ts": "1654795690.989509",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "B/31",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hah! The problem with supporting custom exposure modes is that each constituent camera in the virtual camera has a different min and max iso and shutter speed. Apps written for the past ~10 years are not prepared for min and max ranges to suddenly jump or shift. We would certainly crash a lot of apps if we did this. Also, zoom level is not the only factor that might cause the virtual camera to switch from one constituent camera to another. For instance, on the iPhone 13 Pro, the ultrawide lens is preferred up close because it has such a small minimum focus distance."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "b4f28cf9-7b26-46b0-ac98-313068bee4b0",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "So, we'd need to figure out a way to have a lot of properties jump — and jump atomically — when the constituent camera shifts. That's the reason custom exposure isn't supported on the triple camera.",
          "ts": "1654795942.494619",
          "thread_ts": "1654795690.989509",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "bBTp",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "So, we'd need to figure out a way to have a lot of properties jump — and jump atomically — when the constituent camera shifts. That's the reason custom exposure isn't supported on the triple camera."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "e30796bd-49ba-45e1-ba77-a79277a29212",
          "type": "message",
          "user": "U03JDTS6RKP",
          "text": "Appreciate the detailed answer! Totally get it, logistically its messy. My immediate thought is to expose only common ranges supported across all lenses. As the developer of ProShot I'd gladly take that range hit, and then find my own creative way to visualize it to users in the UI :slightly_smiling_face:",
          "ts": "1654797312.032409",
          "thread_ts": "1654795690.989509",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "b61t7",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Appreciate the detailed answer! Totally get it, logistically its messy. My immediate thought is to expose only common ranges supported across all lenses. As the developer of ProShot I'd gladly take that range hit, and then find my own creative way to visualize it to users in the UI "
                    },
                    {
                      "type": "emoji",
                      "name": "slightly_smiling_face",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "4f2c1db1-8d71-470e-b667-dc2594edea04",
          "type": "message",
          "user": "U03JDTS6RKP",
          "text": "At any rate, I really appreciate all the amazing work that's been going into these APIs, so much good stuff to work with! Thank you all",
          "ts": "1654797394.167899",
          "thread_ts": "1654795690.989509",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "mG/Vo",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "At any rate, I really appreciate all the amazing work that's been going into these APIs, so much good stuff to work with! Thank you all"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03JDS776JH\u003e asked\n\u0026gt; I've noticed that new version of my Camera Extension on macOS 12.3 aren't actually used until I restart, although 'systemextensionsctl list' tells me it is loaded and the old version is unloaded.\n\u0026gt; Is this intended behavior?",
      "ts": "1654795975.179809",
      "thread_ts": "1654795975.179809",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 7,
      "latest_reply": "1654799674.026309",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "Aq/T",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03JDS776JH"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"I've noticed that new version of my Camera Extension on macOS 12.3 aren't actually used until I restart, although 'systemextensionsctl list' tells me it is loaded and the old version is unloaded.\\nIs this intended behavior?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "27e60a6d-63aa-45c9-b4ea-27d8a89f1855",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "\u003c@U03JDS776JH\u003e, in the sample project I built in the CMIO Extensions video (viewing party in half an hour!), the extension is loaded and usable immediately. No need to reboot.",
          "ts": "1654796040.919839",
          "thread_ts": "1654795975.179809",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "xnP+",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "user",
                      "user_id": "U03JDS776JH"
                    },
                    {
                      "type": "text",
                      "text": ", in the sample project I built in the CMIO Extensions video (viewing party in half an hour!), the extension is loaded and usable immediately. No need to reboot."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "d6377575-ae12-40f4-8dcd-5e1dae553f38",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Currently, uninstalling it does not take effect right away — you have to reboot before the extension is unloaded for all apps, and `systemextensionsctl` tells you that.",
          "ts": "1654796076.883959",
          "thread_ts": "1654795975.179809",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "APW1",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Currently, uninstalling it does not take effect right away — you have to reboot before the extension is unloaded for all apps, and "
                    },
                    {
                      "type": "text",
                      "text": "systemextensionsctl",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " tells you that."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "d14ef2c8-a9e4-4eec-bc5e-af8fc8ae1b3e",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "I verified the above behaviors on macOS 12.3, so I'm not sure why you'd be seeing a difference. Perhaps file a bug at feedbackassistant.",
          "ts": "1654796101.109849",
          "thread_ts": "1654795975.179809",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "3uF6",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I verified the above behaviors on macOS 12.3, so I'm not sure why you'd be seeing a difference. Perhaps file a bug at feedbackassistant."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "7fde47d0-d3fd-4889-a2a2-d1f782a2524c",
          "type": "message",
          "user": "U03HZ4B0S1K",
          "text": "do changes to the CMIOExtension take effect before rebooting? I tried a few weeks ago and found that uninstalling, reinstalling, and rebooting sometimes wasn't enough to update the extension",
          "ts": "1654796155.164169",
          "thread_ts": "1654795975.179809",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "B3EHS",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "do changes to the CMIOExtension take effect before rebooting? I tried a few weeks ago and found that uninstalling, reinstalling, and rebooting sometimes wasn't enough to update the extension"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "8e36fbab-0b22-4f75-99ad-2c4e5466c801",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "That should do it every time, Finn. (uninstall, reboot, reinstall). If you want to be completely neurotic, you could bump the version number of your extension. You need to make sure that your installer code is actually telling the system to update or replace the previous one (if you're installing over an old one).",
          "ts": "1654796320.262609",
          "thread_ts": "1654795975.179809",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Stf",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "That should do it every time, Finn. (uninstall, reboot, reinstall). If you want to be completely neurotic, you could bump the version number of your extension. You need to make sure that your installer code is actually telling the system to update or replace the previous one (if you're installing over an old one)."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "9c6162af-6d1e-4557-9f79-2e3f7420e2f2",
          "type": "message",
          "user": "U03JDS776JH",
          "text": "it might be a caching issue. I bump the build number and change the name of the virtual device every time I make a change. Photo Booth will display the name of the build 84 after I’ve succesfully activated build 85, I only see build 85 after a restart. This is with SIP turned off and the hosting app _not_ in /Applications.",
          "ts": "1654797218.587159",
          "thread_ts": "1654795975.179809",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "rY0Vy",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "it might be a caching issue. I bump the build number and change the name of the virtual device every time I make a change. Photo Booth will display the name of the build 84 after I’ve succesfully activated build 85, I only see build 85 after a restart. This is with SIP turned off and the hosting app "
                    },
                    {
                      "type": "text",
                      "text": "not",
                      "style": {
                        "italic": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " in /Applications."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "4016e996-1a7f-4346-97d0-094670e91202",
          "type": "message",
          "user": "U03HZ5T63N1",
          "text": "Can we download the sample project?",
          "ts": "1654799674.026309",
          "thread_ts": "1654795975.179809",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Gsa+L",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Can we download the sample project?"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "b40a2c5b-b466-4a18-a5cb-f5529aa9fd4c",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": "Great questions so far! We've got about 9 minutes before we wrap up this session.",
      "ts": "1654797113.143529",
      "team": "T031SG5MZ7U",
      "reactions": [
        {
          "name": "alarm_clock",
          "count": 3,
          "users": [
            "U03JMC610GH",
            "U03JER2C7MX",
            "U03HXTBNYBC"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "jagKf",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Great questions so far! We've got about 9 minutes before we wrap up this session."
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "20b84c95-5a07-4870-93cf-cab12b4e6db2",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": "Thanks all! :thumbsup: Hope this was helpful.",
      "ts": "1654797593.683449",
      "team": "T031SG5MZ7U",
      "reactions": [
        {
          "name": "heart",
          "count": 2,
          "users": [
            "U03DJTBMHFF",
            "U03HVE4BEBY"
          ]
        },
        {
          "name": "raised_hands",
          "count": 2,
          "users": [
            "U03HB0AV6S3",
            "U03JMLKUF1N"
          ]
        },
        {
          "name": "clap",
          "count": 1,
          "users": [
            "U03JDTS6RKP"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "YWkK2",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Thanks all! "
                },
                {
                  "type": "emoji",
                  "name": "thumbsup",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": " Hope this was helpful."
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "ac61e5ae-3600-4019-b48b-e8dba2b3efc9",
      "type": "message",
      "user": "U03HXSHC1UK",
      "text": "Developers, developers, developers,\n\nWelcome to \"Meet the Presenter: Create camera extensions with Core Media IO!\" We are so happy to have you all here! I’m Stefan from the Camera Software Engineering team. In this hour, we invite everyone to watch the “Create camera extensions with Core Media IO” session together! Here’s how it works. Queue up the video and get ready to hit play at 11:05 am PDT. (\u003chttps://developer.apple.com/videos/play/wwdc2022/10022/\u003e)\n\nWe’ve got the session’s presenter, \u003c@U03HXTBNYBC\u003e, in the room with us. (Hi, Brad! :wave:) We are also joined here by our team of Camera software engineers who are ready to answer your questions!\n\nThere's a lot of us here, so we're going to do our best to keep things organized. As the video progresses, I'll be creating threads associated with each section of the talk, where everyone can chat and ask questions.\n\nWhen the video finishes, we will have some time left over for additional targeted Q\u0026amp;A, which I'll explain when we get there. So for the next few minutes, grab your popcorn, get comfortable, and get ready to hit the play button!",
      "ts": "1654797628.183049",
      "attachments": [
        {
          "fallback": "Apple Developer: Create camera extensions with Core Media IO - WWDC22 - Videos - Apple Developer",
          "id": 1,
          "title": "Create camera extensions with Core Media IO - WWDC22 - Videos - Apple Developer",
          "title_link": "https://developer.apple.com/videos/play/wwdc2022/10022/",
          "text": "Discover how you can use Core Media IO to easily create macOS system extensions for software cameras, hardware cameras, and creative...",
          "image_url": "https://devimages-cdn.apple.com/wwdc-services/images/124/6515/6515_wide_250x141_2x.jpg",
          "service_name": "Apple Developer",
          "service_icon": "https://developer.apple.com/favicon.ico",
          "from_url": "https://developer.apple.com/videos/play/wwdc2022/10022/",
          "original_url": "https://developer.apple.com/videos/play/wwdc2022/10022/",
          "blocks": null
        }
      ],
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "82ip",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Developers, developers, developers,\n\nWelcome to \"Meet the Presenter: Create camera extensions with Core Media IO!\" We are so happy to have you all here! I’m Stefan from the Camera Software Engineering team. In this hour, we invite everyone to watch the “Create camera extensions with Core Media IO” session together! Here’s how it works. Queue up the video and get ready to hit play at 11:05 am PDT. ("
                },
                {
                  "type": "link",
                  "url": "https://developer.apple.com/videos/play/wwdc2022/10022/",
                  "text": ""
                },
                {
                  "type": "text",
                  "text": ")\n\nWe’ve got the session’s presenter, "
                },
                {
                  "type": "user",
                  "user_id": "U03HXTBNYBC"
                },
                {
                  "type": "text",
                  "text": ", in the room with us. (Hi, Brad! "
                },
                {
                  "type": "emoji",
                  "name": "wave",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": ") We are also joined here by our team of Camera software engineers who are ready to answer your questions!\n\nThere's a lot of us here, so we're going to do our best to keep things organized. As the video progresses, I'll be creating threads associated with each section of the talk, where everyone can chat and ask questions.\n\nWhen the video finishes, we will have some time left over for additional targeted Q\u0026A, which I'll explain when we get there. So for the next few minutes, grab your popcorn, get comfortable, and get ready to hit the play button!"
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "f9f769f5-8f6e-4e5b-9dbe-907ead254d26",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": ":wave:",
      "ts": "1654797671.922199",
      "team": "T031SG5MZ7U",
      "reactions": [
        {
          "name": "wave",
          "count": 2,
          "users": [
            "U03HMDRQQ6B",
            "U03JCS2C03Z"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "T7+",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "emoji",
                  "name": "wave",
                  "skin_tone": 0
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "e7c8d153-eb2f-49f8-ad2d-75bdf7bb693f",
      "type": "message",
      "user": "U03HXSHC1UK",
      "text": "5..4..3..2..1.. :arrow_forward:",
      "ts": "1654797901.131269",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "ddqmr",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "5..4..3..2..1.. "
                },
                {
                  "type": "emoji",
                  "name": "arrow_forward",
                  "skin_tone": 0
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "f86209d8-3925-4133-bf71-e9fec207ebef",
      "type": "message",
      "user": "U03HXSHC1UK",
      "text": "Feel free to use the Ask a Question or What is your idea workflow to ask questions.",
      "ts": "1654797941.809819",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "/1xi",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Feel free to use the Ask a Question or What is your idea workflow to ask questions."
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "e4a64c00-ee29-4dc8-b1f5-595af7734aaf",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": "Fun Fact: The DAL began life as a fork of CoreAudio's HAL. Their interfaces look really similar.",
      "ts": "1654798009.371609",
      "thread_ts": "1654798009.371609",
      "reply_count": 2,
      "latest_reply": "1654824329.298069",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "YK8Cv",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Fun Fact: The DAL began life as a fork of CoreAudio's HAL. Their interfaces look really similar."
                }
              ]
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "a448ef00-0aac-487b-9c10-a69b816f6db8",
          "type": "message",
          "user": "U03HZ5T63N1",
          "text": "So, don't HALs have the same security issues as DALs?",
          "ts": "1654806753.268429",
          "thread_ts": "1654798009.371609",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Rqmd",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "So, don't HALs have the same security issues as DALs?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "06395a12-e658-4a94-b06b-8163024176bd",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "The HAL has been modernized along the way. The DAL never got the love.",
          "ts": "1654824329.298069",
          "thread_ts": "1654798009.371609",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "IQD",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "The HAL has been modernized along the way. The DAL never got the love."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "ef7594b1-0f2c-4331-abf4-200a044f90a4",
      "type": "message",
      "user": "U03HXSHC1UK",
      "text": ":thread: Questions about different kinds of camera plugins",
      "ts": "1654798154.916599",
      "thread_ts": "1654798154.916599",
      "reply_count": 1,
      "latest_reply": "1654798195.752899",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "/avO",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "emoji",
                  "name": "thread",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": " Questions about different kinds of camera plugins"
                }
              ]
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "f64b15b7-6b9a-4079-84f4-6f69ff7def5e",
          "type": "message",
          "user": "U03HXSHC1UK",
          "text": "Feel free to post your questions here.",
          "ts": "1654798195.752899",
          "thread_ts": "1654798154.916599",
          "parent_user_id": "U03HXSHC1UK",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Ob5A",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Feel free to post your questions here."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03JER2C7MX\u003e asked\n\u0026gt; Is it possible to use camera directly in app extensions, especially in the keyboard extension? Or at least a Live text, but through our own UI?",
      "ts": "1654798241.501769",
      "thread_ts": "1654798241.501769",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 9,
      "latest_reply": "1654902049.089769",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "05T4",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03JER2C7MX"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Is it possible to use camera directly in app extensions, especially in the keyboard extension? Or at least a Live text, but through our own UI?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "ace1f11a-9243-4ff7-8eed-329880cc466a",
          "type": "message",
          "user": "U03HHA1D44F",
          "text": "An iOS NSExtension? The only iOS NSExtension that supports camera access are iMessage Extensions",
          "ts": "1654798281.891129",
          "thread_ts": "1654798241.501769",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "6QE",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "An iOS NSExtension? The only iOS NSExtension that supports camera access are iMessage Extensions"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "fcf3bab8-97fa-4d31-8960-7f7946c679c7",
          "type": "message",
          "user": "U03JELM0ZNV",
          "text": "Can confirm iMessage extensions work with camera with one important bug with the plist permission entries (I think was fixed last year).",
          "ts": "1654798758.985819",
          "thread_ts": "1654798241.501769",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "f+O",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Can confirm iMessage extensions work with camera with one important bug with the plist permission entries (I think was fixed last year)."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "dccee0c1-a46d-4e3f-a3a9-f7e75c1003d3",
          "type": "message",
          "user": "U03HHA1D44F",
          "text": "Which bug is that? Involving the `NSCameraUsageDescription` entry in the Info.plist?",
          "ts": "1654799178.949449",
          "thread_ts": "1654798241.501769",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U03JELM0ZNV"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "HZs",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Which bug is that? Involving the "
                    },
                    {
                      "type": "text",
                      "text": "NSCameraUsageDescription",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " entry in the Info.plist?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "8dae1e38-bfa0-4544-bb39-a221c6de29b1",
          "type": "message",
          "user": "U03JER2C7MX",
          "text": "\u003c@U03HHA1D44F\u003e\nBut should it be possible to use Live Text then, without directly getting access to the Camera?\n\nP.S. for now, I constantly receive the following error:\n```Assertion failure in -[UIKeyboardCameraSession _keyboardCameraPreparationDidComplete]\n\nTerminating app due to uncaught exception 'NSInternalInconsistencyException', reason: 'Keyboard Camera is being used without remote keyboards enabled```",
          "ts": "1654799848.094959",
          "thread_ts": "1654798241.501769",
          "edited": {
            "user": "U03JER2C7MX",
            "ts": "1654799881.000000"
          },
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "rq3",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "user",
                      "user_id": "U03HHA1D44F"
                    },
                    {
                      "type": "text",
                      "text": "\nBut should it be possible to use Live Text then, without directly getting access to the Camera?\n\nP.S. for now, I constantly receive the following error:\n"
                    }
                  ]
                },
                {
                  "Type": "rich_text_preformatted",
                  "Raw": "{\"type\":\"rich_text_preformatted\",\"elements\":[{\"type\":\"text\",\"text\":\"Assertion failure in -[UIKeyboardCameraSession _keyboardCameraPreparationDidComplete]\\n\\nTerminating app due to uncaught exception 'NSInternalInconsistencyException', reason: 'Keyboard Camera is being used without remote keyboards enabled\"}],\"border\":0}"
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "e542d457-3b44-4959-a7d5-1d3590abcce0",
          "type": "message",
          "user": "U03HHA1D44F",
          "text": "What API do you call to get Live Text in the keyboard?\n\nI am not sure how the Keyboard Camera is implemented but if it tries to use the camera within your process, that makes sense why you are seeing that error",
          "ts": "1654800858.520989",
          "thread_ts": "1654798241.501769",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "C03p",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "What API do you call to get Live Text in the keyboard?\n\nI am not sure how the Keyboard Camera is implemented but if it tries to use the camera within your process, that makes sense why you are seeing that error"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "d38a4ad4-19a4-436c-9c24-0e24ba3a628b",
          "type": "message",
          "user": "U03JER2C7MX",
          "text": "\u003c@U03HHA1D44F\u003e\n\nLive Text API has only two requirements to be called:\n1. Have a UIResponder object\n2. Have a UIKeyInput object\nAnd I was trying to make my UIInputViewController as both of them while returning UITextDocumentProxy properties to satisfy the UIKeyInput protocol. It looked pretty valid from the design view.\n\nAnd the code I’ve been trying to run is close to the similar:\n\n```class KeyboardViewController: UIInputViewController {\n    override func viewDidLoad() {\n        super.viewDidLoad()\n\n        liveTextStraightButton.addAction(\n            UIAction.captureTextFromCamera(\n                responder: self,\n                identifier: .paste\n            ), for: .primaryActionTriggered\n        )\n    }\n}\n\nextension KeyboardViewController: UIKeyInput {\n    var hasText: Bool {\n        textDocumentProxy.hasText\n    }\n\n    func insertText(_ text: String) {\n        textDocumentProxy.insertText(text)\n    }\n\n    func deleteBackward() {\n        textDocumentProxy.deleteBackward()\n    }\n}```",
          "ts": "1654803054.738879",
          "thread_ts": "1654798241.501769",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "xtD7",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "user",
                      "user_id": "U03HHA1D44F"
                    },
                    {
                      "type": "text",
                      "text": "\n\nLive Text API has only two requirements to be called:\n"
                    }
                  ]
                },
                {
                  "Type": "rich_text_list",
                  "Raw": "{\"type\":\"rich_text_list\",\"elements\":[{\"type\":\"rich_text_section\",\"elements\":[{\"type\":\"text\",\"text\":\"Have a UIResponder object\"}]},{\"type\":\"rich_text_section\",\"elements\":[{\"type\":\"text\",\"text\":\"Have a UIKeyInput object\"}]}],\"style\":\"ordered\",\"indent\":0,\"border\":0}"
                },
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "\nAnd I was trying to make my UIInputViewController as both of them while returning UITextDocumentProxy properties to satisfy the UIKeyInput protocol. It looked pretty valid from the design view.\n\nAnd the code I’ve been trying to run is close to the similar:\n\n"
                    }
                  ]
                },
                {
                  "Type": "rich_text_preformatted",
                  "Raw": "{\"type\":\"rich_text_preformatted\",\"elements\":[{\"type\":\"text\",\"text\":\"class KeyboardViewController: UIInputViewController {\\n    override func viewDidLoad() {\\n        super.viewDidLoad()\\n\\n        liveTextStraightButton.addAction(\\n            UIAction.captureTextFromCamera(\\n                responder: self,\\n                identifier: .paste\\n            ), for: .primaryActionTriggered\\n        )\\n    }\\n}\\n\\nextension KeyboardViewController: UIKeyInput {\\n    var hasText: Bool {\\n        textDocumentProxy.hasText\\n    }\\n\\n    func insertText(_ text: String) {\\n        textDocumentProxy.insertText(text)\\n    }\\n\\n    func deleteBackward() {\\n        textDocumentProxy.deleteBackward()\\n    }\\n}\"}],\"border\":0}"
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "b8d2046e-0499-4c8e-9b8a-3202293c6cc8",
          "type": "message",
          "user": "U03JER2C7MX",
          "text": "\u003c@U03HHA1D44F\u003e hey again,\n\nCouldn’t get to the lab today regarding this question. Would be grateful for some attention to the feedback ticket regarding that issue. It has a test project attached, which helps reproduce the issue:\n\u0026gt; FB10022377 Live Text: UIAction.captureTextFromCamera not working in keyboard extension",
          "ts": "1654856900.520359",
          "thread_ts": "1654798241.501769",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "qNz=b",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "user",
                      "user_id": "U03HHA1D44F"
                    },
                    {
                      "type": "text",
                      "text": " hey again,\n\nCouldn’t get to the lab today regarding this question. Would be grateful for some attention to the feedback ticket regarding that issue. It has a test project attached, which helps reproduce the issue:\n"
                    }
                  ]
                },
                {
                  "Type": "rich_text_quote",
                  "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"FB10022377 Live Text: UIAction.captureTextFromCamera not working in keyboard extension\"}]}"
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "7f2fc8da-e909-4679-824f-86365d135ec8",
          "type": "message",
          "user": "U03HHA1D44F",
          "text": "Hi \u003c@U03JER2C7MX\u003e, I've brought FB10022377 to the attention of a colleague who is more familiar with this API to take a look. Thank you for including the test project in the radar!",
          "ts": "1654901582.658339",
          "thread_ts": "1654798241.501769",
          "edited": {
            "user": "U03HHA1D44F",
            "ts": "1654901645.000000"
          },
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "GVhD",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hi "
                    },
                    {
                      "type": "user",
                      "user_id": "U03JER2C7MX"
                    },
                    {
                      "type": "text",
                      "text": ", I've brought FB10022377 to the attention of a colleague who is more familiar with this API to take a look. Thank you for including the test project in the radar!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "C9F0D7E9-AD3D-4E6C-BCA7-FCCEE2E408CE",
          "type": "message",
          "user": "U03JER2C7MX",
          "text": "Wow, those are fantastic news, thank you! :scream::green_heart:",
          "ts": "1654902049.089769",
          "thread_ts": "1654798241.501769",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Q7rPL",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Wow,"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "those"
                    },
                    {
                      "type": "text",
                      "text": " are fantastic news, thank you! "
                    },
                    {
                      "type": "emoji",
                      "name": "scream",
                      "skin_tone": 0
                    },
                    {
                      "type": "emoji",
                      "name": "green_heart",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03HMDRQQ6B\u003e asked\n\u0026gt; We've shipped a \"modern\" Core Media IO system extension in our app. However, we never could figure out how to connect to an XPC service defined in the extension's `CMIOExtensionMachServiceName` — and a DTS ticket didn't get us far either! Is it intended that we can communicate with our extension via the XPC using the mach service? If not, what are your recommended methods of communicating with the extension when we're delivering frames over that connection?",
      "ts": "1654798255.101739",
      "thread_ts": "1654798255.101739",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 10,
      "latest_reply": "1654799697.025469",
      "reactions": [
        {
          "name": "point_up",
          "count": 1,
          "users": [
            "U03JCS2C03Z"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "EtO",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03HMDRQQ6B"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"We've shipped a \\\"modern\\\" Core Media IO system extension in our app. However, we never could figure out how to connect to an XPC service defined in the extension's `CMIOExtensionMachServiceName` \\u2014 and a DTS ticket didn't get us far either! Is it intended that we can communicate with our extension via the XPC using the mach service? If not, what are your recommended methods of communicating with the extension when we're delivering frames over that connection?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "830cf62c-bff0-49b2-9f4d-d845533f02ba",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "CMIOExtensions work a little differently from Endpoint or Network extensions. CMIOExtensions are run a a role user in a background process. That's why you're not able to find them with the named mach service.",
          "ts": "1654798326.018749",
          "thread_ts": "1654798255.101739",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "oelCF",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "CMIOExtensions work a little differently from Endpoint or Network extensions. CMIOExtensions are run a a role user in a background process. That's why you're not able to find them with the named mach service."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "81613383-c639-4846-bc43-cd395a0f6656",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Keep watching. I describe a method to talk to your extension through custom properties.",
          "ts": "1654798341.199099",
          "thread_ts": "1654798255.101739",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "OI16",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Keep watching. I describe a method to talk to your extension through custom properties."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "ceaf27a0-f781-4170-9101-fd56e9699e61",
          "type": "message",
          "user": "U03HMDRQQ6B",
          "text": "\u003c@U03HXTBNYBC\u003e Thanks for the reply. Would custom properties be appropriate for delivering frame buffers in terms of latency/etc? Ideally we’d use the old technique of delivering IOSurface buffers via IPC.",
          "ts": "1654798567.613449",
          "thread_ts": "1654798255.101739",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "6Pz",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "user",
                      "user_id": "U03HXTBNYBC"
                    },
                    {
                      "type": "text",
                      "text": " Thanks for the reply. Would custom properties be appropriate for delivering frame buffers in terms of latency/etc? Ideally we’d use the old technique of delivering IOSurface buffers via IPC."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "f90c8781-45d1-4bdd-abcd-e084b40e4af6",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "No, custom properties would be for smaller state, such as strings or NSData. For frames, you should use IOSurface backed buffers.",
          "ts": "1654798692.114079",
          "thread_ts": "1654798255.101739",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "gT/HW",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "No, custom properties would be for smaller state, such as strings or NSData. For frames, you should use IOSurface backed buffers."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "086b6221-20aa-485b-8ca7-d15e6e67cd31",
          "type": "message",
          "user": "U03HMDRQQ6B",
          "text": "Is it possible to deliver such buffers to our CMIO system extension from our parent app?",
          "ts": "1654798779.133259",
          "thread_ts": "1654798255.101739",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "hbW5n",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Is it possible to deliver such buffers to our CMIO system extension from our parent app?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "4f18bd73-6945-4fc3-a9b5-1bdde9a54110",
          "type": "message",
          "user": "U03HHA1DV9D",
          "text": "Is the idea here that your app is capturing or generating real-time video and you want to get that to other camera-sourcing apps?",
          "ts": "1654798836.186659",
          "thread_ts": "1654798255.101739",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "rtI8",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Is the idea here that your app is capturing or generating real-time video and you want to get that to other camera-sourcing apps?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "47cb2262-1834-4364-851b-0b07db18cbd9",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Yes. One way to do this is to present 2 devices in your extension. One that presents an *output* or *sink* stream, and one that presents an *input* or *source* stream. You push frames to the sink stream device, and then in the extension, re-publish it through the camera.",
          "ts": "1654798857.724659",
          "thread_ts": "1654798255.101739",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "g6X",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Yes. One way to do this is to present 2 devices in your extension. One that presents an "
                    },
                    {
                      "type": "text",
                      "text": "output",
                      "style": {
                        "bold": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " or "
                    },
                    {
                      "type": "text",
                      "text": "sink",
                      "style": {
                        "bold": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " stream, and one that presents an "
                    },
                    {
                      "type": "text",
                      "text": "input",
                      "style": {
                        "bold": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " or "
                    },
                    {
                      "type": "text",
                      "text": "source",
                      "style": {
                        "bold": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " stream. You push frames to the sink stream device, and then in the extension, re-publish it through the camera."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "ef1391f9-31a5-4e68-ad74-4cb28896e7d4",
          "type": "message",
          "user": "U03HMDRQQ6B",
          "text": "\u003c@U03HHA1DV9D\u003e Yup! Our app connects to DSLR/mirrorless cameras over network or USB and lets them be used as webcams even if they’re not UVC devices (which most aren’t). For various reasons, it makes sense for that connection and processing to be going on in the parent app.",
          "ts": "1654798971.333729",
          "thread_ts": "1654798255.101739",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "+2g",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "user",
                      "user_id": "U03HHA1DV9D"
                    },
                    {
                      "type": "text",
                      "text": " Yup! Our app connects to DSLR/mirrorless cameras over network or USB and lets them be used as webcams even if they’re not UVC devices (which most aren’t). For various reasons, it makes sense for that connection and processing to be going on in the parent app."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "05a43b87-caf2-48c7-a8d2-adcfad10ef80",
          "type": "message",
          "user": "U03HMDRQQ6B",
          "text": "\u003c@U03HXTBNYBC\u003e Ok great, thanks for the idea. We have a Feedback open (FB10026784) assuming the XPC thing is a bug — perhaps that should be changed to a documentation request clarifying what the mach service key is for.",
          "ts": "1654799060.863899",
          "thread_ts": "1654798255.101739",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "d6jw",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "user",
                      "user_id": "U03HXTBNYBC"
                    },
                    {
                      "type": "text",
                      "text": " Ok great, thanks for the idea. We have a Feedback open (FB10026784) assuming the XPC thing is a bug — perhaps that should be changed to a documentation request clarifying what the mach service key is for."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "a4a02a05-be79-4f51-a8a8-fae8ea1330cd",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "As of right now, the mach service name is required so that CMIO's registerassistantservice recognizes the extension as a CMIO extension. But it's not currently used as a named /known XPC service that an app connects to. Thanks for the FB.",
          "ts": "1654799697.025469",
          "thread_ts": "1654798255.101739",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Ai3L",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "As of right now, the mach service name is required so that CMIO's registerassistantservice recognizes the extension as a CMIO extension. But it's not currently used as a named /known XPC service that an app connects to. Thanks for the FB."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03HZ4B0S1K\u003e asked\n\u0026gt; Are audio CMIOExtensions nearly identical to the sample video one, where I would just send audio CMSampleBuffers to the CMIOExtensionStream?",
      "ts": "1654798419.630909",
      "thread_ts": "1654798419.630909",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 8,
      "latest_reply": "1654801023.540199",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "8Wv",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03HZ4B0S1K"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Are audio CMIOExtensions nearly identical to the sample video one, where I would just send audio CMSampleBuffers to the CMIOExtensionStream?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "d215923a-d216-4bb6-a496-233dbba3b996",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "We do not recommend shipping audio drivers as CMIOExtensions. Most apps won't work with them. Stick to writing an Audio driver using HAL apis if you're delivering a pure audio driver.",
          "ts": "1654798480.516249",
          "thread_ts": "1654798419.630909",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "BZSBL",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "We do not recommend shipping audio drivers as CMIOExtensions. Most apps won't work with them. Stick to writing an Audio driver using HAL apis if you're delivering a pure audio driver."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "b7d39153-8677-4aeb-86c9-c031b8265e2b",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Audio samples are sometimes interesting to deliver from a CMIOExtension if, for instance, your camera delivers a muxed stream. Like the built in iOS Screen Capture DAL plugin, you can present your stream as a muxxed media type, and then deliver video or audio samples once you're running.",
          "ts": "1654798542.554299",
          "thread_ts": "1654798419.630909",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "fBJf",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Audio samples are sometimes interesting to deliver from a CMIOExtension if, for instance, your camera delivers a muxed stream. Like the built in iOS Screen Capture DAL plugin, you can present your stream as a muxxed media type, and then deliver video or audio samples once you're running."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "e7705c6a-df64-4b20-a4ef-396c1afa622f",
          "type": "message",
          "user": "U03HVC012J2",
          "text": "I expect that shipping a HAL driver with my app would make App Store distribution difficult. It’d be nice to have something like a Camera Extension that works for audio.",
          "ts": "1654798627.158299",
          "thread_ts": "1654798419.630909",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "/cb0s",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I expect that shipping a HAL driver with my app would make App Store distribution difficult. It’d be nice to have something like a Camera Extension that works for audio."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "49c2a98b-eb82-4326-9a73-7f2d562f7a11",
          "type": "message",
          "user": "U03HZ4B0S1K",
          "text": "Hmm okay.  We have a HAL that we use to act as a virtual microphone that we can send any audio to (similar to BlackHole), and from this tweet: \u003chttps://twitter.com/KhaosT/status/1497711090183987204?s=20\u0026amp;t=QwkmE9VvspUaWLmXO3-tyA\u003e I assumed it would be possible to convert to a CMIOExtension for distribution on the app store.",
          "ts": "1654798659.841809",
          "thread_ts": "1654798419.630909",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "z2g",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hmm okay.  We have a HAL that we use to act as a virtual microphone that we can send any audio to (similar to BlackHole), and from this tweet: "
                    },
                    {
                      "type": "link",
                      "url": "https://twitter.com/KhaosT/status/1497711090183987204?s=20\u0026t=QwkmE9VvspUaWLmXO3-tyA",
                      "text": ""
                    },
                    {
                      "type": "text",
                      "text": " I assumed it would be possible to convert to a CMIOExtension for distribution on the app store."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "190bf28a-6b4f-4b87-a0f5-d5c008a8c264",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "You can certainly present it as a CMIOExtension. But most audio apps won't find it. They talk to the HAL, not the DAL.",
          "ts": "1654799756.713439",
          "thread_ts": "1654798419.630909",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "djQV",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "You can certainly present it as a CMIOExtension. But most audio apps won't find it. They talk to the HAL, not the DAL."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "88637248-59f6-43e3-857a-c6d9002953bd",
          "type": "message",
          "user": "U03HZ5T63N1",
          "text": "How about FaceTime? Would that see the CMIOExtension as a \"microphone\"?",
          "ts": "1654799824.743239",
          "thread_ts": "1654798419.630909",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "ZvpW",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "How about FaceTime? Would that see the CMIOExtension as a \"microphone\"?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "664d4b4e-9191-44cf-9c57-f332b2fd57d5",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Unfortunately no.",
          "ts": "1654800958.639769",
          "thread_ts": "1654798419.630909",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "XPY+",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Unfortunately no."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "dde24e7a-b2d2-45a4-8836-f62617f801c5",
          "type": "message",
          "user": "U03HZ5T63N1",
          "text": "In this case we need a replacement for the HALs as well!",
          "ts": "1654801023.540199",
          "thread_ts": "1654798419.630909",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "p11",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "In this case we need a replacement for the HALs as well!"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "898a9cc1-78df-4a88-9903-78150e58f10c",
      "type": "message",
      "user": "U03HXSHC1UK",
      "text": ":thread: Questions about building camera extensions",
      "ts": "1654798432.522529",
      "thread_ts": "1654798432.522529",
      "reply_count": 9,
      "latest_reply": "1654800919.041819",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "/qCL8",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "emoji",
                  "name": "thread",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": " Questions about building camera extensions"
                }
              ]
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "38d08682-d7be-44d4-adb1-c82b18340027",
          "type": "message",
          "user": "U03HXSHC1UK",
          "text": "Let us hear your hardest questions here.",
          "ts": "1654798486.775869",
          "thread_ts": "1654798432.522529",
          "parent_user_id": "U03HXSHC1UK",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "R0HC5",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Let us hear your hardest questions here."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "cc107385-85fc-49c7-87d1-a6d5a45d2d4c",
          "type": "message",
          "user": "U03HZ4B0S1K",
          "text": "Is uninstalling, rebooting, and reinstalling a camera extension the recommended way to develop these extensions, in order to see changes? Disabling SIP lets me avoid moving them to the Applications folder, but rebooting every time I make a change is a little rough",
          "ts": "1654798494.301549",
          "thread_ts": "1654798432.522529",
          "parent_user_id": "U03HXSHC1UK",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "ZilW",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Is uninstalling, rebooting, and reinstalling a camera extension the recommended way to develop these extensions, in order to see changes? Disabling SIP lets me avoid moving them to the Applications folder, but rebooting every time I make a change is a little rough"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "8dfd9799-6e2c-484d-a258-4ca068978d43",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "I hear you. Even with SIP on, you should be able to install your extension and have it be available immediately for use. To uninstall, though, you do need to reboot. That's a bummer and we're looking into making this experience better. I understand how painful it is to develop an extension when you have to reboot to see your changes.",
          "ts": "1654798638.909859",
          "thread_ts": "1654798432.522529",
          "parent_user_id": "U03HXSHC1UK",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "9PC",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I hear you. Even with SIP on, you should be able to install your extension and have it be available immediately for use. To uninstall, though, you do need to reboot. That's a bummer and we're looking into making this experience better. I understand how painful it is to develop an extension when you have to reboot to see your changes."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "b11fe92d-ba00-4c8f-b589-5182ad0cad76",
          "type": "message",
          "user": "U03HZ4B0S1K",
          "text": "Thanks for the response, I'll try to code it all in one go without bugs :wink:",
          "ts": "1654798708.257609",
          "thread_ts": "1654798432.522529",
          "parent_user_id": "U03HXSHC1UK",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "male_superhero",
              "count": 1,
              "users": [
                "U03HXTBNYBC"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "NGbU",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks for the response, I'll try to code it all in one go without bugs "
                    },
                    {
                      "type": "emoji",
                      "name": "wink",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "f233555f-80ac-436a-8e63-e12f893d2a1d",
          "type": "message",
          "user": "U03JDS776JH",
          "text": "I’ve found that if I had no extension activated before, sure enough it is immediately available after activation and approval. But if I’m updating, the old extension is used until I restart.",
          "ts": "1654798825.089249",
          "thread_ts": "1654798432.522529",
          "parent_user_id": "U03HXSHC1UK",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Yvn8a",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I’ve found that if I had no extension activated before, sure enough it is immediately available after activation and approval. But if I’m updating, the old extension is used until I restart."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "83087613-33b8-45f7-9c5a-a69751a85ebc",
          "type": "message",
          "user": "U03HVC012J2",
          "text": "Is connecting to an extension with the Xcode debugger supposed to work? I wasn’t able to do that, last time I tried.",
          "ts": "1654798956.798379",
          "thread_ts": "1654798432.522529",
          "parent_user_id": "U03HXSHC1UK",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "eg7w",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Is connecting to an extension with the Xcode debugger supposed to work? I wasn’t able to do that, last time I tried."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "5ed7bc4c-b836-4cd9-a617-06eab66ea710",
          "type": "message",
          "user": "U03HZ5T63N1",
          "text": "Shouldn't the Camera Extension be removed when the App that exposes it is quit?",
          "ts": "1654799880.802139",
          "thread_ts": "1654798432.522529",
          "parent_user_id": "U03HXSHC1UK",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "JoHnP",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Shouldn't the Camera Extension be removed when the App that exposes it is quit?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "d64bfdc3-1e17-4511-9c55-d15e23a36cac",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "I think you should be able to connect to it in the debugger, Mark, as long as you click the box where you're debugging it as the root user rather than as the foreground user.",
          "ts": "1654800845.449679",
          "thread_ts": "1654798432.522529",
          "parent_user_id": "U03HXSHC1UK",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "iUOM+",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I think you should be able to connect to it in the debugger, Mark, as long as you click the box where you're debugging it as the root user rather than as the foreground user."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "21365efb-0098-49ba-a98c-4376c5dfa4d7",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "\u003c@U03HZ5T63N1\u003e no, the App isn't hosting the extension. It's more like the mail carrier that delivers it to the system, and then installs it (using System Extension APIs) for all users on the system. That's why it needs to live in /Applications. That's by design. Quitting the app doesn't remove the extension. *Deleting* the app does remove it though.",
          "ts": "1654800919.041819",
          "thread_ts": "1654798432.522529",
          "parent_user_id": "U03HXSHC1UK",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "W/dq",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "user",
                      "user_id": "U03HZ5T63N1"
                    },
                    {
                      "type": "text",
                      "text": " no, the App isn't hosting the extension. It's more like the mail carrier that delivers it to the system, and then installs it (using System Extension APIs) for all users on the system. That's why it needs to live in /Applications. That's by design. Quitting the app doesn't remove the extension. "
                    },
                    {
                      "type": "text",
                      "text": "Deleting",
                      "style": {
                        "bold": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " the app does remove it though."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "dd7aeaf9-73dc-48ed-bba3-30070dcadba3",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": "Fun Fact: the DSLR camera on the back table is a Fuji X-E4 with a 16 mm 1.4 ultrawide lens. One of 3 Fuji X-Trans bodies I own. Yes, I'm a camera nerd.",
      "ts": "1654798747.063199",
      "thread_ts": "1654798747.063199",
      "reply_count": 1,
      "latest_reply": "1654805897.038769",
      "team": "T031SG5MZ7U",
      "reactions": [
        {
          "name": "fire",
          "count": 3,
          "users": [
            "U03JDTS6RKP",
            "U03JMB7160Z",
            "U03EBH4MA8Y"
          ]
        },
        {
          "name": "nerd_face",
          "count": 1,
          "users": [
            "U03HBH4EAR4"
          ]
        },
        {
          "name": "star-struck",
          "count": 3,
          "users": [
            "U03JR1WG6SH",
            "U03K9CG5NDP",
            "U03JELDBMT3"
          ]
        },
        {
          "name": "camera",
          "count": 1,
          "users": [
            "U03JMC610GH"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "HVl",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Fun Fact: the DSLR camera on the back table is a Fuji X-E4 with a 16 mm 1.4 ultrawide lens. One of 3 Fuji X-Trans bodies I own. Yes, I'm a camera nerd."
                }
              ]
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "889b2d22-88ff-4ed0-b070-ac23e47ec1f0",
          "type": "message",
          "user": "U03JMC610GH",
          "text": "Such a great combo! Need a separate Fujifilm/X-Trans nerd-out thread.",
          "ts": "1654805897.038769",
          "thread_ts": "1654798747.063199",
          "parent_user_id": "U03HXTBNYBC",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "K4XC",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Such a great combo! Need a separate Fujifilm/X-Trans nerd-out thread."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03JDS776JH\u003e asked\n\u0026gt; one of the use cases is \"providing pre-rendered content\". But that content is likely to be large and on-disk as a file. But I thought Camera Extensions don't have access to the file system?",
      "ts": "1654798894.040499",
      "thread_ts": "1654798894.040499",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 6,
      "latest_reply": "1654801079.106629",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "qN+",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03JDS776JH"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"one of the use cases is \\\"providing pre-rendered content\\\". But that content is likely to be large and on-disk as a file. But I thought Camera Extensions don't have access to the file system?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "b9419a32-ce46-42ba-b6ce-547667bf4d09",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "You're free to use pre-rendered content that resides in your extension's own sandbox. CMIOExtensions don't have general file system access though. They have a more locked down sandbox that regular apps.",
          "ts": "1654798982.319689",
          "thread_ts": "1654798894.040499",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "qeXy",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "You're free to use pre-rendered content that resides in your extension's own sandbox. CMIOExtensions don't have general file system access though. They have a more locked down sandbox that regular apps."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "6e776bcb-acec-4dda-b0d3-b176c6a008e1",
          "type": "message",
          "user": "U03JDS776JH",
          "text": "yes, I just re-watched that bit of your video. So I could send a huge parameter set  (perhaps slowly) as a property, and the extension could cache that in its own container as a file. Can I pre-populate an extension’s container at build time?",
          "ts": "1654799107.202269",
          "thread_ts": "1654798894.040499",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "0GWI",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "yes, I just re-watched that bit of your video. So I could send a huge parameter set  (perhaps slowly) as a property, and the extension could cache that in its own container as a file. Can I pre-populate an extension’s container at build time?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "e8270beb-8210-4963-a202-b82f5ee100bb",
          "type": "message",
          "user": "U03HVC012J2",
          "text": "This is a problem for our use case, too. One suggestion we got from DTS was to set up two devices from the extension - one as the virtual camera, and one as an output device. Then, the app should be able to stream media from the App’s sandbox (and user files) to the output device, which then would route them to the extension. I haven’t tried that out yet, to see how well it works.",
          "ts": "1654799123.988139",
          "thread_ts": "1654798894.040499",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "yoLwd",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "This is a problem for our use case, too. One suggestion we got from DTS was to set up two devices from the extension - one as the virtual camera, and one as an output device. Then, the app should be able to stream media from the App’s sandbox (and user files) to the output device, which then would route them to the extension. I haven’t tried that out yet, to see how well it works."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "cb5c3d7f-1b06-4751-95b9-c96ead5eb826",
          "type": "message",
          "user": "U03JDS776JH",
          "text": "yes, Brad mentioned that idea in a lab yesterday. In principle you can wrap *any* data up in a video buffer and send it, so you could even use a video queue if the property interface is too slow. If extensions were easier to develop and debug I’d be happy to put more intelligence in the extension, but at present I have to restart every time I rev my extension. So for me, for now, the extension if just a conduit for frames created elsewhere.",
          "ts": "1654800213.690199",
          "thread_ts": "1654798894.040499",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "2eYxP",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "yes, Brad mentioned that idea in a lab yesterday. In principle you can wrap "
                    },
                    {
                      "type": "text",
                      "text": "any",
                      "style": {
                        "bold": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " data up in a video buffer and send it, so you could even use a video queue if the property interface is too slow. If extensions were easier to develop and debug I’d be happy to put more intelligence in the extension, but at present I have to restart every time I rev my extension. So for me, for now, the extension if just a conduit for frames created elsewhere."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "92a2ebf1-494b-4cb8-b975-589485d0adaf",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "\u003c@U03JDS776JH\u003e What do you mean by \"build time\"? _Can I pre-populate an extension’s container at build time?_",
          "ts": "1654801023.567599",
          "thread_ts": "1654798894.040499",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "YIGR",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "user",
                      "user_id": "U03JDS776JH"
                    },
                    {
                      "type": "text",
                      "text": " What do you mean by \"build time\"? "
                    },
                    {
                      "type": "text",
                      "text": "Can I pre-populate an extension’s container at build time?",
                      "style": {
                        "italic": true
                      }
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "97af12bb-0b6c-47d5-be6e-ad2682cff553",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "I'm definitely hearing that rebooting to uninstall is a pain point.",
          "ts": "1654801079.106629",
          "thread_ts": "1654798894.040499",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U03HVC012J2"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "iT0UX",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I'm definitely hearing that rebooting to uninstall is a pain point."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "76aa4375-34a0-4269-8bd4-6ea05a2eb1ee",
      "type": "message",
      "user": "U03HXSHC1UK",
      "text": ":thread: Questions about new APIs",
      "ts": "1654798998.177039",
      "thread_ts": "1654798998.177039",
      "reply_count": 1,
      "latest_reply": "1654799059.766879",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "cy=T7",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "emoji",
                  "name": "thread",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": " Questions about new APIs"
                }
              ]
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "6886c517-cc91-44c6-9e87-51f308885dd1",
          "type": "message",
          "user": "U03HXSHC1UK",
          "text": "Let's hear your questions about the new APIs related to Core Media IO extensions",
          "ts": "1654799059.766879",
          "thread_ts": "1654798998.177039",
          "parent_user_id": "U03HXSHC1UK",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "4cOob",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Let's hear your questions about the new APIs related to Core Media IO extensions"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03JDS776JH\u003e asked\n\u0026gt; Camera Extensions can communicate over Firewire (!), USB, Bluetooth... but PCIe (Thunderbolt) is not mentioned. Will that be enabled?",
      "ts": "1654799010.432729",
      "thread_ts": "1654799010.432729",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 2,
      "latest_reply": "1654799161.898539",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "6ud",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03JDS776JH"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Camera Extensions can communicate over Firewire (!), USB, Bluetooth... but PCIe (Thunderbolt) is not mentioned. Will that be enabled?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "0cfd49c7-bbe6-4482-90b8-d19f90d5cb08",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "PCIe access would currently mean you need to resort to the legacy IOVideoFamily kernel interface. Kernel access is deprecated. But unfortunately we don't have a replacement for IOVideoFamily yet (sort of a peer to DEXT but with access to PCI hardware).",
          "ts": "1654799086.166229",
          "thread_ts": "1654799010.432729",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "lB1g",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "PCIe access would currently mean you need to resort to the legacy IOVideoFamily kernel interface. Kernel access is deprecated. But unfortunately we don't have a replacement for IOVideoFamily yet (sort of a peer to DEXT but with access to PCI hardware)."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "a1c43fb7-50bf-4c5a-a8a7-e54c29ccd7bd",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "I didn't mention PCI hardware because of the kext necessity. It's technically possible to use a CMIOExtension in conjunction with IOVideoFamily — so it will work. Just know that if at all possible to keep your code out of the kernel, you should. I'm sure the CoreOS team would love to hear your feedback about what you can and can't do with DEXTs. :slightly_smiling_face:",
          "ts": "1654799161.898539",
          "thread_ts": "1654799010.432729",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "BPja",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I didn't mention PCI hardware because of the kext necessity. It's technically possible to use a CMIOExtension in conjunction with IOVideoFamily — so it will work. Just know that if at all possible to keep your code out of the kernel, you should. I'm sure the CoreOS team would love to hear your feedback about what you can and can't do with DEXTs. "
                    },
                    {
                      "type": "emoji",
                      "name": "slightly_smiling_face",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "4a607b58-4978-46ef-983f-cfee3e1d6709",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": "Another Fun Fact: The lego model to my left is a 1975 Porsche 911 Turbo. The original widow maker. It has a fully functional steering column that moves the wheels when you turn the steering wheel. You can also change it from a Turbo (whale tail) configuration to a Targa configuration. Yes, I'm a Porsche nerd. And a lego nerd.",
      "ts": "1654799227.300859",
      "team": "T031SG5MZ7U",
      "reactions": [
        {
          "name": "laughing",
          "count": 3,
          "users": [
            "U03HXSHBJ8K",
            "U03HB0AV6S3",
            "U03K9CG5NDP"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "xuY",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Another Fun Fact: The lego model to my left is a 1975 Porsche 911 Turbo. The original widow maker. It has a fully functional steering column that moves the wheels when you turn the steering wheel. You can also change it from a Turbo (whale tail) configuration to a Targa configuration. Yes, I'm a Porsche nerd. And a lego nerd."
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03JDS776JH\u003e asked\n\u0026gt; if my Camera Extension already vends to any application, and it has some custom controls accessible over USB (either in a UVC Extension Unit or via HID), why would I use a DEXT to communicate with it, when I can use the HID Manager or user-space USB methods to communicate with the device?",
      "ts": "1654799292.495239",
      "thread_ts": "1654799292.495239",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 5,
      "latest_reply": "1654800755.653329",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "fZbU",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03JDS776JH"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"if my Camera Extension already vends to any application, and it has some custom controls accessible over USB (either in a UVC Extension Unit or via HID), why would I use a DEXT to communicate with it, when I can use the HID Manager or user-space USB methods to communicate with the device?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "4417483a-3efb-4e27-bc0a-3e9feafdbe29",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "You don't have to use a DEXT. You're free to use other services. HID should be fine.",
          "ts": "1654799328.924639",
          "thread_ts": "1654799292.495239",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "N6o1S",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "You don't have to use a DEXT. You're free to use other services. HID should be fine."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "445ef8f4-91c1-4cd8-887b-dd7bfd3ba97c",
          "type": "message",
          "user": "U03JDS776JH",
          "text": "we’ve always had to jump through a small hoop to associate an AVCaptureDevice (which is actually a UVC device) with the HID device on the same USB device which provides us with additional control and status. We have to parse the uniqueID, which contains the USB location ID. That’s messy.",
          "ts": "1654799495.471689",
          "thread_ts": "1654799292.495239",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "MUGeK",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "we’ve always had to jump through a small hoop to associate an AVCaptureDevice (which is actually a UVC device) with the HID device on the same USB device which provides us with additional control and status. We have to parse the uniqueID, which contains the USB location ID. That’s messy."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "ac998d1e-7d87-460d-bb7b-37c250c35184",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Right. We recognized that some 3rd parties are probably encoding bits of the vendor id / product id into their plugin's unique identifier. That's why we didn't force all unique IDs to be GUID style strings in the new extension world. You can implement a legacyID if you need to maintain backward compatibility.",
          "ts": "1654799585.726309",
          "thread_ts": "1654799292.495239",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "nOO",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Right. We recognized that some 3rd parties are probably encoding bits of the vendor id / product id into their plugin's unique identifier. That's why we didn't force all unique IDs to be GUID style strings in the new extension world. You can implement a legacyID if you need to maintain backward compatibility."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "9c9c56b2-0729-4394-90c4-16109ae42dc8",
          "type": "message",
          "user": "U03JDS776JH",
          "text": "I’m talking about Apple’s UVC driver - it creates a unique ID for a USB AVCCaptureDevice which is concatenation of vid, pid and location ID. Even when we wholeheartedly adopt Camera Extensions, we’ll still have to correlate HID devices with UVC devices, and there’s no public API to do so. (FB6146541)",
          "ts": "1654799884.940889",
          "thread_ts": "1654799292.495239",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "d9ft",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I’m talking about Apple’s UVC driver - it creates a unique ID for a USB AVCCaptureDevice which is concatenation of vid, pid and location ID. Even when we wholeheartedly adopt Camera Extensions, we’ll still have to correlate HID devices with UVC devices, and there’s no public API to do so. (FB6146541)"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "8bfeda0e-cc9b-4a91-bb5d-b051373bde09",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Right. Apple's UVC Extension is a client that uses the legacyID feature, so apps such as yours (I suspect!) won't break.",
          "ts": "1654800755.653329",
          "thread_ts": "1654799292.495239",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "KDB97",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Right. Apple's UVC Extension is a client that uses the legacyID feature, so apps such as yours (I suspect!) won't break."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "12e5b6b0-6d0d-4534-a3e6-ea4ef03cfcaf",
      "type": "message",
      "user": "U03HXSHC1UK",
      "text": ":thread: Questions about CoreMedia IO Extensions as output devices",
      "ts": "1654799643.394399",
      "thread_ts": "1654799643.394399",
      "reply_count": 12,
      "latest_reply": "1654801277.130419",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "qrAzM",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "emoji",
                  "name": "thread",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": " Questions about CoreMedia IO Extensions as output devices"
                }
              ]
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "f26702c4-8dd2-47aa-9a56-923454ecf6e3",
          "type": "message",
          "user": "U03HXSHC1UK",
          "text": "Let us hear your questions regarding output devices.",
          "ts": "1654799674.506139",
          "thread_ts": "1654799643.394399",
          "parent_user_id": "U03HXSHC1UK",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "mSE",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Let us hear your questions regarding output devices."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "e266c5a1-9fe0-4641-90e3-c52e89045cfe",
          "type": "message",
          "user": "U03HZ5T63N1",
          "text": "I assume you mean in an app like mimoLive where you use the Camera Extension to send the video to Zoom?",
          "ts": "1654799726.175909",
          "thread_ts": "1654799643.394399",
          "parent_user_id": "U03HXSHC1UK",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "lejmX",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I assume you mean in an app like mimoLive where you use the Camera Extension to send the video to Zoom?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "4aec79b0-98a5-42ee-9b83-f6054b5749a2",
          "type": "message",
          "user": "U03HMDRQQ6B",
          "text": "Is there a sample project somewhere that gives examples of delivering frames into a CMIO extension that supports output?",
          "ts": "1654799784.519019",
          "thread_ts": "1654799643.394399",
          "parent_user_id": "U03HXSHC1UK",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "yqK",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Is there a sample project somewhere that gives examples of delivering frames into a CMIO extension that supports output?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "c2a28980-d8d1-4660-b892-db18bede9b89",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Not yet, but we hope to deliver one! It certainly does remove some development complexity, as you're able to do all the compositing in your configuration app.",
          "ts": "1654799828.063579",
          "thread_ts": "1654799643.394399",
          "parent_user_id": "U03HXSHC1UK",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U03HVC012J2"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "4CR",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Not yet, but we hope to deliver one! It certainly does remove some development complexity, as you're able to do all the compositing in your configuration app."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "a8dfc1d4-89bf-4d79-a812-299d1a08b13e",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "\u003c@U03HZ5T63N1\u003e Output devices can be actual, physical devices. Blackmagic, for instance, has output hardware to which Final Cut Pro can send high quality streams for live preview.",
          "ts": "1654799900.135329",
          "thread_ts": "1654799643.394399",
          "parent_user_id": "U03HXSHC1UK",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "bD48e",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "user",
                      "user_id": "U03HZ5T63N1"
                    },
                    {
                      "type": "text",
                      "text": " Output devices can be actual, physical devices. Blackmagic, for instance, has output hardware to which Final Cut Pro can send high quality streams for live preview."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "662902a6-c0ab-4d74-91e6-66e661299b08",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "But yes, one use of an output device is as a \"virtual\" output device.",
          "ts": "1654799932.297999",
          "thread_ts": "1654799643.394399",
          "parent_user_id": "U03HXSHC1UK",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Er6gB",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "But yes, one use of an output device is as a \"virtual\" output device."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "04a52131-8704-4644-8eca-4e4d626c3ec8",
          "type": "message",
          "user": "U03HMDRQQ6B",
          "text": "Is it possible to “hide” an output device so it’s only visible if you know it’s there? So, for example, a Final Cut user doesn’t end up pushing video into our extension",
          "ts": "1654799958.939989",
          "thread_ts": "1654799643.394399",
          "parent_user_id": "U03HXSHC1UK",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "rZSNf",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Is it possible to “hide” an output device so it’s only visible if you know it’s there? So, for example, a Final Cut user doesn’t end up pushing video into our extension"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "44facd64-c94b-4084-a2ed-fd6824baef17",
          "type": "message",
          "user": "U03HXTE9N4S",
          "text": "CMIOExtensionProvider api `addDevice` `removeDevice` let you control when device is available to app users.",
          "ts": "1654800605.377219",
          "thread_ts": "1654799643.394399",
          "parent_user_id": "U03HXSHC1UK",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "2GvkZ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "CMIOExtensionProvider api "
                    },
                    {
                      "type": "text",
                      "text": "addDevice",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "removeDevice",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " let you control when device is available to app users."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "b971712d-3211-407e-a30e-6c82ceb89797",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": ":point_up_2: Exactly. Your CMIOExtension gets to decide if a client is allowed to connect to it.",
          "ts": "1654801143.407669",
          "thread_ts": "1654799643.394399",
          "parent_user_id": "U03HXSHC1UK",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "1vJMH",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "emoji",
                      "name": "point_up_2",
                      "skin_tone": 0
                    },
                    {
                      "type": "text",
                      "text": " Exactly. Your CMIOExtension gets to decide if a client is allowed to connect to it."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "aff1baa2-cacc-4847-8405-ca217510ff3a",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Or, you could simply only allow a single connection (first client), and deny all other clients to push frames in.",
          "ts": "1654801168.998229",
          "thread_ts": "1654799643.394399",
          "parent_user_id": "U03HXSHC1UK",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "wp0i",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Or, you could simply only allow a single connection (first client), and deny all other clients to push frames in."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "764bf3c1-1cdc-408c-9a70-1b016984c734",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Also of note, \u003c@U03HMDRQQ6B\u003e, is that AVFoundation does not publish CMIODevices that only have output streams. So they are implicitly 'hidden' from a great majority of apps on the system.",
          "ts": "1654801222.103849",
          "thread_ts": "1654799643.394399",
          "parent_user_id": "U03HXSHC1UK",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "9JF4C",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Also of note, "
                    },
                    {
                      "type": "user",
                      "user_id": "U03HMDRQQ6B"
                    },
                    {
                      "type": "text",
                      "text": ", is that AVFoundation does not publish CMIODevices that only have output streams. So they are implicitly 'hidden' from a great majority of apps on the system."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "23003794-6bcd-49f1-8361-787ab3f4556e",
          "type": "message",
          "user": "U03HMDRQQ6B",
          "text": "Alright, sounds like a sensible approach for us to investigate — thanks for the guidance!",
          "ts": "1654801277.130419",
          "thread_ts": "1654799643.394399",
          "parent_user_id": "U03HXSHC1UK",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "dLTB",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Alright, sounds like a sensible approach for us to investigate — thanks for the guidance!"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "dac1084a-8c76-40ac-b0db-632b47012daa",
      "type": "message",
      "user": "U03HXSHC1UK",
      "text": ":thread: Questions about DAL plugins deprecation",
      "ts": "1654799748.051069",
      "thread_ts": "1654799748.051069",
      "reply_count": 6,
      "latest_reply": "1654801645.841529",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "89j8N",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "emoji",
                  "name": "thread",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": " Questions about DAL plugins deprecation"
                }
              ]
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "efddf720-a07f-4989-8a7a-5f9a3c90ad0d",
          "type": "message",
          "user": "U03HXSHC1UK",
          "text": "Please ask your question about DAL plugin deprecation here.",
          "ts": "1654799787.165789",
          "thread_ts": "1654799748.051069",
          "parent_user_id": "U03HXSHC1UK",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "VPHC",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Please ask your question about DAL plugin deprecation here."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "968c2cf7-95c6-4b20-b24b-dda4c8895b2c",
          "type": "message",
          "user": "U03HMDRQQ6B",
          "text": "Is there any kind of “de-duping” done by the pipeline? For example, if my app had a DAL plugin and now has a system extension, if the user still has the DAL plugin installed will they see the camera twice in apps that allow DAL?",
          "ts": "1654799855.900989",
          "thread_ts": "1654799748.051069",
          "parent_user_id": "U03HXSHC1UK",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Nk=z1",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Is there any kind of “de-duping” done by the pipeline? For example, if my app had a DAL plugin and now has a system extension, if the user still has the DAL plugin installed will they see the camera twice in apps that allow DAL?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "a353e158-abef-4e62-83a7-5ab9c5921c40",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Ooh, good question. We currently do not de-dupe at the framework level. Perhaps your CMIOExtension could detect the presence of a DAL Plugin and warn the user during installation, or actually remove it.",
          "ts": "1654800013.676639",
          "thread_ts": "1654799748.051069",
          "parent_user_id": "U03HXSHC1UK",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "cD3",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Ooh, good question. We currently do not de-dupe at the framework level. Perhaps your CMIOExtension could detect the presence of a DAL Plugin and warn the user during installation, or actually remove it."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "c1a5f151-2007-49b2-90e2-5faf757a852b",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "I'm not sure what would happen if you installed a CMIOExtension with the same uniqueIdentifier as an existing DAL Plugin. We will investigate.",
          "ts": "1654800064.578899",
          "thread_ts": "1654799748.051069",
          "parent_user_id": "U03HXSHC1UK",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "OuSVv",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I'm not sure what would happen if you installed a CMIOExtension with the same uniqueIdentifier as an existing DAL Plugin. We will investigate."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "89897925-1bda-431c-9cd5-03e18ed132b9",
          "type": "message",
          "user": "U03HMDRQQ6B",
          "text": "We have implemented exactly that, but I was just wondering if it was wasted effort — getting privilege escalation etc to be able to remove the DAL plugin is a bit of a song and dance considering our app is otherwise sandboxed, and we’d have to remove all that for App Store distribution",
          "ts": "1654800146.085969",
          "thread_ts": "1654799748.051069",
          "parent_user_id": "U03HXSHC1UK",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "4lk",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "We have implemented exactly that, but I was just wondering if it was wasted effort — getting privilege escalation etc to be able to remove the DAL plugin is a bit of a song and dance considering our app is otherwise sandboxed, and we’d have to remove all that for App Store distribution"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "f5861db1-e4e2-4069-970b-e75bd2ea2659",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Aha. Not wasted effort.",
          "ts": "1654801645.841529",
          "thread_ts": "1654799748.051069",
          "parent_user_id": "U03HXSHC1UK",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Aa9f",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Aha. Not wasted effort."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "bdaf694f-e968-4a63-b677-4a94ae5621b5",
      "type": "message",
      "user": "U03HXSHC1UK",
      "text": "OK! Now that we've watched it, let's dig in on the questions.\nI've started a few threads with sample feature areas. Feel free to ask questions there, or, ask your own questions.\nBrad and the team will answer questions until 12:00 PM PDT.",
      "ts": "1654799833.546169",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "RwmW",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "OK! Now that we've watched it, let's dig in on the questions.\nI've started a few threads with sample feature areas. Feel free to ask questions there, or, ask your own questions.\nBrad and the team will answer questions until 12:00 PM PDT."
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03HZ5T63N1\u003e asked\n\u0026gt; The Camera Extension is awesome! Can we have multiple instances of it, say, to send different content from separate documents to the host application?",
      "ts": "1654800080.795259",
      "thread_ts": "1654800080.795259",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 5,
      "latest_reply": "1654806839.115479",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "tP/",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03HZ5T63N1"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"The Camera Extension is awesome! Can we have multiple instances of it, say, to send different content from separate documents to the host application?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "d8a8d1ee-30d4-4bdd-8d4b-74be44a6c80a",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Thank you! We're excited about them. The team has worked really hard to produce a modern replacement. We want everyone to adopt them at lightning speed. :zap:",
          "ts": "1654800119.067899",
          "thread_ts": "1654800080.795259",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "6RV4",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thank you! We're excited about them. The team has worked really hard to produce a modern replacement. We want everyone to adopt them at lightning speed. "
                    },
                    {
                      "type": "emoji",
                      "name": "zap",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "55ba43da-a06a-403c-9cca-0ee44fac8a7f",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "You can only have one instance of your CMIOExtension loaded at a time. But it can vend more than one device. Or, your installer app could install more than one CMIOExtension.",
          "ts": "1654800167.005399",
          "thread_ts": "1654800080.795259",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "X7h3",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "You can only have one instance of your CMIOExtension loaded at a time. But it can vend more than one device. Or, your installer app could install more than one CMIOExtension."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "dc432c9f-1588-469b-9c58-d2c585e10bac",
          "type": "message",
          "user": "U03HZ5T63N1",
          "text": "Sample code that covers everything would be helpful. :slightly_smiling_face:",
          "ts": "1654800177.124679",
          "thread_ts": "1654800080.795259",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "OMCe",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Sample code that covers everything would be helpful. "
                    },
                    {
                      "type": "emoji",
                      "name": "slightly_smiling_face",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "fb0bff28-b34d-4cfd-aaec-f4efe4533c39",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Hopefully the Xcode walk through in the video was helpful. The CMIOExtension template is really a great starting point. It builds a fully functional camera device / stream, so just studying the code produced by the template is a great start.",
          "ts": "1654800230.621659",
          "thread_ts": "1654800080.795259",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "VerKD",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hopefully the Xcode walk through in the video was helpful. The CMIOExtension template is really a great starting point. It builds a fully functional camera device / stream, so just studying the code produced by the template is a great start."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "71bbb8c4-5878-4b6c-b3ce-42b5f5a967ef",
          "type": "message",
          "user": "U03HZ5T63N1",
          "text": "Thanks for the walkthrough. Unfortunately, the video is actually too small to read the code you put in there. It would still be great to have the project as Sample Code.",
          "ts": "1654806839.115479",
          "thread_ts": "1654800080.795259",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "SglS",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks for the walkthrough. Unfortunately, the video is actually too small to read the code you put in there. It would still be great to have the project as Sample Code."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03HZ5T63N1\u003e asked\n\u0026gt; Just because it comes to mind: We currently have a DAL for Video and a corresponding HAL for Audio. Both currently have to be installed by the user separately from the app. The Camera Extension being a part of the app is a great relief. Do you know what corresponding API/Extension we can use for sound so that we do not have to install the HAL component?",
      "ts": "1654800250.074349",
      "thread_ts": "1654800250.074349",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 8,
      "latest_reply": "1654801207.623639",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "HIY=2",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03HZ5T63N1"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Just because it comes to mind: We currently have a DAL for Video and a corresponding HAL for Audio. Both currently have to be installed by the user separately from the app. The Camera Extension being a part of the app is a great relief. Do you know what corresponding API\\/Extension we can use for sound so that we do not have to install the HAL component?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "d405813b-68a2-471f-b84e-76f98b4720ec",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "That is a great question. I don't know if it's possible to install a HAL driver through an app from the app store. Would you mind asking that question over at the \u003c#C03H9J5AW4U|\u003e slack channel?",
          "ts": "1654800294.002999",
          "thread_ts": "1654800250.074349",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "HR4",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "That is a great question. I don't know if it's possible to install a HAL driver through an app from the app store. Would you mind asking that question over at the "
                    },
                    {
                      "type": "channel",
                      "channel_id": "C03H9J5AW4U"
                    },
                    {
                      "type": "text",
                      "text": " slack channel?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "d554f5cb-359b-4f70-8d99-fc5d1211b3ab",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "As I mentioned in a previous thread, you can certainly deliver audio through your CMIOExtension — it just won't get picked up by general purpose audio recording apps, who only query the HAL APIs to find HAL devices. An app like QuickTimePlayerX would be able to record from it though (assuming you've got a \"muxx\" device).",
          "ts": "1654800371.668829",
          "thread_ts": "1654800250.074349",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "j=W",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "As I mentioned in a previous thread, you can certainly deliver audio through your CMIOExtension — it just won't get picked up by general purpose audio recording apps, who only query the HAL APIs to find HAL devices. An app like QuickTimePlayerX would be able to record from it though (assuming you've got a \"muxx\" device)."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "95c1dce1-d68a-48fa-ac07-fd5422c73454",
          "type": "message",
          "user": "U03HZ5T63N1",
          "text": "Not sure if that works in apps like Zoom where you have a separate selector for audio devices.",
          "ts": "1654800623.566169",
          "thread_ts": "1654800250.074349",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "RtH",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Not sure if that works in apps like Zoom where you have a separate selector for audio devices."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "c11191ab-ffc1-4d96-8c24-aedc1b61a2b9",
          "type": "message",
          "user": "U03HZ5T63N1",
          "text": "I asked in the audio-and-video-lounge but they seem to be off duty now.",
          "ts": "1654800676.767339",
          "thread_ts": "1654800250.074349",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "s9YPA",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I asked in the audio-and-video-lounge but they seem to be off duty now."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "42300889-d1e5-4e18-93fa-175f3a29b6ef",
          "type": "message",
          "user": "U03HZ5T63N1",
          "text": "I hope they still see the question",
          "ts": "1654800684.615469",
          "thread_ts": "1654800250.074349",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "J8y",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I hope they still see the question"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "a2d993ba-376e-4b36-9338-4121e525a324",
          "type": "message",
          "user": "U03HHA1DV9D",
          "text": "Typically when an application publishes a list of audio sources they are HAL devices.  If your CMIO Extension delivers audio with its video, it is considered a \"muxed\" CMIO stream.  The original CMIO muxed streams were from DV and HDV cameras.  Taking audio from muxed stream is not usually handled by applications.",
          "ts": "1654801131.450859",
          "thread_ts": "1654800250.074349",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "c5Tnj",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Typically when an application publishes a list of audio sources they are HAL devices.  If your CMIO Extension delivers audio with its video, it is considered a \"muxed\" CMIO stream.  The original CMIO muxed streams were from DV and HDV cameras.  Taking audio from muxed stream is not usually handled by applications."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "52621f42-49f5-4621-bddd-66ef53f5f55c",
          "type": "message",
          "user": "U03HHA1DV9D",
          "text": "Unless the application is also capturing video from the device.",
          "ts": "1654801153.278689",
          "thread_ts": "1654800250.074349",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "/iq",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Unless the application is also capturing video from the device."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "29819dd1-dcfe-4048-b3c3-1db154f0446c",
          "type": "message",
          "user": "U03HHA1DV9D",
          "text": "Audio in this case does not come from CoreAudio, but instead stays in the realm of AVCapture APIs.  An app could use an AVCaptureAudioDataOutput to get access to the audio from a muxed stream, or use an AVCaptureMovieFileOutput to record it.",
          "ts": "1654801207.623639",
          "thread_ts": "1654800250.074349",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "FRAy",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Audio in this case does not come from CoreAudio, but instead stays in the realm of AVCapture APIs.  An app could use an AVCaptureAudioDataOutput to get access to the audio from a muxed stream, or use an AVCaptureMovieFileOutput to record it."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03JCS2C03Z\u003e asked\n\u0026gt; Thanks for the session! I was wondering what would be the best way to transmit an app's view to its Camera Extension? So far I've tried hooking up an XPC Service to pass IOSurface data, but unsure how/where to connect in the extension",
      "ts": "1654800434.518629",
      "thread_ts": "1654800434.518629",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 8,
      "latest_reply": "1654801623.681159",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "pud08",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03JCS2C03Z"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Thanks for the session! I was wondering what would be the best way to transmit an app's view to its Camera Extension? So far I've tried hooking up an XPC Service to pass IOSurface data, but unsure how\\/where to connect in the extension\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "743317ec-2a51-4079-ae03-fd446d090bb2",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Sure seems like a lot of you are trying to hook up an XPC service to pass frames to your extension. That's currently not working due to the fact that CMIOExtensions are run as a background process under a role user account, so they have no connection to the front user / aqua session.",
          "ts": "1654800505.348799",
          "thread_ts": "1654800434.518629",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "mPw",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Sure seems like a lot of you are trying to hook up an XPC service to pass frames to your extension. That's currently not working due to the fact that CMIOExtensions are run as a background process under a role user account, so they have no connection to the front user / aqua session."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "311e1e5b-6e5a-4f0f-b5d1-3a3c895d8f24",
          "type": "message",
          "user": "U03JDS776JH",
          "text": "I have been nagging Brad with questions about exactly this!",
          "ts": "1654800509.627799",
          "thread_ts": "1654800434.518629",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "lO=",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I have been nagging Brad with questions about exactly this!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "4690bb17-778e-4d37-a320-0e827cde9035",
          "type": "message",
          "user": "U03JDS776JH",
          "text": "I’ve even got it to work, but the user experience isn’t ideal.",
          "ts": "1654800551.458479",
          "thread_ts": "1654800434.518629",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "lfCx",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I’ve even got it to work, but the user experience isn’t ideal."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "f9f10346-fdbe-465f-852d-cce5be631d6b",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "One means of doing it is to do the fake output device -\u0026gt; fake camera device dance in your extension. Find the fake output device in your app and push frames to it. Then in your extension, republish those frames as a camera stream.",
          "ts": "1654800553.609479",
          "thread_ts": "1654800434.518629",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "gWcu",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "One means of doing it is to do the fake output device -\u003e fake camera device dance in your extension. Find the fake output device in your app and push frames to it. Then in your extension, republish those frames as a camera stream."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "2bbeb072-7415-40dc-b048-2352366fae83",
          "type": "message",
          "user": "U03HMDRQQ6B",
          "text": "I think we’re all trying to do it because it worked in the old DAL plugin system :stuck_out_tongue:",
          "ts": "1654800635.509869",
          "thread_ts": "1654800434.518629",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "PDdb1",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I think we’re all trying to do it because it worked in the old DAL plugin system "
                    },
                    {
                      "type": "emoji",
                      "name": "stuck_out_tongue",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "d6d37069-7ef9-4de8-952a-661f728c006b",
          "type": "message",
          "user": "U03JCS2C03Z",
          "text": "Yup lot of speculation and attempts before the official docs came out :smile:",
          "ts": "1654800678.840949",
          "thread_ts": "1654800434.518629",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "9hJAi",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Yup lot of speculation and attempts before the official docs came out "
                    },
                    {
                      "type": "emoji",
                      "name": "smile",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "1aa0a563-c5cc-4a3c-bc70-7422b9d5b19e",
          "type": "message",
          "user": "U03JCS2C03Z",
          "text": "As I now understand it: initialize a fake output device within the app to consume frames.\nThen find that device within the extension and republish, probably from within `CMIOExtensionDeviceSource`?",
          "ts": "1654800837.520779",
          "thread_ts": "1654800434.518629",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "+un+",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "As I now understand it: initialize a fake output device within the app to consume frames.\nThen find that device within the extension and republish, probably from within "
                    },
                    {
                      "type": "text",
                      "text": "CMIOExtensionDeviceSource",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "89973e67-c3ca-40a1-96b4-d09061392a3c",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Right. Or the ProviderSource, depending on how you want to separate your code.",
          "ts": "1654801623.681159",
          "thread_ts": "1654800434.518629",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "100",
              "count": 1,
              "users": [
                "U03JCS2C03Z"
              ]
            },
            {
              "name": "pray",
              "count": 1,
              "users": [
                "U03JCS2C03Z"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "mIv2s",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Right. Or the ProviderSource, depending on how you want to separate your code."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03HMDRQQ6B\u003e asked\n\u0026gt; Not a question, but thank you for building this. I'm really happy to have a modern/secure approach for building this kind of plugin, and even happier to be able to distribute it on the App Store!",
      "ts": "1654800577.795249",
      "thread_ts": "1654800577.795249",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 6,
      "latest_reply": "1654801573.712849",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "bBDxC",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03HMDRQQ6B"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Not a question, but thank you for building this. I'm really happy to have a modern\\/secure approach for building this kind of plugin, and even happier to be able to distribute it on the App Store!\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "bd2011ec-1bdd-463b-93de-77153fa9d077",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "From the whole team, THANK YOU!",
          "ts": "1654800596.014209",
          "thread_ts": "1654800577.795249",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "TFn4",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "From the whole team, THANK YOU!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "79a78cbd-7d55-4ee7-959d-7b400d3e8f16",
          "type": "message",
          "user": "U03JDS776JH",
          "text": "I will second that. I’ve wanted this for a very long time!:100:",
          "ts": "1654800619.395379",
          "thread_ts": "1654800577.795249",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "fIK",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I will second that. I’ve wanted this for a very long time!"
                    },
                    {
                      "type": "emoji",
                      "name": "100",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "a9d6a0d7-0149-4002-9099-cd8a738048e0",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "We're excited about it too. That's why we've developed such an aggressive deprecation plan for DAL plugins. The whole system will be more safe and secure once DAL plugins are a thing of the past.",
          "ts": "1654800638.794819",
          "thread_ts": "1654800577.795249",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "raised_hands",
              "count": 2,
              "users": [
                "U03JMB7160Z",
                "U03JCS2C03Z"
              ]
            },
            {
              "name": "white_check_mark",
              "count": 2,
              "users": [
                "U03JDS776JH",
                "U03JCS2C03Z"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "VnkZ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "We're excited about it too. That's why we've developed such an aggressive deprecation plan for DAL plugins. The whole system will be more safe and secure once DAL plugins are a thing of the past."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "ceb9b6c4-76b0-4d31-ae62-939bef0db141",
          "type": "message",
          "user": "U03JDS776JH",
          "text": "does that mean that the fake output device/virtual camera output “dance” approach you mentioned will become impossible? Because the extension is still built on top of DAL…",
          "ts": "1654800705.281789",
          "thread_ts": "1654800577.795249",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "pAJB9",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "does that mean that the fake output device/virtual camera output “dance” approach you mentioned will become impossible? Because the extension is still built on top of DAL…"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "a2c79825-305e-4637-8602-c261cfc1b2be",
          "type": "message",
          "user": "U03HZ5T63N1",
          "text": "I applaud this as the DALs really sucked. But I hope you will provide all features necessary to replace them before you remove them.",
          "ts": "1654800928.405089",
          "thread_ts": "1654800577.795249",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "am9",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I applaud this as the DALs really sucked. But I hope you will provide all features necessary to replace them before you remove them."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "35cf6ec9-4209-4d19-af7d-ef65c2e268e9",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "CMIOExtensions are part of the CoreMediaIO framework, but we consider them distinct from the DAL Plugin interfaces (which are deprecated). We are not planning on removing the ability to use CMIOExtensions as output devices.",
          "ts": "1654801573.712849",
          "thread_ts": "1654800577.795249",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "OLP",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "CMIOExtensions are part of the CoreMediaIO framework, but we consider them distinct from the DAL Plugin interfaces (which are deprecated). We are not planning on removing the ability to use CMIOExtensions as output devices."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "848204ba-60bc-46b6-91d6-b756136a1041",
      "type": "message",
      "user": "U03HXSHC1UK",
      "text": "Time to get your last minute questions in - we are around until 12:00 PM PDT.",
      "ts": "1654800998.225849",
      "edited": {
        "user": "U03HXSHC1UK",
        "ts": "1654801059.000000"
      },
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "LNlov",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Time to get your last minute questions in - we are around until 12:00 PM PDT."
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "3038c6c0-76fb-461f-8c7a-ddf703d7709d",
      "type": "message",
      "user": "U03HXSHC1UK",
      "text": "Thanks everyone for participating in our Meet the Presenter session about creating camera extensions with Core Media IO! It’s a lot to take in. You may still be processing. We’ll be around for one more event during the week:\nFriday 9 AM - 12 PM PDT: Camera Capture Lab #2. Sign up by 6:00 PM PDT today with your questions.\n:wave:   :pray:",
      "ts": "1654801215.591189",
      "team": "T031SG5MZ7U",
      "reactions": [
        {
          "name": "raised_hands",
          "count": 2,
          "users": [
            "U03HZ5T63N1",
            "U03JCS2C03Z"
          ]
        },
        {
          "name": "raised_hands::skin-tone-2",
          "count": 1,
          "users": [
            "U03EBH4MA8Y"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "ukRZK",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Thanks everyone for participating in our Meet the Presenter session about creating camera extensions with Core Media IO! It’s a lot to take in. You may still be processing. We’ll be around for one more event during the week:\nFriday 9 AM - 12 PM PDT: Camera Capture Lab #2. Sign up by 6:00 PM PDT today with your questions.\n"
                },
                {
                  "type": "emoji",
                  "name": "wave",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": "   "
                },
                {
                  "type": "emoji",
                  "name": "pray",
                  "skin_tone": 0
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "a019d0f4-31a7-4546-b596-7287ff7f7581",
      "type": "message",
      "user": "U03HXTBNYBC",
      "text": "Thanks all! Fun talking with you all.",
      "ts": "1654801240.504059",
      "team": "T031SG5MZ7U",
      "reactions": [
        {
          "name": "heart",
          "count": 1,
          "users": [
            "U03HVE4BEBY"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "rl2",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Thanks all! Fun talking with you all."
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03JR1WG6SH\u003e asked\n\u0026gt; Hi Brad! Core Media IO seems very cool. I'm curious, is there or might there every be the capability to capture high quality stills via these plugins? Or do they only provide video streams? Thinking about the use case of a tethered mirrorless camera",
      "ts": "1654801260.234649",
      "thread_ts": "1654801260.234649",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 2,
      "latest_reply": "1654806635.743849",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "GXweL",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03JR1WG6SH"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Hi Brad! Core Media IO seems very cool. I'm curious, is there or might there every be the capability to capture high quality stills via these plugins? Or do they only provide video streams? Thinking about the use case of a tethered mirrorless camera\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "eb1f03b7-0ae9-4d7c-9527-f3f925020d38",
          "type": "message",
          "user": "U03HXTBNYBC",
          "text": "Yes! We'd like to support high res stills very soon. The Continuity Camera that Craig talked about in the WWDC keynote is capable of producing high res (12 MP) stills and delivering them to an AVCapturePhotoOutput. Definitely want 3rd party extensions to be able to do likewise.",
          "ts": "1654801347.671589",
          "thread_ts": "1654801260.234649",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "s=0i",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Yes! We'd like to support high res stills very soon. The Continuity Camera that Craig talked about in the WWDC keynote is capable of producing high res (12 MP) stills and delivering them to an AVCapturePhotoOutput. Definitely want 3rd party extensions to be able to do likewise."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "aaea1d72-6ed0-49a1-9005-87acca2548f5",
          "type": "message",
          "user": "U03HZ5T63N1",
          "text": "Awesome!",
          "ts": "1654806635.743849",
          "thread_ts": "1654801260.234649",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "wIF",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Awesome!"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "7a1ff557-8213-423c-b72e-c0cf1c295719",
      "type": "message",
      "user": "U03DJTBMHFF",
      "text": "\u003c!here\u003e\n*Next Activity… \"Q\u0026amp;A: Photos \u0026amp; PhotoKit\"*\nWe'll be focusing on one topic area for the next hour—Photos and the PhotoKit framework. Joining us is a great team of engineers from the Photos team. They are your resident experts on everything from Photos library access, the Photos Picker, Limited Photos Library, and more. Looking forward to a fun, lively conversation. Start submitting your questions by clicking the  :heavy_plus_sign: button and using the workflow. :workflowbolt:",
      "ts": "1654808513.141199",
      "thread_ts": "1654808513.141199",
      "reply_count": 3,
      "latest_reply": "1654808849.621479",
      "team": "T031SG5MZ7U",
      "reactions": [
        {
          "name": "wave",
          "count": 4,
          "users": [
            "U03JYF8GT7A",
            "U03HBH4EAR4",
            "U03J24JKNCW",
            "U03K5JE9HG8"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "/Sd",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "broadcast",
                  "range": "here"
                },
                {
                  "type": "text",
                  "text": "\n"
                },
                {
                  "type": "text",
                  "text": "Next Activity… \"Q\u0026A: Photos \u0026 PhotoKit\"",
                  "style": {
                    "bold": true
                  }
                },
                {
                  "type": "text",
                  "text": "\nWe'll be focusing on one topic area for the next hour—Photos and the PhotoKit framework. Joining us is a great team of engineers from the Photos team. They are your resident experts on everything from Photos library access, the Photos Picker, Limited Photos Library, and more. Looking forward to a fun, lively conversation. Start submitting your questions by clicking the  "
                },
                {
                  "type": "emoji",
                  "name": "heavy_plus_sign",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": " button and using the workflow. "
                },
                {
                  "type": "emoji",
                  "name": "workflowbolt",
                  "skin_tone": 0
                }
              ]
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "f28615a3-ddfa-45a5-b919-e99350b54ff0",
          "type": "message",
          "user": "U03J4CQQR9A",
          "text": "I think the workflow is not active yet? Can’t see the option",
          "ts": "1654808786.468459",
          "thread_ts": "1654808513.141199",
          "parent_user_id": "U03DJTBMHFF",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "x+r",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I think the workflow is not active yet? Can’t see the option"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "d72e18da-c1be-4fe6-8156-c95b224e5621",
          "type": "message",
          "user": "U03DJTBMHFF",
          "text": "Hmm. It got disabled for some reason. Fixing!",
          "ts": "1654808808.101459",
          "thread_ts": "1654808513.141199",
          "parent_user_id": "U03DJTBMHFF",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "TVsS0",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Hmm. It got disabled for some reason. Fixing!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "50d767e0-e8f1-4dfc-ad10-943afd66e754",
          "type": "message",
          "user": "U03J4CQQR9A",
          "text": "I see it now :+1:",
          "ts": "1654808849.621479",
          "thread_ts": "1654808513.141199",
          "parent_user_id": "U03DJTBMHFF",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "FAk",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I see it now "
                    },
                    {
                      "type": "emoji",
                      "name": "+1",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "3ba996e4-5d2d-45fa-9198-09de78bca377",
      "type": "message",
      "user": "U03DJTBMHFF",
      "text": "Apologies all. Workflow to submit questions has been re-enabled.",
      "ts": "1654808884.453919",
      "team": "T031SG5MZ7U",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "=qw",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Apologies all. Workflow to submit questions has been re-enabled."
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03HMDFMVNK\u003e asked\n\u0026gt; The new iCloud shared photo library looks awesome! Will the content of the shared library be accessible from the PhotoKit API? (e.g. fetching PHAssets)",
      "ts": "1654809040.427319",
      "thread_ts": "1654809040.427319",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 5,
      "latest_reply": "1654810005.854039",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "5Xqfu",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03HMDFMVNK"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"The new iCloud shared photo library looks awesome! Will the content of the shared library be accessible from the PhotoKit API? (e.g. fetching PHAssets)\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "57d1034a-34e3-4968-bef3-60bf23f679e1",
          "type": "message",
          "user": "U03J5R8VAPP",
          "text": "Yes! All Shared assets would be accessible via the existing PHAsset fetches",
          "ts": "1654809087.391789",
          "thread_ts": "1654809040.427319",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U03JMC610GH"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "56mJw",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Yes! All Shared assets would be accessible via the existing PHAsset fetches"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "9d1c2c06-3ed6-4a3b-b4d2-786a2f1d7ca7",
          "type": "message",
          "user": "U03HMDFMVNK",
          "text": "Great! Is there some way to tell apart shared assets from non-shared? I didn’t see any API changes in the new SDK but thought those might not be in since the shared library isn’t in seed 1.",
          "ts": "1654809204.987119",
          "thread_ts": "1654809040.427319",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "=bs",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Great! Is there some way to tell apart shared assets from non-shared? I didn’t see any API changes in the new SDK but thought those might not be in since the shared library isn’t in seed 1."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "afff4c6a-de71-469a-b400-7cc6574b51d8",
          "type": "message",
          "user": "U03J5R8VAPP",
          "text": "There is no API to differentiate shared vs. non-shared. From an API perspective, they would appear to all be part of the same local library",
          "ts": "1654809316.204379",
          "thread_ts": "1654809040.427319",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "KPaxg",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "There is no API to differentiate shared vs. non-shared. From an API perspective, they would appear to all be part of the same local library"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "513f52a8-ccdf-467d-b9b9-e1a12eb74f63",
          "type": "message",
          "user": "U03J5R8VAPP",
          "text": "As always, we would welcome use cases for specific API additions via Feedback requests (The more detail the better). Missed you during the lab slot yesterday \u003c@U03HMDFMVNK\u003e :wink:",
          "ts": "1654809796.963209",
          "thread_ts": "1654809040.427319",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "alarm_clock",
              "count": 1,
              "users": [
                "U03JMC610GH"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "/HY=+",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "As always, we would welcome use cases for specific API additions via Feedback requests (The more detail the better). Missed you during the lab slot yesterday "
                    },
                    {
                      "type": "user",
                      "user_id": "U03HMDFMVNK"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "emoji",
                      "name": "wink",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "d09315f6-ca11-49e1-a4eb-ff42c8a81df7",
          "type": "message",
          "user": "U03HMDFMVNK",
          "text": "Haha, sorry I got caught up watching videos. :sweat_smile: Not exactly sure yet what I might want to do with shared vs. non-shared, but once I have a chance to play around with a seed with the shared library UI, that will give me more ideas and will file feedback accordingly.",
          "ts": "1654810005.854039",
          "thread_ts": "1654809040.427319",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "gUJ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Haha, sorry I got caught up watching videos. "
                    },
                    {
                      "type": "emoji",
                      "name": "sweat_smile",
                      "skin_tone": 0
                    },
                    {
                      "type": "text",
                      "text": " Not exactly sure yet what I might want to do with shared vs. non-shared, but once I have a chance to play around with a seed with the shared library UI, that will give me more ideas and will file feedback accordingly."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03HY66772A\u003e asked\n\u0026gt; Can I get access to the smart filters present in Photos app via `PHAsset.fetchAssets(with:)`?",
      "ts": "1654809173.629259",
      "thread_ts": "1654809173.629259",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 9,
      "latest_reply": "1654812932.583809",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "D84RK",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03HY66772A"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Can I get access to the smart filters present in Photos app via `PHAsset.fetchAssets(with:)`?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "df4b780a-0235-40b5-993c-0137ce34f1bd",
          "type": "message",
          "user": "U03J8LCLQN7",
          "text": "You can fetch the various Media smart albums and favorites (for example) by using the API `fetchAssetCollectionsWithType:subtype:options:` with the appropriate smart album subtype",
          "ts": "1654809244.938909",
          "thread_ts": "1654809173.629259",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "R4+Tm",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "You can fetch the various Media smart albums and favorites (for example) by using the API "
                    },
                    {
                      "type": "text",
                      "text": "fetchAssetCollectionsWithType:subtype:options:",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " with the appropriate smart album subtype"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "6c721663-4f2a-4ec3-905b-1b2f4976250e",
          "type": "message",
          "user": "U03J8LCLQN7",
          "text": "And then use the returned asset collection as the input to `fetchAssets(in:options:)`",
          "ts": "1654809331.188829",
          "thread_ts": "1654809173.629259",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "7KG",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "And then use the returned asset collection as the input to "
                    },
                    {
                      "type": "text",
                      "text": "fetchAssets(in:options:)",
                      "style": {
                        "code": true
                      }
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "7bddeefa-2827-4cd5-b0c5-4d0d98d7abe1",
          "type": "message",
          "user": "U03J8LCLQN7",
          "text": "For example: `PHAssetCollection.fetchAssetCollections(with: .smartAlbum, subtype: .smartAlbumFavorites, options: options)`",
          "ts": "1654809571.207029",
          "thread_ts": "1654809173.629259",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Fxfn",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "For example: "
                    },
                    {
                      "type": "text",
                      "text": "PHAssetCollection.fetchAssetCollections(with: .smartAlbum, subtype: .smartAlbumFavorites, options: options)",
                      "style": {
                        "code": true
                      }
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "f3dd04d8-ff71-4dca-bbb8-246fc83d3f13",
          "type": "message",
          "user": "U03HY66772A",
          "text": "Yeah, I knew that option:) My question was more in the direction of filtering photos by keyword.\n\nFor a bit more of a context: we create a clothing try-on app, and we would greatly benefit from showing our users photos that contain people. There are no smart albums for that, as far as i know:(",
          "ts": "1654809603.296689",
          "thread_ts": "1654809173.629259",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "5dl",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Yeah, I knew that option:) My question was more in the direction of filtering photos by keyword.\n\nFor a bit more of a context: we create a clothing try-on app, and we would greatly benefit from showing our users photos that contain people. There are no smart albums for that, as far as i know:("
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "ad2566e6-0363-4add-aca7-c99ac4a43764",
          "type": "message",
          "user": "U03J8LCLQN7",
          "text": "I see, yes, that's correct- there is no API currently to fetch based on people. If you haven't already submitted an enhancement feedback request please do and provide the specifics of your desired use case.",
          "ts": "1654809774.160319",
          "thread_ts": "1654809173.629259",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "dmpmF",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I see, yes, that's correct- there is no API currently to fetch based on people. If you haven't already submitted an enhancement feedback request please do and provide the specifics of your desired use case."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "3db76b57-59dc-4ac0-aca6-5b30323b0886",
          "type": "message",
          "user": "U03J8LCLQN7",
          "text": "Though it doesn't address your request specifically, you might be able to make use of the PHPicker to give the user a way to select specific assets based on search and filter for keywords",
          "ts": "1654809900.067509",
          "thread_ts": "1654809173.629259",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "WrHut",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Though it doesn't address your request specifically, you might be able to make use of the PHPicker to give the user a way to select specific assets based on search and filter for keywords"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "73e44555-f522-475d-8711-77166bbfa950",
          "type": "message",
          "user": "U03JYF8GT7A",
          "text": "To elaborate, PHPickerViewController now supports \u003chttps://developer.apple.com/documentation/photokit/phpickerfilter|additional filter APIs\u003e (e.g. screenshots filter). Users can also search for terms like “People” in the picker search bar.",
          "ts": "1654810471.883089",
          "thread_ts": "1654809173.629259",
          "edited": {
            "user": "U03JYF8GT7A",
            "ts": "1654810562.000000"
          },
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "dyF",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "To elaborate, PHPickerViewController now supports "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/documentation/photokit/phpickerfilter",
                      "text": "additional filter APIs"
                    },
                    {
                      "type": "text",
                      "text": " (e.g. screenshots filter). Users can also search for terms like “People” in the picker search bar."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "f2fb1dcb-a324-4d6d-8abc-5b883843dd4c",
          "type": "message",
          "user": "U03HY66772A",
          "text": "Could you achieve same result by getting faces smart albums? I don’t know whether it returns anything if user hadn’t marked anyone in his library.",
          "ts": "1654811375.128699",
          "thread_ts": "1654809173.629259",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "3ajx",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Could you achieve same result by getting faces smart albums? I don’t know whether it returns anything if user hadn’t marked anyone in his library."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "09d64744-fe79-4686-b85a-a31360cab605",
          "type": "message",
          "user": "U03JYF8GT7A",
          "text": "Search supports unnamed person",
          "ts": "1654812932.583809",
          "thread_ts": "1654809173.629259",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "eyes",
              "count": 2,
              "users": [
                "U03HY66772A",
                "U03HVE4BEBY"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "G7g7",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Search supports unnamed person"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03HMBQ0KJB\u003e asked\n\u0026gt; Is there a way to query the \"People\" library/collection within the user's Photo library?",
      "ts": "1654809180.154559",
      "thread_ts": "1654809180.154559",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 3,
      "latest_reply": "1654810225.877869",
      "reactions": [
        {
          "name": "eyes",
          "count": 1,
          "users": [
            "U03J20RJQ2X"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "9by2N",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03HMBQ0KJB"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Is there a way to query the \\\"People\\\" library\\/collection within the user's Photo library?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "17ecde11-0090-4ae5-8a36-ffbd918c7714",
          "type": "message",
          "user": "U03HBH4EAR4",
          "text": "People information (e.g. the names associated and groupings) are not provided via PhotoKit",
          "ts": "1654809232.126879",
          "thread_ts": "1654809180.154559",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "KYKi=",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "People information (e.g. the names associated and groupings) are not provided via PhotoKit"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "ddae12b7-a4dd-4534-bb5a-6afa04b7674d",
          "type": "message",
          "user": "U03HBH4EAR4",
          "text": "I encourage you to file a Feedback with your specific use case in mind. Or if you’ve already filed one, please paste it here!",
          "ts": "1654809481.862809",
          "thread_ts": "1654809180.154559",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "RZa92",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I encourage you to file a Feedback with your specific use case in mind. Or if you’ve already filed one, please paste it here!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "400269cf-6053-4276-bc7b-b7c578ea6dba",
          "type": "message",
          "user": "U03HMBQ0KJB",
          "text": "FB9163331 :slightly_smiling_face:",
          "ts": "1654810225.877869",
          "thread_ts": "1654809180.154559",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "gratitude-thank-you",
              "count": 1,
              "users": [
                "U03HBH4EAR4"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "JtIY",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "FB9163331 "
                    },
                    {
                      "type": "emoji",
                      "name": "slightly_smiling_face",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03K7KBHSV6\u003e asked\n\u0026gt; UIImagePickerViewController has the ability to crop and resize a selected image, but PHPickerViewController does not (unless it was added in iOS 16 and I missed it?). Since picking photos using UIImagePickerViewController is being deprecated, what is the correct way to now do this? Would we need a custom overlay?",
      "ts": "1654809300.917829",
      "thread_ts": "1654809300.917829",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 12,
      "latest_reply": "1654894201.952909",
      "reactions": [
        {
          "name": "point_up",
          "count": 1,
          "users": [
            "U03J221UN9G"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "cXZ",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03K7KBHSV6"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"UIImagePickerViewController has the ability to crop and resize a selected image, but PHPickerViewController does not (unless it was added in iOS 16 and I missed it?). Since picking photos using UIImagePickerViewController is being deprecated, what is the correct way to now do this? Would we need a custom overlay?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "5bef0c90-045d-41d4-a577-b98105ad1acc",
          "type": "message",
          "user": "U03JMC610GH",
          "text": "`allowsEditing` to enable crop is indeed only available on `UIImagePickerController`. If you want to support any kind of editing, including crop, you'd need to combine `PHPicker` + your own UI.",
          "ts": "1654809336.311359",
          "thread_ts": "1654809300.917829",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "vkFp",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "allowsEditing",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " to enable crop is indeed only available on "
                    },
                    {
                      "type": "text",
                      "text": "UIImagePickerController",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": ". If you want to support any kind of editing, including crop, you'd need to combine "
                    },
                    {
                      "type": "text",
                      "text": "PHPicker",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " + your own UI."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "4858b65f-ae17-4e79-aab2-ce9d61e250e9",
          "type": "message",
          "user": "U03K7KBHSV6",
          "text": "Ah I see, is there a reason why it wasn't included in PHPickerViewController?",
          "ts": "1654809396.389779",
          "thread_ts": "1654809300.917829",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "kB84e",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Ah I see, is there a reason why it wasn't included in PHPickerViewController?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "27c08fa2-aebf-4ad8-9400-156b75a3db9e",
          "type": "message",
          "user": "U03JMC610GH",
          "text": "I think part of it is the on-demand nature of the file provider; also each app can have its own requirements on crop parameters (aspect ratios, minimum sizes, etc.)",
          "ts": "1654809577.936079",
          "thread_ts": "1654809300.917829",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "=b5",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I think part of it is the on-demand nature of the file provider; also each app can have its own requirements on crop parameters (aspect ratios, minimum sizes, etc.)"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "2df011f7-2042-4024-bb27-ce9d7dc853af",
          "type": "message",
          "user": "U03K7KBHSV6",
          "text": "That makes sense, it does appear to only allow a square crop. Thank you for your answer!",
          "ts": "1654809622.490039",
          "thread_ts": "1654809300.917829",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "GXN",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "That makes sense, it does appear to only allow a square crop. Thank you for your answer!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "6be59cf2-f71c-4ecd-9868-a2e69e62d7ee",
          "type": "message",
          "user": "U03JYF8GT7A",
          "text": "Yes as Greg mentioned, PHPickerViewController allows you to fetch asset data after the picker is dismissed. You can implement your own edit/crop UI separately based on your own use case.",
          "ts": "1654809623.464589",
          "thread_ts": "1654809300.917829",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Rz4z",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Yes as Greg mentioned, PHPickerViewController allows you to fetch asset data after the picker is dismissed. You can implement your own edit/crop UI separately based on your own use case."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "b3359ad0-648a-45c5-b262-78c65d1ef193",
          "type": "message",
          "user": "U03K7KBHSV6",
          "text": "Thank you!",
          "ts": "1654809663.540799",
          "thread_ts": "1654809300.917829",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "raised_hands",
              "count": 1,
              "users": [
                "U03JMC610GH"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "EwcH",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thank you!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "75ef5a1f-7209-4fa1-bb7f-02bad05b28a6",
          "type": "message",
          "user": "U03J221UN9G",
          "text": "Really wish there was a default `allowsEditing` capability in PHPicker!",
          "ts": "1654879363.206839",
          "thread_ts": "1654809300.917829",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "L8e",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Really wish there was a default "
                    },
                    {
                      "type": "text",
                      "text": "allowsEditing",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " capability in PHPicker!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "d9a42f56-5430-42e7-b484-e4b3526fa9ef",
          "type": "message",
          "user": "U03JYF8GT7A",
          "text": "Please file a feedback request!",
          "ts": "1654880082.440429",
          "thread_ts": "1654809300.917829",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "tbKzH",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Please file a feedback request!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "ec7c7d6a-898b-47cb-ab65-053e185f3fe2",
          "type": "message",
          "user": "U03J221UN9G",
          "text": "\u003c@U03JYF8GT7A\u003e Will do. The default square crop is perfect for things like quickly adjusting profile pics in profile setup flows.",
          "ts": "1654880732.768229",
          "thread_ts": "1654809300.917829",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "x7hv",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "user",
                      "user_id": "U03JYF8GT7A"
                    },
                    {
                      "type": "text",
                      "text": " Will do. The default square crop is perfect for things like quickly adjusting profile pics in profile setup flows."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "2abc57e9-b75b-4a38-b7ea-3805f63601bd",
          "type": "message",
          "user": "U03JMC610GH",
          "text": "Bonus tip for any feedback is to also include some use cases / reasons / user impact as well. It really helps to include the context of your app in particular!",
          "ts": "1654882260.180279",
          "thread_ts": "1654809300.917829",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "UH+0",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Bonus tip for any feedback is to also include some use cases / reasons / user impact as well. It really helps to include the context of your app in particular!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "1f37c767-5fa2-4866-83bc-eb3568c0cb50",
          "type": "message",
          "user": "U03J221UN9G",
          "text": "Thanks Greg! Any difference if I submit it in my “Personal” account vs my LLC which is a member of the Apple Developer Program?",
          "ts": "1654884412.823149",
          "thread_ts": "1654809300.917829",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "PDE",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks Greg! Any difference if I submit it in my “Personal” account vs my LLC which is a member of the Apple Developer Program?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "15a0536c-43b5-4adf-ae50-6b68f0377e84",
          "type": "message",
          "user": "U03JMC610GH",
          "text": "I don't think it matters, but maybe the developer program one would be more appropriate if it's dev/SDK kind of feedback.",
          "ts": "1654894201.952909",
          "thread_ts": "1654809300.917829",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "878YB",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I don't think it matters, but maybe the developer program one would be more appropriate if it's dev/SDK kind of feedback."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03K0BHRMNC\u003e asked\n\u0026gt; Is it possible yet to read (and write) the \"caption\" metadata property of a user's photo from their library?",
      "ts": "1654809416.170539",
      "thread_ts": "1654809416.170539",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 5,
      "latest_reply": "1654810581.801559",
      "reactions": [
        {
          "name": "heavy_plus_sign",
          "count": 2,
          "users": [
            "U03HMCT187R",
            "U03HVE4BEBY"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "Hzb",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03K0BHRMNC"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Is it possible yet to read (and write) the \\\"caption\\\" metadata property of a user's photo from their library?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "9e70871f-84ff-41ff-b1a2-3ef72883bff4",
          "type": "message",
          "user": "U03HBH4EAR4",
          "text": "That is not possible today. I encourage you to file a Feedback with your specific use case in mind. Or if you’ve already filed one, please paste it here!",
          "ts": "1654809466.718239",
          "thread_ts": "1654809416.170539",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "k+l",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "That is not possible today. I encourage you to file a Feedback with your specific use case in mind. Or if you’ve already filed one, please paste it here!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "491f9a81-b70a-4ff0-af8e-e46ecb1dd29f",
          "type": "message",
          "user": "U03K0BHRMNC",
          "text": "I havent filed a feedback for this, but I will do. Thanks for the suggestion :slightly_smiling_face:",
          "ts": "1654809506.335919",
          "thread_ts": "1654809416.170539",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "gratitude-thank-you",
              "count": 2,
              "users": [
                "U03HBH4EAR4",
                "U03HU4PCSET"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "DlUoa",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I havent filed a feedback for this, but I will do. Thanks for the suggestion "
                    },
                    {
                      "type": "emoji",
                      "name": "slightly_smiling_face",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "fa7ff691-b153-48b5-9b6b-3baf9245c2b7",
          "type": "message",
          "user": "U03HMCT187R",
          "text": "I did! :raised_hand: Def have a use case for this too. FB8244665",
          "ts": "1654810010.395329",
          "thread_ts": "1654809416.170539",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "heart",
              "count": 2,
              "users": [
                "U03K0BHRMNC",
                "U03HVE4BEBY"
              ]
            },
            {
              "name": "gratitude-thank-you",
              "count": 2,
              "users": [
                "U03HBH4EAR4",
                "U03HU4PCSET"
              ]
            },
            {
              "name": "mag",
              "count": 1,
              "users": [
                "U03JMC610GH"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Uck",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I did! "
                    },
                    {
                      "type": "emoji",
                      "name": "raised_hand",
                      "skin_tone": 0
                    },
                    {
                      "type": "text",
                      "text": " Def have a use case for this too. FB8244665"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "f63763b1-5158-4f0d-a48b-fa6b1560ea6f",
          "type": "message",
          "user": "U03HU4PCSET",
          "text": "For what it's worth: If you are using the picker API and get an exported image, and that image had a caption, it should be in the IPTC metadata within the file",
          "ts": "1654810500.745309",
          "thread_ts": "1654809416.170539",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "raised_hands",
              "count": 1,
              "users": [
                "U03J22YQMK4"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "e38",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "For what it's worth: If you are using the picker API and get an exported image, and that image had a caption, it should be in the IPTC metadata within the file"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "72dd9831-e645-45bd-814a-78e93ad6aded",
          "type": "message",
          "user": "U03HMCT187R",
          "text": "Ooo it’s in the metadata alongside EXIF etc. I haven’t noticed IPTC before I’ll have to investigate. That would solve my use case fr! Thank you",
          "ts": "1654810581.801559",
          "thread_ts": "1654809416.170539",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "raised_hands",
              "count": 2,
              "users": [
                "U03JMC610GH",
                "U03JYF8GT7A"
              ]
            },
            {
              "name": "raised_hands::skin-tone-4",
              "count": 1,
              "users": [
                "U03HU4PCSET"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "9Kuxr",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Ooo it’s in the metadata alongside EXIF etc. I haven’t noticed IPTC before I’ll have to investigate. That would solve my use case fr! Thank you"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03J4CQQR9A\u003e asked\n\u0026gt; I am working on an app to edit the metadata of photos in the iCloud Library, using Image I/O. After editing a RAW photo, it is no longer possible to edit that photo as a RAW image on any RAW photo editor (Darkroom, for example). My guess is that when we have to save the image as JPEG for the PHAssetChangeRequest, editors only see the PHAsset as JPEG instead of raw. Is there a way to edit a RAW photo’s metadata but not remove the ability to edit it as RAW afterwards?",
      "ts": "1654809650.382719",
      "thread_ts": "1654809650.382719",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 7,
      "latest_reply": "1654811479.513509",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "I2o",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03J4CQQR9A"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"I am working on an app to edit the metadata of photos in the iCloud Library, using Image I\\/O. After editing a RAW photo, it is no longer possible to edit that photo as a RAW image on any RAW photo editor (Darkroom, for example). My guess is that when we have to save the image as JPEG for the PHAssetChangeRequest, editors only see the PHAsset as JPEG instead of raw. Is there a way to edit a RAW photo\\u2019s metadata but not remove the ability to edit it as RAW afterwards?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "6a025a46-7c04-4813-8e20-855a1e4f8eab",
          "type": "message",
          "user": "U03HU4PD371",
          "text": "If your goal is primarily to be able to edit the metadata - then your assessment is correct, any adjustment must be submitted in the form of a JPEG, which would produce a different file.\n\nThe only way I could think of to change attributes of the original asset - would be to create a new asset with the updated original data, and delete the old one.\n\nAdditionally, feel free to submit a feedback request with some more context and what your requirements are.",
          "ts": "1654809899.140279",
          "thread_ts": "1654809650.382719",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "xp+t",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "If your goal is primarily to be able to edit the metadata - then your assessment is correct, any adjustment must be submitted in the form of a JPEG, which would produce a different file.\n\nThe only way I could think of to change attributes of the original asset - would be to create a new asset with the updated original data, and delete the old one.\n\nAdditionally, feel free to submit a feedback request with some more context and what your requirements are."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "f7638423-6049-4b1a-a1e9-8c8163e26b57",
          "type": "message",
          "user": "U03HU4PCSET",
          "text": "It'd be useful to know which specific metadata (if any) you're thinking about writing, too!",
          "ts": "1654810224.367159",
          "thread_ts": "1654809650.382719",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "XpD",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "It'd be useful to know which specific metadata (if any) you're thinking about writing, too!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "73c31b51-dd91-4e1b-9dca-4a7ece55f2b4",
          "type": "message",
          "user": "U03J4CQQR9A",
          "text": "Yep, that is the only workaround I could think. I will try it, see how it goes but if I have any limitations I will file a feedback.",
          "ts": "1654810299.547059",
          "thread_ts": "1654809650.382719",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "eZoQ2",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Yep, that is the only workaround I could think. I will try it, see how it goes but if I have any limitations I will file a feedback."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "195dde24-c433-4863-99d3-1ae113b70965",
          "type": "message",
          "user": "U03J4CQQR9A",
          "text": "\u003c@U03HU4PCSET\u003e I allow users to edit a subset of all metadata tags, but this specific scenario affects especially pro photographers who want to mainly edit IPTC tags. If their workflow is edit metadata first and then edit their RAW photo, then is when we get into trouble because they can’t edit the photo as RAW no more.",
          "ts": "1654810566.289859",
          "thread_ts": "1654809650.382719",
          "edited": {
            "user": "U03J4CQQR9A",
            "ts": "1654810726.000000"
          },
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Xm2VI",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "user",
                      "user_id": "U03HU4PCSET"
                    },
                    {
                      "type": "text",
                      "text": " I allow users to edit a subset of all metadata tags, but this specific scenario affects especially pro photographers who want to mainly edit IPTC tags. If their workflow is edit metadata first and then edit their RAW photo, then is when we get into trouble because they can’t edit the photo as RAW no more."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "e63b7583-2815-464a-afd1-3ae4da9edfb8",
          "type": "message",
          "user": "U03J4CQQR9A",
          "text": "I wish we weren’t limited to only writing JPEG images to PHContentEditingOutput’s renderedContentURL",
          "ts": "1654810619.046509",
          "thread_ts": "1654809650.382719",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "YOJ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I wish we weren’t limited to only writing JPEG images to PHContentEditingOutput’s renderedContentURL"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "9be4c536-4a6d-41b9-ab08-2b35a6e9df27",
          "type": "message",
          "user": "U03HU4PCSET",
          "text": "Those are great reasons, thank you \u003c@U03J4CQQR9A\u003e! Adding that context when submitting a feedback request would be really great. The Photos app treats assets as \"digital negatives\" and doesn't modify them in place (an edited image is an additional resource, for example). So I think right now, \u003c@U03HU4PD371\u003e's suggestion of adding a new asset (and deleting the old one) would be the way to do this (though it's likely not a great user experience).\n\nYou may want to talk in the Core Graphics lab tomorrow to the ImageIO team, to see if writing specific RAW file formats are supported",
          "ts": "1654810971.973299",
          "thread_ts": "1654809650.382719",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "W/w+2",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Those are great reasons, thank you "
                    },
                    {
                      "type": "user",
                      "user_id": "U03J4CQQR9A"
                    },
                    {
                      "type": "text",
                      "text": "! Adding that context when submitting a feedback request would be really great. The Photos app treats assets as \"digital negatives\" and doesn't modify them in place (an edited image is an additional resource, for example). So I think right now, "
                    },
                    {
                      "type": "user",
                      "user_id": "U03HU4PD371"
                    },
                    {
                      "type": "text",
                      "text": "'s suggestion of adding a new asset (and deleting the old one) would be the way to do this (though it's likely not a great user experience).\n\nYou may want to talk in the Core Graphics lab tomorrow to the ImageIO team, to see if writing specific RAW file formats are supported"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "4d686904-d78f-45cd-831b-9694128402c1",
          "type": "message",
          "user": "U03J4CQQR9A",
          "text": "Sadly I can’t make it to tomorrow’s lab. If I have trouble in the future writing RAW files would a Technical Support Incident (TSI) be an appropriate channel to get help?",
          "ts": "1654811479.513509",
          "thread_ts": "1654809650.382719",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Y9+vW",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Sadly I can’t make it to tomorrow’s lab. If I have trouble in the future writing RAW files would a Technical Support Incident (TSI) be an appropriate channel to get help?"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03HMDFMVNK\u003e asked\n\u0026gt; Does the new ability to \"lock\" the Hidden and Recently Deleted albums have any effect on being able to change the hidden state of a photo or delete a photo using PhotoKit?",
      "ts": "1654809790.232829",
      "thread_ts": "1654809790.232829",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 4,
      "latest_reply": "1654809909.236429",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "6I1cS",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03HMDFMVNK"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Does the new ability to \\\"lock\\\" the Hidden and Recently Deleted albums have any effect on being able to change the hidden state of a photo or delete a photo using PhotoKit?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "db1da129-2bce-4800-a206-0110042b524b",
          "type": "message",
          "user": "U03HBH4EAR4",
          "text": "Your app will still be able to hide photos however it won’t be able to fetch the hidden photos back (if the user has chosen to keep the setting on which requires authentication for the hidden and recently deleted albums). Your app will still be able to attempt to delete photos and the user will be prompted to accept the deletion like in previous releases.",
          "ts": "1654809795.253289",
          "thread_ts": "1654809790.232829",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "jSpn",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Your app will still be able to hide photos however it won’t be able to fetch the hidden photos back (if the user has chosen to keep the setting on which requires authentication for the hidden and recently deleted albums). Your app will still be able to attempt to delete photos and the user will be prompted to accept the deletion like in previous releases."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "0abbcfe7-4171-44d3-83c8-e9ed91e0e2f9",
          "type": "message",
          "user": "U03HBH4EAR4",
          "text": "Elaborating a bit, this means your app won’t be able to _unhide_ photos as it doesn’t have access to hidden photos.",
          "ts": "1654809846.603949",
          "thread_ts": "1654809790.232829",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "xg0H",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Elaborating a bit, this means your app won’t be able to "
                    },
                    {
                      "type": "text",
                      "text": "unhide",
                      "style": {
                        "italic": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " photos as it doesn’t have access to hidden photos."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "cbee8586-2023-4f14-b7f1-8df79ce13d3d",
          "type": "message",
          "user": "U03HMDFMVNK",
          "text": "I see, so if the hidden album is locked, then those hidden assets just won’t be included in any fetch requests that would normally return them?",
          "ts": "1654809901.258359",
          "thread_ts": "1654809790.232829",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "+1::skin-tone-4",
              "count": 1,
              "users": [
                "U03HU4PCSET"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "j7S5",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I see, so if the hidden album is locked, then those hidden assets just won’t be included in any fetch requests that would normally return them?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "acfe1cba-db9c-43a3-b348-b3b9d22ac130",
          "type": "message",
          "user": "U03HBH4EAR4",
          "text": "correct",
          "ts": "1654809909.236429",
          "thread_ts": "1654809790.232829",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U03HMDFMVNK"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "qXXO",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "correct"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03K0BHRMNC\u003e asked\n\u0026gt; Im building an app that tries to recognise and identify people in a photo. I believe the current Image framework is able to identify faces with great success, but has there been any progress in the framework that can help us \"recognize\" faces? (obvious use case here is to find and associate people to an identified face in a photo)",
      "ts": "1654810034.687209",
      "thread_ts": "1654810034.687209",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 4,
      "latest_reply": "1654810601.550439",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "6v7M",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03K0BHRMNC"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Im building an app that tries to recognise and identify people in a photo. I believe the current Image framework is able to identify faces with great success, but has there been any progress in the framework that can help us \\\"recognize\\\" faces? (obvious use case here is to find and associate people to an identified face in a photo)\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "de1dddf5-a451-4598-bdd4-6d17c8bda86e",
          "type": "message",
          "user": "U03HBH4EAR4",
          "text": "If by “the framework” you’re referring to PhotoKit, there isn’t any mechanism to try and associate images with the People that are tagged / named within the Photos app / Photo Library. I’m not familiar enough with the Vision framework to know if there are clustering APIs which aid in you doing the face recognition all within your app though. Is that more what you were getting at?",
          "ts": "1654810156.088639",
          "thread_ts": "1654810034.687209",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "VFpS",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "If by “the framework” you’re referring to PhotoKit, there isn’t any mechanism to try and associate images with the People that are tagged / named within the Photos app / Photo Library. I’m not familiar enough with the Vision framework to know if there are clustering APIs which aid in you doing the face recognition all within your app though. Is that more what you were getting at?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "d17819ff-c250-4270-9905-f487be43733b",
          "type": "message",
          "user": "U03K0BHRMNC",
          "text": "yeah I think possibly what Im needing to do is extract identified faces then build some ML model to further recognise familiar faces. Probably then the wrong channel for this. :slightly_smiling_face: thanks!",
          "ts": "1654810280.770499",
          "thread_ts": "1654810034.687209",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "6Xz",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "yeah I think possibly what Im needing to do is extract identified faces then build some ML model to further recognise familiar faces. Probably then the wrong channel for this. "
                    },
                    {
                      "type": "emoji",
                      "name": "slightly_smiling_face",
                      "skin_tone": 0
                    },
                    {
                      "type": "text",
                      "text": " thanks!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "a09bcd98-4d57-4c96-94b8-8856c519b1b8",
          "type": "message",
          "user": "U03DJTBMHFF",
          "text": "\u003c@U03K0BHRMNC\u003e Are you in the machine-learning-lounge as well? There is an active Q\u0026amp;A going on with the Vision team right now. We probably have the right experts there that can give you suggestions of what to pursue.",
          "ts": "1654810477.186679",
          "thread_ts": "1654810034.687209",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "anXv",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "user",
                      "user_id": "U03K0BHRMNC"
                    },
                    {
                      "type": "text",
                      "text": " Are you in the machine-learning-lounge as well? There is an active Q\u0026A going on with the Vision team right now. We probably have the right experts there that can give you suggestions of what to pursue."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "e86ede22-1ec5-4d32-887a-d5a8340c55c1",
          "type": "message",
          "user": "U03K0BHRMNC",
          "text": "i will hop over there... thanks!",
          "ts": "1654810601.550439",
          "thread_ts": "1654810034.687209",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "8Sev",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "i will hop over there... thanks!"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03K0BHRMNC\u003e asked\n\u0026gt; Hey! So Im currently needing to get the file extension of a PHAsset from the user's photo library. At the moment the way Ive been directed to follow is to request `requestContentEditingInput` of the asset, and then get the extension from the `fullSizeImageURL` value. But im currently occasionally getting a `[ImageManager] Media resource request failed to return valid data or url with error: Error` with this request and I cant understand why.  \n\u0026gt; so maybe 2 questions... \n\u0026gt; 1) is this the ideal/suggested way to understand if an asset is a PNG/JPEG/HEIC, and \n\u0026gt; 2) what would possibly be the reason why I would get this error sometimes? And how do I \"recover\" from it so I can get the extension of the file reliably?\n\u0026gt; Thanks!",
      "ts": "1654810219.427859",
      "thread_ts": "1654810219.427859",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 4,
      "latest_reply": "1654810570.989369",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "LUeY",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03K0BHRMNC"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Hey! So Im currently needing to get the file extension of a PHAsset from the user's photo library. At the moment the way Ive been directed to follow is to request `requestContentEditingInput` of the asset, and then get the extension from the `fullSizeImageURL` value. But im currently occasionally getting a `[ImageManager] Media resource request failed to return valid data or url with error: Error` with this request and I cant understand why.  \\nso maybe 2 questions... \\n1) is this the ideal\\/suggested way to understand if an asset is a PNG\\/JPEG\\/HEIC, and \\n2) what would possibly be the reason why I would get this error sometimes? And how do I \\\"recover\\\" from it so I can get the extension of the file reliably?\\nThanks!\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "09d3c893-9de7-4780-80d0-c3a57f1ee26f",
          "type": "message",
          "user": "U03K0BHRMNC",
          "text": "to be a little clearer, the error code i got with this was `code=3164`. Ive seen some suggestions that its possibly because the asset is in iCloud, but Im fetching the asset first and then calling this request. So it seems hard to think that its iCloud related.. but maybe it is?",
          "ts": "1654810355.036259",
          "thread_ts": "1654810219.427859",
          "edited": {
            "user": "U03K0BHRMNC",
            "ts": "1654810373.000000"
          },
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "5kl",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "to be a little clearer, the error code i got with this was "
                    },
                    {
                      "type": "text",
                      "text": "code=3164",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": ". Ive seen some suggestions that its possibly because the asset is in iCloud, but Im fetching the asset first and then calling this request. So it seems hard to think that its iCloud related.. but maybe it is?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "b374a1fb-72ca-47c7-9fd9-16ea2a4bb25b",
          "type": "message",
          "user": "U03HU4PD371",
          "text": "The best way to determine the kind of file for an original image would be to use PHAssetResourceManager -- ie, get the list of resources for an asset, then isolate the one with PHAssetResourceTypePhoto, and call: -[PHAssetResource uniformTypeIdentifier]",
          "ts": "1654810379.402409",
          "thread_ts": "1654810219.427859",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "/yPoY",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "The best way to determine the kind of file for an original image would be to use PHAssetResourceManager -- ie, get the list of resources for an asset, then isolate the one with PHAssetResourceTypePhoto, and call: -[PHAssetResource uniformTypeIdentifier]"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "e7b7bf1c-ddb3-4157-9656-aaa51d3e1082",
          "type": "message",
          "user": "U03HU4PD371",
          "text": "and the above method doesn't require use of the network",
          "ts": "1654810431.565819",
          "thread_ts": "1654810219.427859",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "9G9",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "and the above method doesn't require use of the network"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "104a4383-ff3f-4750-a610-75771afe319b",
          "type": "message",
          "user": "U03K0BHRMNC",
          "text": "ah ok, that seems helpful and surprised I missed it earlier.. Thanks! :blush:",
          "ts": "1654810570.989369",
          "thread_ts": "1654810219.427859",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "100",
              "count": 1,
              "users": [
                "U03HU4PCSET"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "ja6g",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "ah ok, that seems helpful and surprised I missed it earlier.. Thanks! "
                    },
                    {
                      "type": "emoji",
                      "name": "blush",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03HMCT187R\u003e asked\n\u0026gt; Is there a way to determine if your app has edited a given PHAsset? For example if I edit a photo in my app and then edit it in a different app, is there a way to know that my app has edited it? I'm wondering because I'd like to build a filter to only show photos my app has edited (as opposed to all edited photos).",
      "ts": "1654810673.885689",
      "thread_ts": "1654810673.885689",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 20,
      "latest_reply": "1654814182.135469",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "Q98tR",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03HMCT187R"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Is there a way to determine if your app has edited a given PHAsset? For example if I edit a photo in my app and then edit it in a different app, is there a way to know that my app has edited it? I'm wondering because I'd like to build a filter to only show photos my app has edited (as opposed to all edited photos).\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "c8ff291a-792f-45a6-a3b5-eaefeb99b5ed",
          "type": "message",
          "user": "U03HU4PD371",
          "text": "Given a PHAsset, if you wanted to know if your app owns the top level adjustment, then you might inspect the data in the `PHAssetResourceTypeAdjustmentData` resource.\n\nIf another app has placed an adjustment on top of yours, you could tell by also inspecting data from `PHAssetResourceTypeAdjustmentBasePhoto` .",
          "ts": "1654810794.329379",
          "thread_ts": "1654810673.885689",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "=/pEi",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Given a PHAsset, if you wanted to know if your app owns the top level adjustment, then you might inspect the data in the "
                    },
                    {
                      "type": "text",
                      "text": "PHAssetResourceTypeAdjustmentData",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " resource.\n\nIf another app has placed an adjustment on top of yours, you could tell by also inspecting data from "
                    },
                    {
                      "type": "text",
                      "text": "PHAssetResourceTypeAdjustmentBasePhoto",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " ."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "841cd5a3-270a-4131-880e-36c3985960be",
          "type": "message",
          "user": "U03HU4PD371",
          "text": "You might inspect the value from `-[PHAdjustmentData formatIdentifier]` and see if it matches your app's bundle",
          "ts": "1654810920.110939",
          "thread_ts": "1654810673.885689",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "YgtS8",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "You might inspect the value from "
                    },
                    {
                      "type": "text",
                      "text": "-[PHAdjustmentData formatIdentifier]",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " and see if it matches your app's bundle"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "0719d663-bbbd-481d-ba7d-18ae718299b5",
          "type": "message",
          "user": "U03K5JE9HG8",
          "text": "Another approach would be to keep track of edited assets' `PHCloudIdentifier` on the app side.",
          "ts": "1654811014.638419",
          "thread_ts": "1654810673.885689",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "4sRfs",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Another approach would be to keep track of edited assets' "
                    },
                    {
                      "type": "text",
                      "text": "PHCloudIdentifier",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " on the app side."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "2f6c9423-331d-4d8b-b41d-299ac1789907",
          "type": "message",
          "user": "U03HMCT187R",
          "text": "So `PHAsset.adjustmentFormatIdentifier` does tell you the id of the last applied edit, though you can edit it in another app and then at that point you can’t detect your app has edited it. Unless `PHAssetResourceTypeAdjustmentBasePhoto` does this but I don’t understand how :thinking_face: as that provides an unaltered version of its photo asset for use in for use in reconstructing recent edits.",
          "ts": "1654811028.117049",
          "thread_ts": "1654810673.885689",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "u0BBc",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "So "
                    },
                    {
                      "type": "text",
                      "text": "PHAsset.adjustmentFormatIdentifier",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " does tell you the id of the last applied edit, though you can edit it in another app and then at that point you can’t detect your app has edited it. Unless "
                    },
                    {
                      "type": "text",
                      "text": "PHAssetResourceTypeAdjustmentBasePhoto",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " does this but I don’t understand how "
                    },
                    {
                      "type": "emoji",
                      "name": "thinking_face",
                      "skin_tone": 0
                    },
                    {
                      "type": "text",
                      "text": " as that provides an unaltered version of its photo asset for use in for use in reconstructing recent edits."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "49832e35-7730-4370-a098-b4ab6763bb92",
          "type": "message",
          "user": "U03K5JE9HG8",
          "text": "if you're looking for \"ever edited with my app\"",
          "ts": "1654811028.826129",
          "thread_ts": "1654810673.885689",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "ijEi/",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "if you're looking for \"ever edited with my app\""
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "d2feaf70-9778-4e3c-be8a-530ac3864d60",
          "type": "message",
          "user": "U03HMCT187R",
          "text": "That’s indeed what I want - filter out all photos except those that my app has edited even if they’ve edited it afterwards in another app :slightly_smiling_face: I understand `PHCloudIdentifier` is kind of a heavy operation to convert to local identifiers, likely much too inefficient to loop over the entire photo library (or even as they’re scrolling to show an “edited” indicator on the thumbnail).",
          "ts": "1654811147.414149",
          "thread_ts": "1654810673.885689",
          "edited": {
            "user": "U03HMCT187R",
            "ts": "1654811199.000000"
          },
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "FDK4",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "That’s indeed what I want - filter out all photos except those that my app has edited even if they’ve edited it afterwards in another app "
                    },
                    {
                      "type": "emoji",
                      "name": "slightly_smiling_face",
                      "skin_tone": 0
                    },
                    {
                      "type": "text",
                      "text": " I understand "
                    },
                    {
                      "type": "text",
                      "text": "PHCloudIdentifier",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " is kind of a heavy operation to convert to local identifiers, likely much too inefficient to loop over the entire photo library (or even as they’re scrolling to show an “edited” indicator on the thumbnail)."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "259d9e23-cffb-4e17-a00b-d0c3dec454a0",
          "type": "message",
          "user": "U03HU4PD371",
          "text": "If a resource is present with the type `PHAssetResourceTypeAdjustmentBasePhoto` , it is an indication that an adjustment is applied to an asset, on top of another adjustment which didn't originate from the Photos app.  Using requestDataForAssetResource... passing in the resource should give you back enough info to determine if the earlier adjustment is yours.",
          "ts": "1654811175.924599",
          "thread_ts": "1654810673.885689",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "UoNbk",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "If a resource is present with the type "
                    },
                    {
                      "type": "text",
                      "text": "PHAssetResourceTypeAdjustmentBasePhoto",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " , it is an indication that an adjustment is applied to an asset, on top of another adjustment which didn't originate from the Photos app.  Using requestDataForAssetResource... passing in the resource should give you back enough info to determine if the earlier adjustment is yours."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "fae9c7a7-ec18-48da-ab32-08494c8ab65a",
          "type": "message",
          "user": "U03HU4PD371",
          "text": "'Ever' edited with your app might require additional state -- as once as user reverts all adjustments, you would no longer be able to depend on adjustment data to answer that question.",
          "ts": "1654811212.410239",
          "thread_ts": "1654810673.885689",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "weUfN",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "'Ever' edited with your app might require additional state -- as once as user reverts all adjustments, you would no longer be able to depend on adjustment data to answer that question."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "63dfb4ff-793f-492a-87f9-43dad2a40dc8",
          "type": "message",
          "user": "U03HMCT187R",
          "text": "Ah yah, sorry “ever edited” is not quite desired, just that there is an adjustment to that asset that my app performed. If they wipe out all edits, I don’t want to indicate my app has edited it.",
          "ts": "1654811267.675639",
          "thread_ts": "1654810673.885689",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "qN0Wt",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Ah yah, sorry “ever edited” is not quite desired, just that there is an adjustment to that asset that my app performed. If they wipe out all edits, I don’t want to indicate my app has edited it."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "59648e92-524e-4f6c-8c59-70454c84ac73",
          "type": "message",
          "user": "U03HMCT187R",
          "text": "Gotcha, yah that would do the trick if I needed to know that per photo asynchronously. For this use case it’d need to be synchronous and efficient.",
          "ts": "1654811371.574179",
          "thread_ts": "1654810673.885689",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "UKXd",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Gotcha, yah that would do the trick if I needed to know that per photo asynchronously. For this use case it’d need to be synchronous and efficient."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "2dae9c7e-30d3-49f5-9bb2-984c088554f9",
          "type": "message",
          "user": "U03HU4PD371",
          "text": "I believe this data should be on disk already -- (in most cases does not require a download from network), it still might work for your use case, depending on how many assets you need to run this check against.",
          "ts": "1654811459.725139",
          "thread_ts": "1654810673.885689",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "m=LFh",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I believe this data should be on disk already -- (in most cases does not require a download from network), it still might work for your use case, depending on how many assets you need to run this check against."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "30cc0e88-7fc0-44d0-b0a5-70a996bb14b4",
          "type": "message",
          "user": "U03HU4PD371",
          "text": "(It probably is not efficient enough to run in a loop against a large collection of assets - but perhaps efficient enough to run once for all assets, then run incrementally based on changes to the library)",
          "ts": "1654811504.686829",
          "thread_ts": "1654810673.885689",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Ow0e",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "(It probably is not efficient enough to run in a loop against a large collection of assets - but perhaps efficient enough to run once for all assets, then run incrementally based on changes to the library)"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "f6473ec9-8119-47e3-8ba6-e0dbe3b56d4d",
          "type": "message",
          "user": "U03HMCT187R",
          "text": "Gotcha thanks! My gut is that wouldn’t quite accomplish what I need. I previously filed FB5415719 about this but doesn’t include a lot of details for what I intend to use this for which I imagine would be helpful. Would yall prefer a new bug report or I can send a reply on this one to provide additional deets? :slightly_smiling_face:",
          "ts": "1654811632.230789",
          "thread_ts": "1654810673.885689",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "PfsXb",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Gotcha thanks! My gut is that wouldn’t quite accomplish what I need. I previously filed FB5415719 about this but doesn’t include a lot of details for what I intend to use this for which I imagine would be helpful. Would yall prefer a new bug report or I can send a reply on this one to provide additional deets? "
                    },
                    {
                      "type": "emoji",
                      "name": "slightly_smiling_face",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "ba53f816-cd78-4238-ba4d-62c4cab74da4",
          "type": "message",
          "user": "U03K5JE9HG8",
          "text": "\u003c@U03HMCT187R\u003e to make it efficient for scrolling, you can convert the PHCloudIdentifiers of edited photos to local identifiers, and fetch them all with `+[PHAsset fetchAssetsWithLocalIdentifiers:options:]` and keep that `fetchResult` around\n\nthen in the cell, you can check if that asset has been edited via `[fetchResult containsObject:assetInCell]` , behind the scenes `containsObject` is very efficient and fast",
          "ts": "1654811767.902869",
          "thread_ts": "1654810673.885689",
          "edited": {
            "user": "U03K5JE9HG8",
            "ts": "1654811824.000000"
          },
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "o0q",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "user",
                      "user_id": "U03HMCT187R"
                    },
                    {
                      "type": "text",
                      "text": " to make it efficient for scrolling, you can convert the PHCloudIdentifiers of edited photos to local identifiers, and fetch them all with "
                    },
                    {
                      "type": "text",
                      "text": "+[PHAsset fetchAssetsWithLocalIdentifiers:options:]",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " and keep that "
                    },
                    {
                      "type": "text",
                      "text": "fetchResult",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " around\n\nthen in the cell, you can check if that asset has been edited via "
                    },
                    {
                      "type": "text",
                      "text": "[fetchResult containsObject:assetInCell]",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " , behind the scenes "
                    },
                    {
                      "type": "text",
                      "text": "containsObject",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " is very efficient and fast"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "0e370f85-a85f-4f64-af1c-db7389e35671",
          "type": "message",
          "user": "U03HU4PD371",
          "text": "You can reply here with comments and I can add them to the FB.  I think providing more context on how many assets you'd like to run the check on, the use case in the app, etc. would be helpful.",
          "ts": "1654811780.008329",
          "thread_ts": "1654810673.885689",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "tMfdI",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "You can reply here with comments and I can add them to the FB.  I think providing more context on how many assets you'd like to run the check on, the use case in the app, etc. would be helpful."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "66a33b85-c8e0-4eaf-aaff-989fa0300bba",
          "type": "message",
          "user": "U03HMCT187R",
          "text": "Oh okay that approach makes sense! Though I can think of some drawbacks that doesn’t really work for my use case. When the user edits a photo I’d need to persist the cloud identifier for that asset, and sync that list of identifiers to all their devices, otherwise it wouldn’t know about the edited photos from different devices. I also support editing photos from inside the Photos app, so need to use App Groups to try to update that in a shared location (which I actually don’t think is possible because you don’t get a PHAsset). If they go revert a photo in the Photos app, now my app thinks that photo is edited by my app but it no longer is.",
          "ts": "1654811994.925869",
          "thread_ts": "1654810673.885689",
          "edited": {
            "user": "U03HMCT187R",
            "ts": "1654812066.000000"
          },
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "75j",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Oh okay that approach makes sense! Though I can think of some drawbacks that doesn’t really work for my use case. When the user edits a photo I’d need to persist the cloud identifier for that asset, and sync that list of identifiers to all their devices, otherwise it wouldn’t know about the edited photos from different devices. I also support editing photos from inside the Photos app, so need to use App Groups to try to update that in a shared location (which I actually don’t think is possible because you don’t get a PHAsset). If they go revert a photo in the Photos app, now my app thinks that photo is edited by my app but it no longer is."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "304d6398-bb4b-41f5-ab34-c019893d3666",
          "type": "message",
          "user": "U03HMCT187R",
          "text": "I’ll compose a message detailing my use case. Thank you so much!! :hugging_face:",
          "ts": "1654812019.476009",
          "thread_ts": "1654810673.885689",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "CW6c",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I’ll compose a message detailing my use case. Thank you so much!! "
                    },
                    {
                      "type": "emoji",
                      "name": "hugging_face",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "98bd3581-fe45-4871-8dc5-d747c511d434",
          "type": "message",
          "user": "U03HMCT187R",
          "text": "I have an app (DateStamper) that loads up the user’s photo library and allows them to scroll through a collection view of thumbnails, very similar to the Photos app. My app can edit photos as well (in the app and in a Photos editing extension). I would like to show a little “edited” indicator on each photo thumbnail if my app has edited that photo, more precisely, if that asset currently has adjustments that were performed by my app. To be super clear, if the user reverts edits to the photo, I do not want the “edited” indicator to show up anymore. I’d also potentially like to provide a way for them to filter the photos to only show photos that my app edited in the collection view. I believe this may not quite be possible to achieve for this use case.\n\nYou can determine if a PHAsset has been edited via `PHAssetResource.assetResources(for: asset).contains(where: { $0.type == .adjustmentData })` (and there’s new API in iOS 16 for `PHAsset.hasAdjustments`) but this means any app could have edited it. I want to know if my app edited it.\n\nYou can determine if your app edited a PHAsset by checking if `PHAsset.adjustmentFormatIdentifier` is one of your app’s identifiers but this only gives you the id of the last edit performed. For example if you edit a photo in my app, then edit it in the Photos app or another third party app, you can no longer detect that your app has edited the photo.\n\nYou could keep track of all the assets your app has edited via PHCloudIdentifier but this has some problems. The Photos editing extension doesn’t have access to that, photos can be edited on other devices, and photos can be reverted outside of your app. Trying to track this manually would not accurately represent photos that are currently edited by your app.\n\n You could use PHAssetResourceManager to fetch the adjustment data and examine it to see if there’s any created by your app, but this wouldn’t really work for this use case, it would only really work in async contexts likely limited to a single photo at a time as opposed to a filter applied to all photos in the library.",
          "ts": "1654812913.243009",
          "thread_ts": "1654810673.885689",
          "edited": {
            "user": "U03HMCT187R",
            "ts": "1654813164.000000"
          },
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U03HU4PD371"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "4Hee",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I have an app (DateStamper) that loads up the user’s photo library and allows them to scroll through a collection view of thumbnails, very similar to the Photos app. My app can edit photos as well (in the app and in a Photos editing extension). I would like to show a little “edited” indicator on each photo thumbnail if my app has edited that photo, more precisely, if that asset currently has adjustments that were performed by my app. To be super clear, if the user reverts edits to the photo, I do not want the “edited” indicator to show up anymore. I’d also potentially like to provide a way for them to filter the photos to only show photos that my app edited in the collection view. I believe this may not quite be possible to achieve for this use case.\n\nYou can determine if a PHAsset has been edited via "
                    },
                    {
                      "type": "text",
                      "text": "PHAssetResource.assetResources(for: asset).contains(where: { $0.type == .adjustmentData })",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " (and there’s new API in iOS 16 for "
                    },
                    {
                      "type": "text",
                      "text": "PHAsset.hasAdjustments",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": ") but this means any app could have edited it. I want to know if my app edited it.\n\nYou can determine if your app edited a PHAsset by checking if "
                    },
                    {
                      "type": "text",
                      "text": "PHAsset.adjustmentFormatIdentifier",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " is one of your app’s identifiers but this only gives you the id of the last edit performed. For example if you edit a photo in my app, then edit it in the Photos app or another third party app, you can no longer detect that your app has edited the photo.\n\nYou could keep track of all the assets your app has edited via PHCloudIdentifier but this has some problems. The Photos editing extension doesn’t have access to that, photos can be edited on other devices, and photos can be reverted outside of your app. Trying to track this manually would not accurately represent photos that are currently edited by your app.\n\n You could use PHAssetResourceManager to fetch the adjustment data and examine it to see if there’s any created by your app, but this wouldn’t really work for this use case, it would only really work in async contexts likely limited to a single photo at a time as opposed to a filter applied to all photos in the library."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "a1af060a-56c9-4a23-8ff3-e01587aa47ff",
          "type": "message",
          "user": "U03HMCT187R",
          "text": "Thanks \u003c@U03HU4PD371\u003e! When you add this to the feedback will that show up as additional info to me? I’d like to have that recorded for my future viewing too. I can go into follow-up with that as additional information if needed.",
          "ts": "1654814035.768429",
          "thread_ts": "1654810673.885689",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "dlq1j",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks "
                    },
                    {
                      "type": "user",
                      "user_id": "U03HU4PD371"
                    },
                    {
                      "type": "text",
                      "text": "! When you add this to the feedback will that show up as additional info to me? I’d like to have that recorded for my future viewing too. I can go into follow-up with that as additional information if needed."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "de32e901-f6ed-4ab7-aa99-eb97ee61e1c8",
          "type": "message",
          "user": "U03HU4PD371",
          "text": "I've added the discussion thread today to the radar, \u003c@U03DJTBMHFF\u003e would Jordan be able to see any additional info on his end?",
          "ts": "1654814182.135469",
          "thread_ts": "1654810673.885689",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "pray",
              "count": 1,
              "users": [
                "U03HMCT187R"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "hak",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I've added the discussion thread today to the radar, "
                    },
                    {
                      "type": "user",
                      "user_id": "U03DJTBMHFF"
                    },
                    {
                      "type": "text",
                      "text": " would Jordan be able to see any additional info on his end?"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03J4DD447N\u003e asked\n\u0026gt; Is there a way to use PHFetchOptions to find only JPEG+RAW pairs and then split them or discard one half of the pair?  ",
      "ts": "1654810781.185639",
      "thread_ts": "1654810781.185639",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 4,
      "latest_reply": "1654812985.460219",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "ZBI4g",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03J4DD447N"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Is there a way to use PHFetchOptions to find only JPEG+RAW pairs and then split them or discard one half of the pair?  \"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "038c381a-21ab-4e72-bc87-3c24aa24407d",
          "type": "message",
          "user": "U03J8LCLQN7",
          "text": "There isn't any API for fetch options to choose assets based on JPEG+RAW original resources.\nAnd there's no way to remove an original resource from an asset, you'd have to create a new asset from one or more of the resources.",
          "ts": "1654810961.269509",
          "thread_ts": "1654810781.185639",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "pt5o",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "There isn't any API for fetch options to choose assets based on JPEG+RAW original resources.\nAnd there's no way to remove an original resource from an asset, you'd have to create a new asset from one or more of the resources."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "c44a0e45-70ff-4844-b0c4-73bdadf01f43",
          "type": "message",
          "user": "U03J8LCLQN7",
          "text": "Please do file a feedback to request support for searching based on R+J resource if that would still be useful for you",
          "ts": "1654811148.172639",
          "thread_ts": "1654810781.185639",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U03J4DD447N"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "qWTy",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Please do file a feedback to request support for searching based on R+J resource if that would still be useful for you"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "1b80b824-b849-4ef2-ac98-3a8d8e8ba7ce",
          "type": "message",
          "user": "U03HBH4EAR4",
          "text": "In general, R+J Assets use the `PHAssetResourceTypeAlternatePhoto` resource to store one of the pairs. This tied with looking at the `uniformTypeIdentifier` would allow you to identify them. Unfortunately this will be slower than a fetchOption supported way.",
          "ts": "1654811445.025869",
          "thread_ts": "1654810781.185639",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U03J4DD447N"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "24q",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "In general, R+J Assets use the "
                    },
                    {
                      "type": "text",
                      "text": "PHAssetResourceTypeAlternatePhoto",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " resource to store one of the pairs. This tied with looking at the "
                    },
                    {
                      "type": "text",
                      "text": "uniformTypeIdentifier",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " would allow you to identify them. Unfortunately this will be slower than a fetchOption supported way."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "E5A4B686-682B-45A9-9E0F-7073A6D14E58",
          "type": "message",
          "user": "U03J4DD447N",
          "text": "Ok thanks! My use case is basically trying to clean up a library and discard unnecessary RAWs so I'll look into the uniformTypeIdentifier option. ",
          "ts": "1654812985.460219",
          "thread_ts": "1654810781.185639",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "HfIg",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Ok"
                    },
                    {
                      "type": "text",
                      "text": " thanks"
                    },
                    {
                      "type": "text",
                      "text": "!"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "My"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "use"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "case"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "is"
                    },
                    {
                      "type": "text",
                      "text": " basically "
                    },
                    {
                      "type": "text",
                      "text": "trying"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "to"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "clean"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "up"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "a"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "library"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "and"
                    },
                    {
                      "type": "text",
                      "text": " discard unnecessary "
                    },
                    {
                      "type": "text",
                      "text": "RAWs"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "so"
                    },
                    {
                      "type": "text",
                      "text": " I'll look into "
                    },
                    {
                      "type": "text",
                      "text": "the"
                    },
                    {
                      "type": "text",
                      "text": " uniform"
                    },
                    {
                      "type": "text",
                      "text": "TypeIdentifier"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "option. "
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03J20RJQ2X\u003e asked\n\u0026gt; In my testing, the modificationDate property of PHAsset gets updated every time a photo is viewed in the photos app (and other apps), even if no edits were made - it seems to behave more like a last viewed date. Is this intended behavior?",
      "ts": "1654811322.529529",
      "thread_ts": "1654811322.529529",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 2,
      "latest_reply": "1654811924.368029",
      "reactions": [
        {
          "name": "thinking_face",
          "count": 1,
          "users": [
            "U03HMCT187R"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "+Kp",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03J20RJQ2X"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"In my testing, the modificationDate property of PHAsset gets updated every time a photo is viewed in the photos app (and other apps), even if no edits were made - it seems to behave more like a last viewed date. Is this intended behavior?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "9c18b1e1-42b0-479d-9777-9670166079cd",
          "type": "message",
          "user": "U03J8LCLQN7",
          "text": "Yes this is expected, not specifically to reflect that the asset was viewed, but the `modificationDate` will reflect changes due to internal bookkeeping and processing. If you expected or would better be able to use a modification date property that reflects only changes to properties exposed on PHAsset I'd encourage you to submit a feedback request with your specific use case",
          "ts": "1654811588.241649",
          "thread_ts": "1654811322.529529",
          "edited": {
            "user": "U03J8LCLQN7",
            "ts": "1654811611.000000"
          },
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "white_check_mark",
              "count": 1,
              "users": [
                "U03J20RJQ2X"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "+SedZ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Yes this is expected, not specifically to reflect that the asset was viewed, but the "
                    },
                    {
                      "type": "text",
                      "text": "modificationDate",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " will reflect changes due to internal bookkeeping and processing. If you expected or would better be able to use a modification date property that reflects only changes to properties exposed on PHAsset I'd encourage you to submit a feedback request with your specific use case"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "4dd74f87-da16-474a-8fae-bf3b9c4b7c39",
          "type": "message",
          "user": "U03J20RJQ2X",
          "text": "Thanks for the clarification!",
          "ts": "1654811924.368029",
          "thread_ts": "1654811322.529529",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "Lxs",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks for the clarification!"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03HMDFMVNK\u003e asked\n\u0026gt; With iCloud shared photo library, it sounds like PhotoKit basically shows just one system library like normal, which might happen to have shared assets if the user has the shared library enabled. So would that mean for example, if they then disabled the shared library on their system, that things like change observers and the new change history API would get notified of a whole bunch of deletions, since the shared assets would no longer be appearing in the library?",
      "ts": "1654811382.492859",
      "thread_ts": "1654811382.492859",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 1,
      "latest_reply": "1654811409.113279",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "bnq/",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03HMDFMVNK"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"With iCloud shared photo library, it sounds like PhotoKit basically shows just one system library like normal, which might happen to have shared assets if the user has the shared library enabled. So would that mean for example, if they then disabled the shared library on their system, that things like change observers and the new change history API would get notified of a whole bunch of deletions, since the shared assets would no longer be appearing in the library?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "fb95c1dd-5325-44da-a6eb-7b57cf7292d5",
          "type": "message",
          "user": "U03J5R8VAPP",
          "text": "Basically yes you’re right. When a user disables Shared Library on their system, they get a choice of either keeping *all* shared assets or just the assets they’ve contributed into the Shared Library. Based on the choice they make here, there could be a bunch of deletions appearing in the local system library",
          "ts": "1654811409.113279",
          "thread_ts": "1654811382.492859",
          "edited": {
            "user": "U03J5R8VAPP",
            "ts": "1654811588.000000"
          },
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "eyi",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Basically yes you’re right. When a user disables Shared Library on their system, they get a choice of either keeping "
                    },
                    {
                      "type": "text",
                      "text": "all",
                      "style": {
                        "bold": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " shared assets or just the assets they’ve contributed into the Shared Library. Based on the choice they make here, there could be a bunch of deletions appearing in the local system library"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03J4BFE17W\u003e asked\n\u0026gt; Are CloudIdentifiers globally unique? Would two users ever have the same CloudIdentifier?",
      "ts": "1654811695.156109",
      "thread_ts": "1654811695.156109",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 3,
      "latest_reply": "1654812275.557839",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "rGXD",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03J4BFE17W"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Are CloudIdentifiers globally unique? Would two users ever have the same CloudIdentifier?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "b2427583-60f9-439e-a737-1991e5cc0d9f",
          "type": "message",
          "user": "U03J8LCLQN7",
          "text": "The short answer is YES - they are unique. The more complete answer reflects what you get back from the lookup APIs when looking up a local identifier based on a `PHCloudIdentifier` :\n1. In a set up where the user has enabled iCloud Photo Library the cloud identifier will be able to uniquely distinguish the asset and it's local identifier even when there are assets with the same image/video data\n2. In the case where the photo library is not associated with an iCloud account (in iCloud Photo Library), it is possible for a cloud identifier to resolve to more than one local asset when looking up the local identifier via `localIdentifierMappings(for:)` - in that case the local identifier mapping result will indicate the error code: `PHPhotosErrorMultipleIdentifiersFound`",
          "ts": "1654812179.574249",
          "thread_ts": "1654811695.156109",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "6zlrJ",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "The short answer is YES - they are unique. The more complete answer reflects what you get back from the lookup APIs when looking up a local identifier based on a "
                    },
                    {
                      "type": "text",
                      "text": "PHCloudIdentifier",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": " :\n"
                    }
                  ]
                },
                {
                  "Type": "rich_text_list",
                  "Raw": "{\"type\":\"rich_text_list\",\"elements\":[{\"type\":\"rich_text_section\",\"elements\":[{\"type\":\"text\",\"text\":\"In a set up where the user has enabled iCloud Photo Library the cloud identifier will be able to uniquely distinguish the asset and it's local identifier even when there are assets with the same image\\/video data\"}]},{\"type\":\"rich_text_section\",\"elements\":[{\"type\":\"text\",\"text\":\"In the case where the photo library is not associated with an iCloud account (in iCloud Photo Library), it is possible for a cloud identifier to resolve to more than one local asset when looking up the local identifier via \"},{\"type\":\"text\",\"text\":\"localIdentifierMappings(for:)\",\"style\":{\"code\":true}},{\"type\":\"text\",\"text\":\" - in that case the local identifier mapping result will indicate the error code: \"},{\"type\":\"text\",\"text\":\"PHPhotosErrorMultipleIdentifiersFound\",\"style\":{\"code\":true}}]}],\"style\":\"ordered\",\"indent\":0,\"border\":0}"
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "f304b49c-6f2b-4c0f-ae4e-fbdf19efc03a",
          "type": "message",
          "user": "U03J4BFE17W",
          "text": "Thanks!",
          "ts": "1654812252.884049",
          "thread_ts": "1654811695.156109",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "bIf=",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks!"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "cd181cc1-37de-4e0f-9bf7-7465a042badf",
          "type": "message",
          "user": "U03J8LCLQN7",
          "text": "... and you can get the set of potential matches for that cloud identifier via the error user info via the key: `PHLocalIdentifiersErrorKey`",
          "ts": "1654812275.557839",
          "thread_ts": "1654811695.156109",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "eyes",
              "count": 1,
              "users": [
                "U03J4BFE17W"
              ]
            },
            {
              "name": "white_check_mark",
              "count": 1,
              "users": [
                "U03J4BFE17W"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "S9T+",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "... and you can get the set of potential matches for that cloud identifier via the error user info via the key: "
                    },
                    {
                      "type": "text",
                      "text": "PHLocalIdentifiersErrorKey",
                      "style": {
                        "code": true
                      }
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03J4BFE17W\u003e asked\n\u0026gt; Is there a precalculated hash for a PHAsset to help check for duplicates? I've been using a Perceptual Hash of the image's thumbnail and having success, but was wondering if there was a better way.",
      "ts": "1654812057.939629",
      "thread_ts": "1654812057.939629",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 3,
      "latest_reply": "1654812267.903759",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "Wv01C",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03J4BFE17W"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Is there a precalculated hash for a PHAsset to help check for duplicates? I've been using a Perceptual Hash of the image's thumbnail and having success, but was wondering if there was a better way.\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "11116903-6b2f-44ce-8f69-a72590f6365d",
          "type": "message",
          "user": "U03HBH4EAR4",
          "text": "There is not any sort of API around a pre-calculated hash for a given PHAsset. A perceptual hash of the thumbnail is a reasonable approach. Combining that with metadata information and asset resource information would be a good way of checking for duplicates across the library.",
          "ts": "1654812138.962819",
          "thread_ts": "1654812057.939629",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "6QxNE",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "There is not any sort of API around a pre-calculated hash for a given PHAsset. A perceptual hash of the thumbnail is a reasonable approach. Combining that with metadata information and asset resource information would be a good way of checking for duplicates across the library."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "fa37a509-c648-4c9d-b577-621c6e7cac1e",
          "type": "message",
          "user": "U03HMDFMVNK",
          "text": "Also check out VNGenerateImageFeaturePrintRequest in the Vision framework. It does something similar in concept to a perceptual hash.",
          "ts": "1654812223.364199",
          "thread_ts": "1654812057.939629",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "star-struck",
              "count": 1,
              "users": [
                "U03HBH4EAR4"
              ]
            },
            {
              "name": "heart",
              "count": 1,
              "users": [
                "U03HU4PCSET"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "dX5Ng",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Also check out VNGenerateImageFeaturePrintRequest in the Vision framework. It does something similar in concept to a perceptual hash."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "86e91fe4-4443-4de0-860d-841a0692cbcd",
          "type": "message",
          "user": "U03J4BFE17W",
          "text": "Thanks!!",
          "ts": "1654812267.903759",
          "thread_ts": "1654812057.939629",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "QZfq",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks!!"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03HMDFMVNK\u003e asked\n\u0026gt; I've found that if I request an image thumbnail using PHImageManager passing the .original option for the imageVersion, then if that asset hasn't had its original image downloaded from iCloud yet, it returns an error. The only workaround I've found is to manually request the original photo resource via PHAssetResourceManager and create the thumbnail myself. Is there any way to force PHImageManager to download the asset so it can create the thumbnail in this case, or is the current behavior how it's intended to work?",
      "ts": "1654812116.596909",
      "thread_ts": "1654812116.596909",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 8,
      "latest_reply": "1654812452.604939",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "2ESzd",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03HMDFMVNK"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"I've found that if I request an image thumbnail using PHImageManager passing the .original option for the imageVersion, then if that asset hasn't had its original image downloaded from iCloud yet, it returns an error. The only workaround I've found is to manually request the original photo resource via PHAssetResourceManager and create the thumbnail myself. Is there any way to force PHImageManager to download the asset so it can create the thumbnail in this case, or is the current behavior how it's intended to work?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "59018596-ae7a-42bc-84ab-df926f4dd683",
          "type": "message",
          "user": "U03HU4PD371",
          "text": "Do you have `networkAccessAllowed`  set in the request options?",
          "ts": "1654812182.525689",
          "thread_ts": "1654812116.596909",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "UiXo",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Do you have "
                    },
                    {
                      "type": "text",
                      "text": "networkAccessAllowed",
                      "style": {
                        "code": true
                      }
                    },
                    {
                      "type": "text",
                      "text": "  set in the request options?"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "f32bdd68-e276-4d47-baaf-df2ea790c494",
          "type": "message",
          "user": "U03HMDFMVNK",
          "text": "Yes",
          "ts": "1654812231.516279",
          "thread_ts": "1654812116.596909",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "uxa",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Yes"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "da5b9a5f-5a82-4edc-8d60-773beff963b9",
          "type": "message",
          "user": "U03HU4PD371",
          "text": "also - in your case do you specifically need the original file?  if your goal is to get a thumbnail, usually 'current' is better and more efficient",
          "ts": "1654812236.184939",
          "thread_ts": "1654812116.596909",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "cAN1d",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "also - in your case do you specifically need the original file?  if your goal is to get a thumbnail, usually 'current' is better and more efficient"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "fc59284a-c219-4a94-a834-cd5d36c388d6",
          "type": "message",
          "user": "U03HU4PD371",
          "text": "I would not expect an error to be returned in the case you describe -- if you have a case that repro's, pls file a feedback and we can look further.",
          "ts": "1654812294.935029",
          "thread_ts": "1654812116.596909",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "rci6L",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I would not expect an error to be returned in the case you describe -- if you have a case that repro's, pls file a feedback and we can look further."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "21802e5c-d939-47ab-811a-d65faaf5b1d7",
          "type": "message",
          "user": "U03HMDFMVNK",
          "text": "Yes, in my case I’m displaying a preview of what something will look like when I copy a photo elsewhere, and I have an option in my UI to copy the unmodified original instead of the current one, so I’d want to show a thumbnail reflecting the version that’s going to be copied.",
          "ts": "1654812343.174029",
          "thread_ts": "1654812116.596909",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "1Bv",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Yes, in my case I’m displaying a preview of what something will look like when I copy a photo elsewhere, and I have an option in my UI to copy the unmodified original instead of the current one, so I’d want to show a thumbnail reflecting the version that’s going to be copied."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "85ae2e9e-d753-466d-a0c3-e867a3b4fb31",
          "type": "message",
          "user": "U03HMDFMVNK",
          "text": "To be honest I encountered this one a while back and haven’t checked on more recent versions of macOS, so I’ll check the behavior again to see if it’s changed. Just seemed like odd behavior and wanted to check to make sure I wasn’t missing anything.",
          "ts": "1654812388.934599",
          "thread_ts": "1654812116.596909",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "5b1/U",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "To be honest I encountered this one a while back and haven’t checked on more recent versions of macOS, so I’ll check the behavior again to see if it’s changed. Just seemed like odd behavior and wanted to check to make sure I wasn’t missing anything."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "08cd64d3-2a79-431d-990f-830e681415c5",
          "type": "message",
          "user": "U03HU4PD371",
          "text": "I see - yes in the case of an adjusted asset that makes sense.  If the asset is not adjusted you'll get better performance using 'current'.",
          "ts": "1654812407.177069",
          "thread_ts": "1654812116.596909",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "+=VR",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "I see - yes in the case of an adjusted asset that makes sense.  If the asset is not adjusted you'll get better performance using 'current'."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "c9d56f4b-ce24-44e6-b769-844c28a31dd8",
          "type": "message",
          "user": "U03HU4PD371",
          "text": "Odd indeed - pls include all the options you're using to set up the request, and all the logs/error details you're getting, as well as a sample asset that produces the issue.",
          "ts": "1654812452.604939",
          "thread_ts": "1654812116.596909",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U03HMDFMVNK"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "LMW",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Odd indeed - pls include all the options you're using to set up the request, and all the logs/error details you're getting, as well as a sample asset that produces the issue."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "07a9b981-b4a9-4bee-a8cf-23f610d1aab6",
      "type": "message",
      "user": "U03DJTBMHFF",
      "text": "\u003c!here\u003e *That's a wrap… sort of!* Thank you for all the great questions over the past hour. The Photos engineering team will begin peeling off to tend to other things, but they'll be checking back periodically throughout the rest of the day, night, and week. So… we're going to keep the workflows active. Don't hesitate to drop new questions anytime.",
      "ts": "1654812124.770169",
      "team": "T031SG5MZ7U",
      "reactions": [
        {
          "name": "raised_hands",
          "count": 7,
          "users": [
            "U03JMC610GH",
            "U03J20RJQ2X",
            "U03J4BFE17W",
            "U03HMDFMVNK",
            "U03J4CVE1U4",
            "U03J8LCLQN7",
            "U03JRSAP7U0"
          ]
        },
        {
          "name": "+1",
          "count": 2,
          "users": [
            "U03HVDWU0ES",
            "U03J4CVE1U4"
          ]
        },
        {
          "name": "cool",
          "count": 2,
          "users": [
            "U03J4BFE17W",
            "U03J24JKNCW"
          ]
        },
        {
          "name": "fire",
          "count": 3,
          "users": [
            "U03J4BFE17W",
            "U03J24JKNCW",
            "U03J4CVE1U4"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "LBJ",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "broadcast",
                  "range": "here"
                },
                {
                  "type": "text",
                  "text": " "
                },
                {
                  "type": "text",
                  "text": "That's a wrap… sort of!",
                  "style": {
                    "bold": true
                  }
                },
                {
                  "type": "text",
                  "text": " Thank you for all the great questions over the past hour. The Photos engineering team will begin peeling off to tend to other things, but they'll be checking back periodically throughout the rest of the day, night, and week. So… we're going to keep the workflows active. Don't hesitate to drop new questions anytime."
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "6de1c5b8-e3eb-452c-8319-b0487ae2275a",
      "type": "message",
      "user": "U03HBH4EAR4",
      "text": "Thank you for all the questions so far! The Photos team is always excited to see the amazing apps you all build on top of PhotoKit :grinning_face_with_star_eyes:",
      "ts": "1654812365.117339",
      "team": "T031SG5MZ7U",
      "reactions": [
        {
          "name": "heart",
          "count": 2,
          "users": [
            "U03J4CVE1U4",
            "U03HMCT187R"
          ]
        },
        {
          "name": "fire",
          "count": 1,
          "users": [
            "U03JMC610GH"
          ]
        },
        {
          "name": "100",
          "count": 1,
          "users": [
            "U03JMC610GH"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "nMuP",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "text",
                  "text": "Thank you for all the questions so far! The Photos team is always excited to see the amazing apps you all build on top of PhotoKit "
                },
                {
                  "type": "emoji",
                  "name": "grinning_face_with_star_eyes",
                  "skin_tone": 0
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03J4CVE1U4\u003e asked\n\u0026gt; Is there a way manually create depth data for existing images? I'm looking to build something where I can basically \"paint in\" the depth information into images that are maybe not shot on iPhone.",
      "ts": "1654812878.748649",
      "thread_ts": "1654812878.748649",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 6,
      "latest_reply": "1654886333.060519",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "9LWd",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03J4CVE1U4"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Is there a way manually create depth data for existing images? I'm looking to build something where I can basically \\\"paint in\\\" the depth information into images that are maybe not shot on iPhone.\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "f7d88109-4f22-4e31-9714-f3013ba4fa37",
          "type": "message",
          "user": "U03HBH4EAR4",
          "text": "Not sure if we have the appropriate people here right now, but I will reach out. From the photokit perspective the data would need to be in the original image, so a new PHAsset would have to be created with the appropriate depth information in the original image. I’ll leave it up to the camera folks to chime in on the depth creation part.",
          "ts": "1654813015.672809",
          "thread_ts": "1654812878.748649",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "bBN",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Not sure if we have the appropriate people here right now, but I will reach out. From the photokit perspective the data would need to be in the original image, so a new PHAsset would have to be created with the appropriate depth information in the original image. I’ll leave it up to the camera folks to chime in on the depth creation part."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "9e0ccde6-4efd-41b3-837a-9b6b1b26ec7b",
          "type": "message",
          "user": "U03J1U4Q77D",
          "text": "Check out Vision’s segmentation API: \u003chttps://betterprogramming.pub/new-in-ios-15-vision-person-segmentation-5c031a2f3822\u003e",
          "ts": "1654813243.275149",
          "thread_ts": "1654812878.748649",
          "attachments": [
            {
              "fallback": "Medium: New in iOS 15: Vision Person Segmentation",
              "id": 1,
              "title": "New in iOS 15: Vision Person Segmentation",
              "title_link": "https://betterprogramming.pub/new-in-ios-15-vision-person-segmentation-5c031a2f3822",
              "text": "Separate people from backgrounds in images and videos",
              "image_url": "https://miro.medium.com/max/1200/1*KIJPtVMpLdMQ3qJGx_bNFw.png",
              "service_name": "Medium",
              "service_icon": "https://miro.medium.com/fit/c/152/152/1*sHhtYhaCe2Uc3IU0IgKwIQ.png",
              "from_url": "https://betterprogramming.pub/new-in-ios-15-vision-person-segmentation-5c031a2f3822",
              "original_url": "https://betterprogramming.pub/new-in-ios-15-vision-person-segmentation-5c031a2f3822",
              "fields": [
                {
                  "title": "Reading time",
                  "value": "4 min read",
                  "short": true
                }
              ],
              "blocks": null,
              "ts": 1625064465
            }
          ],
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "6n05",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Check out Vision’s segmentation API: "
                    },
                    {
                      "type": "link",
                      "url": "https://betterprogramming.pub/new-in-ios-15-vision-person-segmentation-5c031a2f3822",
                      "text": ""
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "800f8c15-567e-41f2-ade4-e0941f896dbb",
          "type": "message",
          "user": "U03J20RJQ2X",
          "text": "This sounds similar to what the Focos app does",
          "ts": "1654816527.758449",
          "thread_ts": "1654812878.748649",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "waT",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "This sounds similar to what the Focos app does"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "0d371e8f-8e9c-4b65-9c21-3d4d37d436f0",
          "type": "message",
          "user": "U03J4CVE1U4",
          "text": "Cool, I'll check out all your suggestions. Thanks everyone! :raised_hands:",
          "ts": "1654816602.110599",
          "thread_ts": "1654812878.748649",
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "raised_hands",
              "count": 1,
              "users": [
                "U03JMC610GH"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "iAf1",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Cool, I'll check out all your suggestions. Thanks everyone! "
                    },
                    {
                      "type": "emoji",
                      "name": "raised_hands",
                      "skin_tone": 0
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "8d87050d-447a-453b-81b0-28f75d986bbb",
          "type": "message",
          "user": "U03DJTBMHFF",
          "text": "There are some other machine-learning models out there that estimate depth based solely on an image. One of them, *FCRN-DepthPrediction*, is available as a Core ML model in our model gallery. \u003chttps://developer.apple.com/machine-learning/models/\u003e\n\nUsing a model like this along with the Vision framework you may be able to achieve exactly what you're looking for.",
          "ts": "1654871621.868319",
          "thread_ts": "1654812878.748649",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "ziiV",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "There are some other machine-learning models out there that estimate depth based solely on an image. One of them, "
                    },
                    {
                      "type": "text",
                      "text": "FCRN-DepthPrediction",
                      "style": {
                        "bold": true
                      }
                    },
                    {
                      "type": "text",
                      "text": ", is available as a Core ML model in our model gallery. "
                    },
                    {
                      "type": "link",
                      "url": "https://developer.apple.com/machine-learning/models/",
                      "text": ""
                    },
                    {
                      "type": "text",
                      "text": "\n\nUsing a model like this along with the Vision framework you may be able to achieve exactly what you're looking for."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "BE5A35E3-A424-4BE4-BDF2-FB0F69DF9A0F",
          "type": "message",
          "user": "U03JLRZJHQR",
          "text": "Monocular depth estimation is super cool, the best results I've gotten are with the model “MiDaS”. I was able to convert it to coreml using CoreML tools and use it in my Swift Student Challenge submission (with some quantizing to reduce the size). They also have a newer transformer model, which I haven't been able to convert to CoreML using the builtin tools, but I'd like to try again in the future.",
          "ts": "1654886333.060519",
          "thread_ts": "1654812878.748649",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "GiQAC",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "M"
                    },
                    {
                      "type": "text",
                      "text": "onocular"
                    },
                    {
                      "type": "text",
                      "text": " depth "
                    },
                    {
                      "type": "text",
                      "text": "estimation"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "is"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "super"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "cool,"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "the"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "best"
                    },
                    {
                      "type": "text",
                      "text": " results I've "
                    },
                    {
                      "type": "text",
                      "text": "gotten"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "are"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "with"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "the"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "model"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "“MiDaS”."
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "I"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "was"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "able"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "to"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "convert"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "it"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "to"
                    },
                    {
                      "type": "text",
                      "text": " cor"
                    },
                    {
                      "type": "text",
                      "text": "eml"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "using"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "CoreML"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "tools"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "and"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "use"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "it"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "in"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "my"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "Swift"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "Student"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "Challenge"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "submission"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "(with"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "some"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "quantizing"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "to"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "reduce"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "the"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "size). They"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "also"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "have"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "a"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "newer"
                    },
                    {
                      "type": "text",
                      "text": " transformer "
                    },
                    {
                      "type": "text",
                      "text": "model,"
                    },
                    {
                      "type": "text",
                      "text": " which I haven't "
                    },
                    {
                      "type": "text",
                      "text": "been"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "able"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "to"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "convert"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "to"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "CoreML"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "using"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "the"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "builtin"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "tools,"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "but"
                    },
                    {
                      "type": "text",
                      "text": " I'd "
                    },
                    {
                      "type": "text",
                      "text": "like"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "to"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "try"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "again"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "in"
                    },
                    {
                      "type": "text",
                      "text": " "
                    },
                    {
                      "type": "text",
                      "text": "the"
                    },
                    {
                      "type": "text",
                      "text": " future"
                    },
                    {
                      "type": "text",
                      "text": "."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03JRSAP7U0\u003e asked\n\u0026gt; In the new iCloud Shared Album (w your family), will photos shared to you be located on the your Camera Roll (`smartAlbum/smartAlbumUserLibrary`)?\n\u0026gt; Follow up: will all of those photos be locally available in all devices of the family or will they be “iCloud dehydrated” and the user or an app needs to do an explicit download?",
      "ts": "1654813140.540059",
      "thread_ts": "1654813140.540059",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 2,
      "latest_reply": "1654813321.553429",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "8Pbm",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03JRSAP7U0"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"In the new iCloud Shared Album (w your family), will photos shared to you be located on the your Camera Roll (`smartAlbum\\/smartAlbumUserLibrary`)?\\nFollow up: will all of those photos be locally available in all devices of the family or will they be \\u201ciCloud dehydrated\\u201d and the user or an app needs to do an explicit download?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "925b417c-0ff4-40b9-baf1-8a854595eae9",
          "type": "message",
          "user": "U03J5R8VAPP",
          "text": "Yes! From a PhotoKit API POV, all Shared assets that are inserted via the iCloud Shared Photo Library feature would appear as normal assets and would be shown in all the usual places (Photos tab, For You tab, Albums tab) and be available through all the usual fetches",
          "ts": "1654813262.890539",
          "thread_ts": "1654813140.540059",
          "edited": {
            "user": "U03J5R8VAPP",
            "ts": "1654813553.000000"
          },
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U03JRSAP7U0"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "E36kd",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Yes! From a PhotoKit API POV, all Shared assets that are inserted via the iCloud Shared Photo Library feature would appear as normal assets and would be shown in all the usual places (Photos tab, For You tab, Albums tab) and be available through all the usual fetches"
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "9a70b82a-c25b-48eb-b87d-1e3a1fe83269",
          "type": "message",
          "user": "U03J5R8VAPP",
          "text": "Bonus followup question: The same per-device policy applies here based on what they have setup in Settings \u0026gt; Photos \u0026gt; [Optimize Storage OR Download and Keep Originals] on that device.",
          "ts": "1654813321.553429",
          "thread_ts": "1654813140.540059",
          "edited": {
            "user": "U03J5R8VAPP",
            "ts": "1654813359.000000"
          },
          "team": "T031SG5MZ7U",
          "reactions": [
            {
              "name": "+1",
              "count": 1,
              "users": [
                "U03JRSAP7U0"
              ]
            }
          ],
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "hvaA",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Bonus followup question: The same per-device policy applies here based on what they have setup in Settings \u003e Photos \u003e [Optimize Storage OR Download and Keep Originals] on that device."
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "type": "message",
      "text": "\u003c@U03JEEU1MF1\u003e asked\n\u0026gt; Are there any APIs for editing videos shot in Cinematic mode?",
      "ts": "1654886517.917899",
      "thread_ts": "1654886517.917899",
      "subtype": "bot_message",
      "bot_id": "B03J03EENBE",
      "username": "Photos and Camera - Ask a Question",
      "reply_count": 3,
      "latest_reply": "1654891406.199609",
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "KmS",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "user",
                  "user_id": "U03JEEU1MF1"
                },
                {
                  "type": "text",
                  "text": " asked\n"
                }
              ]
            },
            {
              "Type": "rich_text_quote",
              "Raw": "{\"type\":\"rich_text_quote\",\"elements\":[{\"type\":\"text\",\"text\":\"Are there any APIs for editing videos shot in Cinematic mode?\"}]}"
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "902483a3-a7f6-4f16-b011-c78283924f95",
          "type": "message",
          "user": "U03JYFCQY5N",
          "text": "There are not any at this point for editing the cinematic-ness of the video, but the video can be edited in the same way that any other video can be edited.",
          "ts": "1654886563.591509",
          "thread_ts": "1654886517.917899",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "C=8d",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "There are not any at this point for editing the cinematic-ness of the video, but the video can be edited in the same way that any other video can be edited."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "e80da7d9-c23f-4c14-82d9-091cebb224c9",
          "type": "message",
          "user": "U03JEEU1MF1",
          "text": "Thanks for the reply! I know you can't comment on future plans but I hope to see this feature in the future.",
          "ts": "1654890241.246449",
          "thread_ts": "1654886517.917899",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "uWpC",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks for the reply! I know you can't comment on future plans but I hope to see this feature in the future."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "client_msg_id": "d944e95f-ed93-4959-834c-38b6bf33fa02",
          "type": "message",
          "user": "U03JYFCQY5N",
          "text": "Thanks for the feedback and interest!",
          "ts": "1654891406.199609",
          "thread_ts": "1654886517.917899",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "pmIJK",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thanks for the feedback and interest!"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "client_msg_id": "55372abb-8d7e-4d80-8397-4ea51f13d7f9",
      "type": "message",
      "user": "U03DF5L7S30",
      "text": ":wave:  Thank you so much for joining in the Photos and Camera Digital Lounge! We hope you enjoyed the space as much as we did! :star-struck: Before you head out: *\u003chttps://essentials.applesurveys.com/jfe/form/SV_2cw6N3JbrxFcoiq|Our WWDC22 Developer Survey is now live\u003e*! It would mean SO much to us if you could take a few moments — 5 minutes, max — and let us know what you loved about WWDC22 and what we could make better for you. Your feedback has major impact on the programs and events we host for developers, and we’re excited to hear from you.\n\nFor just a bit of fun, I’m going to open up threads :thread: for a while. Let us know here what you thought!",
      "ts": "1654901229.979159",
      "thread_ts": "1654901229.979159",
      "pinned_to": [
        "C03HHECB9JB"
      ],
      "reply_count": 1,
      "latest_reply": "1654909111.606019",
      "team": "T031SG5MZ7U",
      "reactions": [
        {
          "name": "wwdc22",
          "count": 1,
          "users": [
            "U03JRP87THN"
          ]
        },
        {
          "name": "gratitude-thank-you",
          "count": 1,
          "users": [
            "U03JRP87THN"
          ]
        },
        {
          "name": "clap",
          "count": 2,
          "users": [
            "U03JRP87THN",
            "U03HVD5TM7G"
          ]
        }
      ],
      "replace_original": false,
      "delete_original": false,
      "blocks": [
        {
          "type": "rich_text",
          "block_id": "vr0",
          "elements": [
            {
              "type": "rich_text_section",
              "elements": [
                {
                  "type": "emoji",
                  "name": "wave",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": "  Thank you so much for joining in the Photos and Camera Digital Lounge! We hope you enjoyed the space as much as we did! "
                },
                {
                  "type": "emoji",
                  "name": "star-struck",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": " Before you head out: "
                },
                {
                  "type": "link",
                  "url": "https://essentials.applesurveys.com/jfe/form/SV_2cw6N3JbrxFcoiq",
                  "text": "Our WWDC22 Developer Survey is now live",
                  "style": {
                    "bold": true
                  }
                },
                {
                  "type": "text",
                  "text": "! It would mean SO much to us if you could take a few moments — 5 minutes, max — and let us know what you loved about WWDC22 and what we could make better for you. Your feedback has major impact on the programs and events we host for developers, and we’re excited to hear from you.\n\nFor just a bit of fun, I’m going to open up threads "
                },
                {
                  "type": "emoji",
                  "name": "thread",
                  "skin_tone": 0
                },
                {
                  "type": "text",
                  "text": " for a while. Let us know here what you thought!"
                }
              ]
            }
          ]
        }
      ],
      "slackdump_thread_replies": [
        {
          "client_msg_id": "E201FE71-B710-4DDE-BEA3-18C6340D9ED5",
          "type": "message",
          "user": "U03JBMMB10A",
          "text": "Thank you for all your work and a great WWDC!",
          "ts": "1654909111.606019",
          "thread_ts": "1654901229.979159",
          "parent_user_id": "U03DF5L7S30",
          "team": "T031SG5MZ7U",
          "replace_original": false,
          "delete_original": false,
          "blocks": [
            {
              "type": "rich_text",
              "block_id": "pBkq",
              "elements": [
                {
                  "type": "rich_text_section",
                  "elements": [
                    {
                      "type": "text",
                      "text": "Thank you for all your work and a great WWDC!"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    }
  ],
  "channel_id": "C03HHECB9JB"
}
